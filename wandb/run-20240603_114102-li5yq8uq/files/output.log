Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making Datasets...
Making Dataloaders...
Defining network...
5/5: Training network...
[1/1, 10/938] Training Loss: 1.07121399641037
[1/1, 20/938] Training Loss: 1.0369687616825103
[1/1, 30/938] Training Loss: 1.0333403885364532
[1/1, 40/938] Training Loss: 1.0141785562038421
[1/1, 50/938] Training Loss: 0.9643324494361878
[1/1, 60/938] Training Loss: 0.9883775591850281
[1/1, 70/938] Training Loss: 0.9338561117649078
[1/1, 80/938] Training Loss: 0.9476238906383514
[1/1, 90/938] Training Loss: 0.9337220132350922
[1/1, 100/938] Training Loss: 0.93568314909935
[1/1, 110/938] Training Loss: 0.9052875399589538
[1/1, 120/938] Training Loss: 0.8842587292194366
[1/1, 130/938] Training Loss: 0.900249844789505
[1/1, 140/938] Training Loss: 0.8845265865325928
[1/1, 150/938] Training Loss: 0.880464243888855
[1/1, 160/938] Training Loss: 0.8470785677433014
[1/1, 170/938] Training Loss: 0.8307802975177765
[1/1, 180/938] Training Loss: 0.86668381690979
[1/1, 190/938] Training Loss: 0.8245330691337586
[1/1, 200/938] Training Loss: 0.8574039340019226
[1/1, 210/938] Training Loss: 0.8437261939048767
[1/1, 220/938] Training Loss: 0.7961423993110657
[1/1, 230/938] Training Loss: 0.7628312110900879
[1/1, 240/938] Training Loss: 0.7679908633232116
[1/1, 250/938] Training Loss: 0.7641157329082489
[1/1, 260/938] Training Loss: 0.7546307861804962
[1/1, 270/938] Training Loss: 0.7424643456935882
[1/1, 280/938] Training Loss: 0.7491696953773499
[1/1, 290/938] Training Loss: 0.7532852351665497
[1/1, 300/938] Training Loss: 0.7339432895183563
[1/1, 310/938] Training Loss: 0.7296351790428162
[1/1, 320/938] Training Loss: 0.7137564122676849
[1/1, 330/938] Training Loss: 0.6925999879837036
[1/1, 340/938] Training Loss: 0.7006991922855377
[1/1, 350/938] Training Loss: 0.6798196077346802
[1/1, 360/938] Training Loss: 0.6777283549308777
[1/1, 370/938] Training Loss: 0.6652028918266296
[1/1, 380/938] Training Loss: 0.6597790062427521
[1/1, 390/938] Training Loss: 0.6468248724937439
[1/1, 400/938] Training Loss: 0.6217135608196258
[1/1, 410/938] Training Loss: 0.6317407608032226
[1/1, 420/938] Training Loss: 0.5996719360351562
[1/1, 430/938] Training Loss: 0.6097547888755799
[1/1, 440/938] Training Loss: 0.5817206978797913
[1/1, 450/938] Training Loss: 0.5635765999555588
[1/1, 460/938] Training Loss: 0.5609507024288177
[1/1, 470/938] Training Loss: 0.546034774184227
[1/1, 480/938] Training Loss: 0.541970407962799
[1/1, 490/938] Training Loss: 0.5230786323547363
[1/1, 500/938] Training Loss: 0.5148668795824051
[1/1, 510/938] Training Loss: 0.4990487933158875
[1/1, 520/938] Training Loss: 0.48736812472343444
[1/1, 530/938] Training Loss: 0.4880921930074692
[1/1, 540/938] Training Loss: 0.4963992923498154
[1/1, 550/938] Training Loss: 0.47939239740371703
[1/1, 560/938] Training Loss: 0.4904307097196579
[1/1, 570/938] Training Loss: 0.4850163787603378
[1/1, 580/938] Training Loss: 0.46336556375026705
[1/1, 590/938] Training Loss: 0.4761234998703003
[1/1, 600/938] Training Loss: 0.46823698580265044
[1/1, 610/938] Training Loss: 0.4596328228712082
[1/1, 620/938] Training Loss: 0.4604521095752716
[1/1, 630/938] Training Loss: 0.45627316534519197
[1/1, 640/938] Training Loss: 0.44545103907585143
[1/1, 650/938] Training Loss: 0.4491588532924652
[1/1, 660/938] Training Loss: 0.4446903496980667
[1/1, 670/938] Training Loss: 0.43333859741687775
[1/1, 680/938] Training Loss: 0.42574226260185244
[1/1, 690/938] Training Loss: 0.4076663821935654
[1/1, 700/938] Training Loss: 0.42754541635513305
[1/1, 710/938] Training Loss: 0.41385078728199004
[1/1, 720/938] Training Loss: 0.4172458529472351
[1/1, 730/938] Training Loss: 0.39879605174064636
[1/1, 740/938] Training Loss: 0.40595701038837434
[1/1, 750/938] Training Loss: 0.3996798902750015
[1/1, 760/938] Training Loss: 0.40108256638050077
[1/1, 770/938] Training Loss: 0.400553759932518
[1/1, 780/938] Training Loss: 0.4119335263967514
[1/1, 790/938] Training Loss: 0.3880899727344513
[1/1, 800/938] Training Loss: 0.3926114410161972
[1/1, 810/938] Training Loss: 0.40212036669254303
[1/1, 820/938] Training Loss: 0.3822260558605194
[1/1, 830/938] Training Loss: 0.3859579384326935
[1/1, 840/938] Training Loss: 0.38122587502002714
[1/1, 850/938] Training Loss: 0.37336801290512084
[1/1, 860/938] Training Loss: 0.38440080881118777
[1/1, 870/938] Training Loss: 0.3499502092599869
[1/1, 880/938] Training Loss: 0.3673023670911789
[1/1, 890/938] Training Loss: 0.3578122198581696
[1/1, 900/938] Training Loss: 0.3597999602556229
[1/1, 910/938] Training Loss: 0.35275169610977175
[1/1, 920/938] Training Loss: 0.34127227365970614
[1/1, 930/938] Training Loss: 0.33729823529720304
5/5: Testing network...
Testing: 1/157
Testing: 2/157
Testing: 3/157
Testing: 4/157
Testing: 5/157
Testing: 6/157
Testing: 7/157
Testing: 8/157
Testing: 9/157
Testing: 10/157
Testing: 11/157
Testing: 12/157
Testing: 13/157
Testing: 14/157
Testing: 15/157
Testing: 16/157
Testing: 17/157
Testing: 18/157
Testing: 19/157
Testing: 20/157
Testing: 21/157
Testing: 22/157
Testing: 23/157
Testing: 24/157
Testing: 25/157
Testing: 26/157
Testing: 27/157
Testing: 28/157
Testing: 29/157
Testing: 30/157
Testing: 31/157
Testing: 32/157
Testing: 33/157
Testing: 34/157
Testing: 35/157
Testing: 36/157
Testing: 37/157
Testing: 38/157
Testing: 39/157
Testing: 40/157
Testing: 41/157
Testing: 42/157
Testing: 43/157
Testing: 44/157
Testing: 45/157
Testing: 46/157
Testing: 47/157
Testing: 48/157
Testing: 49/157
Testing: 50/157
Testing: 51/157
Testing: 52/157
Testing: 53/157
Testing: 54/157
Testing: 55/157
Testing: 56/157
Testing: 57/157
Testing: 58/157
Testing: 59/157
Testing: 60/157
Testing: 61/157
Testing: 62/157
Testing: 63/157
Testing: 64/157
Testing: 65/157
Testing: 66/157
Testing: 67/157
Testing: 68/157
Testing: 69/157
Testing: 70/157
Testing: 71/157
Testing: 72/157
Testing: 73/157
Testing: 74/157
Testing: 75/157
Testing: 76/157
Testing: 77/157
Testing: 78/157
Testing: 79/157
Testing: 80/157
Testing: 81/157
Testing: 82/157
Testing: 83/157
Testing: 84/157
Testing: 85/157
Testing: 86/157
Testing: 87/157
Testing: 88/157
Testing: 89/157
Testing: 90/157
Testing: 91/157
Testing: 92/157
Testing: 93/157
Testing: 94/157
Testing: 95/157
Testing: 96/157
Testing: 97/157
Testing: 98/157
Testing: 99/157
Testing: 100/157
Testing: 101/157
Testing: 102/157
Testing: 103/157
Testing: 104/157
Testing: 105/157
Testing: 106/157
Testing: 107/157
Testing: 108/157
Testing: 109/157
Testing: 110/157
Testing: 111/157
Testing: 112/157
Testing: 113/157
Testing: 114/157
Testing: 115/157
Testing: 116/157
Testing: 117/157
Testing: 118/157
Testing: 119/157
Testing: 120/157
Testing: 121/157
Testing: 122/157
Testing: 123/157
Testing: 124/157
Testing: 125/157
Testing: 126/157
Testing: 127/157
Testing: 128/157
Testing: 129/157
Testing: 130/157
Testing: 131/157
Testing: 132/157
Testing: 133/157
Testing: 134/157
Testing: 135/157
Testing: 136/157
Testing: 137/157
Testing: 138/157
Testing: 139/157
Testing: 140/157
Testing: 141/157
Testing: 142/157
Testing: 143/157
Testing: 144/157
Testing: 145/157
Testing: 146/157
Testing: 147/157
Testing: 148/157
Testing: 149/157
Testing: 150/157
Testing: 151/157
Testing: 152/157
Testing: 153/157
Testing: 154/157
Testing: 155/157
Testing: 156/157
Testing: 157/157
Testing Loss: 0.34471122225125633
Training and Testing Finished
Assembling test data for t-sne projection
Batch: 1/157
Batch: 2/157
Batch: 3/157
Batch: 4/157
Batch: 5/157
Batch: 6/157
Batch: 7/157
Batch: 8/157
Batch: 9/157
Batch: 10/157
Batch: 11/157
Batch: 12/157
Batch: 13/157
Batch: 14/157
Batch: 15/157
Batch: 16/157
Batch: 17/157
Batch: 18/157
Batch: 19/157
Batch: 20/157
Batch: 21/157
Batch: 22/157
Batch: 23/157
Batch: 24/157
Batch: 25/157
Batch: 26/157
Batch: 27/157
Batch: 28/157
Batch: 29/157
Batch: 30/157
Batch: 31/157
Batch: 32/157
Batch: 33/157
Batch: 34/157
Batch: 35/157
Batch: 36/157
Batch: 37/157
Batch: 38/157
Batch: 39/157
Batch: 40/157
Batch: 41/157
Batch: 42/157
Batch: 43/157
Batch: 44/157
Batch: 45/157
Batch: 46/157
Batch: 47/157
Batch: 48/157
Batch: 49/157
Batch: 50/157
Batch: 51/157
Batch: 52/157
Batch: 53/157
Batch: 54/157
Batch: 55/157
Batch: 56/157
Batch: 57/157
Batch: 58/157
Batch: 59/157
Batch: 60/157
Batch: 61/157
Batch: 62/157
Batch: 63/157
Batch: 64/157
Batch: 65/157
Batch: 66/157
Batch: 67/157
Batch: 68/157
Batch: 69/157
Batch: 70/157
Batch: 71/157
Batch: 72/157
Batch: 73/157
Batch: 74/157
Batch: 75/157
Batch: 76/157
Batch: 77/157
Batch: 78/157
Batch: 79/157
Batch: 80/157
Batch: 81/157
Batch: 82/157
Batch: 83/157
Batch: 84/157
Batch: 85/157
Batch: 86/157
Batch: 87/157
Batch: 88/157
Batch: 89/157
Batch: 90/157
Batch: 91/157
Batch: 92/157
Batch: 93/157
Batch: 94/157
Batch: 95/157
Batch: 96/157
Batch: 97/157
Batch: 98/157
Batch: 99/157
Batch: 100/157
Batch: 101/157
Batch: 102/157
Batch: 103/157
Batch: 104/157
Batch: 105/157
Batch: 106/157
Batch: 107/157
Batch: 108/157
Batch: 109/157
Batch: 110/157
Batch: 111/157
Batch: 112/157
Batch: 113/157
Batch: 114/157
Batch: 115/157
Batch: 116/157
Batch: 117/157
Batch: 118/157
Batch: 119/157
Batch: 120/157
Batch: 121/157
Batch: 122/157
Batch: 123/157
Batch: 124/157
Batch: 125/157
Batch: 126/157
Batch: 127/157
Batch: 128/157
Batch: 129/157
Batch: 130/157
Batch: 131/157
Batch: 132/157
Batch: 133/157
Batch: 134/157
Batch: 135/157
Batch: 136/157
Batch: 137/157
Batch: 138/157
Batch: 139/157
Batch: 140/157
Batch: 141/157
Batch: 142/157
Batch: 143/157
Batch: 144/157
Batch: 145/157
Batch: 146/157
Batch: 147/157
Batch: 148/157
Batch: 149/157
Batch: 150/157
Batch: 151/157
Batch: 152/157
Batch: 153/157
Batch: 154/157
Batch: 155/157
Batch: 156/157
Batch: 157/157
Applying t-SNE
7 added
0 added
4 added
2 added
3 added
5 added
1 added
6 added
9 added
8 added