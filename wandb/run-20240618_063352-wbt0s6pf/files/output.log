Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 06:33:53.323799
Scaler Value: 0.1
Training - 2024-06-18 06:33:53.324791
[1/9, 10/94] Training Loss: 3.0693 - Iteration Time: 0:00:01.490383
[1/9, 20/94] Training Loss: 2.8506 - Iteration Time: 0:00:01.403573
[1/9, 30/94] Training Loss: 2.7374 - Iteration Time: 0:00:01.395171
[1/9, 40/94] Training Loss: 2.6748 - Iteration Time: 0:00:01.480458
[1/9, 50/94] Training Loss: 2.6212 - Iteration Time: 0:00:01.409076
[1/9, 60/94] Training Loss: 2.5783 - Iteration Time: 0:00:01.594599
[1/9, 70/94] Training Loss: 2.5436 - Iteration Time: 0:00:01.397598
[1/9, 80/94] Training Loss: 2.5138 - Iteration Time: 0:00:01.428863
[1/9, 90/94] Training Loss: 2.4816 - Iteration Time: 0:00:01.400142
Testing - 2024-06-18 06:36:09.495456
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 2.4363 - Epoch Time: 0:02:29.455350
Training - 2024-06-18 06:36:22.780141
[2/9, 10/94] Training Loss: 2.4342 - Iteration Time: 0:00:01.398652
[2/9, 20/94] Training Loss: 2.3981 - Iteration Time: 0:00:01.423363
[2/9, 30/94] Training Loss: 2.3710 - Iteration Time: 0:00:01.399618
[2/9, 40/94] Training Loss: 2.3431 - Iteration Time: 0:00:01.396256
[2/9, 50/94] Training Loss: 2.3058 - Iteration Time: 0:00:01.463125
[2/9, 60/94] Training Loss: 2.2852 - Iteration Time: 0:00:01.415979
[2/9, 70/94] Training Loss: 2.2575 - Iteration Time: 0:00:01.565310
[2/9, 80/94] Training Loss: 2.2240 - Iteration Time: 0:00:01.422039
[2/9, 90/94] Training Loss: 2.1892 - Iteration Time: 0:00:01.390677
Testing - 2024-06-18 06:38:38.253105
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 2.1568 - Epoch Time: 0:02:28.906938
Training - 2024-06-18 06:38:51.687576
[3/9, 10/94] Training Loss: 2.1538 - Iteration Time: 0:00:01.404182
[3/9, 20/94] Training Loss: 2.1395 - Iteration Time: 0:00:01.429341
[3/9, 30/94] Training Loss: 2.1265 - Iteration Time: 0:00:01.438852
[3/9, 40/94] Training Loss: 2.1117 - Iteration Time: 0:00:01.444338
[3/9, 50/94] Training Loss: 2.0995 - Iteration Time: 0:00:01.413503
[3/9, 60/94] Training Loss: 2.0808 - Iteration Time: 0:00:01.452727
[3/9, 70/94] Training Loss: 2.0591 - Iteration Time: 0:00:01.427965
[3/9, 80/94] Training Loss: 2.0387 - Iteration Time: 0:00:01.417518
[3/9, 90/94] Training Loss: 2.0050 - Iteration Time: 0:00:01.511259
Testing - 2024-06-18 06:41:07.041765
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 1.9731 - Epoch Time: 0:02:28.750195
Training - 2024-06-18 06:41:20.437771
[4/9, 10/94] Training Loss: 1.9666 - Iteration Time: 0:00:01.578293
[4/9, 20/94] Training Loss: 1.9512 - Iteration Time: 0:00:01.534519
[4/9, 30/94] Training Loss: 1.9289 - Iteration Time: 0:00:01.508309
[4/9, 40/94] Training Loss: 1.9080 - Iteration Time: 0:00:01.409045
[4/9, 50/94] Training Loss: 1.8995 - Iteration Time: 0:00:01.407478
[4/9, 60/94] Training Loss: 1.8762 - Iteration Time: 0:00:01.386216
[4/9, 70/94] Training Loss: 1.8655 - Iteration Time: 0:00:01.402133
[4/9, 80/94] Training Loss: 1.8458 - Iteration Time: 0:00:01.421984
[4/9, 90/94] Training Loss: 1.8326 - Iteration Time: 0:00:01.419472
Testing - 2024-06-18 06:43:42.248878
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 1.8060 - Epoch Time: 0:02:35.115564
Training - 2024-06-18 06:43:55.553832
[5/9, 10/94] Training Loss: 1.7937 - Iteration Time: 0:00:01.393226
[5/9, 20/94] Training Loss: 1.7741 - Iteration Time: 0:00:01.406620
[5/9, 30/94] Training Loss: 1.7559 - Iteration Time: 0:00:01.429389
[5/9, 40/94] Training Loss: 1.7461 - Iteration Time: 0:00:01.389221
[5/9, 50/94] Training Loss: 1.7308 - Iteration Time: 0:00:01.407113
[5/9, 60/94] Training Loss: 1.7015 - Iteration Time: 0:00:01.423923
[5/9, 70/94] Training Loss: 1.6866 - Iteration Time: 0:00:01.416025
[5/9, 80/94] Training Loss: 1.6695 - Iteration Time: 0:00:01.433373
[5/9, 90/94] Training Loss: 1.6477 - Iteration Time: 0:00:01.418561
Testing - 2024-06-18 06:46:10.957415
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 1.6306 - Epoch Time: 0:02:28.683638
Training - 2024-06-18 06:46:24.237470
[6/9, 10/94] Training Loss: 1.6278 - Iteration Time: 0:00:01.402083
[6/9, 20/94] Training Loss: 1.6192 - Iteration Time: 0:00:01.396703
[6/9, 30/94] Training Loss: 1.6132 - Iteration Time: 0:00:01.432807
[6/9, 40/94] Training Loss: 1.6087 - Iteration Time: 0:00:01.392229
[6/9, 50/94] Training Loss: 1.5969 - Iteration Time: 0:00:01.426445
[6/9, 60/94] Training Loss: 1.5720 - Iteration Time: 0:00:01.509730
[6/9, 70/94] Training Loss: 1.5536 - Iteration Time: 0:00:01.421359
[6/9, 80/94] Training Loss: 1.5405 - Iteration Time: 0:00:01.428908
[6/9, 90/94] Training Loss: 1.5329 - Iteration Time: 0:00:01.410093
Testing - 2024-06-18 06:48:40.140743
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 1.5220 - Epoch Time: 0:02:28.965267
Training - 2024-06-18 06:48:53.202737
[7/9, 10/94] Training Loss: 1.5287 - Iteration Time: 0:00:01.416458
[7/9, 20/94] Training Loss: 1.5229 - Iteration Time: 0:00:01.430821
[7/9, 30/94] Training Loss: 1.5165 - Iteration Time: 0:00:01.424110
[7/9, 40/94] Training Loss: 1.5044 - Iteration Time: 0:00:01.406576
[7/9, 50/94] Training Loss: 1.4902 - Iteration Time: 0:00:01.411946
[7/9, 60/94] Training Loss: 1.4825 - Iteration Time: 0:00:01.404258
[7/9, 70/94] Training Loss: 1.4777 - Iteration Time: 0:00:01.494400
[7/9, 80/94] Training Loss: 1.4758 - Iteration Time: 0:00:01.437319
[7/9, 90/94] Training Loss: 1.4763 - Iteration Time: 0:00:01.459107
Testing - 2024-06-18 06:51:08.777830
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 1.4578 - Epoch Time: 0:02:28.862651
Training - 2024-06-18 06:51:22.065885
[8/9, 10/94] Training Loss: 1.4642 - Iteration Time: 0:00:01.426925
[8/9, 20/94] Training Loss: 1.4523 - Iteration Time: 0:00:01.405079
[8/9, 30/94] Training Loss: 1.4485 - Iteration Time: 0:00:01.407133
[8/9, 40/94] Training Loss: 1.4399 - Iteration Time: 0:00:01.420010
[8/9, 50/94] Training Loss: 1.4333 - Iteration Time: 0:00:01.381276
[8/9, 60/94] Training Loss: 1.4253 - Iteration Time: 0:00:01.390225
[8/9, 70/94] Training Loss: 1.4068 - Iteration Time: 0:00:01.482437
[8/9, 80/94] Training Loss: 1.3887 - Iteration Time: 0:00:01.505858
[8/9, 90/94] Training Loss: 1.3801 - Iteration Time: 0:00:01.419415
Testing - 2024-06-18 06:53:37.140047
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 1.3714 - Epoch Time: 0:02:28.410448
Training - 2024-06-18 06:53:50.476829
[9/9, 10/94] Training Loss: 1.3736 - Iteration Time: 0:00:01.429880
[9/9, 20/94] Training Loss: 1.3686 - Iteration Time: 0:00:01.460157
[9/9, 30/94] Training Loss: 1.3621 - Iteration Time: 0:00:01.465513
[9/9, 40/94] Training Loss: 1.3570 - Iteration Time: 0:00:01.408546
[9/9, 50/94] Training Loss: 1.3426 - Iteration Time: 0:00:01.437290
[9/9, 60/94] Training Loss: 1.3384 - Iteration Time: 0:00:01.421967
[9/9, 70/94] Training Loss: 1.3313 - Iteration Time: 0:00:01.407176
[9/9, 80/94] Training Loss: 1.3139 - Iteration Time: 0:00:01.403552
[9/9, 90/94] Training Loss: 1.2968 - Iteration Time: 0:00:01.489923
Testing - 2024-06-18 06:56:06.812003
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 1.2864 - Epoch Time: 0:02:29.722974
Training and Testing Finished - Time: 0:22:26.876500
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0    1      2      3    4  ...     94     95   96   97   98   99
0       2  0.0  0.0  0.280  0.420  0.0  ...  0.160  0.000  0.0  0.0  0.0  0.0
1       4  0.0  0.0  0.235  0.400  0.0  ...  0.140  0.000  0.0  0.0  0.0  0.0
2       7  0.0  0.0  0.260  0.440  0.0  ...  0.125  0.005  0.0  0.0  0.0  0.0
3       3  0.0  0.0  0.235  0.465  0.0  ...  0.155  0.000  0.0  0.0  0.0  0.0
4       7  0.0  0.0  0.245  0.425  0.0  ...  0.150  0.000  0.0  0.0  0.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP