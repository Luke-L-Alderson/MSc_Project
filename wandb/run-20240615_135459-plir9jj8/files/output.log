Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-15 13:55:01.012028
Scaler Value: 0.013513513513513514
Training - 2024-06-15 13:55:01.012524
[1/9, 1/94] Training Loss: 0.0695 - Iteration Time: 0:00:01.941489
[1/9, 2/94] Training Loss: 0.0698 - Iteration Time: 0:00:01.467973
[1/9, 3/94] Training Loss: 0.0718 - Iteration Time: 0:00:01.531091
[1/9, 4/94] Training Loss: 0.0717 - Iteration Time: 0:00:01.480879
[1/9, 5/94] Training Loss: 0.0705 - Iteration Time: 0:00:01.481447
[1/9, 6/94] Training Loss: 0.0692 - Iteration Time: 0:00:01.466527
[1/9, 7/94] Training Loss: 0.0689 - Iteration Time: 0:00:01.445187
[1/9, 8/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.460064
[1/9, 9/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.487876
[1/9, 10/94] Training Loss: 0.0706 - Iteration Time: 0:00:01.508690
[1/9, 11/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.483919
[1/9, 12/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.451600
[1/9, 13/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.540920
[1/9, 14/94] Training Loss: 0.0697 - Iteration Time: 0:00:01.523078
[1/9, 15/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.483430
[1/9, 16/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.467990
[1/9, 17/94] Training Loss: 0.0710 - Iteration Time: 0:00:01.547908
[1/9, 18/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.524031
[1/9, 19/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.485876
[1/9, 20/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.448125
[1/9, 21/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.561807
[1/9, 22/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.515094
[1/9, 23/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.474962
[1/9, 24/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.523583
[1/9, 25/94] Training Loss: 0.0702 - Iteration Time: 0:00:01.520144
[1/9, 26/94] Training Loss: 0.0680 - Iteration Time: 0:00:01.488321
[1/9, 27/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.431803
[1/9, 28/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.533488
[1/9, 29/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.548928
[1/9, 30/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.444660
[1/9, 31/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.416936
[1/9, 32/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.525113
[1/9, 33/94] Training Loss: 0.0707 - Iteration Time: 0:00:01.536491
[1/9, 34/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.530497
[1/9, 35/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.497795
[1/9, 36/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.417410
[1/9, 37/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.503272
[1/9, 38/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.522115
[1/9, 39/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.553388
[1/9, 40/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.573182
[1/9, 41/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.468047
[1/9, 42/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.505688
[1/9, 43/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.533512
[1/9, 44/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.551846
[1/9, 45/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.443710
[1/9, 46/94] Training Loss: 0.0680 - Iteration Time: 0:00:01.674385
[1/9, 47/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.436727
[1/9, 48/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.567239
[1/9, 49/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.530547
[1/9, 50/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.563240
[1/9, 51/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.508245
[1/9, 52/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.470979
[1/9, 53/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.516125
[1/9, 54/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.431763
[1/9, 55/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.444224
[1/9, 56/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.500242
[1/9, 57/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.432780
[1/9, 58/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.432299
[1/9, 59/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.496496
[1/9, 60/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.455650
[1/9, 61/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.517189
[1/9, 62/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.484483
[1/9, 63/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.471056
[1/9, 64/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.522625
[1/9, 65/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.429838
[1/9, 66/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.455617
[1/9, 67/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.474551
[1/9, 68/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.490936
[1/9, 69/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.505308
[1/9, 70/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.545923
[1/9, 71/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.522655
[1/9, 72/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.525589
[1/9, 73/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.685834
[1/9, 74/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.485378
[1/9, 75/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.521135
[1/9, 76/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.455153
[1/9, 77/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.567338
[1/9, 78/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.475884
[1/9, 79/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.434300
[1/9, 80/94] Training Loss: 0.0692 - Iteration Time: 0:00:01.438759
[1/9, 81/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.468565
[1/9, 82/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.544494
[1/9, 83/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.475960
[1/9, 84/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.504230
[1/9, 85/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.443740
[1/9, 86/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.482905
[1/9, 87/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.543943
[1/9, 88/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.429818
[1/9, 89/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.541016
[1/9, 90/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.462015
[1/9, 91/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.479008
[1/9, 92/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.673436
[1/9, 93/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.496427
[1/9, 94/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.543534
Testing - 2024-06-15 13:57:33.222825
[1/9, 1/16]
[1/9, 2/16]
[1/9, 3/16]
[1/9, 4/16]
[1/9, 5/16]
[1/9, 6/16]
[1/9, 7/16]
[1/9, 8/16]
[1/9, 9/16]
[1/9, 10/16]
[1/9, 11/16]
[1/9, 12/16]
[1/9, 13/16]
[1/9, 14/16]
[1/9, 15/16]
[1/9, 16/16]
Testing Loss: 0.0619 - Epoch Time: 0:02:55.256642
Training - 2024-06-15 13:57:56.269662
[2/9, 1/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.557333
[2/9, 2/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.545919
[2/9, 3/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.554443
[2/9, 4/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.523125
[2/9, 5/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.590612
[2/9, 6/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.446775
[2/9, 7/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.465585
[2/9, 8/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.434774
[2/9, 9/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.438363
[2/9, 10/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.507369
[2/9, 11/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.514713
[2/9, 12/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.520593
[2/9, 13/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.577247
[2/9, 14/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.520191
[2/9, 15/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.455620
[2/9, 16/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.496799
[2/9, 17/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.534607
[2/9, 18/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.440839
[2/9, 19/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.478931
[2/9, 20/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.447646
[2/9, 21/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.552907
[2/9, 22/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.428791
[2/9, 23/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.481916
[2/9, 24/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.543973
[2/9, 25/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.438323
[2/9, 26/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.528062
[2/9, 27/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.475953
[2/9, 28/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.476960
[2/9, 29/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.494338
[2/9, 30/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.432322
[2/9, 31/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.517196
[2/9, 32/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.595501
[2/9, 33/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.460163
[2/9, 34/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.467995
[2/9, 35/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.444769
[2/9, 36/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.531507
[2/9, 37/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.452647
[2/9, 38/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.544403
[2/9, 39/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.500326
[2/9, 40/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.512218
[2/9, 41/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.481017
[2/9, 42/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.430801
[2/9, 43/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.703234
[2/9, 44/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.577770
[2/9, 45/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.417966
[2/9, 46/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.492319
[2/9, 47/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.500816
[2/9, 48/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.483009
[2/9, 49/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.489432
[2/9, 50/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.502774
[2/9, 51/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.496354
[2/9, 52/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.456739
[2/9, 53/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.502312
[2/9, 54/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.515191
[2/9, 55/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.511180
[2/9, 56/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.433320
[2/9, 57/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.527677
[2/9, 58/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.547857
[2/9, 59/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.460100
[2/9, 60/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.491888
[2/9, 61/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.458156
[2/9, 62/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.492831
[2/9, 63/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.437789
[2/9, 64/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.453154
[2/9, 65/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.578208
[2/9, 66/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.481999
[2/9, 67/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.477466
[2/9, 68/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.464022
[2/9, 69/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.517157
[2/9, 70/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.488322
[2/9, 71/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.515165
[2/9, 72/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.552381
[2/9, 73/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.488883
[2/9, 74/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.470993
[2/9, 75/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.505283
[2/9, 76/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.462547
[2/9, 77/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.469020
[2/9, 78/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.524537
[2/9, 79/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.484395
[2/9, 80/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.469488
[2/9, 81/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.469560
[2/9, 82/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.451619
[2/9, 83/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.489872
[2/9, 84/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.662487
[2/9, 85/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.486370
[2/9, 86/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.493306
[2/9, 87/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.485092
[2/9, 88/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.467015
[2/9, 89/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.518637
[2/9, 90/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.522568
[2/9, 91/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.617468
[2/9, 92/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.511680
[2/9, 93/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.485441
[2/9, 94/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.409523
Testing - 2024-06-15 14:00:17.171913
[2/9, 1/16]
[2/9, 2/16]
[2/9, 3/16]
[2/9, 4/16]
[2/9, 5/16]
[2/9, 6/16]
[2/9, 7/16]
[2/9, 8/16]
[2/9, 9/16]
[2/9, 10/16]
[2/9, 11/16]
[2/9, 12/16]
[2/9, 13/16]
[2/9, 14/16]
[2/9, 15/16]
[2/9, 16/16]
Testing Loss: 0.0617 - Epoch Time: 0:02:34.441158
Training - 2024-06-15 14:00:30.710820
[3/9, 1/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.440734
[3/9, 2/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.434831
[3/9, 3/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.461073
[3/9, 4/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.566313
[3/9, 5/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.489842
[3/9, 6/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.518135
[3/9, 7/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.508201
[3/9, 8/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.465071
[3/9, 9/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.524091
[3/9, 10/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.475488
[3/9, 11/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.451734
[3/9, 12/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.456585
[3/9, 13/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.477942
[3/9, 14/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.577667
[3/9, 15/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.499742
[3/9, 16/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.478935
[3/9, 17/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.516140
[3/9, 18/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.505257
[3/9, 19/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.536464
[3/9, 20/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.535990
[3/9, 21/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.624839
[3/9, 22/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.470081
[3/9, 23/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.451108
[3/9, 24/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.476497
[3/9, 25/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.443215
[3/9, 26/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.535998
[3/9, 27/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.501715
[3/9, 28/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.480419
[3/9, 29/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.541942
[3/9, 30/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.435810
[3/9, 31/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.449183
[3/9, 32/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.501747
[3/9, 33/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.450129
[3/9, 34/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.440708
[3/9, 35/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.454607
[3/9, 36/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.514626
[3/9, 37/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.456660
[3/9, 38/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.467984
[3/9, 39/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.445222
[3/9, 40/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.486905
[3/9, 41/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.551424
[3/9, 42/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.469995
[3/9, 43/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.471951
[3/9, 44/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.519606
[3/9, 45/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.447679
[3/9, 46/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.467483
[3/9, 47/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.549903
[3/9, 48/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.565304
[3/9, 49/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.589117
[3/9, 50/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.494859
[3/9, 51/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.476468
[3/9, 52/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.476982
[3/9, 53/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.446186
[3/9, 54/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.602977
[3/9, 55/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.460553
[3/9, 56/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.459120
[3/9, 57/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.512692
[3/9, 58/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.493302
[3/9, 59/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.515195
[3/9, 60/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.480887
[3/9, 61/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.515707
[3/9, 62/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.592575
[3/9, 63/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.511216
[3/9, 64/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.502733
[3/9, 65/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.493921
[3/9, 66/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.442699
[3/9, 67/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.468011
[3/9, 68/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.476944
[3/9, 69/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.459128
[3/9, 70/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.462049
[3/9, 71/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.455605
[3/9, 72/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.482385
[3/9, 73/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.487378
[3/9, 74/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.468968
[3/9, 75/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.428340
[3/9, 76/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.440729
[3/9, 77/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.512182
[3/9, 78/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.555312
[3/9, 79/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.509218
[3/9, 80/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.460749
[3/9, 81/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.527556
[3/9, 82/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.561247
[3/9, 83/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.467059
[3/9, 84/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.484392
[3/9, 85/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.480923
[3/9, 86/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.433318
[3/9, 87/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.426311
[3/9, 88/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.442232
[3/9, 89/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.529056
[3/9, 90/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.459655
[3/9, 91/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.447205
[3/9, 92/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.454150
[3/9, 93/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.516151
[3/9, 94/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.448230
Testing - 2024-06-15 14:02:50.797791
[3/9, 1/16]
[3/9, 2/16]
[3/9, 3/16]
[3/9, 4/16]
[3/9, 5/16]
[3/9, 6/16]
[3/9, 7/16]
[3/9, 8/16]
[3/9, 9/16]
[3/9, 10/16]
[3/9, 11/16]
[3/9, 12/16]
[3/9, 13/16]
[3/9, 14/16]
[3/9, 15/16]
[3/9, 16/16]
Testing Loss: 0.0569 - Epoch Time: 0:02:33.870451
Training - 2024-06-15 14:03:04.581767
[4/9, 1/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.661979
[4/9, 2/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.478418
[4/9, 3/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.437218
[4/9, 4/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.455646
[4/9, 5/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.457575
[4/9, 6/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.506245
[4/9, 7/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.484886
[4/9, 8/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.470999
[4/9, 9/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.488937
[4/9, 10/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.516129
[4/9, 11/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.436269
[4/9, 12/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.500282
[4/9, 13/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.580232
[4/9, 14/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.459162
[4/9, 15/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.443203
[4/9, 16/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.460098
[4/9, 17/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.459073
[4/9, 18/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.496285
[4/9, 19/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.529591
[4/9, 20/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.437328
[4/9, 21/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.497928
[4/9, 22/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.456056
[4/9, 23/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.486492
[4/9, 24/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.484861
[4/9, 25/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.452261
[4/9, 26/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.546858
[4/9, 27/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.512688
[4/9, 28/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.450772
[4/9, 29/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.485917
[4/9, 30/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.463611
[4/9, 31/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.574284
[4/9, 32/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.534027
[4/9, 33/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.476485
[4/9, 34/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.445159
[4/9, 35/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.480969
[4/9, 36/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.509745
[4/9, 37/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.535078
[4/9, 38/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.520724
[4/9, 39/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.610479
[4/9, 40/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.546910
[4/9, 41/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.498306
[4/9, 42/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.500745
[4/9, 43/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.466597
[4/9, 44/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.475970
[4/9, 45/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.452191
[4/9, 46/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.601963
[4/9, 47/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.468045
[4/9, 48/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.441311
[4/9, 49/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.449201
[4/9, 50/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.487840
[4/9, 51/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.492979
[4/9, 52/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.446859
[4/9, 53/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.471081
[4/9, 54/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.514631
[4/9, 55/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.498837
[4/9, 56/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.549430
[4/9, 57/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.437363
[4/9, 58/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.470541
[4/9, 59/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.472523
[4/9, 60/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.527610
[4/9, 61/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.687910
[4/9, 62/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.498305
[4/9, 63/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.507279
[4/9, 64/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.513656
[4/9, 65/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.489908
[4/9, 66/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.531546
[4/9, 67/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.458624
[4/9, 68/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.490915
[4/9, 69/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.444231
[4/9, 70/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.502258
[4/9, 71/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.522202
[4/9, 72/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.444833
[4/9, 73/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.465714
[4/9, 74/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.443231
[4/9, 75/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.447681
[4/9, 76/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.434346
[4/9, 77/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.479520
[4/9, 78/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.511169
[4/9, 79/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.646137
[4/9, 80/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.479992
[4/9, 81/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.486978
[4/9, 82/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.558285
[4/9, 83/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.558858
[4/9, 84/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.466021
[4/9, 85/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.519612
[4/9, 86/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.495513
[4/9, 87/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.475499
[4/9, 88/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.552889
[4/9, 89/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.444738
[4/9, 90/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.453610
[4/9, 91/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.521130
[4/9, 92/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.505234
[4/9, 93/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.605968
[4/9, 94/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.382161
Testing - 2024-06-15 14:05:25.254017
[4/9, 1/16]
[4/9, 2/16]
[4/9, 3/16]
[4/9, 4/16]
[4/9, 5/16]
[4/9, 6/16]
[4/9, 7/16]
[4/9, 8/16]
[4/9, 9/16]
[4/9, 10/16]
[4/9, 11/16]
[4/9, 12/16]
[4/9, 13/16]
[4/9, 14/16]
[4/9, 15/16]
[4/9, 16/16]
Testing Loss: 0.0526 - Epoch Time: 0:02:34.474208
Training - 2024-06-15 14:05:39.055975
[5/9, 1/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.534571
[5/9, 2/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.480453
[5/9, 3/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.549949
[5/9, 4/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.514631
[5/9, 5/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.497449
[5/9, 6/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.536980
[5/9, 7/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.461629
[5/9, 8/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.638243
[5/9, 9/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.569790
[5/9, 10/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.612416
[5/9, 11/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.462161
[5/9, 12/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.556899
[5/9, 13/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.546434
[5/9, 14/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.467594
[5/9, 15/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.492830
[5/9, 16/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.602913
[5/9, 17/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.509261
[5/9, 18/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.465530
[5/9, 19/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.473537
[5/9, 20/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.442690
[5/9, 21/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.455241
[5/9, 22/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.515637
[5/9, 23/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.495813
[5/9, 24/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.522119
[5/9, 25/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.459699
[5/9, 26/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.456124
[5/9, 27/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.568845
[5/9, 28/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.455228
[5/9, 29/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.460691
[5/9, 30/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.451198
[5/9, 31/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.449222
[5/9, 32/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.518151
[5/9, 33/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.484063
[5/9, 34/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.426399
[5/9, 35/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.511208
[5/9, 36/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.572750
[5/9, 37/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.444231
[5/9, 38/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.465110
[5/9, 39/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.497304
[5/9, 40/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.452642
[5/9, 41/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.484900
[5/9, 42/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.532618
[5/9, 43/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.635752
[5/9, 44/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.499230
[5/9, 45/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.445357
[5/9, 46/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.454707
[5/9, 47/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.454624
[5/9, 48/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.453601
[5/9, 49/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.477098
[5/9, 50/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.607509
[5/9, 51/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.425448
[5/9, 52/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.473563
[5/9, 53/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.482959
[5/9, 54/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.442731
[5/9, 55/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.632769
[5/9, 56/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.498741
[5/9, 57/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.477044
[5/9, 58/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.509692
[5/9, 59/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.468593
[5/9, 60/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.552883
[5/9, 61/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.548903
[5/9, 62/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.454132
[5/9, 63/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.452150
[5/9, 64/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.464063
[5/9, 65/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.511225
[5/9, 66/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.452651
[5/9, 67/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.518142
[5/9, 68/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.456167
[5/9, 69/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.438821
[5/9, 70/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.661193
[5/9, 71/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.524626
[5/9, 72/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.474499
[5/9, 73/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.459686
[5/9, 74/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.448736
[5/9, 75/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.460582
[5/9, 76/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.489125
[5/9, 77/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.541077
[5/9, 78/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.518199
[5/9, 79/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.482922
[5/9, 80/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.491918
[5/9, 81/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.438329
[5/9, 82/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.509819
[5/9, 83/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.551915
[5/9, 84/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.509249
[5/9, 85/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.442765
[5/9, 86/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.614899
[5/9, 87/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.505768
[5/9, 88/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.517286
[5/9, 89/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.447256
[5/9, 90/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.566279
[5/9, 91/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.490307
[5/9, 92/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.443270
[5/9, 93/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.463583
[5/9, 94/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.412073
Testing - 2024-06-15 14:07:59.996146
[5/9, 1/16]
[5/9, 2/16]
[5/9, 3/16]
[5/9, 4/16]
[5/9, 5/16]
[5/9, 6/16]
[5/9, 7/16]
[5/9, 8/16]
[5/9, 9/16]
[5/9, 10/16]
[5/9, 11/16]
[5/9, 12/16]
[5/9, 13/16]
[5/9, 14/16]
[5/9, 15/16]
[5/9, 16/16]
Testing Loss: 0.0498 - Epoch Time: 0:02:34.768855
Training - 2024-06-15 14:08:13.825325
[6/9, 1/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.504177
[6/9, 2/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.594062
[6/9, 3/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.475138
[6/9, 4/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.632783
[6/9, 5/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.501714
[6/9, 6/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.456856
[6/9, 7/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.450723
[6/9, 8/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.528562
[6/9, 9/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.453213
[6/9, 10/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.465088
[6/9, 11/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.530004
[6/9, 12/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.528564
[6/9, 13/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.527992
[6/9, 14/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.474157
[6/9, 15/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.497292
[6/9, 16/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.510313
[6/9, 17/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.499853
[6/9, 18/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.582749
[6/9, 19/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.486029
[6/9, 20/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.533640
[6/9, 21/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.490194
[6/9, 22/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.491920
[6/9, 23/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.444742
[6/9, 24/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.452764
[6/9, 25/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.479450
[6/9, 26/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.512730
[6/9, 27/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.509844
[6/9, 28/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.471549
[6/9, 29/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.461083
[6/9, 30/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.538076
[6/9, 31/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.550451
[6/9, 32/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.656120
[6/9, 33/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.441229
[6/9, 34/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.525594
[6/9, 35/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.486884
[6/9, 36/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.466063
[6/9, 37/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.495827
[6/9, 38/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.498807
[6/9, 39/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.508191
[6/9, 40/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.525583
[6/9, 41/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.575630
[6/9, 42/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.471009
[6/9, 43/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.478926
[6/9, 44/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.537990
[6/9, 45/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.464030
[6/9, 46/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.460131
[6/9, 47/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.506689
[6/9, 48/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.479010
[6/9, 49/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.511139
[6/9, 50/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.529576
[6/9, 51/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.649126
[6/9, 52/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.554833
[6/9, 53/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.527067
[6/9, 54/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.540480
[6/9, 55/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.579243
[6/9, 56/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.500266
[6/9, 57/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.548406
[6/9, 58/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.485356
[6/9, 59/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.503224
[6/9, 60/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.554353
[6/9, 61/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.532659
[6/9, 62/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.459185
[6/9, 63/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.498828
[6/9, 64/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.493861
[6/9, 65/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.512792
[6/9, 66/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.505757
[6/9, 67/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.501295
[6/9, 68/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.515656
[6/9, 69/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.471611
[6/9, 70/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.456235
[6/9, 71/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.549933
[6/9, 72/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.528142
[6/9, 73/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.655125
[6/9, 74/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.447276
[6/9, 75/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.447328
[6/9, 76/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.449271
[6/9, 77/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.519736
[6/9, 78/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.514673
[6/9, 79/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.478496
[6/9, 80/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.487399
[6/9, 81/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.505256
[6/9, 82/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.490850
[6/9, 83/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.503321
[6/9, 84/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.577747
[6/9, 85/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.505927
[6/9, 86/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.448865
[6/9, 87/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.512671
[6/9, 88/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.458629
[6/9, 89/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.470054
[6/9, 90/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.508209
[6/9, 91/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.553367
[6/9, 92/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.482941
[6/9, 93/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.485387
[6/9, 94/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.445292
Testing - 2024-06-15 14:10:35.584230
[6/9, 1/16]
[6/9, 2/16]
[6/9, 3/16]
[6/9, 4/16]
[6/9, 5/16]
[6/9, 6/16]
[6/9, 7/16]
[6/9, 8/16]
[6/9, 9/16]
[6/9, 10/16]
[6/9, 11/16]
[6/9, 12/16]
[6/9, 13/16]
[6/9, 14/16]
[6/9, 15/16]
[6/9, 16/16]
Testing Loss: 0.0494 - Epoch Time: 0:02:35.839372
Training - 2024-06-15 14:10:49.664697
[7/9, 1/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.508382
[7/9, 2/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.450681
[7/9, 3/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.425383
[7/9, 4/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.523622
[7/9, 5/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.467544
[7/9, 6/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.679969
[7/9, 7/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.584667
[7/9, 8/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.637308
[7/9, 9/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.463548
[7/9, 10/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.435342
[7/9, 11/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.476470
[7/9, 12/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.495845
[7/9, 13/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.494586
[7/9, 14/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.460099
[7/9, 15/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.462598
[7/9, 16/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.457139
[7/9, 17/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.500866
[7/9, 18/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.433875
[7/9, 19/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.467546
[7/9, 20/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.477475
[7/9, 21/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.505725
[7/9, 22/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.455682
[7/9, 23/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.494888
[7/9, 24/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.492407
[7/9, 25/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.464551
[7/9, 26/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.483423
[7/9, 27/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.479442
[7/9, 28/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.513744
[7/9, 29/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.500308
[7/9, 30/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.531615
[7/9, 31/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.564302
[7/9, 32/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.582222
[7/9, 33/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.573268
[7/9, 34/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.489960
[7/9, 35/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.476971
[7/9, 36/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.548911
[7/9, 37/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.476481
[7/9, 38/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.457696
[7/9, 39/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.449675
[7/9, 40/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.497838
[7/9, 41/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.542997
[7/9, 42/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.525598
[7/9, 43/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.461714
[7/9, 44/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.480000
[7/9, 45/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.474603
[7/9, 46/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.462071
[7/9, 47/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.455641
[7/9, 48/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.524633
[7/9, 49/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.573278
[7/9, 50/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.531157
[7/9, 51/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.496403
[7/9, 52/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.543495
[7/9, 53/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.527133
[7/9, 54/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.660053
[7/9, 55/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.545438
[7/9, 56/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.488969
[7/9, 57/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.449191
[7/9, 58/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.476481
[7/9, 59/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.497887
[7/9, 60/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.456173
[7/9, 61/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.506217
[7/9, 62/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.472518
[7/9, 63/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.480890
[7/9, 64/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.535556
[7/9, 65/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.552942
[7/9, 66/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.541165
[7/9, 67/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.489236
[7/9, 68/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.495906
[7/9, 69/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.494408
[7/9, 70/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.557375
[7/9, 71/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.506882
[7/9, 72/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.480988
[7/9, 73/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.499345
[7/9, 74/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.496956
[7/9, 75/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.526123
[7/9, 76/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.591684
[7/9, 77/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.560301
[7/9, 78/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.499912
[7/9, 79/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.467144
[7/9, 80/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.515239
[7/9, 81/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.493369
[7/9, 82/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.492875
[7/9, 83/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.511206
[7/9, 84/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.458162
[7/9, 85/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.521102
[7/9, 86/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.473538
[7/9, 87/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.508681
[7/9, 88/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.669531
[7/9, 89/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.497778
[7/9, 90/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.479928
[7/9, 91/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.489382
[7/9, 92/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.528075
[7/9, 93/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.473490
[7/9, 94/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.430312
Testing - 2024-06-15 14:13:11.164165
[7/9, 1/16]
[7/9, 2/16]
[7/9, 3/16]
[7/9, 4/16]
[7/9, 5/16]
[7/9, 6/16]
[7/9, 7/16]
[7/9, 8/16]
[7/9, 9/16]
[7/9, 10/16]
[7/9, 11/16]
[7/9, 12/16]
[7/9, 13/16]
[7/9, 14/16]
[7/9, 15/16]
[7/9, 16/16]
Testing Loss: 0.0478 - Epoch Time: 0:02:35.454380
Training - 2024-06-15 14:13:25.119574
[8/9, 1/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.465064
[8/9, 2/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.508786
[8/9, 3/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.533612
[8/9, 4/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.498291
[8/9, 5/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.532577
[8/9, 6/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.460642
[8/9, 7/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.542498
[8/9, 8/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.477688
[8/9, 9/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.509794
[8/9, 10/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.513367
[8/9, 11/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.489480
[8/9, 12/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.729129
[8/9, 13/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.513714
[8/9, 14/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.493846
[8/9, 15/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.558918
[8/9, 16/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.498301
[8/9, 17/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.456766
[8/9, 18/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.473038
[8/9, 19/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.460224
[8/9, 20/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.533580
[8/9, 21/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.511898
[8/9, 22/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.571855
[8/9, 23/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.497829
[8/9, 24/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.483395
[8/9, 25/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.613473
[8/9, 26/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.517634
[8/9, 27/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.463119
[8/9, 28/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.448159
[8/9, 29/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.513386
[8/9, 30/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.516613
[8/9, 31/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.521184
[8/9, 32/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.492948
[8/9, 33/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.539977
[8/9, 34/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.566324
[8/9, 35/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.559448
[8/9, 36/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.501252
[8/9, 37/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.453213
[8/9, 38/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.467502
[8/9, 39/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.457143
[8/9, 40/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.451691
[8/9, 41/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.498876
[8/9, 42/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.462086
[8/9, 43/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.535057
[8/9, 44/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.505760
[8/9, 45/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.571408
[8/9, 46/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.477962
[8/9, 47/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.483894
[8/9, 48/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.509158
[8/9, 49/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.557979
[8/9, 50/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.519644
[8/9, 51/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.458679
[8/9, 52/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.608441
[8/9, 53/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.524166
[8/9, 54/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.484335
[8/9, 55/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.448801
[8/9, 56/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.569789
[8/9, 57/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.636337
[8/9, 58/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.474575
[8/9, 59/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.478985
[8/9, 60/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.521578
[8/9, 61/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.498277
[8/9, 62/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.522260
[8/9, 63/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.480984
[8/9, 64/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.618375
[8/9, 65/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.498762
[8/9, 66/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.519711
[8/9, 67/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.452150
[8/9, 68/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.509742
[8/9, 69/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.468492
[8/9, 70/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.493433
[8/9, 71/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.472962
[8/9, 72/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.468000
[8/9, 73/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.543426
[8/9, 74/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.527644
[8/9, 75/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.487394
[8/9, 76/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.531123
[8/9, 77/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.480376
[8/9, 78/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.441817
[8/9, 79/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.446718
[8/9, 80/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.450275
[8/9, 81/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.579166
[8/9, 82/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.495429
[8/9, 83/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.522168
[8/9, 84/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.518192
[8/9, 85/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.444763
[8/9, 86/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.487440
[8/9, 87/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.448747
[8/9, 88/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.460071
[8/9, 89/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.472046
[8/9, 90/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.557428
[8/9, 91/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.463153
[8/9, 92/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.601076
[8/9, 93/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.495334
[8/9, 94/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.410185
Testing - 2024-06-15 14:15:46.803705
[8/9, 1/16]
[8/9, 2/16]
[8/9, 3/16]
[8/9, 4/16]
[8/9, 5/16]
[8/9, 6/16]
[8/9, 7/16]
[8/9, 8/16]
[8/9, 9/16]
[8/9, 10/16]
[8/9, 11/16]
[8/9, 12/16]
[8/9, 13/16]
[8/9, 14/16]
[8/9, 15/16]
[8/9, 16/16]
Testing Loss: 0.0476 - Epoch Time: 0:02:35.428478
Training - 2024-06-15 14:16:00.548052
[9/9, 1/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.612488
[9/9, 2/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.485874
[9/9, 3/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.492917
[9/9, 4/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.502303
[9/9, 5/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.464097
[9/9, 6/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.456652
[9/9, 7/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.519752
[9/9, 8/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.611003
[9/9, 9/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.577696
[9/9, 10/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.453147
[9/9, 11/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.523255
[9/9, 12/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.443246
[9/9, 13/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.500772
[9/9, 14/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.486394
[9/9, 15/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.539508
[9/9, 16/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.470963
[9/9, 17/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.527139
[9/9, 18/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.499775
[9/9, 19/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.429381
[9/9, 20/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.443721
[9/9, 21/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.482007
[9/9, 22/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.500306
[9/9, 23/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.429861
[9/9, 24/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.442813
[9/9, 25/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.446752
[9/9, 26/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.475079
[9/9, 27/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.444893
[9/9, 28/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.489510
[9/9, 29/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.595058
[9/9, 30/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.492817
[9/9, 31/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.457134
[9/9, 32/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.464578
[9/9, 33/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.521120
[9/9, 34/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.509778
[9/9, 35/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.548482
[9/9, 36/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.460578
[9/9, 37/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.474454
[9/9, 38/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.455173
[9/9, 39/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.456639
[9/9, 40/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.521622
[9/9, 41/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.692376
[9/9, 42/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.461695
[9/9, 43/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.422925
[9/9, 44/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.495906
[9/9, 45/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.441235
[9/9, 46/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.599159
[9/9, 47/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.510230
[9/9, 48/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.482972
[9/9, 49/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.515664
[9/9, 50/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.455646
[9/9, 51/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.526228
[9/9, 52/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.489116
[9/9, 53/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.456150
[9/9, 54/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.562883
[9/9, 55/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.438271
[9/9, 56/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.506827
[9/9, 57/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.488464
[9/9, 58/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.439310
[9/9, 59/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.472546
[9/9, 60/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.436317
[9/9, 61/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.442207
[9/9, 62/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.508896
[9/9, 63/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.455210
[9/9, 64/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.451206
[9/9, 65/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.531675
[9/9, 66/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.568876
[9/9, 67/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.489435
[9/9, 68/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.522748
[9/9, 69/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.603544
[9/9, 70/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.478522
[9/9, 71/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.447278
[9/9, 72/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.451221
[9/9, 73/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.437809
[9/9, 74/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.541580
[9/9, 75/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.470611
[9/9, 76/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.433850
[9/9, 77/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.568237
[9/9, 78/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.540978
[9/9, 79/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.445727
[9/9, 80/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.469532
[9/9, 81/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.501741
[9/9, 82/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.601521
[9/9, 83/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.487392
[9/9, 84/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.441277
[9/9, 85/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.473547
[9/9, 86/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.471009
[9/9, 87/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.537123
[9/9, 88/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.516721
[9/9, 89/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.509675
[9/9, 90/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.514747
[9/9, 91/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.424382
[9/9, 92/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.448188
[9/9, 93/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.469527
[9/9, 94/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.388647
Testing - 2024-06-15 14:18:20.887061
[9/9, 1/16]
[9/9, 2/16]
[9/9, 3/16]
[9/9, 4/16]
[9/9, 5/16]
[9/9, 6/16]
[9/9, 7/16]
[9/9, 8/16]
[9/9, 9/16]
[9/9, 10/16]
[9/9, 11/16]
[9/9, 12/16]
[9/9, 13/16]
[9/9, 14/16]
[9/9, 15/16]
[9/9, 16/16]
Testing Loss: 0.0453 - Epoch Time: 0:02:33.898651
Training and Testing Finished - Time: 0:23:33.435172
Assembling test data for t-sne projection
-- 1/16 --
-- 2/16 --
-- 3/16 --
-- 4/16 --
-- 5/16 --
-- 6/16 --
-- 7/16 --
-- 8/16 --
-- 9/16 --
-- 10/16 --
-- 11/16 --
-- 12/16 --
-- 13/16 --
-- 14/16 --
-- 15/16 --
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 4
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 4
Applying t-SNE