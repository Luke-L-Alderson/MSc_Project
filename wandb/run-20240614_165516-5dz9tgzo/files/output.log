Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-14 16:55:17.289196
Scaler Value: 0.013513513513513514
Training - 2024-06-14 16:55:17.289692
[1/9, 1/94] Training Loss: 0.0694 - Iteration Time: 0:00:01.690394
[1/9, 2/94] Training Loss: 0.0699 - Iteration Time: 0:00:01.262137
[1/9, 3/94] Training Loss: 0.0716 - Iteration Time: 0:00:01.267582
[1/9, 4/94] Training Loss: 0.0715 - Iteration Time: 0:00:01.248709
[1/9, 5/94] Training Loss: 0.0703 - Iteration Time: 0:00:01.268700
[1/9, 6/94] Training Loss: 0.0691 - Iteration Time: 0:00:01.277004
[1/9, 7/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.272536
[1/9, 8/94] Training Loss: 0.0689 - Iteration Time: 0:00:01.291397
[1/9, 9/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.278539
[1/9, 10/94] Training Loss: 0.0709 - Iteration Time: 0:00:01.326633
[1/9, 11/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.285004
[1/9, 12/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.273216
[1/9, 13/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.314231
[1/9, 14/94] Training Loss: 0.0700 - Iteration Time: 0:00:01.274594
[1/9, 15/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.278977
[1/9, 16/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.297429
[1/9, 17/94] Training Loss: 0.0717 - Iteration Time: 0:00:01.266794
[1/9, 18/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.343040
[1/9, 19/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.262236
[1/9, 20/94] Training Loss: 0.0694 - Iteration Time: 0:00:01.270675
[1/9, 21/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.244269
[1/9, 22/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.256250
[1/9, 23/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.279105
[1/9, 24/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.266548
[1/9, 25/94] Training Loss: 0.0708 - Iteration Time: 0:00:01.275038
[1/9, 26/94] Training Loss: 0.0689 - Iteration Time: 0:00:01.236346
[1/9, 27/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.331732
[1/9, 28/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.499970
[1/9, 29/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.309317
[1/9, 30/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.317668
[1/9, 31/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.341610
[1/9, 32/94] Training Loss: 0.0691 - Iteration Time: 0:00:01.257153
[1/9, 33/94] Training Loss: 0.0713 - Iteration Time: 0:00:01.290458
[1/9, 34/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.289927
[1/9, 35/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.311814
[1/9, 36/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.260712
[1/9, 37/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.263630
[1/9, 38/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.259225
[1/9, 39/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.255670
[1/9, 40/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.333637
[1/9, 41/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.282431
[1/9, 42/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.248741
[1/9, 43/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.273039
[1/9, 44/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.294388
[1/9, 45/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.249244
[1/9, 46/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.245752
[1/9, 47/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.253193
[1/9, 48/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.248230
[1/9, 49/94] Training Loss: 0.0701 - Iteration Time: 0:00:01.272638
[1/9, 50/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.441692
[1/9, 51/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.264092
[1/9, 52/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.310773
[1/9, 53/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.289375
[1/9, 54/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.280472
[1/9, 55/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.266061
[1/9, 56/94] Training Loss: 0.0697 - Iteration Time: 0:00:01.250238
[1/9, 57/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.256162
[1/9, 58/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.252239
[1/9, 59/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.274524
[1/9, 60/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.321648
[1/9, 61/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.282980
[1/9, 62/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.232483
[1/9, 63/94] Training Loss: 0.0695 - Iteration Time: 0:00:01.238362
[1/9, 64/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.271117
[1/9, 65/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.265146
[1/9, 66/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.267579
[1/9, 67/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.307900
[1/9, 68/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.250158
[1/9, 69/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.274133
[1/9, 70/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.249239
[1/9, 71/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.250239
[1/9, 72/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.216511
[1/9, 73/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.289999
[1/9, 74/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.310233
[1/9, 75/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.339540
[1/9, 76/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.512685
[1/9, 77/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.327118
[1/9, 78/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.329602
[1/9, 79/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.252213
[1/9, 80/94] Training Loss: 0.0700 - Iteration Time: 0:00:01.256625
[1/9, 81/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.242809
[1/9, 82/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.240749
[1/9, 83/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.260129
[1/9, 84/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.316715
[1/9, 85/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.271047
[1/9, 86/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.276602
[1/9, 87/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.275536
[1/9, 88/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.299364
[1/9, 89/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.258702
[1/9, 90/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.279544
[1/9, 91/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.237361
[1/9, 92/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.268610
[1/9, 93/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.259736
[1/9, 94/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.354472
Testing - 2024-06-14 16:57:27.082138
[1/9, 1/16]
[1/9, 2/16]
[1/9, 3/16]
[1/9, 4/16]
[1/9, 5/16]
[1/9, 6/16]
[1/9, 7/16]
[1/9, 8/16]
[1/9, 9/16]
[1/9, 10/16]
[1/9, 11/16]
[1/9, 12/16]
[1/9, 13/16]
[1/9, 14/16]
[1/9, 15/16]
[1/9, 16/16]
Testing Loss: 0.0621 - Epoch Time: 0:02:30.399933
Training - 2024-06-14 16:57:47.689625
[2/9, 1/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.417974
[2/9, 2/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.433932
[2/9, 3/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.288942
[2/9, 4/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.267116
[2/9, 5/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.313846
[2/9, 6/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.318197
[2/9, 7/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.288560
[2/9, 8/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.294932
[2/9, 9/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.264673
[2/9, 10/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.356025
[2/9, 11/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.452733
[2/9, 12/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.294855
[2/9, 13/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.323668
[2/9, 14/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.329759
[2/9, 15/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.275629
[2/9, 16/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.284493
[2/9, 17/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.259686
[2/9, 18/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.276639
[2/9, 19/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.289920
[2/9, 20/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.268145
[2/9, 21/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.271572
[2/9, 22/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.250297
[2/9, 23/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.263138
[2/9, 24/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.334553
[2/9, 25/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.300948
[2/9, 26/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.305865
[2/9, 27/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.260731
[2/9, 28/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.240842
[2/9, 29/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.249239
[2/9, 30/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.256231
[2/9, 31/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.269665
[2/9, 32/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.245286
[2/9, 33/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.313397
[2/9, 34/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.283071
[2/9, 35/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.263140
[2/9, 36/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.274666
[2/9, 37/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.284546
[2/9, 38/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.301972
[2/9, 39/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.272082
[2/9, 40/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.270171
[2/9, 41/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.248296
[2/9, 42/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.257902
[2/9, 43/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.290479
[2/9, 44/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.260226
[2/9, 45/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.270691
[2/9, 46/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.304347
[2/9, 47/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.280312
[2/9, 48/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.284138
[2/9, 49/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.240321
[2/9, 50/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.428914
[2/9, 51/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.299828
[2/9, 52/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.250279
[2/9, 53/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.258786
[2/9, 54/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.341111
[2/9, 55/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.258676
[2/9, 56/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.309811
[2/9, 57/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.312795
[2/9, 58/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.585141
[2/9, 59/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.316330
[2/9, 60/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.384675
[2/9, 61/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.302870
[2/9, 62/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.302848
[2/9, 63/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.251237
[2/9, 64/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.280008
[2/9, 65/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.294407
[2/9, 66/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.291500
[2/9, 67/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.253807
[2/9, 68/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.307333
[2/9, 69/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.245817
[2/9, 70/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.271164
[2/9, 71/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.274570
[2/9, 72/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.275613
[2/9, 73/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.314834
[2/9, 74/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.286516
[2/9, 75/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.298842
[2/9, 76/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.312250
[2/9, 77/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.246245
[2/9, 78/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.282541
[2/9, 79/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.279550
[2/9, 80/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.236483
[2/9, 81/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.246875
[2/9, 82/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.256732
[2/9, 83/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.291560
[2/9, 84/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.243813
[2/9, 85/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.267103
[2/9, 86/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.345641
[2/9, 87/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.258159
[2/9, 88/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.277586
[2/9, 89/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.288505
[2/9, 90/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.259682
[2/9, 91/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.266644
[2/9, 92/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.254746
[2/9, 93/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.285435
[2/9, 94/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.236385
Testing - 2024-06-14 16:59:49.159911
[2/9, 1/16]
[2/9, 2/16]
[2/9, 3/16]
[2/9, 4/16]
[2/9, 5/16]
[2/9, 6/16]
[2/9, 7/16]
[2/9, 8/16]
[2/9, 9/16]
[2/9, 10/16]
[2/9, 11/16]
[2/9, 12/16]
[2/9, 13/16]
[2/9, 14/16]
[2/9, 15/16]
[2/9, 16/16]
Testing Loss: 0.0611 - Epoch Time: 0:02:12.956052
Training - 2024-06-14 17:00:00.645677
[3/9, 1/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.635935
[3/9, 2/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.264948
[3/9, 3/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.321692
[3/9, 4/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.335050
[3/9, 5/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.269637
[3/9, 6/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.250744
[3/9, 7/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.302911
[3/9, 8/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.306361
[3/9, 9/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.268202
[3/9, 10/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.261795
[3/9, 11/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.264803
[3/9, 12/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.263184
[3/9, 13/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.263153
[3/9, 14/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.304437
[3/9, 15/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.285064
[3/9, 16/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.269207
[3/9, 17/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.311795
[3/9, 18/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.263185
[3/9, 19/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.262168
[3/9, 20/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.275597
[3/9, 21/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.294906
[3/9, 22/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.341522
[3/9, 23/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.312796
[3/9, 24/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.318270
[3/9, 25/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.260218
[3/9, 26/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.312357
[3/9, 27/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.303930
[3/9, 28/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.267122
[3/9, 29/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.261684
[3/9, 30/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.256225
[3/9, 31/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.276058
[3/9, 32/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.241785
[3/9, 33/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.249834
[3/9, 34/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.251275
[3/9, 35/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.263657
[3/9, 36/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.270546
[3/9, 37/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.315291
[3/9, 38/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.312238
[3/9, 39/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.293423
[3/9, 40/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.348534
[3/9, 41/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.295861
[3/9, 42/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.260750
[3/9, 43/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.272571
[3/9, 44/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.257169
[3/9, 45/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.293911
[3/9, 46/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.427453
[3/9, 47/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.356003
[3/9, 48/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.622327
[3/9, 49/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.384701
[3/9, 50/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.389159
[3/9, 51/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.308875
[3/9, 52/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.302492
[3/9, 53/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.276017
[3/9, 54/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.277101
[3/9, 55/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.281576
[3/9, 56/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.264621
[3/9, 57/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.265630
[3/9, 58/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.317315
[3/9, 59/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.244768
[3/9, 60/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.296424
[3/9, 61/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.301928
[3/9, 62/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.268621
[3/9, 63/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.316767
[3/9, 64/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.258222
[3/9, 65/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.283986
[3/9, 66/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.256747
[3/9, 67/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.246272
[3/9, 68/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.253785
[3/9, 69/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.330146
[3/9, 70/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.252798
[3/9, 71/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.323305
[3/9, 72/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.288025
[3/9, 73/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.293921
[3/9, 74/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.280616
[3/9, 75/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.289402
[3/9, 76/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.260754
[3/9, 77/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.264685
[3/9, 78/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.278562
[3/9, 79/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.269150
[3/9, 80/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.290488
[3/9, 81/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.317794
[3/9, 82/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.266175
[3/9, 83/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.279523
[3/9, 84/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.291451
[3/9, 85/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.248727
[3/9, 86/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.282964
[3/9, 87/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.250903
[3/9, 88/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.274547
[3/9, 89/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.263704
[3/9, 90/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.304427
[3/9, 91/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.352488
[3/9, 92/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.278195
[3/9, 93/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.324290
[3/9, 94/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.433963
Testing - 2024-06-14 17:02:02.640496
[3/9, 1/16]
[3/9, 2/16]
[3/9, 3/16]
[3/9, 4/16]
[3/9, 5/16]
[3/9, 6/16]
[3/9, 7/16]
[3/9, 8/16]
[3/9, 9/16]
[3/9, 10/16]
[3/9, 11/16]
[3/9, 12/16]
[3/9, 13/16]
[3/9, 14/16]
[3/9, 15/16]
[3/9, 16/16]
Testing Loss: 0.0560 - Epoch Time: 0:02:13.680311
Training - 2024-06-14 17:02:14.325988
[4/9, 1/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.277630
[4/9, 2/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.252320
[4/9, 3/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.292913
[4/9, 4/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.265206
[4/9, 5/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.390126
[4/9, 6/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.292871
[4/9, 7/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.280141
[4/9, 8/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.270142
[4/9, 9/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.273607
[4/9, 10/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.266193
[4/9, 11/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.252783
[4/9, 12/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.322185
[4/9, 13/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.257266
[4/9, 14/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.258230
[4/9, 15/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.267204
[4/9, 16/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.295986
[4/9, 17/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.260196
[4/9, 18/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.269721
[4/9, 19/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.272639
[4/9, 20/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.289018
[4/9, 21/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.278048
[4/9, 22/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.323720
[4/9, 23/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.369870
[4/9, 24/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.284565
[4/9, 25/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.312333
[4/9, 26/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.339581
[4/9, 27/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.318231
[4/9, 28/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.294929
[4/9, 29/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.281504
[4/9, 30/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.255201
[4/9, 31/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.269578
[4/9, 32/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.253267
[4/9, 33/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.339086
[4/9, 34/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.255264
[4/9, 35/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.280608
[4/9, 36/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.292416
[4/9, 37/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.458594
[4/9, 38/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.297937
[4/9, 39/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.272115
[4/9, 40/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.341077
[4/9, 41/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.280706
[4/9, 42/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.295999
[4/9, 43/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.280535
[4/9, 44/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.263293
[4/9, 45/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.293001
[4/9, 46/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.305863
[4/9, 47/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.281992
[4/9, 48/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.241336
[4/9, 49/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.247341
[4/9, 50/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.310311
[4/9, 51/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.265195
[4/9, 52/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.319797
[4/9, 53/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.317324
[4/9, 54/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.272535
[4/9, 55/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.252313
[4/9, 56/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.388249
[4/9, 57/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.265090
[4/9, 58/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.277623
[4/9, 59/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.259187
[4/9, 60/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.265249
[4/9, 61/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.278015
[4/9, 62/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.262638
[4/9, 63/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.261170
[4/9, 64/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.312259
[4/9, 65/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.574947
[4/9, 66/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.437781
[4/9, 67/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.418506
[4/9, 68/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.401595
[4/9, 69/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.438737
[4/9, 70/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.495435
[4/9, 71/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.451189
[4/9, 72/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.401108
[4/9, 73/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.629268
[4/9, 74/94] Training Loss: 0.0537 - Iteration Time: 0:00:02.542775
[4/9, 75/94] Training Loss: 0.0546 - Iteration Time: 0:00:02.411219
[4/9, 76/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.859046
[4/9, 77/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.568745
[4/9, 78/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.546398
[4/9, 79/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.646205
[4/9, 80/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.508731
[4/9, 81/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.371335
[4/9, 82/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.535513
[4/9, 83/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.379793
[4/9, 84/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.380732
[4/9, 85/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.383210
[4/9, 86/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.391648
[4/9, 87/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.351974
[4/9, 88/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.379254
[4/9, 89/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.370851
[4/9, 90/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.433780
[4/9, 91/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.409017
[4/9, 92/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.360393
[4/9, 93/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.339555
[4/9, 94/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.321701
Testing - 2024-06-14 17:04:22.680425
[4/9, 1/16]
[4/9, 2/16]
[4/9, 3/16]
[4/9, 4/16]
[4/9, 5/16]
[4/9, 6/16]
[4/9, 7/16]
[4/9, 8/16]
[4/9, 9/16]
[4/9, 10/16]
[4/9, 11/16]
[4/9, 12/16]
[4/9, 13/16]
[4/9, 14/16]
[4/9, 15/16]
[4/9, 16/16]
Testing Loss: 0.0522 - Epoch Time: 0:02:20.551155
Training - 2024-06-14 17:04:34.877143
[5/9, 1/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.455150
[5/9, 2/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.284502
[5/9, 3/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.304313
[5/9, 4/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.259165
[5/9, 5/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.278080
[5/9, 6/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.249303
[5/9, 7/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.265136
[5/9, 8/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.260678
[5/9, 9/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.392417
[5/9, 10/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.273290
[5/9, 11/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.313309
[5/9, 12/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.310874
[5/9, 13/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.278096
[5/9, 14/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.308746
[5/9, 15/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.279138
[5/9, 16/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.276080
[5/9, 17/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.294056
[5/9, 18/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.313316
[5/9, 19/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.299977
[5/9, 20/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.331213
[5/9, 21/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.320269
[5/9, 22/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.565446
[5/9, 23/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.285924
[5/9, 24/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.333615
[5/9, 25/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.279073
[5/9, 26/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.243356
[5/9, 27/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.253234
[5/9, 28/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.255823
[5/9, 29/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.277574
[5/9, 30/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.312311
[5/9, 31/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.263699
[5/9, 32/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.259247
[5/9, 33/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.285625
[5/9, 34/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.323181
[5/9, 35/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.262687
[5/9, 36/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.317193
[5/9, 37/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.300365
[5/9, 38/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.280008
[5/9, 39/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.283538
[5/9, 40/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.283504
[5/9, 41/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.255327
[5/9, 42/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.248787
[5/9, 43/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.248296
[5/9, 44/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.262164
[5/9, 45/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.357404
[5/9, 46/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.284103
[5/9, 47/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.282480
[5/9, 48/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.276573
[5/9, 49/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.281020
[5/9, 50/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.283071
[5/9, 51/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.250235
[5/9, 52/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.255353
[5/9, 53/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.277048
[5/9, 54/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.297913
[5/9, 55/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.391683
[5/9, 56/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.291986
[5/9, 57/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.265161
[5/9, 58/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.259680
[5/9, 59/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.290902
[5/9, 60/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.253981
[5/9, 61/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.258188
[5/9, 62/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.290945
[5/9, 63/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.294375
[5/9, 64/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.243857
[5/9, 65/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.384795
[5/9, 66/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.482524
[5/9, 67/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.741466
[5/9, 68/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.368855
[5/9, 69/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.384308
[5/9, 70/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.371820
[5/9, 71/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.243738
[5/9, 72/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.275136
[5/9, 73/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.254809
[5/9, 74/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.288616
[5/9, 75/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.250246
[5/9, 76/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.257744
[5/9, 77/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.346520
[5/9, 78/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.299485
[5/9, 79/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.265167
[5/9, 80/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.328155
[5/9, 81/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.292560
[5/9, 82/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.254723
[5/9, 83/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.250341
[5/9, 84/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.252817
[5/9, 85/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.255308
[5/9, 86/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.286483
[5/9, 87/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.285929
[5/9, 88/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.272133
[5/9, 89/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.259303
[5/9, 90/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.294874
[5/9, 91/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.262217
[5/9, 92/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.309301
[5/9, 93/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.277571
[5/9, 94/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.252237
Testing - 2024-06-14 17:06:37.034115
[5/9, 1/16]
[5/9, 2/16]
[5/9, 3/16]
[5/9, 4/16]
[5/9, 5/16]
[5/9, 6/16]
[5/9, 7/16]
[5/9, 8/16]
[5/9, 9/16]
[5/9, 10/16]
[5/9, 11/16]
[5/9, 12/16]
[5/9, 13/16]
[5/9, 14/16]
[5/9, 15/16]
[5/9, 16/16]
Testing Loss: 0.0480 - Epoch Time: 0:02:13.858954
Training - 2024-06-14 17:06:48.736593
[6/9, 1/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.283951
[6/9, 2/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.289103
[6/9, 3/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.273620
[6/9, 4/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.334588
[6/9, 5/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.304355
[6/9, 6/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.292426
[6/9, 7/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.431947
[6/9, 8/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.353440
[6/9, 9/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.378797
[6/9, 10/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.502325
[6/9, 11/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.275579
[6/9, 12/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.266116
[6/9, 13/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.347548
[6/9, 14/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.291938
[6/9, 15/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.245395
[6/9, 16/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.246336
[6/9, 17/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.286501
[6/9, 18/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.252754
[6/9, 19/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.303945
[6/9, 20/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.262202
[6/9, 21/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.251756
[6/9, 22/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.310954
[6/9, 23/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.272135
[6/9, 24/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.279514
[6/9, 25/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.289945
[6/9, 26/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.285026
[6/9, 27/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.293381
[6/9, 28/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.262664
[6/9, 29/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.285479
[6/9, 30/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.250303
[6/9, 31/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.262187
[6/9, 32/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.317223
[6/9, 33/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.297937
[6/9, 34/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.326688
[6/9, 35/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.320759
[6/9, 36/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.267646
[6/9, 37/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.293438
[6/9, 38/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.263629
[6/9, 39/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.307883
[6/9, 40/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.288020
[6/9, 41/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.276035
[6/9, 42/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.326215
[6/9, 43/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.284076
[6/9, 44/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.266717
[6/9, 45/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.318298
[6/9, 46/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.324677
[6/9, 47/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.272626
[6/9, 48/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.275022
[6/9, 49/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.297959
[6/9, 50/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.283556
[6/9, 51/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.314852
[6/9, 52/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.275076
[6/9, 53/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.317735
[6/9, 54/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.258190
[6/9, 55/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.477577
[6/9, 56/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.560864
[6/9, 57/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.305345
[6/9, 58/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.315738
[6/9, 59/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.425940
[6/9, 60/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.326157
[6/9, 61/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.300901
[6/9, 62/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.285091
[6/9, 63/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.325270
[6/9, 64/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.257220
[6/9, 65/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.262236
[6/9, 66/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.253326
[6/9, 67/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.280498
[6/9, 68/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.297913
[6/9, 69/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.279606
[6/9, 70/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.260202
[6/9, 71/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.243320
[6/9, 72/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.284990
[6/9, 73/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.269233
[6/9, 74/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.248328
[6/9, 75/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.308342
[6/9, 76/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.309805
[6/9, 77/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.300463
[6/9, 78/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.266604
[6/9, 79/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.293415
[6/9, 80/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.264623
[6/9, 81/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.261259
[6/9, 82/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.384683
[6/9, 83/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.305323
[6/9, 84/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.314736
[6/9, 85/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.268226
[6/9, 86/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.274757
[6/9, 87/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.283975
[6/9, 88/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.266238
[6/9, 89/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.249729
[6/9, 90/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.265669
[6/9, 91/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.253232
[6/9, 92/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.297346
[6/9, 93/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.289021
[6/9, 94/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.228951
Testing - 2024-06-14 17:08:50.806069
[6/9, 1/16]
[6/9, 2/16]
[6/9, 3/16]
[6/9, 4/16]
[6/9, 5/16]
[6/9, 6/16]
[6/9, 7/16]
[6/9, 8/16]
[6/9, 9/16]
[6/9, 10/16]
[6/9, 11/16]
[6/9, 12/16]
[6/9, 13/16]
[6/9, 14/16]
[6/9, 15/16]
[6/9, 16/16]
Testing Loss: 0.0473 - Epoch Time: 0:02:13.759465
Training - 2024-06-14 17:09:02.496058
[7/9, 1/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.508847
[7/9, 2/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.333735
[7/9, 3/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.358493
[7/9, 4/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.287992
[7/9, 5/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.449670
[7/9, 6/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.312792
[7/9, 7/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.286433
[7/9, 8/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.270172
[7/9, 9/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.262668
[7/9, 10/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.305974
[7/9, 11/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.275592
[7/9, 12/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.318729
[7/9, 13/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.249267
[7/9, 14/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.318248
[7/9, 15/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.266104
[7/9, 16/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.274586
[7/9, 17/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.261702
[7/9, 18/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.299343
[7/9, 19/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.334111
[7/9, 20/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.279130
[7/9, 21/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.268764
[7/9, 22/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.290466
[7/9, 23/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.334621
[7/9, 24/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.258742
[7/9, 25/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.273108
[7/9, 26/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.278067
[7/9, 27/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.263687
[7/9, 28/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.255791
[7/9, 29/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.277045
[7/9, 30/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.338588
[7/9, 31/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.310739
[7/9, 32/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.277578
[7/9, 33/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.305785
[7/9, 34/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.286523
[7/9, 35/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.253248
[7/9, 36/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.307862
[7/9, 37/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.304941
[7/9, 38/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.269616
[7/9, 39/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.238346
[7/9, 40/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.251696
[7/9, 41/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.305394
[7/9, 42/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.255816
[7/9, 43/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.255243
[7/9, 44/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.330709
[7/9, 45/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.317303
[7/9, 46/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.461636
[7/9, 47/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.287522
[7/9, 48/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.301925
[7/9, 49/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.335610
[7/9, 50/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.252698
[7/9, 51/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.284120
[7/9, 52/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.301842
[7/9, 53/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.401621
[7/9, 54/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.263660
[7/9, 55/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.286894
[7/9, 56/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.290514
[7/9, 57/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.259668
[7/9, 58/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.291034
[7/9, 59/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.370409
[7/9, 60/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.301356
[7/9, 61/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.254860
[7/9, 62/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.252258
[7/9, 63/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.257210
[7/9, 64/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.260187
[7/9, 65/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.280020
[7/9, 66/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.284445
[7/9, 67/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.236397
[7/9, 68/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.258176
[7/9, 69/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.263159
[7/9, 70/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.319757
[7/9, 71/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.264196
[7/9, 72/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.291420
[7/9, 73/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.244793
[7/9, 74/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.249711
[7/9, 75/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.288435
[7/9, 76/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.251748
[7/9, 77/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.302370
[7/9, 78/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.271082
[7/9, 79/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.262238
[7/9, 80/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.266118
[7/9, 81/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.297879
[7/9, 82/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.285912
[7/9, 83/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.288484
[7/9, 84/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.257172
[7/9, 85/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.308277
[7/9, 86/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.267633
[7/9, 87/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.293886
[7/9, 88/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.311770
[7/9, 89/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.255182
[7/9, 90/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.276134
[7/9, 91/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.248214
[7/9, 92/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.344528
[7/9, 93/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.490887
[7/9, 94/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.225394
Testing - 2024-06-14 17:11:04.148553
[7/9, 1/16]
[7/9, 2/16]
[7/9, 3/16]
[7/9, 4/16]
[7/9, 5/16]
[7/9, 6/16]
[7/9, 7/16]
[7/9, 8/16]
[7/9, 9/16]
[7/9, 10/16]
[7/9, 11/16]
[7/9, 12/16]
[7/9, 13/16]
[7/9, 14/16]
[7/9, 15/16]
[7/9, 16/16]
Testing Loss: 0.0444 - Epoch Time: 0:02:13.193521
Training - 2024-06-14 17:11:15.689579
[8/9, 1/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.422875
[8/9, 2/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.322684
[8/9, 3/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.286973
[8/9, 4/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.272547
[8/9, 5/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.263105
[8/9, 6/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.322701
[8/9, 7/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.306786
[8/9, 8/94] Training Loss: 0.0439 - Iteration Time: 0:00:01.263603
[8/9, 9/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.259652
[8/9, 10/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.246291
[8/9, 11/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.242292
[8/9, 12/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.271073
[8/9, 13/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.289911
[8/9, 14/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.248777
[8/9, 15/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.244788
[8/9, 16/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.244751
[8/9, 17/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.320205
[8/9, 18/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.240368
[8/9, 19/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.278987
[8/9, 20/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.281003
[8/9, 21/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.267122
[8/9, 22/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.286473
[8/9, 23/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.236337
[8/9, 24/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.260188
[8/9, 25/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.315241
[8/9, 26/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.285999
[8/9, 27/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.267566
[8/9, 28/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.292408
[8/9, 29/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.290940
[8/9, 30/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.297332
[8/9, 31/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.299383
[8/9, 32/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.259142
[8/9, 33/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.284532
[8/9, 34/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.279516
[8/9, 35/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.346031
[8/9, 36/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.469072
[8/9, 37/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.294445
[8/9, 38/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.276554
[8/9, 39/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.347016
[8/9, 40/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.261199
[8/9, 41/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.257675
[8/9, 42/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.256783
[8/9, 43/94] Training Loss: 0.0427 - Iteration Time: 0:00:01.243796
[8/9, 44/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.292887
[8/9, 45/94] Training Loss: 0.0439 - Iteration Time: 0:00:01.259707
[8/9, 46/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.270165
[8/9, 47/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.250194
[8/9, 48/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.261200
[8/9, 49/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.458105
[8/9, 50/94] Training Loss: 0.0427 - Iteration Time: 0:00:01.387267
[8/9, 51/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.262168
[8/9, 52/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.260656
[8/9, 53/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.332606
[8/9, 54/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.293929
[8/9, 55/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.262169
[8/9, 56/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.257690
[8/9, 57/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.261151
[8/9, 58/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.271581
[8/9, 59/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.273096
[8/9, 60/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.287420
[8/9, 61/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.260628
[8/9, 62/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.259174
[8/9, 63/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.241805
[8/9, 64/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.251224
[8/9, 65/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.257688
[8/9, 66/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.267638
[8/9, 67/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.238317
[8/9, 68/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.265614
[8/9, 69/94] Training Loss: 0.0439 - Iteration Time: 0:00:01.280961
[8/9, 70/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.244793
[8/9, 71/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.246280
[8/9, 72/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.249731
[8/9, 73/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.275581
[8/9, 74/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.307283
[8/9, 75/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.260661
[8/9, 76/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.272554
[8/9, 77/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.251199
[8/9, 78/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.316763
[8/9, 79/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.322199
[8/9, 80/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.265080
[8/9, 81/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.296900
[8/9, 82/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.350959
[8/9, 83/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.340010
[8/9, 84/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.482950
[8/9, 85/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.342533
[8/9, 86/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.344529
[8/9, 87/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.272098
[8/9, 88/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.289447
[8/9, 89/94] Training Loss: 0.0427 - Iteration Time: 0:00:01.292881
[8/9, 90/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.339656
[8/9, 91/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.301848
[8/9, 92/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.276991
[8/9, 93/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.270098
[8/9, 94/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.249794
Testing - 2024-06-14 17:13:16.811868
[8/9, 1/16]
[8/9, 2/16]
[8/9, 3/16]
[8/9, 4/16]
[8/9, 5/16]
[8/9, 6/16]
[8/9, 7/16]
[8/9, 8/16]
[8/9, 9/16]
[8/9, 10/16]
[8/9, 11/16]
[8/9, 12/16]
[8/9, 13/16]
[8/9, 14/16]
[8/9, 15/16]
[8/9, 16/16]
Testing Loss: 0.0428 - Epoch Time: 0:02:12.798475
Training - 2024-06-14 17:13:28.488549
[9/9, 1/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.357450
[9/9, 2/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.251225
[9/9, 3/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.306328
[9/9, 4/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.413460
[9/9, 5/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.254191
[9/9, 6/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.277981
[9/9, 7/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.309857
[9/9, 8/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.291194
[9/9, 9/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.284442
[9/9, 10/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.272556
[9/9, 11/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.241326
[9/9, 12/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.274041
[9/9, 13/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.253205
[9/9, 14/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.362364
[9/9, 15/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.301878
[9/9, 16/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.270054
[9/9, 17/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.258658
[9/9, 18/94] Training Loss: 0.0403 - Iteration Time: 0:00:01.294905
[9/9, 19/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.244298
[9/9, 20/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.277980
[9/9, 21/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.284475
[9/9, 22/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.282963
[9/9, 23/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.272060
[9/9, 24/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.270094
[9/9, 25/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.343981
[9/9, 26/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.594038
[9/9, 27/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.255742
[9/9, 28/94] Training Loss: 0.0404 - Iteration Time: 0:00:01.312268
[9/9, 29/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.336527
[9/9, 30/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.319194
[9/9, 31/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.295426
[9/9, 32/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.308558
[9/9, 33/94] Training Loss: 0.0405 - Iteration Time: 0:00:01.254688
[9/9, 34/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.280026
[9/9, 35/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.266651
[9/9, 36/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.294876
[9/9, 37/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.279994
[9/9, 38/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.253257
[9/9, 39/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.270132
[9/9, 40/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.272040
[9/9, 41/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.278574
[9/9, 42/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.268054
[9/9, 43/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.248752
[9/9, 44/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.311258
[9/9, 45/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.284499
[9/9, 46/94] Training Loss: 0.0409 - Iteration Time: 0:00:01.259139
[9/9, 47/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.263678
[9/9, 48/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.268090
[9/9, 49/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.361402
[9/9, 50/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.364886
[9/9, 51/94] Training Loss: 0.0401 - Iteration Time: 0:00:01.324248
[9/9, 52/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.237869
[9/9, 53/94] Training Loss: 0.0405 - Iteration Time: 0:00:01.411512
[9/9, 54/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.282938
[9/9, 55/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.275133
[9/9, 56/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.231874
[9/9, 57/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.261116
[9/9, 58/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.246768
[9/9, 59/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.299351
[9/9, 60/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.224456
[9/9, 61/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.276009
[9/9, 62/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.316229
[9/9, 63/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.269640
[9/9, 64/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.246283
[9/9, 65/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.373245
[9/9, 66/94] Training Loss: 0.0403 - Iteration Time: 0:00:01.351472
[9/9, 67/94] Training Loss: 0.0404 - Iteration Time: 0:00:01.350464
[9/9, 68/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.267080
[9/9, 69/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.279542
[9/9, 70/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.273556
[9/9, 71/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.287944
[9/9, 72/94] Training Loss: 0.0400 - Iteration Time: 0:00:01.472582
[9/9, 73/94] Training Loss: 0.0402 - Iteration Time: 0:00:01.342837
[9/9, 74/94] Training Loss: 0.0402 - Iteration Time: 0:00:01.309206
[9/9, 75/94] Training Loss: 0.0395 - Iteration Time: 0:00:01.405614
[9/9, 76/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.327178
[9/9, 77/94] Training Loss: 0.0401 - Iteration Time: 0:00:01.267556
[9/9, 78/94] Training Loss: 0.0401 - Iteration Time: 0:00:01.263187
[9/9, 79/94] Training Loss: 0.0398 - Iteration Time: 0:00:01.279509
[9/9, 80/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.276418
[9/9, 81/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.247806
[9/9, 82/94] Training Loss: 0.0396 - Iteration Time: 0:00:01.288940
[9/9, 83/94] Training Loss: 0.0399 - Iteration Time: 0:00:01.262639
[9/9, 84/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.298351
[9/9, 85/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.292404
[9/9, 86/94] Training Loss: 0.0397 - Iteration Time: 0:00:01.281482
[9/9, 87/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.284003
[9/9, 88/94] Training Loss: 0.0402 - Iteration Time: 0:00:01.236301
[9/9, 89/94] Training Loss: 0.0389 - Iteration Time: 0:00:01.267657
[9/9, 90/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.265639
[9/9, 91/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.271579
[9/9, 92/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.313815
[9/9, 93/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.243324
[9/9, 94/94] Training Loss: 0.0381 - Iteration Time: 0:00:01.274126
Testing - 2024-06-14 17:15:30.192461
[9/9, 1/16]
[9/9, 2/16]
[9/9, 3/16]
[9/9, 4/16]
[9/9, 5/16]
[9/9, 6/16]
[9/9, 7/16]
[9/9, 8/16]
[9/9, 9/16]
[9/9, 10/16]
[9/9, 11/16]
[9/9, 12/16]
[9/9, 13/16]
[9/9, 14/16]
[9/9, 15/16]
[9/9, 16/16]
Testing Loss: 0.0397 - Epoch Time: 0:02:13.460998
Training and Testing Finished - Time: 0:20:24.660847
Assembling test data for t-sne projection
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 4
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 4
Applying t-SNE