Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 07:43:57.519350
Scaler Value: 0.05
Training - 2024-06-18 07:43:57.519847
[1/9, 10/94] Training Loss: 1.8465 - Iteration Time: 0:00:01.466777
[1/9, 20/94] Training Loss: 1.7186 - Iteration Time: 0:00:01.501298
[1/9, 30/94] Training Loss: 1.6409 - Iteration Time: 0:00:01.380729
[1/9, 40/94] Training Loss: 1.6075 - Iteration Time: 0:00:02.203299
[1/9, 50/94] Training Loss: 1.5858 - Iteration Time: 0:00:01.472126
[1/9, 60/94] Training Loss: 1.5717 - Iteration Time: 0:00:01.472560
[1/9, 70/94] Training Loss: 1.5585 - Iteration Time: 0:00:01.405009
[1/9, 80/94] Training Loss: 1.5411 - Iteration Time: 0:00:01.454193
[1/9, 90/94] Training Loss: 1.5165 - Iteration Time: 0:00:01.438252
Testing - 2024-06-18 07:46:19.834948
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 1.5007 - Epoch Time: 0:02:36.097117
Training - 2024-06-18 07:46:33.617460
[2/9, 10/94] Training Loss: 1.4856 - Iteration Time: 0:00:01.398083
[2/9, 20/94] Training Loss: 1.4759 - Iteration Time: 0:00:01.508707
[2/9, 30/94] Training Loss: 1.4638 - Iteration Time: 0:00:01.421351
[2/9, 40/94] Training Loss: 1.4461 - Iteration Time: 0:00:01.437240
[2/9, 50/94] Training Loss: 1.4224 - Iteration Time: 0:00:01.401535
[2/9, 60/94] Training Loss: 1.4000 - Iteration Time: 0:00:01.497333
[2/9, 70/94] Training Loss: 1.3849 - Iteration Time: 0:00:01.394658
[2/9, 80/94] Training Loss: 1.3694 - Iteration Time: 0:00:01.405984
[2/9, 90/94] Training Loss: 1.3473 - Iteration Time: 0:00:01.417402
Testing - 2024-06-18 07:48:49.515594
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 1.3305 - Epoch Time: 0:02:29.614072
Training - 2024-06-18 07:49:03.232029
[3/9, 10/94] Training Loss: 1.3214 - Iteration Time: 0:00:01.448153
[3/9, 20/94] Training Loss: 1.3076 - Iteration Time: 0:00:01.390178
[3/9, 30/94] Training Loss: 1.2938 - Iteration Time: 0:00:01.418903
[3/9, 40/94] Training Loss: 1.2764 - Iteration Time: 0:00:01.480921
[3/9, 50/94] Training Loss: 1.2599 - Iteration Time: 0:00:01.422902
[3/9, 60/94] Training Loss: 1.2479 - Iteration Time: 0:00:01.420871
[3/9, 70/94] Training Loss: 1.2374 - Iteration Time: 0:00:01.445746
[3/9, 80/94] Training Loss: 1.2257 - Iteration Time: 0:00:01.406039
[3/9, 90/94] Training Loss: 1.2141 - Iteration Time: 0:00:01.467516
Testing - 2024-06-18 07:51:19.513617
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 1.2084 - Epoch Time: 0:02:29.813958
Training - 2024-06-18 07:51:33.045987
[4/9, 10/94] Training Loss: 1.2012 - Iteration Time: 0:00:01.454145
[4/9, 20/94] Training Loss: 1.1957 - Iteration Time: 0:00:01.519159
[4/9, 30/94] Training Loss: 1.1901 - Iteration Time: 0:00:01.650114
[4/9, 40/94] Training Loss: 1.1830 - Iteration Time: 0:00:01.437333
[4/9, 50/94] Training Loss: 1.1731 - Iteration Time: 0:00:01.438490
[4/9, 60/94] Training Loss: 1.1671 - Iteration Time: 0:00:01.427308
[4/9, 70/94] Training Loss: 1.1556 - Iteration Time: 0:00:01.466554
[4/9, 80/94] Training Loss: 1.1428 - Iteration Time: 0:00:01.448722
[4/9, 90/94] Training Loss: 1.1296 - Iteration Time: 0:00:01.435254
Testing - 2024-06-18 07:53:49.584453
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 1.1198 - Epoch Time: 0:02:30.182079
Training - 2024-06-18 07:54:03.228562
[5/9, 10/94] Training Loss: 1.1128 - Iteration Time: 0:00:01.384694
[5/9, 20/94] Training Loss: 1.1018 - Iteration Time: 0:00:01.377223
[5/9, 30/94] Training Loss: 1.0968 - Iteration Time: 0:00:01.408524
[5/9, 40/94] Training Loss: 1.0882 - Iteration Time: 0:00:01.513196
[5/9, 50/94] Training Loss: 1.0775 - Iteration Time: 0:00:01.442225
[5/9, 60/94] Training Loss: 1.0701 - Iteration Time: 0:00:01.440736
[5/9, 70/94] Training Loss: 1.0630 - Iteration Time: 0:00:01.397581
[5/9, 80/94] Training Loss: 1.0584 - Iteration Time: 0:00:01.438562
[5/9, 90/94] Training Loss: 1.0508 - Iteration Time: 0:00:01.395575
Testing - 2024-06-18 07:56:18.376651
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 1.0459 - Epoch Time: 0:02:28.525904
Training - 2024-06-18 07:56:31.754962
[6/9, 10/94] Training Loss: 1.0401 - Iteration Time: 0:00:01.404019
[6/9, 20/94] Training Loss: 1.0368 - Iteration Time: 0:00:01.420396
[6/9, 30/94] Training Loss: 1.0281 - Iteration Time: 0:00:01.468995
[6/9, 40/94] Training Loss: 1.0199 - Iteration Time: 0:00:01.415914
[6/9, 50/94] Training Loss: 1.0112 - Iteration Time: 0:00:01.489390
[6/9, 60/94] Training Loss: 1.0055 - Iteration Time: 0:00:01.383161
[6/9, 70/94] Training Loss: 0.9971 - Iteration Time: 0:00:01.410967
[6/9, 80/94] Training Loss: 0.9915 - Iteration Time: 0:00:01.539008
[6/9, 90/94] Training Loss: 0.9845 - Iteration Time: 0:00:01.412939
Testing - 2024-06-18 07:58:47.059015
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.9817 - Epoch Time: 0:02:28.785141
Training - 2024-06-18 07:59:00.540599
[7/9, 10/94] Training Loss: 0.9753 - Iteration Time: 0:00:01.402524
[7/9, 20/94] Training Loss: 0.9712 - Iteration Time: 0:00:01.418442
[7/9, 30/94] Training Loss: 0.9659 - Iteration Time: 0:00:01.396595
[7/9, 40/94] Training Loss: 0.9589 - Iteration Time: 0:00:01.422366
[7/9, 50/94] Training Loss: 0.9531 - Iteration Time: 0:00:01.411509
[7/9, 60/94] Training Loss: 0.9425 - Iteration Time: 0:00:01.539994
[7/9, 70/94] Training Loss: 0.9288 - Iteration Time: 0:00:01.599521
[7/9, 80/94] Training Loss: 0.9217 - Iteration Time: 0:00:01.412925
[7/9, 90/94] Training Loss: 0.9175 - Iteration Time: 0:00:01.402197
Testing - 2024-06-18 08:01:16.386715
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.9166 - Epoch Time: 0:02:29.356800
Training - 2024-06-18 08:01:29.897399
[8/9, 10/94] Training Loss: 0.9113 - Iteration Time: 0:00:01.405520
[8/9, 20/94] Training Loss: 0.9003 - Iteration Time: 0:00:01.411510
[8/9, 30/94] Training Loss: 0.8925 - Iteration Time: 0:00:01.407589
[8/9, 40/94] Training Loss: 0.8885 - Iteration Time: 0:00:01.705138
[8/9, 50/94] Training Loss: 0.8874 - Iteration Time: 0:00:01.489893
[8/9, 60/94] Training Loss: 0.8850 - Iteration Time: 0:00:01.439326
[8/9, 70/94] Training Loss: 0.8805 - Iteration Time: 0:00:01.423414
[8/9, 80/94] Training Loss: 0.8772 - Iteration Time: 0:00:01.437300
[8/9, 90/94] Training Loss: 0.8709 - Iteration Time: 0:00:01.449719
Testing - 2024-06-18 08:03:45.615728
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.8688 - Epoch Time: 0:02:29.159375
Training - 2024-06-18 08:03:59.056774
[9/9, 10/94] Training Loss: 0.8644 - Iteration Time: 0:00:01.672946
[9/9, 20/94] Training Loss: 0.8625 - Iteration Time: 0:00:01.452124
[9/9, 30/94] Training Loss: 0.8588 - Iteration Time: 0:00:01.439784
[9/9, 40/94] Training Loss: 0.8549 - Iteration Time: 0:00:01.403047
[9/9, 50/94] Training Loss: 0.8542 - Iteration Time: 0:00:01.426831
[9/9, 60/94] Training Loss: 0.8521 - Iteration Time: 0:00:01.464541
[9/9, 70/94] Training Loss: 0.8497 - Iteration Time: 0:00:01.442268
[9/9, 80/94] Training Loss: 0.8447 - Iteration Time: 0:00:01.380691
[9/9, 90/94] Training Loss: 0.8423 - Iteration Time: 0:00:01.438797
Testing - 2024-06-18 08:06:16.522238
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.8435 - Epoch Time: 0:02:31.492556
Training and Testing Finished - Time: 0:22:33.029980
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0    1      2      3      4  ...     94     95   96   97   98   99
0       2  0.0  0.0  0.185  0.290  0.420  ...  0.045  0.140  0.0  0.0  0.0  0.0
1       4  0.0  0.0  0.265  0.330  0.355  ...  0.075  0.170  0.0  0.0  0.0  0.0
2       7  0.0  0.0  0.220  0.290  0.410  ...  0.095  0.065  0.0  0.0  0.0  0.0
3       3  0.0  0.0  0.260  0.255  0.435  ...  0.090  0.115  0.0  0.0  0.0  0.0
4       7  0.0  0.0  0.245  0.275  0.420  ...  0.075  0.145  0.0  0.0  0.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP