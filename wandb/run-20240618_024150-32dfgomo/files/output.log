Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 02:41:51.577590
Scaler Value: 0.03333333333333333
Training - 2024-06-18 02:41:51.578581
[1/9, 10/94] Training Loss: 0.5551 - Iteration Time: 0:00:01.464581
[1/9, 20/94] Training Loss: 0.5326 - Iteration Time: 0:00:01.396721
[1/9, 30/94] Training Loss: 0.5228 - Iteration Time: 0:00:01.379166
[1/9, 40/94] Training Loss: 0.5157 - Iteration Time: 0:00:01.408974
[1/9, 50/94] Training Loss: 0.5088 - Iteration Time: 0:00:01.435710
[1/9, 60/94] Training Loss: 0.5024 - Iteration Time: 0:00:01.404159
[1/9, 70/94] Training Loss: 0.4939 - Iteration Time: 0:00:01.431815
[1/9, 80/94] Training Loss: 0.4923 - Iteration Time: 0:00:01.402001
[1/9, 90/94] Training Loss: 0.4867 - Iteration Time: 0:00:01.467054
Testing - 2024-06-18 02:44:07.055810
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.4716 - Epoch Time: 0:02:28.997926
Training - 2024-06-18 02:44:20.576507
[2/9, 10/94] Training Loss: 0.4851 - Iteration Time: 0:00:01.425830
[2/9, 20/94] Training Loss: 0.4742 - Iteration Time: 0:00:01.470487
[2/9, 30/94] Training Loss: 0.4704 - Iteration Time: 0:00:01.452121
[2/9, 40/94] Training Loss: 0.4656 - Iteration Time: 0:00:01.402550
[2/9, 50/94] Training Loss: 0.4581 - Iteration Time: 0:00:01.425388
[2/9, 60/94] Training Loss: 0.4566 - Iteration Time: 0:00:01.423380
[2/9, 70/94] Training Loss: 0.4492 - Iteration Time: 0:00:01.474931
[2/9, 80/94] Training Loss: 0.4402 - Iteration Time: 0:00:01.405570
[2/9, 90/94] Training Loss: 0.4378 - Iteration Time: 0:00:01.402546
Testing - 2024-06-18 02:46:36.645790
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.4269 - Epoch Time: 0:02:29.394907
Training - 2024-06-18 02:46:49.971911
[3/9, 10/94] Training Loss: 0.4298 - Iteration Time: 0:00:01.455117
[3/9, 20/94] Training Loss: 0.4286 - Iteration Time: 0:00:01.391625
[3/9, 30/94] Training Loss: 0.4185 - Iteration Time: 0:00:01.423856
[3/9, 40/94] Training Loss: 0.4125 - Iteration Time: 0:00:01.416932
[3/9, 50/94] Training Loss: 0.4071 - Iteration Time: 0:00:01.697725
[3/9, 60/94] Training Loss: 0.3989 - Iteration Time: 0:00:01.563303
[3/9, 70/94] Training Loss: 0.3901 - Iteration Time: 0:00:01.402529
[3/9, 80/94] Training Loss: 0.3878 - Iteration Time: 0:00:01.391577
[3/9, 90/94] Training Loss: 0.3844 - Iteration Time: 0:00:01.376728
Testing - 2024-06-18 02:49:05.182747
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.3747 - Epoch Time: 0:02:28.641715
Training - 2024-06-18 02:49:18.613626
[4/9, 10/94] Training Loss: 0.3764 - Iteration Time: 0:00:01.407528
[4/9, 20/94] Training Loss: 0.3762 - Iteration Time: 0:00:01.375721
[4/9, 30/94] Training Loss: 0.3709 - Iteration Time: 0:00:01.465027
[4/9, 40/94] Training Loss: 0.3634 - Iteration Time: 0:00:01.403501
[4/9, 50/94] Training Loss: 0.3590 - Iteration Time: 0:00:01.405994
[4/9, 60/94] Training Loss: 0.3561 - Iteration Time: 0:00:01.488358
[4/9, 70/94] Training Loss: 0.3559 - Iteration Time: 0:00:01.428319
[4/9, 80/94] Training Loss: 0.3515 - Iteration Time: 0:00:01.405994
[4/9, 90/94] Training Loss: 0.3475 - Iteration Time: 0:00:01.409462
Testing - 2024-06-18 02:51:34.156241
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.3417 - Epoch Time: 0:02:28.883475
Training - 2024-06-18 02:51:47.497101
[5/9, 10/94] Training Loss: 0.3431 - Iteration Time: 0:00:01.586593
[5/9, 20/94] Training Loss: 0.3413 - Iteration Time: 0:00:01.386148
[5/9, 30/94] Training Loss: 0.3360 - Iteration Time: 0:00:01.405088
[5/9, 40/94] Training Loss: 0.3339 - Iteration Time: 0:00:01.402548
[5/9, 50/94] Training Loss: 0.3329 - Iteration Time: 0:00:01.390099
[5/9, 60/94] Training Loss: 0.3313 - Iteration Time: 0:00:01.424883
[5/9, 70/94] Training Loss: 0.3300 - Iteration Time: 0:00:01.437246
[5/9, 80/94] Training Loss: 0.3265 - Iteration Time: 0:00:01.457148
[5/9, 90/94] Training Loss: 0.3256 - Iteration Time: 0:00:01.400056
Testing - 2024-06-18 02:54:03.421246
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.3215 - Epoch Time: 0:02:29.270222
Training - 2024-06-18 02:54:16.767820
[6/9, 10/94] Training Loss: 0.3240 - Iteration Time: 0:00:01.445173
[6/9, 20/94] Training Loss: 0.3215 - Iteration Time: 0:00:01.408509
[6/9, 30/94] Training Loss: 0.3199 - Iteration Time: 0:00:01.411466
[6/9, 40/94] Training Loss: 0.3195 - Iteration Time: 0:00:01.400011
[6/9, 50/94] Training Loss: 0.3153 - Iteration Time: 0:00:01.440737
[6/9, 60/94] Training Loss: 0.3117 - Iteration Time: 0:00:01.408513
[6/9, 70/94] Training Loss: 0.3104 - Iteration Time: 0:00:01.409457
[6/9, 80/94] Training Loss: 0.3088 - Iteration Time: 0:00:01.400561
[6/9, 90/94] Training Loss: 0.3075 - Iteration Time: 0:00:01.504789
Testing - 2024-06-18 02:56:32.023763
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.2994 - Epoch Time: 0:02:28.636076
Training - 2024-06-18 02:56:45.403896
[7/9, 10/94] Training Loss: 0.3032 - Iteration Time: 0:00:01.425894
[7/9, 20/94] Training Loss: 0.3022 - Iteration Time: 0:00:01.560259
[7/9, 30/94] Training Loss: 0.3005 - Iteration Time: 0:00:01.401578
[7/9, 40/94] Training Loss: 0.2974 - Iteration Time: 0:00:01.402052
[7/9, 50/94] Training Loss: 0.2968 - Iteration Time: 0:00:01.439297
[7/9, 60/94] Training Loss: 0.2924 - Iteration Time: 0:00:01.428344
[7/9, 70/94] Training Loss: 0.2926 - Iteration Time: 0:00:01.490844
[7/9, 80/94] Training Loss: 0.2901 - Iteration Time: 0:00:01.388246
[7/9, 90/94] Training Loss: 0.2886 - Iteration Time: 0:00:01.420017
Testing - 2024-06-18 02:59:01.563956
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.2804 - Epoch Time: 0:02:32.198812
Training - 2024-06-18 02:59:17.603204
[8/9, 10/94] Training Loss: 0.2863 - Iteration Time: 0:00:01.467480
[8/9, 20/94] Training Loss: 0.2841 - Iteration Time: 0:00:01.464045
[8/9, 30/94] Training Loss: 0.2829 - Iteration Time: 0:00:01.472522
[8/9, 40/94] Training Loss: 0.2796 - Iteration Time: 0:00:01.443723
[8/9, 50/94] Training Loss: 0.2780 - Iteration Time: 0:00:01.451630
[8/9, 60/94] Training Loss: 0.2777 - Iteration Time: 0:00:01.406731
[8/9, 70/94] Training Loss: 0.2749 - Iteration Time: 0:00:01.631759
[8/9, 80/94] Training Loss: 0.2734 - Iteration Time: 0:00:01.406008
[8/9, 90/94] Training Loss: 0.2712 - Iteration Time: 0:00:01.402014
Testing - 2024-06-18 03:01:36.029651
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.2661 - Epoch Time: 0:02:31.757892
Training - 2024-06-18 03:01:49.361592
[9/9, 10/94] Training Loss: 0.2682 - Iteration Time: 0:00:01.567758
[9/9, 20/94] Training Loss: 0.2676 - Iteration Time: 0:00:01.421901
[9/9, 30/94] Training Loss: 0.2665 - Iteration Time: 0:00:01.424386
[9/9, 40/94] Training Loss: 0.2643 - Iteration Time: 0:00:01.405034
[9/9, 50/94] Training Loss: 0.2636 - Iteration Time: 0:00:01.554402
[9/9, 60/94] Training Loss: 0.2649 - Iteration Time: 0:00:01.428823
[9/9, 70/94] Training Loss: 0.2631 - Iteration Time: 0:00:01.455094
[9/9, 80/94] Training Loss: 0.2614 - Iteration Time: 0:00:01.502279
[9/9, 90/94] Training Loss: 0.2641 - Iteration Time: 0:00:01.402539
Testing - 2024-06-18 03:04:05.381904
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.2576 - Epoch Time: 0:02:29.531171
Training and Testing Finished - Time: 0:22:27.315669
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels      0      1      2    3    4  ...     94   95   96   97     98   99
0       2  0.290  0.200  0.295  0.0  0.0  ...  0.110  0.0  0.0  0.0  0.155  0.0
1       4  0.280  0.215  0.210  0.0  0.0  ...  0.125  0.0  0.0  0.0  0.075  0.0
2       7  0.295  0.200  0.315  0.0  0.0  ...  0.165  0.0  0.0  0.0  0.065  0.0
3       3  0.060  0.200  0.135  0.0  0.0  ...  0.120  0.0  0.0  0.0  0.080  0.0
4       7  0.175  0.225  0.265  0.0  0.0  ...  0.225  0.0  0.0  0.0  0.155  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP