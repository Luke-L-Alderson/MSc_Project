Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-14 11:41:29.362439
Scaler Value: 0.013513513513513514
Training - 2024-06-14 11:41:29.363429
[1/9, 10/94] Training Loss: 0.0699 - Iteration Time: 0:00:14.384066
[1/9, 20/94] Training Loss: 0.0682 - Iteration Time: 0:00:14.373108
[1/9, 30/94] Training Loss: 0.0685 - Iteration Time: 0:00:10.744419
[1/9, 40/94] Training Loss: 0.0686 - Iteration Time: 0:00:06.445209
[1/9, 50/94] Training Loss: 0.0681 - Iteration Time: 0:00:06.993574
[1/9, 60/94] Training Loss: 0.0673 - Iteration Time: 0:00:07.581739
[1/9, 70/94] Training Loss: 0.0667 - Iteration Time: 0:00:06.182487
[1/9, 80/94] Training Loss: 0.0669 - Iteration Time: 0:00:06.152467
[1/9, 90/94] Training Loss: 0.0661 - Iteration Time: 0:00:08.157064
Testing - 2024-06-14 11:55:13.646524
[1/9, 10/16]
Testing Loss: 0.0636 - Epoch Time: 0:14:12.575263
Training - 2024-06-14 11:55:41.939189
[2/9, 10/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.426826
[2/9, 20/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.444242
[2/9, 30/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.494206
[2/9, 40/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.437548
[2/9, 50/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.413881
[2/9, 60/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.437848
[2/9, 70/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.376918
[2/9, 80/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.395935
[2/9, 90/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.427793
Testing - 2024-06-14 11:58:01.580737
[2/9, 10/16]
Testing Loss: 0.0589 - Epoch Time: 0:02:32.420389
Training - 2024-06-14 11:58:14.360073
[3/9, 10/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.488629
[3/9, 20/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.390975
[3/9, 30/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.382468
[3/9, 40/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.426445
[3/9, 50/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.383246
[3/9, 60/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.434000
[3/9, 70/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.385533
[3/9, 80/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.441316
[3/9, 90/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.470104
Testing - 2024-06-14 12:00:31.087061
[3/9, 10/16]
Testing Loss: 0.0567 - Epoch Time: 0:02:29.391544
Training - 2024-06-14 12:00:43.752610
[4/9, 10/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.417862
[4/9, 20/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.417112
[4/9, 30/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.378949
[4/9, 40/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.406630
[4/9, 50/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.554864
[4/9, 60/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.387198
[4/9, 70/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.478639
[4/9, 80/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.398123
[4/9, 90/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.438078
Testing - 2024-06-14 12:02:59.082233
[4/9, 10/16]
Testing Loss: 0.0525 - Epoch Time: 0:02:28.747732
Training - 2024-06-14 12:03:12.500838
[5/9, 10/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.519574
[5/9, 20/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.371266
[5/9, 30/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.452758
[5/9, 40/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.421061
[5/9, 50/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.375492
[5/9, 60/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.458314
[5/9, 70/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.447306
[5/9, 80/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.420595
[5/9, 90/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.413371
Testing - 2024-06-14 12:05:30.881843
[5/9, 10/16]
Testing Loss: 0.0490 - Epoch Time: 0:02:31.311247
Training - 2024-06-14 12:05:43.812581
[6/9, 10/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.458115
[6/9, 20/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.504764
[6/9, 30/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.524034
[6/9, 40/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.523208
[6/9, 50/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.619162
[6/9, 60/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.567962
[6/9, 70/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.462942
[6/9, 80/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.459208
[6/9, 90/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.406653
Testing - 2024-06-14 12:08:04.600241
[6/9, 10/16]
Testing Loss: 0.0453 - Epoch Time: 0:02:33.527723
Training - 2024-06-14 12:08:17.340798
[7/9, 10/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.489941
[7/9, 20/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.402325
[7/9, 30/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.836512
[7/9, 40/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.412223
[7/9, 50/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.477096
[7/9, 60/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.413501
[7/9, 70/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.439733
[7/9, 80/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.422888
[7/9, 90/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.433379
Testing - 2024-06-14 12:10:34.995637
[7/9, 10/16]
Testing Loss: 0.0429 - Epoch Time: 0:02:30.487681
Training - 2024-06-14 12:10:47.828976
[8/9, 10/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.480626
[8/9, 20/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.428532
[8/9, 30/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.425836
[8/9, 40/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.407806
[8/9, 50/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.510331
[8/9, 60/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.556011
[8/9, 70/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.382326
[8/9, 80/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.416839
[8/9, 90/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.504274
Testing - 2024-06-14 12:13:05.663320
[8/9, 10/16]
Testing Loss: 0.0406 - Epoch Time: 0:02:30.375522
Training - 2024-06-14 12:13:18.204994
[9/9, 10/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.421823
[9/9, 20/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.414035
[9/9, 30/94] Training Loss: 0.0409 - Iteration Time: 0:00:01.687547
[9/9, 40/94] Training Loss: 0.0407 - Iteration Time: 0:00:01.439153
[9/9, 50/94] Training Loss: 0.0407 - Iteration Time: 0:00:01.404823
[9/9, 60/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.458227
[9/9, 70/94] Training Loss: 0.0402 - Iteration Time: 0:00:01.462667
[9/9, 80/94] Training Loss: 0.0396 - Iteration Time: 0:00:01.428576
[9/9, 90/94] Training Loss: 0.0398 - Iteration Time: 0:00:01.457761
Testing - 2024-06-14 12:15:35.080743
[9/9, 10/16]
Testing Loss: 0.0390 - Epoch Time: 0:02:29.387714
Training and Testing Finished - Time: 0:34:18.231788
Assembling test data for t-sne projection
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 4
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 4
Applying t-SNE