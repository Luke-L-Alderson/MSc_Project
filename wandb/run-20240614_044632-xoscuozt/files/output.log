Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-14 04:46:33.877997
Scaler Value: 1000
Training - 2024-06-14 04:46:33.878492
[1/9, 10/94] Training Loss: 29348.89 - Iteration Time: 0:00:01.289594
[1/9, 20/94] Training Loss: 27536.45 - Iteration Time: 0:00:01.351642
[1/9, 30/94] Training Loss: 26527.37 - Iteration Time: 0:00:01.265406
[1/9, 40/94] Training Loss: 25881.58 - Iteration Time: 0:00:01.357621
[1/9, 50/94] Training Loss: 25389.61 - Iteration Time: 0:00:01.291541
[1/9, 60/94] Training Loss: 24961.77 - Iteration Time: 0:00:01.313447
[1/9, 70/94] Training Loss: 24639.78 - Iteration Time: 0:00:01.330952
[1/9, 80/94] Training Loss: 24395.37 - Iteration Time: 0:00:01.276297
[1/9, 90/94] Training Loss: 24093.62 - Iteration Time: 0:00:01.286653
Testing - 2024-06-14 04:48:40.336525
[1/9, 10/16]
Testing Loss: 23758.48 - Epoch Time: 0:02:18.281111
Training - 2024-06-14 04:48:52.160099
[2/9, 10/94] Training Loss: 23654.91 - Iteration Time: 0:00:01.369436
[2/9, 20/94] Training Loss: 23476.26 - Iteration Time: 0:00:01.320842
[2/9, 30/94] Training Loss: 23239.14 - Iteration Time: 0:00:01.273246
[2/9, 40/94] Training Loss: 22830.07 - Iteration Time: 0:00:01.282677
[2/9, 50/94] Training Loss: 22519.14 - Iteration Time: 0:00:01.276228
[2/9, 60/94] Training Loss: 22273.83 - Iteration Time: 0:00:01.292558
[2/9, 70/94] Training Loss: 21854.90 - Iteration Time: 0:00:01.282687
[2/9, 80/94] Training Loss: 21487.13 - Iteration Time: 0:00:01.285622
[2/9, 90/94] Training Loss: 21266.73 - Iteration Time: 0:00:01.308933
Testing - 2024-06-14 04:50:57.159982
[2/9, 10/16]
Testing Loss: 21039.17 - Epoch Time: 0:02:17.097458
Training - 2024-06-14 04:51:09.258556
[3/9, 10/94] Training Loss: 20963.10 - Iteration Time: 0:00:01.333799
[3/9, 20/94] Training Loss: 20801.07 - Iteration Time: 0:00:01.347185
[3/9, 30/94] Training Loss: 20569.03 - Iteration Time: 0:00:01.300670
[3/9, 40/94] Training Loss: 20368.15 - Iteration Time: 0:00:01.472701
[3/9, 50/94] Training Loss: 20271.70 - Iteration Time: 0:00:01.311478
[3/9, 60/94] Training Loss: 20041.66 - Iteration Time: 0:00:01.312514
[3/9, 70/94] Training Loss: 19812.87 - Iteration Time: 0:00:01.293618
[3/9, 80/94] Training Loss: 19689.25 - Iteration Time: 0:00:01.336722
[3/9, 90/94] Training Loss: 19573.12 - Iteration Time: 0:00:01.306497
Testing - 2024-06-14 04:53:15.038755
[3/9, 10/16]
Testing Loss: 19425.08 - Epoch Time: 0:02:17.621206
Training - 2024-06-14 04:53:26.880258
[4/9, 10/94] Training Loss: 19339.10 - Iteration Time: 0:00:01.267278
[4/9, 20/94] Training Loss: 19109.91 - Iteration Time: 0:00:01.264853
[4/9, 30/94] Training Loss: 18854.02 - Iteration Time: 0:00:01.276253
[4/9, 40/94] Training Loss: 18637.67 - Iteration Time: 0:00:01.286207
[4/9, 50/94] Training Loss: 18353.12 - Iteration Time: 0:00:01.329325
[4/9, 60/94] Training Loss: 18099.91 - Iteration Time: 0:00:01.292600
[4/9, 70/94] Training Loss: 17842.08 - Iteration Time: 0:00:01.341694
[4/9, 80/94] Training Loss: 17587.30 - Iteration Time: 0:00:01.308436
[4/9, 90/94] Training Loss: 17396.29 - Iteration Time: 0:00:01.316895
Testing - 2024-06-14 04:55:32.390730
[4/9, 10/16]
Testing Loss: 17214.96 - Epoch Time: 0:02:17.575418
Training - 2024-06-14 04:55:44.455676
[5/9, 10/94] Training Loss: 17147.12 - Iteration Time: 0:00:01.283670
[5/9, 20/94] Training Loss: 16980.77 - Iteration Time: 0:00:01.307446
[5/9, 30/94] Training Loss: 16831.92 - Iteration Time: 0:00:01.291221
[5/9, 40/94] Training Loss: 16748.82 - Iteration Time: 0:00:01.327848
[5/9, 50/94] Training Loss: 16602.40 - Iteration Time: 0:00:01.354466
[5/9, 60/94] Training Loss: 16514.44 - Iteration Time: 0:00:01.328847
[5/9, 70/94] Training Loss: 16341.50 - Iteration Time: 0:00:01.280699
[5/9, 80/94] Training Loss: 16134.22 - Iteration Time: 0:00:01.251844
[5/9, 90/94] Training Loss: 16012.14 - Iteration Time: 0:00:01.298526
Testing - 2024-06-14 04:57:50.749600
[5/9, 10/16]
Testing Loss: 15906.10 - Epoch Time: 0:02:18.492381
Training - 2024-06-14 04:58:02.948554
[6/9, 10/94] Training Loss: 15847.27 - Iteration Time: 0:00:01.295495
[6/9, 20/94] Training Loss: 15707.66 - Iteration Time: 0:00:01.289148
[6/9, 30/94] Training Loss: 15434.45 - Iteration Time: 0:00:01.277140
[6/9, 40/94] Training Loss: 15265.34 - Iteration Time: 0:00:01.253872
[6/9, 50/94] Training Loss: 15144.86 - Iteration Time: 0:00:01.291589
[6/9, 60/94] Training Loss: 15039.85 - Iteration Time: 0:00:01.340719
[6/9, 70/94] Training Loss: 14813.62 - Iteration Time: 0:00:01.324704
[6/9, 80/94] Training Loss: 14648.95 - Iteration Time: 0:00:01.281126
[6/9, 90/94] Training Loss: 14392.28 - Iteration Time: 0:00:01.508851
Testing - 2024-06-14 05:00:07.958476
[6/9, 10/16]
Testing Loss: 14246.76 - Epoch Time: 0:02:16.914501
Training - 2024-06-14 05:00:19.863551
[7/9, 10/94] Training Loss: 14210.41 - Iteration Time: 0:00:01.296994
[7/9, 20/94] Training Loss: 14070.22 - Iteration Time: 0:00:01.299956
[7/9, 30/94] Training Loss: 13941.42 - Iteration Time: 0:00:01.374461
[7/9, 40/94] Training Loss: 13788.06 - Iteration Time: 0:00:01.285560
[7/9, 50/94] Training Loss: 13718.53 - Iteration Time: 0:00:01.293508
[7/9, 60/94] Training Loss: 13663.41 - Iteration Time: 0:00:01.295979
[7/9, 70/94] Training Loss: 13629.69 - Iteration Time: 0:00:01.312351
[7/9, 80/94] Training Loss: 13574.87 - Iteration Time: 0:00:01.310938
[7/9, 90/94] Training Loss: 13429.04 - Iteration Time: 0:00:01.333168
Testing - 2024-06-14 05:02:25.622934
[7/9, 10/16]
Testing Loss: 13301.23 - Epoch Time: 0:02:18.424800
Training - 2024-06-14 05:02:38.288847
[8/9, 10/94] Training Loss: 13262.23 - Iteration Time: 0:00:01.293004
[8/9, 20/94] Training Loss: 13132.62 - Iteration Time: 0:00:01.404213
[8/9, 30/94] Training Loss: 13071.22 - Iteration Time: 0:00:01.321313
[8/9, 40/94] Training Loss: 13002.99 - Iteration Time: 0:00:01.288535
[8/9, 50/94] Training Loss: 12980.08 - Iteration Time: 0:00:01.323273
[8/9, 60/94] Training Loss: 12921.42 - Iteration Time: 0:00:01.306440
[8/9, 70/94] Training Loss: 12847.29 - Iteration Time: 0:00:01.380361
[8/9, 80/94] Training Loss: 12726.87 - Iteration Time: 0:00:01.318777
[8/9, 90/94] Training Loss: 12545.73 - Iteration Time: 0:00:01.285065
Testing - 2024-06-14 05:04:44.531174
[8/9, 10/16]
Testing Loss: 12491.18 - Epoch Time: 0:02:18.169059
Training - 2024-06-14 05:04:56.458402
[9/9, 10/94] Training Loss: 12490.38 - Iteration Time: 0:00:01.296503
[9/9, 20/94] Training Loss: 12463.84 - Iteration Time: 0:00:01.318906
[9/9, 30/94] Training Loss: 12426.48 - Iteration Time: 0:00:01.309373
[9/9, 40/94] Training Loss: 12372.37 - Iteration Time: 0:00:01.382316
[9/9, 50/94] Training Loss: 12302.10 - Iteration Time: 0:00:01.467265
[9/9, 60/94] Training Loss: 12255.20 - Iteration Time: 0:00:01.457936
[9/9, 70/94] Training Loss: 12248.47 - Iteration Time: 0:00:01.472666
[9/9, 80/94] Training Loss: 12215.89 - Iteration Time: 0:00:01.474116
[9/9, 90/94] Training Loss: 12156.14 - Iteration Time: 0:00:01.460699
Testing - 2024-06-14 05:07:12.770204
[9/9, 10/16]
Testing Loss: 12113.77 - Epoch Time: 0:02:29.664712
Training and Testing Finished - Time: 0:20:52.246110
Assembling test data for t-sne projection
-- 1/16 --
-- 2/16 --
-- 3/16 --
-- 4/16 --
-- 5/16 --
-- 6/16 --
-- 7/16 --
-- 8/16 --
-- 9/16 --
-- 10/16 --
-- 11/16 --
-- 12/16 --
-- 13/16 --
-- 14/16 --
-- 15/16 --
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2