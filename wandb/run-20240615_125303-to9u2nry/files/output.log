Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-15 12:53:05.023636
Scaler Value: 0.013513513513513514
Training - 2024-06-15 12:53:05.024132
[1/9, 1/94] Training Loss: 0.0694 - Iteration Time: 0:00:01.873116
[1/9, 2/94] Training Loss: 0.0699 - Iteration Time: 0:00:01.476024
[1/9, 3/94] Training Loss: 0.0716 - Iteration Time: 0:00:01.428878
[1/9, 4/94] Training Loss: 0.0715 - Iteration Time: 0:00:01.471022
[1/9, 5/94] Training Loss: 0.0703 - Iteration Time: 0:00:01.467575
[1/9, 6/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.448296
[1/9, 7/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.459086
[1/9, 8/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.433816
[1/9, 9/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.429853
[1/9, 10/94] Training Loss: 0.0708 - Iteration Time: 0:00:01.411461
[1/9, 11/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.414431
[1/9, 12/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.511205
[1/9, 13/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.422925
[1/9, 14/94] Training Loss: 0.0699 - Iteration Time: 0:00:01.403486
[1/9, 15/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.417963
[1/9, 16/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.463583
[1/9, 17/94] Training Loss: 0.0718 - Iteration Time: 0:00:01.434279
[1/9, 18/94] Training Loss: 0.0680 - Iteration Time: 0:00:01.400046
[1/9, 19/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.440260
[1/9, 20/94] Training Loss: 0.0692 - Iteration Time: 0:00:01.565281
[1/9, 21/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.441233
[1/9, 22/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.422400
[1/9, 23/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.412453
[1/9, 24/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.482438
[1/9, 25/94] Training Loss: 0.0709 - Iteration Time: 0:00:01.433277
[1/9, 26/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.472009
[1/9, 27/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.428829
[1/9, 28/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.432788
[1/9, 29/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.388147
[1/9, 30/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.471972
[1/9, 31/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.489837
[1/9, 32/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.534980
[1/9, 33/94] Training Loss: 0.0712 - Iteration Time: 0:00:01.473022
[1/9, 34/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.489311
[1/9, 35/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.447691
[1/9, 36/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.481899
[1/9, 37/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.410502
[1/9, 38/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.461119
[1/9, 39/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.441213
[1/9, 40/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.582207
[1/9, 41/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.482937
[1/9, 42/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.432411
[1/9, 43/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.414984
[1/9, 44/94] Training Loss: 0.0689 - Iteration Time: 0:00:01.450670
[1/9, 45/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.523638
[1/9, 46/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.426927
[1/9, 47/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.448649
[1/9, 48/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.459104
[1/9, 49/94] Training Loss: 0.0698 - Iteration Time: 0:00:01.434763
[1/9, 50/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.672491
[1/9, 51/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.495823
[1/9, 52/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.469506
[1/9, 53/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.532504
[1/9, 54/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.440734
[1/9, 55/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.444709
[1/9, 56/94] Training Loss: 0.0696 - Iteration Time: 0:00:01.435270
[1/9, 57/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.499273
[1/9, 58/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.451628
[1/9, 59/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.422352
[1/9, 60/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.488387
[1/9, 61/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.486430
[1/9, 62/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.464095
[1/9, 63/94] Training Loss: 0.0689 - Iteration Time: 0:00:01.471034
[1/9, 64/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.472506
[1/9, 65/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.489881
[1/9, 66/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.479928
[1/9, 67/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.410423
[1/9, 68/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.407004
[1/9, 69/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.528067
[1/9, 70/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.472964
[1/9, 71/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.459112
[1/9, 72/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.552858
[1/9, 73/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.607511
[1/9, 74/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.414874
[1/9, 75/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.428362
[1/9, 76/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.477407
[1/9, 77/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.434772
[1/9, 78/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.392628
[1/9, 79/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.474927
[1/9, 80/94] Training Loss: 0.0693 - Iteration Time: 0:00:01.447179
[1/9, 81/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.481396
[1/9, 82/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.499265
[1/9, 83/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.463001
[1/9, 84/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.431784
[1/9, 85/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.491808
[1/9, 86/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.418916
[1/9, 87/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.475953
[1/9, 88/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.430302
[1/9, 89/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.511676
[1/9, 90/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.413915
[1/9, 91/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.522567
[1/9, 92/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.470488
[1/9, 93/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.510227
[1/9, 94/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.637834
Testing - 2024-06-15 12:55:32.663222
[1/9, 1/16]
[1/9, 2/16]
[1/9, 3/16]
[1/9, 4/16]
[1/9, 5/16]
[1/9, 6/16]
[1/9, 7/16]
[1/9, 8/16]
[1/9, 9/16]
[1/9, 10/16]
[1/9, 11/16]
[1/9, 12/16]
[1/9, 13/16]
[1/9, 14/16]
[1/9, 15/16]
[1/9, 16/16]
Testing Loss: 0.0614 - Epoch Time: 0:02:49.553460
Training - 2024-06-15 12:55:54.577592
[2/9, 1/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.573234
[2/9, 2/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.446663
[2/9, 3/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.428287
[2/9, 4/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.508171
[2/9, 5/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.571676
[2/9, 6/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.554297
[2/9, 7/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.558053
[2/9, 8/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.466560
[2/9, 9/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.544905
[2/9, 10/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.454126
[2/9, 11/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.455118
[2/9, 12/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.479402
[2/9, 13/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.466561
[2/9, 14/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.500246
[2/9, 15/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.467489
[2/9, 16/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.461556
[2/9, 17/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.494357
[2/9, 18/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.468997
[2/9, 19/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.450139
[2/9, 20/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.478396
[2/9, 21/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.489828
[2/9, 22/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.459518
[2/9, 23/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.549842
[2/9, 24/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.429260
[2/9, 25/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.560308
[2/9, 26/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.522544
[2/9, 27/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.462507
[2/9, 28/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.447651
[2/9, 29/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.421843
[2/9, 30/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.435690
[2/9, 31/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.425797
[2/9, 32/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.386191
[2/9, 33/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.494760
[2/9, 34/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.455073
[2/9, 35/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.394565
[2/9, 36/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.399020
[2/9, 37/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.478866
[2/9, 38/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.467525
[2/9, 39/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.513748
[2/9, 40/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.462059
[2/9, 41/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.458524
[2/9, 42/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.500782
[2/9, 43/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.434348
[2/9, 44/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.400510
[2/9, 45/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.569279
[2/9, 46/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.532495
[2/9, 47/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.497273
[2/9, 48/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.437256
[2/9, 49/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.445212
[2/9, 50/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.425342
[2/9, 51/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.419061
[2/9, 52/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.448165
[2/9, 53/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.477599
[2/9, 54/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.565399
[2/9, 55/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.456613
[2/9, 56/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.481487
[2/9, 57/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.508283
[2/9, 58/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.456541
[2/9, 59/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.458665
[2/9, 60/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.443689
[2/9, 61/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.418439
[2/9, 62/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.419923
[2/9, 63/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.512218
[2/9, 64/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.446640
[2/9, 65/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.475436
[2/9, 66/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.424325
[2/9, 67/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.541911
[2/9, 68/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.465475
[2/9, 69/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.507159
[2/9, 70/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.439227
[2/9, 71/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.445628
[2/9, 72/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.456080
[2/9, 73/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.414905
[2/9, 74/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.557290
[2/9, 75/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.424815
[2/9, 76/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.496258
[2/9, 77/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.474982
[2/9, 78/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.497230
[2/9, 79/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.480870
[2/9, 80/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.398992
[2/9, 81/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.500243
[2/9, 82/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.432256
[2/9, 83/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.440764
[2/9, 84/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.451099
[2/9, 85/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.462094
[2/9, 86/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.499702
[2/9, 87/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.539509
[2/9, 88/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.584612
[2/9, 89/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.518121
[2/9, 90/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.486856
[2/9, 91/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.463546
[2/9, 92/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.447146
[2/9, 93/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.469997
[2/9, 94/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.461500
Testing - 2024-06-15 12:58:13.217559
[2/9, 1/16]
[2/9, 2/16]
[2/9, 3/16]
[2/9, 4/16]
[2/9, 5/16]
[2/9, 6/16]
[2/9, 7/16]
[2/9, 8/16]
[2/9, 9/16]
[2/9, 10/16]
[2/9, 11/16]
[2/9, 12/16]
[2/9, 13/16]
[2/9, 14/16]
[2/9, 15/16]
[2/9, 16/16]
Testing Loss: 0.0612 - Epoch Time: 0:02:32.000513
Training - 2024-06-15 12:58:26.578105
[3/9, 1/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.421889
[3/9, 2/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.417895
[3/9, 3/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.434280
[3/9, 4/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.470062
[3/9, 5/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.421918
[3/9, 6/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.444259
[3/9, 7/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.434292
[3/9, 8/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.469065
[3/9, 9/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.493765
[3/9, 10/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.485345
[3/9, 11/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.610841
[3/9, 12/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.504195
[3/9, 13/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.420367
[3/9, 14/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.427318
[3/9, 15/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.404455
[3/9, 16/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.520624
[3/9, 17/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.396024
[3/9, 18/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.464069
[3/9, 19/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.454074
[3/9, 20/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.390593
[3/9, 21/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.413897
[3/9, 22/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.466498
[3/9, 23/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.441700
[3/9, 24/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.550352
[3/9, 25/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.437703
[3/9, 26/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.493749
[3/9, 27/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.394583
[3/9, 28/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.420814
[3/9, 29/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.457068
[3/9, 30/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.500713
[3/9, 31/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.476919
[3/9, 32/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.441679
[3/9, 33/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.467477
[3/9, 34/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.396567
[3/9, 35/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.471450
[3/9, 36/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.421817
[3/9, 37/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.426301
[3/9, 38/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.414972
[3/9, 39/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.453557
[3/9, 40/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.411426
[3/9, 41/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.464120
[3/9, 42/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.409982
[3/9, 43/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.421807
[3/9, 44/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.412902
[3/9, 45/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.456194
[3/9, 46/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.420822
[3/9, 47/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.453192
[3/9, 48/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.464110
[3/9, 49/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.480422
[3/9, 50/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.550445
[3/9, 51/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.486943
[3/9, 52/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.436926
[3/9, 53/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.497460
[3/9, 54/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.485355
[3/9, 55/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.463164
[3/9, 56/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.455703
[3/9, 57/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.530737
[3/9, 58/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.426344
[3/9, 59/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.574221
[3/9, 60/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.407015
[3/9, 61/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.453075
[3/9, 62/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.448147
[3/9, 63/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.456064
[3/9, 64/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.417371
[3/9, 65/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.500711
[3/9, 66/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.514141
[3/9, 67/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.410414
[3/9, 68/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.476432
[3/9, 69/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.415897
[3/9, 70/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.434230
[3/9, 71/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.419857
[3/9, 72/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.445621
[3/9, 73/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.462050
[3/9, 74/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.474916
[3/9, 75/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.512628
[3/9, 76/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.414904
[3/9, 77/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.434279
[3/9, 78/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.417888
[3/9, 79/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.531993
[3/9, 80/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.463015
[3/9, 81/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.472926
[3/9, 82/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.435231
[3/9, 83/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.599994
[3/9, 84/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.476917
[3/9, 85/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.415383
[3/9, 86/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.424845
[3/9, 87/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.446686
[3/9, 88/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.480918
[3/9, 89/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.427276
[3/9, 90/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.432750
[3/9, 91/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.404994
[3/9, 92/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.425341
[3/9, 93/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.453637
[3/9, 94/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.428383
Testing - 2024-06-15 13:00:43.436302
[3/9, 1/16]
[3/9, 2/16]
[3/9, 3/16]
[3/9, 4/16]
[3/9, 5/16]
[3/9, 6/16]
[3/9, 7/16]
[3/9, 8/16]
[3/9, 9/16]
[3/9, 10/16]
[3/9, 11/16]
[3/9, 12/16]
[3/9, 13/16]
[3/9, 14/16]
[3/9, 15/16]
[3/9, 16/16]
Testing Loss: 0.0569 - Epoch Time: 0:02:30.496304
Training - 2024-06-15 13:00:57.074906
[4/9, 1/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.550926
[4/9, 2/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.394565
[4/9, 3/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.556921
[4/9, 4/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.431812
[4/9, 5/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.412966
[4/9, 6/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.429829
[4/9, 7/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.387208
[4/9, 8/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.589117
[4/9, 9/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.410949
[4/9, 10/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.528042
[4/9, 11/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.430295
[4/9, 12/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.437298
[4/9, 13/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.399085
[4/9, 14/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.488333
[4/9, 15/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.506237
[4/9, 16/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.477003
[4/9, 17/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.386300
[4/9, 18/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.440718
[4/9, 19/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.400570
[4/9, 20/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.434822
[4/9, 21/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.443168
[4/9, 22/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.425351
[4/9, 23/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.467524
[4/9, 24/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.481448
[4/9, 25/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.437222
[4/9, 26/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.409042
[4/9, 27/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.424320
[4/9, 28/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.436708
[4/9, 29/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.432735
[4/9, 30/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.381646
[4/9, 31/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.439718
[4/9, 32/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.470463
[4/9, 33/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.489332
[4/9, 34/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.435725
[4/9, 35/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.461041
[4/9, 36/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.429252
[4/9, 37/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.419876
[4/9, 38/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.481382
[4/9, 39/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.444132
[4/9, 40/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.421353
[4/9, 41/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.493267
[4/9, 42/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.528023
[4/9, 43/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.533438
[4/9, 44/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.463549
[4/9, 45/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.465718
[4/9, 46/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.606893
[4/9, 47/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.438306
[4/9, 48/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.425313
[4/9, 49/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.451632
[4/9, 50/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.449666
[4/9, 51/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.463124
[4/9, 52/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.604391
[4/9, 53/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.437229
[4/9, 54/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.445206
[4/9, 55/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.456089
[4/9, 56/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.454106
[4/9, 57/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.448227
[4/9, 58/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.456134
[4/9, 59/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.489393
[4/9, 60/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.476498
[4/9, 61/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.410008
[4/9, 62/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.438246
[4/9, 63/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.525100
[4/9, 64/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.445858
[4/9, 65/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.415947
[4/9, 66/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.492363
[4/9, 67/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.430815
[4/9, 68/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.469018
[4/9, 69/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.422307
[4/9, 70/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.424298
[4/9, 71/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.420142
[4/9, 72/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.440218
[4/9, 73/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.528726
[4/9, 74/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.438902
[4/9, 75/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.470581
[4/9, 76/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.461386
[4/9, 77/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.500762
[4/9, 78/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.489868
[4/9, 79/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.566744
[4/9, 80/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.469973
[4/9, 81/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.453115
[4/9, 82/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.434487
[4/9, 83/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.471021
[4/9, 84/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.455076
[4/9, 85/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.651641
[4/9, 86/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.505292
[4/9, 87/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.440276
[4/9, 88/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.425293
[4/9, 89/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.476007
[4/9, 90/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.434264
[4/9, 91/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.439735
[4/9, 92/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.452683
[4/9, 93/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.442363
[4/9, 94/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.560796
Testing - 2024-06-15 13:03:14.576201
[4/9, 1/16]
[4/9, 2/16]
[4/9, 3/16]
[4/9, 4/16]
[4/9, 5/16]
[4/9, 6/16]
[4/9, 7/16]
[4/9, 8/16]
[4/9, 9/16]
[4/9, 10/16]
[4/9, 11/16]
[4/9, 12/16]
[4/9, 13/16]
[4/9, 14/16]
[4/9, 15/16]
[4/9, 16/16]
Testing Loss: 0.0527 - Epoch Time: 0:02:31.002915
Training - 2024-06-15 13:03:28.078317
[5/9, 1/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.435240
[5/9, 2/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.430359
[5/9, 3/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.454598
[5/9, 4/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.460187
[5/9, 5/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.417333
[5/9, 6/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.402016
[5/9, 7/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.482980
[5/9, 8/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.514098
[5/9, 9/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.447274
[5/9, 10/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.556807
[5/9, 11/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.480428
[5/9, 12/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.411947
[5/9, 13/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.418408
[5/9, 14/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.468495
[5/9, 15/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.514216
[5/9, 16/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.394557
[5/9, 17/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.496291
[5/9, 18/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.568261
[5/9, 19/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.445723
[5/9, 20/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.527595
[5/9, 21/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.539057
[5/9, 22/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.507675
[5/9, 23/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.580690
[5/9, 24/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.417365
[5/9, 25/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.468504
[5/9, 26/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.507293
[5/9, 27/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.456728
[5/9, 28/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.425866
[5/9, 29/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.535039
[5/9, 30/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.505251
[5/9, 31/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.485865
[5/9, 32/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.491938
[5/9, 33/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.419386
[5/9, 34/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.502741
[5/9, 35/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.422338
[5/9, 36/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.402095
[5/9, 37/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.480466
[5/9, 38/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.496872
[5/9, 39/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.479926
[5/9, 40/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.550351
[5/9, 41/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.472942
[5/9, 42/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.409950
[5/9, 43/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.536907
[5/9, 44/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.462561
[5/9, 45/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.465026
[5/9, 46/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.421826
[5/9, 47/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.650554
[5/9, 48/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.440214
[5/9, 49/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.610385
[5/9, 50/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.416441
[5/9, 51/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.520539
[5/9, 52/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.419412
[5/9, 53/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.400069
[5/9, 54/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.443646
[5/9, 55/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.401075
[5/9, 56/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.388616
[5/9, 57/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.491945
[5/9, 58/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.415882
[5/9, 59/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.415509
[5/9, 60/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.412452
[5/9, 61/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.422817
[5/9, 62/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.441728
[5/9, 63/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.425454
[5/9, 64/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.591544
[5/9, 65/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.468952
[5/9, 66/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.429300
[5/9, 67/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.458075
[5/9, 68/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.440179
[5/9, 69/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.415422
[5/9, 70/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.414459
[5/9, 71/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.438748
[5/9, 72/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.516178
[5/9, 73/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.450849
[5/9, 74/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.444762
[5/9, 75/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.433802
[5/9, 76/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.476925
[5/9, 77/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.491880
[5/9, 78/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.441205
[5/9, 79/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.442199
[5/9, 80/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.414468
[5/9, 81/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.417389
[5/9, 82/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.475467
[5/9, 83/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.474465
[5/9, 84/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.428451
[5/9, 85/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.444197
[5/9, 86/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.451626
[5/9, 87/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.501191
[5/9, 88/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.427819
[5/9, 89/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.415904
[5/9, 90/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.462023
[5/9, 91/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.520583
[5/9, 92/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.599967
[5/9, 93/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.515102
[5/9, 94/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.390090
Testing - 2024-06-15 13:05:45.946572
[5/9, 1/16]
[5/9, 2/16]
[5/9, 3/16]
[5/9, 4/16]
[5/9, 5/16]
[5/9, 6/16]
[5/9, 7/16]
[5/9, 8/16]
[5/9, 9/16]
[5/9, 10/16]
[5/9, 11/16]
[5/9, 12/16]
[5/9, 13/16]
[5/9, 14/16]
[5/9, 15/16]
[5/9, 16/16]
Testing Loss: 0.0493 - Epoch Time: 0:02:31.385938
Training - 2024-06-15 13:05:59.464752
[6/9, 1/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.551853
[6/9, 2/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.630213
[6/9, 3/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.499738
[6/9, 4/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.424796
[6/9, 5/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.515147
[6/9, 6/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.487318
[6/9, 7/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.407444
[6/9, 8/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.490792
[6/9, 9/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.415473
[6/9, 10/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.469951
[6/9, 11/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.461504
[6/9, 12/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.444675
[6/9, 13/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.418360
[6/9, 14/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.418849
[6/9, 15/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.441690
[6/9, 16/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.484936
[6/9, 17/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.413947
[6/9, 18/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.516693
[6/9, 19/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.515683
[6/9, 20/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.447262
[6/9, 21/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.451191
[6/9, 22/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.443686
[6/9, 23/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.480956
[6/9, 24/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.464552
[6/9, 25/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.428884
[6/9, 26/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.514269
[6/9, 27/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.448712
[6/9, 28/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.433788
[6/9, 29/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.473495
[6/9, 30/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.521681
[6/9, 31/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.418958
[6/9, 32/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.409552
[6/9, 33/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.488351
[6/9, 34/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.446239
[6/9, 35/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.448196
[6/9, 36/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.416215
[6/9, 37/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.452158
[6/9, 38/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.404989
[6/9, 39/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.408427
[6/9, 40/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.430755
[6/9, 41/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.430276
[6/9, 42/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.466972
[6/9, 43/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.594975
[6/9, 44/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.623257
[6/9, 45/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.445649
[6/9, 46/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.475919
[6/9, 47/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.476389
[6/9, 48/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.414393
[6/9, 49/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.472941
[6/9, 50/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.453093
[6/9, 51/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.431847
[6/9, 52/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.612869
[6/9, 53/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.392069
[6/9, 54/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.475911
[6/9, 55/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.481386
[6/9, 56/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.500226
[6/9, 57/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.465508
[6/9, 58/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.526023
[6/9, 59/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.476923
[6/9, 60/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.443154
[6/9, 61/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.421878
[6/9, 62/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.428302
[6/9, 63/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.444672
[6/9, 64/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.403022
[6/9, 65/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.448709
[6/9, 66/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.469448
[6/9, 67/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.417880
[6/9, 68/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.470041
[6/9, 69/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.469582
[6/9, 70/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.501790
[6/9, 71/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.562349
[6/9, 72/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.491394
[6/9, 73/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.459673
[6/9, 74/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.377282
[6/9, 75/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.473453
[6/9, 76/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.425390
[6/9, 77/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.433811
[6/9, 78/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.485928
[6/9, 79/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.414488
[6/9, 80/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.474464
[6/9, 81/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.449147
[6/9, 82/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.451605
[6/9, 83/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.585922
[6/9, 84/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.572224
[6/9, 85/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.483387
[6/9, 86/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.484917
[6/9, 87/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.491872
[6/9, 88/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.477756
[6/9, 89/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.510724
[6/9, 90/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.740382
[6/9, 91/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.498520
[6/9, 92/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.460552
[6/9, 93/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.468958
[6/9, 94/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.414881
Testing - 2024-06-15 13:08:17.818137
[6/9, 1/16]
[6/9, 2/16]
[6/9, 3/16]
[6/9, 4/16]
[6/9, 5/16]
[6/9, 6/16]
[6/9, 7/16]
[6/9, 8/16]
[6/9, 9/16]
[6/9, 10/16]
[6/9, 11/16]
[6/9, 12/16]
[6/9, 13/16]
[6/9, 14/16]
[6/9, 15/16]
[6/9, 16/16]
Testing Loss: 0.0481 - Epoch Time: 0:02:31.691845
Training - 2024-06-15 13:08:31.156597
[7/9, 1/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.423342
[7/9, 2/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.420358
[7/9, 3/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.504746
[7/9, 4/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.477022
[7/9, 5/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.448101
[7/9, 6/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.516720
[7/9, 7/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.445199
[7/9, 8/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.436230
[7/9, 9/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.504685
[7/9, 10/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.396547
[7/9, 11/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.432793
[7/9, 12/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.444676
[7/9, 13/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.517577
[7/9, 14/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.452127
[7/9, 15/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.559271
[7/9, 16/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.623757
[7/9, 17/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.471947
[7/9, 18/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.527521
[7/9, 19/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.391099
[7/9, 20/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.536964
[7/9, 21/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.580110
[7/9, 22/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.476902
[7/9, 23/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.454087
[7/9, 24/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.450115
[7/9, 25/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.455076
[7/9, 26/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.450120
[7/9, 27/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.471942
[7/9, 28/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.432243
[7/9, 29/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.444653
[7/9, 30/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.452600
[7/9, 31/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.416364
[7/9, 32/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.503235
[7/9, 33/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.473470
[7/9, 34/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.454623
[7/9, 35/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.436830
[7/9, 36/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.527150
[7/9, 37/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.415561
[7/9, 38/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.483496
[7/9, 39/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.475421
[7/9, 40/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.465540
[7/9, 41/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.529578
[7/9, 42/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.500790
[7/9, 43/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.440748
[7/9, 44/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.456658
[7/9, 45/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.561779
[7/9, 46/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.583114
[7/9, 47/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.475880
[7/9, 48/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.527546
[7/9, 49/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.484859
[7/9, 50/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.453093
[7/9, 51/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.515622
[7/9, 52/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.483375
[7/9, 53/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.483366
[7/9, 54/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.452598
[7/9, 55/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.461998
[7/9, 56/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.494797
[7/9, 57/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.404960
[7/9, 58/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.477383
[7/9, 59/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.432754
[7/9, 60/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.464514
[7/9, 61/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.517132
[7/9, 62/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.531959
[7/9, 63/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.541895
[7/9, 64/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.448631
[7/9, 65/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.430769
[7/9, 66/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.425772
[7/9, 67/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.534520
[7/9, 68/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.507174
[7/9, 69/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.527612
[7/9, 70/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.500763
[7/9, 71/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.504797
[7/9, 72/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.480384
[7/9, 73/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.501843
[7/9, 74/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.468469
[7/9, 75/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.420851
[7/9, 76/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.480377
[7/9, 77/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.431355
[7/9, 78/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.468463
[7/9, 79/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.426301
[7/9, 80/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.462053
[7/9, 81/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.464007
[7/9, 82/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.476391
[7/9, 83/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.522041
[7/9, 84/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.493779
[7/9, 85/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.488809
[7/9, 86/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.429350
[7/9, 87/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.556858
[7/9, 88/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.583685
[7/9, 89/94] Training Loss: 0.0461 - Iteration Time: 0:00:02.465314
[7/9, 90/94] Training Loss: 0.0460 - Iteration Time: 0:00:02.575534
[7/9, 91/94] Training Loss: 0.0442 - Iteration Time: 0:00:02.084257
[7/9, 92/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.717313
[7/9, 93/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.580114
[7/9, 94/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.415476
Testing - 2024-06-15 13:10:53.248553
[7/9, 1/16]
[7/9, 2/16]
[7/9, 3/16]
[7/9, 4/16]
[7/9, 5/16]
[7/9, 6/16]
[7/9, 7/16]
[7/9, 8/16]
[7/9, 9/16]
[7/9, 10/16]
[7/9, 11/16]
[7/9, 12/16]
[7/9, 13/16]
[7/9, 14/16]
[7/9, 15/16]
[7/9, 16/16]
Testing Loss: 0.0450 - Epoch Time: 0:02:35.844554
Training - 2024-06-15 13:11:07.001647
[8/9, 1/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.685256
[8/9, 2/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.571260
[8/9, 3/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.511218
[8/9, 4/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.428314
[8/9, 5/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.626720
[8/9, 6/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.856478
[8/9, 7/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.798474
[8/9, 8/94] Training Loss: 0.0439 - Iteration Time: 0:00:01.659012
[8/9, 9/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.791050
[8/9, 10/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.811324
[8/9, 11/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.703155
[8/9, 12/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.698289
[8/9, 13/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.606873
[8/9, 14/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.472470
[8/9, 15/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.486872
[8/9, 16/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.484399
[8/9, 17/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.453061
[8/9, 18/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.482832
[8/9, 19/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.468498
[8/9, 20/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.505681
[8/9, 21/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.440656
[8/9, 22/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.464034
[8/9, 23/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.694744
[8/9, 24/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.743815
[8/9, 25/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.592552
[8/9, 26/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.474424
[8/9, 27/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.449621
[8/9, 28/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.455072
[8/9, 29/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.461533
[8/9, 30/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.436209
[8/9, 31/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.478392
[8/9, 32/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.572190
[8/9, 33/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.594034
[8/9, 34/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.781578
[8/9, 35/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.899196
[8/9, 36/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.508366
[8/9, 37/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.494303
[8/9, 38/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.490419
[8/9, 39/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.517598
[8/9, 40/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.444192
[8/9, 41/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.484373
[8/9, 42/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.428963
[8/9, 43/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.441767
[8/9, 44/94] Training Loss: 0.0439 - Iteration Time: 0:00:01.452691
[8/9, 45/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.493816
[8/9, 46/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.459668
[8/9, 47/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.493823
[8/9, 48/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.446734
[8/9, 49/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.620837
[8/9, 50/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.458556
[8/9, 51/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.489807
[8/9, 52/94] Training Loss: 0.0439 - Iteration Time: 0:00:01.416429
[8/9, 53/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.459087
[8/9, 54/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.452706
[8/9, 55/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.580136
[8/9, 56/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.617851
[8/9, 57/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.495734
[8/9, 58/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.475914
[8/9, 59/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.509730
[8/9, 60/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.479398
[8/9, 61/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.451129
[8/9, 62/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.552316
[8/9, 63/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.581572
[8/9, 64/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.437273
[8/9, 65/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.455573
[8/9, 66/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.503201
[8/9, 67/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.465007
[8/9, 68/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.489790
[8/9, 69/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.431281
[8/9, 70/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.420829
[8/9, 71/94] Training Loss: 0.0427 - Iteration Time: 0:00:01.474026
[8/9, 72/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.423362
[8/9, 73/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.443326
[8/9, 74/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.473913
[8/9, 75/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.616840
[8/9, 76/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.493776
[8/9, 77/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.512216
[8/9, 78/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.467464
[8/9, 79/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.519089
[8/9, 80/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.513630
[8/9, 81/94] Training Loss: 0.0427 - Iteration Time: 0:00:01.462534
[8/9, 82/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.497746
[8/9, 83/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.488474
[8/9, 84/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.447178
[8/9, 85/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.427795
[8/9, 86/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.443153
[8/9, 87/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.451601
[8/9, 88/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.460045
[8/9, 89/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.416859
[8/9, 90/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.469510
[8/9, 91/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.471503
[8/9, 92/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.439777
[8/9, 93/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.444644
[8/9, 94/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.548028
Testing - 2024-06-15 13:13:30.135635
[8/9, 1/16]
[8/9, 2/16]
[8/9, 3/16]
[8/9, 4/16]
[8/9, 5/16]
[8/9, 6/16]
[8/9, 7/16]
[8/9, 8/16]
[8/9, 9/16]
[8/9, 10/16]
[8/9, 11/16]
[8/9, 12/16]
[8/9, 13/16]
[8/9, 14/16]
[8/9, 15/16]
[8/9, 16/16]
Testing Loss: 0.0426 - Epoch Time: 0:02:36.949104
Training - 2024-06-15 13:13:43.950751
[9/9, 1/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.649683
[9/9, 2/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.591118
[9/9, 3/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.456588
[9/9, 4/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.477464
[9/9, 5/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.475986
[9/9, 6/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.520196
[9/9, 7/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.452102
[9/9, 8/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.439302
[9/9, 9/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.480375
[9/9, 10/94] Training Loss: 0.0409 - Iteration Time: 0:00:01.452098
[9/9, 11/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.460662
[9/9, 12/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.504183
[9/9, 13/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.638754
[9/9, 14/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.479903
[9/9, 15/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.501717
[9/9, 16/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.489809
[9/9, 17/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.546345
[9/9, 18/94] Training Loss: 0.0399 - Iteration Time: 0:00:01.549377
[9/9, 19/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.513090
[9/9, 20/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.483852
[9/9, 21/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.468457
[9/9, 22/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.483860
[9/9, 23/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.435717
[9/9, 24/94] Training Loss: 0.0427 - Iteration Time: 0:00:01.455071
[9/9, 25/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.447671
[9/9, 26/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.523024
[9/9, 27/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.465973
[9/9, 28/94] Training Loss: 0.0399 - Iteration Time: 0:00:01.472428
[9/9, 29/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.483876
[9/9, 30/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.430234
[9/9, 31/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.477415
[9/9, 32/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.434251
[9/9, 33/94] Training Loss: 0.0400 - Iteration Time: 0:00:01.457092
[9/9, 34/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.460503
[9/9, 35/94] Training Loss: 0.0403 - Iteration Time: 0:00:01.469550
[9/9, 36/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.478944
[9/9, 37/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.489425
[9/9, 38/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.502177
[9/9, 39/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.481564
[9/9, 40/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.546843
[9/9, 41/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.457736
[9/9, 42/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.467586
[9/9, 43/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.532618
[9/9, 44/94] Training Loss: 0.0407 - Iteration Time: 0:00:01.484990
[9/9, 45/94] Training Loss: 0.0407 - Iteration Time: 0:00:01.467668
[9/9, 46/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.440320
[9/9, 47/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.496780
[9/9, 48/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.647685
[9/9, 49/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.425484
[9/9, 50/94] Training Loss: 0.0405 - Iteration Time: 0:00:01.529992
[9/9, 51/94] Training Loss: 0.0399 - Iteration Time: 0:00:01.514633
[9/9, 52/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.661033
[9/9, 53/94] Training Loss: 0.0404 - Iteration Time: 0:00:01.418987
[9/9, 54/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.449661
[9/9, 55/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.449641
[9/9, 56/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.456599
[9/9, 57/94] Training Loss: 0.0404 - Iteration Time: 0:00:01.456063
[9/9, 58/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.470931
[9/9, 59/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.461019
[9/9, 60/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.537978
[9/9, 61/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.458026
[9/9, 62/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.549880
[9/9, 63/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.478417
[9/9, 64/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.437712
[9/9, 65/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.488787
[9/9, 66/94] Training Loss: 0.0404 - Iteration Time: 0:00:01.437712
[9/9, 67/94] Training Loss: 0.0400 - Iteration Time: 0:00:01.449928
[9/9, 68/94] Training Loss: 0.0409 - Iteration Time: 0:00:01.500713
[9/9, 69/94] Training Loss: 0.0403 - Iteration Time: 0:00:01.440657
[9/9, 70/94] Training Loss: 0.0405 - Iteration Time: 0:00:01.482875
[9/9, 71/94] Training Loss: 0.0409 - Iteration Time: 0:00:01.442147
[9/9, 72/94] Training Loss: 0.0400 - Iteration Time: 0:00:01.470942
[9/9, 73/94] Training Loss: 0.0396 - Iteration Time: 0:00:01.450588
[9/9, 74/94] Training Loss: 0.0400 - Iteration Time: 0:00:01.468048
[9/9, 75/94] Training Loss: 0.0396 - Iteration Time: 0:00:01.465033
[9/9, 76/94] Training Loss: 0.0409 - Iteration Time: 0:00:01.462998
[9/9, 77/94] Training Loss: 0.0397 - Iteration Time: 0:00:01.471993
[9/9, 78/94] Training Loss: 0.0401 - Iteration Time: 0:00:01.446700
[9/9, 79/94] Training Loss: 0.0397 - Iteration Time: 0:00:01.434295
[9/9, 80/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.497260
[9/9, 81/94] Training Loss: 0.0404 - Iteration Time: 0:00:01.654558
[9/9, 82/94] Training Loss: 0.0397 - Iteration Time: 0:00:01.554413
[9/9, 83/94] Training Loss: 0.0396 - Iteration Time: 0:00:01.447159
[9/9, 84/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.456550
[9/9, 85/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.415446
[9/9, 86/94] Training Loss: 0.0396 - Iteration Time: 0:00:01.442199
[9/9, 87/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.494864
[9/9, 88/94] Training Loss: 0.0399 - Iteration Time: 0:00:01.450118
[9/9, 89/94] Training Loss: 0.0385 - Iteration Time: 0:00:01.442688
[9/9, 90/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.472935
[9/9, 91/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.468986
[9/9, 92/94] Training Loss: 0.0403 - Iteration Time: 0:00:01.476910
[9/9, 93/94] Training Loss: 0.0409 - Iteration Time: 0:00:01.638749
[9/9, 94/94] Training Loss: 0.0382 - Iteration Time: 0:00:01.398570
Testing - 2024-06-15 13:16:03.647996
[9/9, 1/16]
[9/9, 2/16]
[9/9, 3/16]
[9/9, 4/16]
[9/9, 5/16]
[9/9, 6/16]
[9/9, 7/16]
[9/9, 8/16]
[9/9, 9/16]
[9/9, 10/16]
[9/9, 11/16]
[9/9, 12/16]
[9/9, 13/16]
[9/9, 14/16]
[9/9, 15/16]
[9/9, 16/16]
Testing Loss: 0.0399 - Epoch Time: 0:02:33.149772
Training and Testing Finished - Time: 0:23:12.076887
Assembling test data for t-sne projection
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 4
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 4
Applying t-SNE