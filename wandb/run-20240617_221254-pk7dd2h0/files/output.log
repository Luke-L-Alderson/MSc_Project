Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-17 22:12:56.050756
Scaler Value: 1000
Training - 2024-06-17 22:12:56.051748
[1/9, 10/94] Training Loss: 0.5549 - Iteration Time: 0:00:01.420696
[1/9, 20/94] Training Loss: 0.4927 - Iteration Time: 0:00:01.355906
[1/9, 30/94] Training Loss: 0.4976 - Iteration Time: 0:00:01.388650
[1/9, 40/94] Training Loss: 0.4963 - Iteration Time: 0:00:01.409535
[1/9, 50/94] Training Loss: 0.4976 - Iteration Time: 0:00:01.414919
[1/9, 60/94] Training Loss: 0.4994 - Iteration Time: 0:00:01.471727
[1/9, 70/94] Training Loss: 0.5017 - Iteration Time: 0:00:01.374786
[1/9, 80/94] Training Loss: 0.5057 - Iteration Time: 0:00:01.372326
[1/9, 90/94] Training Loss: 0.5053 - Iteration Time: 0:00:01.369918
Testing - 2024-06-17 22:15:12.453671
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.5048 - Epoch Time: 0:02:29.556347
Training - 2024-06-17 22:15:25.608095
[2/9, 10/94] Training Loss: 0.5078 - Iteration Time: 0:00:01.381693
[2/9, 20/94] Training Loss: 0.5072 - Iteration Time: 0:00:01.437862
[2/9, 30/94] Training Loss: 0.5097 - Iteration Time: 0:00:01.401216
[2/9, 40/94] Training Loss: 0.5096 - Iteration Time: 0:00:01.385315
[2/9, 50/94] Training Loss: 0.5104 - Iteration Time: 0:00:01.415363
[2/9, 60/94] Training Loss: 0.5112 - Iteration Time: 0:00:01.406013
[2/9, 70/94] Training Loss: 0.5127 - Iteration Time: 0:00:01.468092
[2/9, 80/94] Training Loss: 0.5156 - Iteration Time: 0:00:01.412521
[2/9, 90/94] Training Loss: 0.5158 - Iteration Time: 0:00:01.380571
Testing - 2024-06-17 22:17:39.532858
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.5115 - Epoch Time: 0:02:27.178371
Training - 2024-06-17 22:17:52.786963
[3/9, 10/94] Training Loss: 0.5155 - Iteration Time: 0:00:01.450334
[3/9, 20/94] Training Loss: 0.5155 - Iteration Time: 0:00:01.609188
[3/9, 30/94] Training Loss: 0.5154 - Iteration Time: 0:00:01.439241
[3/9, 40/94] Training Loss: 0.5169 - Iteration Time: 0:00:01.362394
[3/9, 50/94] Training Loss: 0.5191 - Iteration Time: 0:00:01.357427
[3/9, 60/94] Training Loss: 0.5201 - Iteration Time: 0:00:01.352448
[3/9, 70/94] Training Loss: 0.5194 - Iteration Time: 0:00:01.349481
[3/9, 80/94] Training Loss: 0.5216 - Iteration Time: 0:00:01.434937
[3/9, 90/94] Training Loss: 0.5234 - Iteration Time: 0:00:01.440283
Testing - 2024-06-17 22:20:08.990457
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.5190 - Epoch Time: 0:02:29.247341
Training - 2024-06-17 22:20:22.034304
[4/9, 10/94] Training Loss: 0.5224 - Iteration Time: 0:00:01.403083
[4/9, 20/94] Training Loss: 0.5244 - Iteration Time: 0:00:01.353917
[4/9, 30/94] Training Loss: 0.5255 - Iteration Time: 0:00:01.455605
[4/9, 40/94] Training Loss: 0.5253 - Iteration Time: 0:00:01.401117
[4/9, 50/94] Training Loss: 0.5264 - Iteration Time: 0:00:01.402041
[4/9, 60/94] Training Loss: 0.5246 - Iteration Time: 0:00:01.393723
[4/9, 70/94] Training Loss: 0.5268 - Iteration Time: 0:00:01.452191
[4/9, 80/94] Training Loss: 0.5269 - Iteration Time: 0:00:01.375284
[4/9, 90/94] Training Loss: 0.5277 - Iteration Time: 0:00:01.366317
Testing - 2024-06-17 22:22:35.655575
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.5212 - Epoch Time: 0:02:26.614389
Training - 2024-06-17 22:22:48.648693
[5/9, 10/94] Training Loss: 0.5292 - Iteration Time: 0:00:01.454149
[5/9, 20/94] Training Loss: 0.5296 - Iteration Time: 0:00:01.400142
[5/9, 30/94] Training Loss: 0.5303 - Iteration Time: 0:00:01.404686
[5/9, 40/94] Training Loss: 0.5322 - Iteration Time: 0:00:01.386219
[5/9, 50/94] Training Loss: 0.5300 - Iteration Time: 0:00:01.392628
[5/9, 60/94] Training Loss: 0.5324 - Iteration Time: 0:00:01.388728
[5/9, 70/94] Training Loss: 0.5311 - Iteration Time: 0:00:01.375289
[5/9, 80/94] Training Loss: 0.5309 - Iteration Time: 0:00:01.454729
[5/9, 90/94] Training Loss: 0.5335 - Iteration Time: 0:00:01.445727
Testing - 2024-06-17 22:25:02.621150
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.5287 - Epoch Time: 0:02:27.202685
Training - 2024-06-17 22:25:15.851874
[6/9, 10/94] Training Loss: 0.5329 - Iteration Time: 0:00:01.408032
[6/9, 20/94] Training Loss: 0.5349 - Iteration Time: 0:00:01.396648
[6/9, 30/94] Training Loss: 0.5346 - Iteration Time: 0:00:01.474448
[6/9, 40/94] Training Loss: 0.5313 - Iteration Time: 0:00:01.394645
[6/9, 50/94] Training Loss: 0.5360 - Iteration Time: 0:00:01.375353
[6/9, 60/94] Training Loss: 0.5330 - Iteration Time: 0:00:01.406612
[6/9, 70/94] Training Loss: 0.5358 - Iteration Time: 0:00:01.381188
[6/9, 80/94] Training Loss: 0.5366 - Iteration Time: 0:00:01.368904
[6/9, 90/94] Training Loss: 0.5349 - Iteration Time: 0:00:01.472558
Testing - 2024-06-17 22:27:29.057920
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.5403 - Epoch Time: 0:02:26.327187
Training - 2024-06-17 22:27:42.179558
[7/9, 10/94] Training Loss: 0.5361 - Iteration Time: 0:00:01.470035
[7/9, 20/94] Training Loss: 0.5375 - Iteration Time: 0:00:01.383219
[7/9, 30/94] Training Loss: 0.5347 - Iteration Time: 0:00:01.433843
[7/9, 40/94] Training Loss: 0.5403 - Iteration Time: 0:00:01.376006
[7/9, 50/94] Training Loss: 0.5405 - Iteration Time: 0:00:01.564280
[7/9, 60/94] Training Loss: 0.5410 - Iteration Time: 0:00:01.408478
[7/9, 70/94] Training Loss: 0.5427 - Iteration Time: 0:00:01.374808
[7/9, 80/94] Training Loss: 0.5436 - Iteration Time: 0:00:01.383689
[7/9, 90/94] Training Loss: 0.5413 - Iteration Time: 0:00:01.392142
Testing - 2024-06-17 22:29:55.218122
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.5418 - Epoch Time: 0:02:26.617974
Training - 2024-06-17 22:30:08.797532
[8/9, 10/94] Training Loss: 0.5412 - Iteration Time: 0:00:01.545501
[8/9, 20/94] Training Loss: 0.5434 - Iteration Time: 0:00:01.455791
[8/9, 30/94] Training Loss: 0.5446 - Iteration Time: 0:00:01.412991
[8/9, 40/94] Training Loss: 0.5409 - Iteration Time: 0:00:01.387202
[8/9, 50/94] Training Loss: 0.5451 - Iteration Time: 0:00:01.396223
[8/9, 60/94] Training Loss: 0.5447 - Iteration Time: 0:00:01.415078
[8/9, 70/94] Training Loss: 0.5452 - Iteration Time: 0:00:01.399116
[8/9, 80/94] Training Loss: 0.5448 - Iteration Time: 0:00:01.548352
[8/9, 90/94] Training Loss: 0.5451 - Iteration Time: 0:00:01.406012
Testing - 2024-06-17 22:32:21.950460
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.5619 - Epoch Time: 0:02:26.260987
Training - 2024-06-17 22:32:35.059013
[9/9, 10/94] Training Loss: 0.5454 - Iteration Time: 0:00:01.405065
[9/9, 20/94] Training Loss: 0.5463 - Iteration Time: 0:00:01.391637
[9/9, 30/94] Training Loss: 0.5452 - Iteration Time: 0:00:01.386689
[9/9, 40/94] Training Loss: 0.5486 - Iteration Time: 0:00:01.378815
[9/9, 50/94] Training Loss: 0.5443 - Iteration Time: 0:00:01.417373
[9/9, 60/94] Training Loss: 0.5480 - Iteration Time: 0:00:01.396536
[9/9, 70/94] Training Loss: 0.5469 - Iteration Time: 0:00:01.378749
[9/9, 80/94] Training Loss: 0.5494 - Iteration Time: 0:00:01.377768
[9/9, 90/94] Training Loss: 0.5504 - Iteration Time: 0:00:01.402079
Testing - 2024-06-17 22:34:48.421942
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.5543 - Epoch Time: 0:02:26.788190
Training and Testing Finished - Time: 0:22:05.796944
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels      0    1    2      3    4  ...   94   95   96   97     98   99
0       2  0.135  0.0  0.0  0.140  0.0  ...  0.0  0.0  0.0  0.0  0.095  0.0
1       4  0.130  0.0  0.0  0.145  0.0  ...  0.0  0.0  0.0  0.0  0.095  0.0
2       7  0.130  0.0  0.0  0.140  0.0  ...  0.0  0.0  0.0  0.0  0.095  0.0
3       3  0.135  0.0  0.0  0.140  0.0  ...  0.0  0.0  0.0  0.0  0.095  0.0
4       7  0.130  0.0  0.0  0.140  0.0  ...  0.0  0.0  0.0  0.0  0.095  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP