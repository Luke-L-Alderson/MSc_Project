Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 14:53:53.222961
Scaler Value: 0.2631578947368421
Training - 2024-06-18 14:53:53.223459
[1/9, 10/94] Training Loss: 0.4234 - Iteration Time: 0:00:01.645573
[1/9, 20/94] Training Loss: 0.4134 - Iteration Time: 0:00:01.423732
[1/9, 30/94] Training Loss: 0.4154 - Iteration Time: 0:00:01.467205
[1/9, 40/94] Training Loss: 0.4164 - Iteration Time: 0:00:01.426311
[1/9, 50/94] Training Loss: 0.4136 - Iteration Time: 0:00:01.525662
[1/9, 60/94] Training Loss: 0.4100 - Iteration Time: 0:00:01.467957
[1/9, 70/94] Training Loss: 0.4066 - Iteration Time: 0:00:01.635653
[1/9, 80/94] Training Loss: 0.4078 - Iteration Time: 0:00:01.563829
[1/9, 90/94] Training Loss: 0.4073 - Iteration Time: 0:00:01.429444
Testing - 2024-06-18 14:56:13.641993
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.3915 - Epoch Time: 0:02:34.052857
Training - 2024-06-18 14:56:27.276813
[2/9, 10/94] Training Loss: 0.4090 - Iteration Time: 0:00:01.452665
[2/9, 20/94] Training Loss: 0.3995 - Iteration Time: 0:00:01.530737
[2/9, 30/94] Training Loss: 0.4010 - Iteration Time: 0:00:01.495172
[2/9, 40/94] Training Loss: 0.4014 - Iteration Time: 0:00:01.483027
[2/9, 50/94] Training Loss: 0.3997 - Iteration Time: 0:00:01.542052
[2/9, 60/94] Training Loss: 0.4013 - Iteration Time: 0:00:01.527245
[2/9, 70/94] Training Loss: 0.3962 - Iteration Time: 0:00:01.470495
[2/9, 80/94] Training Loss: 0.3913 - Iteration Time: 0:00:01.386394
[2/9, 90/94] Training Loss: 0.3933 - Iteration Time: 0:00:01.381673
Testing - 2024-06-18 14:58:46.753223
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.3840 - Epoch Time: 0:02:32.510395
Training - 2024-06-18 14:58:59.787705
[3/9, 10/94] Training Loss: 0.3897 - Iteration Time: 0:00:01.419254
[3/9, 20/94] Training Loss: 0.3925 - Iteration Time: 0:00:01.663384
[3/9, 30/94] Training Loss: 0.3889 - Iteration Time: 0:00:01.612795
[3/9, 40/94] Training Loss: 0.3908 - Iteration Time: 0:00:01.372973
[3/9, 50/94] Training Loss: 0.3908 - Iteration Time: 0:00:01.440208
[3/9, 60/94] Training Loss: 0.3882 - Iteration Time: 0:00:01.444573
[3/9, 70/94] Training Loss: 0.3849 - Iteration Time: 0:00:01.593585
[3/9, 80/94] Training Loss: 0.3873 - Iteration Time: 0:00:01.407993
[3/9, 90/94] Training Loss: 0.3916 - Iteration Time: 0:00:01.443273
Testing - 2024-06-18 15:01:17.869012
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.3772 - Epoch Time: 0:02:31.445009
Training - 2024-06-18 15:01:31.233210
[4/9, 10/94] Training Loss: 0.3837 - Iteration Time: 0:00:01.433350
[4/9, 20/94] Training Loss: 0.3843 - Iteration Time: 0:00:01.530596
[4/9, 30/94] Training Loss: 0.3820 - Iteration Time: 0:00:01.399048
[4/9, 40/94] Training Loss: 0.3804 - Iteration Time: 0:00:01.393150
[4/9, 50/94] Training Loss: 0.3817 - Iteration Time: 0:00:01.707201
[4/9, 60/94] Training Loss: 0.3801 - Iteration Time: 0:00:01.449176
[4/9, 70/94] Training Loss: 0.3845 - Iteration Time: 0:00:01.461606
[4/9, 80/94] Training Loss: 0.3810 - Iteration Time: 0:00:01.444722
[4/9, 90/94] Training Loss: 0.3772 - Iteration Time: 0:00:01.402058
Testing - 2024-06-18 15:03:49.604490
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.3709 - Epoch Time: 0:02:32.593502
Training - 2024-06-18 15:04:03.826712
[5/9, 10/94] Training Loss: 0.3760 - Iteration Time: 0:00:01.576713
[5/9, 20/94] Training Loss: 0.3786 - Iteration Time: 0:00:01.460079
[5/9, 30/94] Training Loss: 0.3736 - Iteration Time: 0:00:01.411551
[5/9, 40/94] Training Loss: 0.3736 - Iteration Time: 0:00:01.561321
[5/9, 50/94] Training Loss: 0.3774 - Iteration Time: 0:00:01.501742
[5/9, 60/94] Training Loss: 0.3748 - Iteration Time: 0:00:01.698307
[5/9, 70/94] Training Loss: 0.3734 - Iteration Time: 0:00:01.501295
[5/9, 80/94] Training Loss: 0.3675 - Iteration Time: 0:00:01.549907
[5/9, 90/94] Training Loss: 0.3695 - Iteration Time: 0:00:01.573733
Testing - 2024-06-18 15:06:30.827477
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.3602 - Epoch Time: 0:02:41.434613
Training - 2024-06-18 15:06:45.261821
[6/9, 10/94] Training Loss: 0.3741 - Iteration Time: 0:00:01.493422
[6/9, 20/94] Training Loss: 0.3775 - Iteration Time: 0:00:01.616405
[6/9, 30/94] Training Loss: 0.3710 - Iteration Time: 0:00:01.490367
[6/9, 40/94] Training Loss: 0.3687 - Iteration Time: 0:00:01.415927
[6/9, 50/94] Training Loss: 0.3662 - Iteration Time: 0:00:01.610920
[6/9, 60/94] Training Loss: 0.3671 - Iteration Time: 0:00:01.583165
[6/9, 70/94] Training Loss: 0.3659 - Iteration Time: 0:00:01.477480
[6/9, 80/94] Training Loss: 0.3647 - Iteration Time: 0:00:01.741989
[6/9, 90/94] Training Loss: 0.3642 - Iteration Time: 0:00:01.402034
Testing - 2024-06-18 15:09:09.364730
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.3485 - Epoch Time: 0:02:38.076924
Training - 2024-06-18 15:09:23.339241
[7/9, 10/94] Training Loss: 0.3615 - Iteration Time: 0:00:01.421901
[7/9, 20/94] Training Loss: 0.3613 - Iteration Time: 0:00:01.475114
[7/9, 30/94] Training Loss: 0.3614 - Iteration Time: 0:00:01.410515
[7/9, 40/94] Training Loss: 0.3570 - Iteration Time: 0:00:01.390645
[7/9, 50/94] Training Loss: 0.3573 - Iteration Time: 0:00:01.484922
[7/9, 60/94] Training Loss: 0.3530 - Iteration Time: 0:00:01.415426
[7/9, 70/94] Training Loss: 0.3559 - Iteration Time: 0:00:01.558344
[7/9, 80/94] Training Loss: 0.3548 - Iteration Time: 0:00:01.495842
[7/9, 90/94] Training Loss: 0.3533 - Iteration Time: 0:00:01.530054
Testing - 2024-06-18 15:11:41.953353
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.3407 - Epoch Time: 0:02:33.120957
Training - 2024-06-18 15:11:56.460198
[8/9, 10/94] Training Loss: 0.3543 - Iteration Time: 0:00:01.492922
[8/9, 20/94] Training Loss: 0.3509 - Iteration Time: 0:00:01.458725
[8/9, 30/94] Training Loss: 0.3496 - Iteration Time: 0:00:01.581327
[8/9, 40/94] Training Loss: 0.3495 - Iteration Time: 0:00:01.488685
[8/9, 50/94] Training Loss: 0.3497 - Iteration Time: 0:00:01.581924
[8/9, 60/94] Training Loss: 0.3526 - Iteration Time: 0:00:01.507244
[8/9, 70/94] Training Loss: 0.3478 - Iteration Time: 0:00:01.699394
[8/9, 80/94] Training Loss: 0.3489 - Iteration Time: 0:00:01.507749
[8/9, 90/94] Training Loss: 0.3464 - Iteration Time: 0:00:01.396557
Testing - 2024-06-18 15:14:20.577364
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.3356 - Epoch Time: 0:02:37.671822
Training - 2024-06-18 15:14:34.132020
[9/9, 10/94] Training Loss: 0.3447 - Iteration Time: 0:00:01.528644
[9/9, 20/94] Training Loss: 0.3441 - Iteration Time: 0:00:02.388419
[9/9, 30/94] Training Loss: 0.3452 - Iteration Time: 0:00:01.562298
[9/9, 40/94] Training Loss: 0.3413 - Iteration Time: 0:00:01.501278
[9/9, 50/94] Training Loss: 0.3397 - Iteration Time: 0:00:01.629773
[9/9, 60/94] Training Loss: 0.3414 - Iteration Time: 0:00:01.492949
[9/9, 70/94] Training Loss: 0.3399 - Iteration Time: 0:00:01.380737
[9/9, 80/94] Training Loss: 0.3421 - Iteration Time: 0:00:01.684397
[9/9, 90/94] Training Loss: 0.3447 - Iteration Time: 0:00:01.651226
Testing - 2024-06-18 15:17:07.459063
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.3270 - Epoch Time: 0:02:48.045739
Training and Testing Finished - Time: 0:23:28.954798
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
-- 1/16 --
-- 2/16 --
-- 3/16 --
-- 4/16 --
-- 5/16 --
-- 6/16 --
-- 7/16 --
-- 8/16 --
-- 9/16 --
-- 10/16 --
-- 11/16 --
-- 12/16 --
-- 13/16 --
-- 14/16 --
-- 15/16 --
-- 16/16 --
   Labels    0    1    2      3      4  ...   94   95   96   97     98     99
0       2  0.0  0.0  0.0  0.190  0.115  ...  0.0  0.0  0.0  0.0  0.105  0.050
1       4  0.0  0.0  0.0  0.190  0.055  ...  0.0  0.0  0.0  0.0  0.085  0.020
2       7  0.0  0.0  0.0  0.195  0.095  ...  0.0  0.0  0.0  0.0  0.095  0.025
3       3  0.0  0.0  0.0  0.205  0.100  ...  0.0  0.0  0.0  0.0  0.085  0.045
4       7  0.0  0.0  0.0  0.185  0.090  ...  0.0  0.0  0.0  0.0  0.090  0.005
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP