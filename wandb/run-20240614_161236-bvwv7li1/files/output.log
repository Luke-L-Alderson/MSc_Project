Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-14 16:12:38.625732
Scaler Value: 0.013513513513513514
Training - 2024-06-14 16:12:38.627220
[1/9, 1/94] Training Loss: 0.0695 - Iteration Time: 0:00:01.895919
[1/9, 2/94] Training Loss: 0.0698 - Iteration Time: 0:00:01.308946
[1/9, 3/94] Training Loss: 0.0720 - Iteration Time: 0:00:01.298900
[1/9, 4/94] Training Loss: 0.0719 - Iteration Time: 0:00:01.314792
[1/9, 5/94] Training Loss: 0.0709 - Iteration Time: 0:00:01.490580
[1/9, 6/94] Training Loss: 0.0695 - Iteration Time: 0:00:01.542525
[1/9, 7/94] Training Loss: 0.0691 - Iteration Time: 0:00:01.826081
[1/9, 8/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.386739
[1/9, 9/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.698788
[1/9, 10/94] Training Loss: 0.0710 - Iteration Time: 0:00:01.428920
[1/9, 11/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.389500
[1/9, 12/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.275587
[1/9, 13/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.280067
[1/9, 14/94] Training Loss: 0.0698 - Iteration Time: 0:00:01.262161
[1/9, 15/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.263630
[1/9, 16/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.267776
[1/9, 17/94] Training Loss: 0.0716 - Iteration Time: 0:00:01.262680
[1/9, 18/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.278601
[1/9, 19/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.293470
[1/9, 20/94] Training Loss: 0.0692 - Iteration Time: 0:00:01.269078
[1/9, 21/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.261747
[1/9, 22/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.273628
[1/9, 23/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.267615
[1/9, 24/94] Training Loss: 0.0680 - Iteration Time: 0:00:01.267639
[1/9, 25/94] Training Loss: 0.0703 - Iteration Time: 0:00:01.253230
[1/9, 26/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.257749
[1/9, 27/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.258684
[1/9, 28/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.253266
[1/9, 29/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.301932
[1/9, 30/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.351509
[1/9, 31/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.308849
[1/9, 32/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.261652
[1/9, 33/94] Training Loss: 0.0708 - Iteration Time: 0:00:01.245360
[1/9, 34/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.268683
[1/9, 35/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.580082
[1/9, 36/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.267717
[1/9, 37/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.270662
[1/9, 38/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.270093
[1/9, 39/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.277611
[1/9, 40/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.302856
[1/9, 41/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.253776
[1/9, 42/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.299445
[1/9, 43/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.261207
[1/9, 44/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.253780
[1/9, 45/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.270192
[1/9, 46/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.263725
[1/9, 47/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.287953
[1/9, 48/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.265661
[1/9, 49/94] Training Loss: 0.0692 - Iteration Time: 0:00:01.281518
[1/9, 50/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.307884
[1/9, 51/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.264169
[1/9, 52/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.283059
[1/9, 53/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.335121
[1/9, 54/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.546402
[1/9, 55/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.303334
[1/9, 56/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.399649
[1/9, 57/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.289951
[1/9, 58/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.254325
[1/9, 59/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.251315
[1/9, 60/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.349956
[1/9, 61/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.291044
[1/9, 62/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.265190
[1/9, 63/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.260225
[1/9, 64/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.277063
[1/9, 65/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.273558
[1/9, 66/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.240386
[1/9, 67/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.251286
[1/9, 68/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.285489
[1/9, 69/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.256251
[1/9, 70/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.255764
[1/9, 71/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.261761
[1/9, 72/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.322778
[1/9, 73/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.305871
[1/9, 74/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.294972
[1/9, 75/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.292988
[1/9, 76/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.256702
[1/9, 77/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.291052
[1/9, 78/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.318196
[1/9, 79/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.338559
[1/9, 80/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.359885
[1/9, 81/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.281015
[1/9, 82/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.258201
[1/9, 83/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.310785
[1/9, 84/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.310783
[1/9, 85/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.309818
[1/9, 86/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.291905
[1/9, 87/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.267648
[1/9, 88/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.491454
[1/9, 89/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.267199
[1/9, 90/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.255290
[1/9, 91/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.263617
[1/9, 92/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.297875
[1/9, 93/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.235949
[1/9, 94/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.384610
Testing - 2024-06-14 16:14:54.537774
[1/9, 1/16]
[1/9, 2/16]
[1/9, 3/16]
[1/9, 4/16]
[1/9, 5/16]
[1/9, 6/16]
[1/9, 7/16]
[1/9, 8/16]
[1/9, 9/16]
[1/9, 10/16]
[1/9, 11/16]
[1/9, 12/16]
[1/9, 13/16]
[1/9, 14/16]
[1/9, 15/16]
[1/9, 16/16]
Testing Loss: 0.0611 - Epoch Time: 0:02:37.086982
Training - 2024-06-14 16:15:15.714202
[2/9, 1/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.406563
[2/9, 2/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.319216
[2/9, 3/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.279543
[2/9, 4/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.262634
[2/9, 5/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.249319
[2/9, 6/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.328660
[2/9, 7/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.262162
[2/9, 8/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.267545
[2/9, 9/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.240351
[2/9, 10/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.317719
[2/9, 11/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.274114
[2/9, 12/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.286415
[2/9, 13/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.265597
[2/9, 14/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.253256
[2/9, 15/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.276501
[2/9, 16/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.276563
[2/9, 17/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.258169
[2/9, 18/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.289445
[2/9, 19/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.324647
[2/9, 20/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.281491
[2/9, 21/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.257162
[2/9, 22/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.251581
[2/9, 23/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.293408
[2/9, 24/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.279553
[2/9, 25/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.270600
[2/9, 26/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.272175
[2/9, 27/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.259277
[2/9, 28/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.259172
[2/9, 29/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.282500
[2/9, 30/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.267085
[2/9, 31/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.288972
[2/9, 32/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.253228
[2/9, 33/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.266606
[2/9, 34/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.265727
[2/9, 35/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.376723
[2/9, 36/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.486913
[2/9, 37/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.290486
[2/9, 38/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.273089
[2/9, 39/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.355955
[2/9, 40/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.251762
[2/9, 41/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.276039
[2/9, 42/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.295478
[2/9, 43/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.285536
[2/9, 44/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.305379
[2/9, 45/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.301859
[2/9, 46/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.453313
[2/9, 47/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.255784
[2/9, 48/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.264233
[2/9, 49/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.268186
[2/9, 50/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.268663
[2/9, 51/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.318786
[2/9, 52/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.265651
[2/9, 53/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.329741
[2/9, 54/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.262663
[2/9, 55/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.257678
[2/9, 56/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.275598
[2/9, 57/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.258712
[2/9, 58/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.313263
[2/9, 59/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.262177
[2/9, 60/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.272088
[2/9, 61/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.290453
[2/9, 62/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.269623
[2/9, 63/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.276085
[2/9, 64/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.270112
[2/9, 65/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.247257
[2/9, 66/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.264630
[2/9, 67/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.243303
[2/9, 68/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.251806
[2/9, 69/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.327125
[2/9, 70/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.292914
[2/9, 71/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.267617
[2/9, 72/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.273141
[2/9, 73/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.355935
[2/9, 74/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.299888
[2/9, 75/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.295364
[2/9, 76/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.264762
[2/9, 77/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.273558
[2/9, 78/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.294421
[2/9, 79/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.313816
[2/9, 80/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.277550
[2/9, 81/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.274599
[2/9, 82/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.335232
[2/9, 83/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.325181
[2/9, 84/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.546524
[2/9, 85/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.353068
[2/9, 86/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.316665
[2/9, 87/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.263182
[2/9, 88/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.306867
[2/9, 89/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.258658
[2/9, 90/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.300387
[2/9, 91/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.301907
[2/9, 92/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.336097
[2/9, 93/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.403592
[2/9, 94/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.281541
Testing - 2024-06-14 16:17:17.365562
[2/9, 1/16]
[2/9, 2/16]
[2/9, 3/16]
[2/9, 4/16]
[2/9, 5/16]
[2/9, 6/16]
[2/9, 7/16]
[2/9, 8/16]
[2/9, 9/16]
[2/9, 10/16]
[2/9, 11/16]
[2/9, 12/16]
[2/9, 13/16]
[2/9, 14/16]
[2/9, 15/16]
[2/9, 16/16]
Testing Loss: 0.0613 - Epoch Time: 0:02:13.133416
Training - 2024-06-14 16:17:28.847618
[3/9, 1/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.308345
[3/9, 2/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.270089
[3/9, 3/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.263124
[3/9, 4/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.298405
[3/9, 5/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.344545
[3/9, 6/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.330183
[3/9, 7/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.296895
[3/9, 8/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.261196
[3/9, 9/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.275032
[3/9, 10/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.296886
[3/9, 11/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.267662
[3/9, 12/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.257209
[3/9, 13/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.283479
[3/9, 14/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.269601
[3/9, 15/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.293925
[3/9, 16/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.320737
[3/9, 17/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.314220
[3/9, 18/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.303907
[3/9, 19/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.289540
[3/9, 20/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.268115
[3/9, 21/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.290441
[3/9, 22/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.277065
[3/9, 23/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.278050
[3/9, 24/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.300397
[3/9, 25/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.358524
[3/9, 26/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.426326
[3/9, 27/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.264672
[3/9, 28/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.302422
[3/9, 29/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.298867
[3/9, 30/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.290537
[3/9, 31/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.339633
[3/9, 32/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.278096
[3/9, 33/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.274059
[3/9, 34/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.312300
[3/9, 35/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.294008
[3/9, 36/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.273611
[3/9, 37/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.280556
[3/9, 38/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.309846
[3/9, 39/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.306453
[3/9, 40/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.267071
[3/9, 41/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.346033
[3/9, 42/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.295886
[3/9, 43/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.444757
[3/9, 44/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.268176
[3/9, 45/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.263649
[3/9, 46/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.272642
[3/9, 47/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.285540
[3/9, 48/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.257230
[3/9, 49/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.294481
[3/9, 50/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.283490
[3/9, 51/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.289463
[3/9, 52/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.304822
[3/9, 53/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.273609
[3/9, 54/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.273047
[3/9, 55/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.344118
[3/9, 56/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.255219
[3/9, 57/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.309259
[3/9, 58/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.265641
[3/9, 59/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.277136
[3/9, 60/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.274612
[3/9, 61/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.282478
[3/9, 62/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.260153
[3/9, 63/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.259723
[3/9, 64/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.262169
[3/9, 65/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.266095
[3/9, 66/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.274597
[3/9, 67/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.332656
[3/9, 68/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.278507
[3/9, 69/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.296911
[3/9, 70/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.302864
[3/9, 71/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.358408
[3/9, 72/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.495436
[3/9, 73/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.249317
[3/9, 74/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.296378
[3/9, 75/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.392152
[3/9, 76/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.289521
[3/9, 77/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.312265
[3/9, 78/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.234421
[3/9, 79/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.280523
[3/9, 80/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.290916
[3/9, 81/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.327635
[3/9, 82/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.333700
[3/9, 83/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.269576
[3/9, 84/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.355911
[3/9, 85/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.280061
[3/9, 86/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.269591
[3/9, 87/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.320173
[3/9, 88/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.253248
[3/9, 89/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.262632
[3/9, 90/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.253818
[3/9, 91/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.440270
[3/9, 92/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.320763
[3/9, 93/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.274587
[3/9, 94/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.235854
Testing - 2024-06-14 16:19:30.862445
[3/9, 1/16]
[3/9, 2/16]
[3/9, 3/16]
[3/9, 4/16]
[3/9, 5/16]
[3/9, 6/16]
[3/9, 7/16]
[3/9, 8/16]
[3/9, 9/16]
[3/9, 10/16]
[3/9, 11/16]
[3/9, 12/16]
[3/9, 13/16]
[3/9, 14/16]
[3/9, 15/16]
[3/9, 16/16]
Testing Loss: 0.0574 - Epoch Time: 0:02:13.490371
Training - 2024-06-14 16:19:42.338485
[4/9, 1/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.272603
[4/9, 2/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.249209
[4/9, 3/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.341093
[4/9, 4/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.314305
[4/9, 5/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.279978
[4/9, 6/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.276101
[4/9, 7/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.265298
[4/9, 8/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.285963
[4/9, 9/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.319720
[4/9, 10/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.278087
[4/9, 11/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.289456
[4/9, 12/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.294395
[4/9, 13/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.296926
[4/9, 14/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.360467
[4/9, 15/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.472582
[4/9, 16/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.260707
[4/9, 17/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.260163
[4/9, 18/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.345095
[4/9, 19/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.278094
[4/9, 20/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.264693
[4/9, 21/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.282997
[4/9, 22/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.263115
[4/9, 23/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.262279
[4/9, 24/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.260719
[4/9, 25/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.293515
[4/9, 26/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.253803
[4/9, 27/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.265762
[4/9, 28/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.310788
[4/9, 29/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.311304
[4/9, 30/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.263148
[4/9, 31/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.292442
[4/9, 32/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.243448
[4/9, 33/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.251249
[4/9, 34/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.263771
[4/9, 35/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.241856
[4/9, 36/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.304352
[4/9, 37/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.306332
[4/9, 38/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.305848
[4/9, 39/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.330126
[4/9, 40/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.375289
[4/9, 41/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.281027
[4/9, 42/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.295381
[4/9, 43/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.253219
[4/9, 44/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.279027
[4/9, 45/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.245355
[4/9, 46/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.257707
[4/9, 47/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.278036
[4/9, 48/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.259216
[4/9, 49/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.274144
[4/9, 50/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.273062
[4/9, 51/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.272593
[4/9, 52/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.256304
[4/9, 53/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.324179
[4/9, 54/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.289935
[4/9, 55/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.269139
[4/9, 56/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.279553
[4/9, 57/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.271076
[4/9, 58/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.284466
[4/9, 59/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.314305
[4/9, 60/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.272072
[4/9, 61/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.294418
[4/9, 62/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.298394
[4/9, 63/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.648201
[4/9, 64/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.369360
[4/9, 65/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.324642
[4/9, 66/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.278568
[4/9, 67/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.256221
[4/9, 68/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.271566
[4/9, 69/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.299391
[4/9, 70/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.257194
[4/9, 71/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.269609
[4/9, 72/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.359432
[4/9, 73/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.296894
[4/9, 74/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.322180
[4/9, 75/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.290480
[4/9, 76/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.314220
[4/9, 77/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.306778
[4/9, 78/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.266133
[4/9, 79/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.274099
[4/9, 80/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.325151
[4/9, 81/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.291964
[4/9, 82/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.301906
[4/9, 83/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.275129
[4/9, 84/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.304328
[4/9, 85/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.259772
[4/9, 86/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.345044
[4/9, 87/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.269635
[4/9, 88/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.429026
[4/9, 89/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.289950
[4/9, 90/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.283128
[4/9, 91/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.267681
[4/9, 92/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.248331
[4/9, 93/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.270644
[4/9, 94/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.216537
Testing - 2024-06-14 16:21:44.020603
[4/9, 1/16]
[4/9, 2/16]
[4/9, 3/16]
[4/9, 4/16]
[4/9, 5/16]
[4/9, 6/16]
[4/9, 7/16]
[4/9, 8/16]
[4/9, 9/16]
[4/9, 10/16]
[4/9, 11/16]
[4/9, 12/16]
[4/9, 13/16]
[4/9, 14/16]
[4/9, 15/16]
[4/9, 16/16]
Testing Loss: 0.0531 - Epoch Time: 0:02:13.411538
Training - 2024-06-14 16:21:55.750023
[5/9, 1/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.317230
[5/9, 2/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.250969
[5/9, 3/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.322185
[5/9, 4/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.368354
[5/9, 5/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.476579
[5/9, 6/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.274041
[5/9, 7/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.333657
[5/9, 8/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.361875
[5/9, 9/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.273575
[5/9, 10/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.389175
[5/9, 11/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.315766
[5/9, 12/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.286472
[5/9, 13/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.301310
[5/9, 14/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.287061
[5/9, 15/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.293395
[5/9, 16/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.293456
[5/9, 17/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.308781
[5/9, 18/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.287957
[5/9, 19/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.267135
[5/9, 20/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.275036
[5/9, 21/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.302384
[5/9, 22/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.304287
[5/9, 23/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.311340
[5/9, 24/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.271656
[5/9, 25/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.298429
[5/9, 26/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.260672
[5/9, 27/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.303855
[5/9, 28/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.260645
[5/9, 29/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.352996
[5/9, 30/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.317190
[5/9, 31/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.276160
[5/9, 32/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.267596
[5/9, 33/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.305332
[5/9, 34/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.296373
[5/9, 35/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.384282
[5/9, 36/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.295390
[5/9, 37/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.261171
[5/9, 38/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.279068
[5/9, 39/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.288497
[5/9, 40/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.260244
[5/9, 41/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.245837
[5/9, 42/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.241881
[5/9, 43/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.392679
[5/9, 44/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.303354
[5/9, 45/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.275672
[5/9, 46/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.281562
[5/9, 47/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.264166
[5/9, 48/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.271624
[5/9, 49/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.253263
[5/9, 50/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.356955
[5/9, 51/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.505901
[5/9, 52/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.291947
[5/9, 53/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.272585
[5/9, 54/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.365444
[5/9, 55/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.285515
[5/9, 56/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.305790
[5/9, 57/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.258693
[5/9, 58/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.273115
[5/9, 59/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.291916
[5/9, 60/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.329579
[5/9, 61/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.280559
[5/9, 62/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.286442
[5/9, 63/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.286537
[5/9, 64/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.262664
[5/9, 65/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.267657
[5/9, 66/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.283114
[5/9, 67/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.287550
[5/9, 68/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.288477
[5/9, 69/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.282020
[5/9, 70/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.268614
[5/9, 71/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.288978
[5/9, 72/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.243382
[5/9, 73/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.296752
[5/9, 74/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.322204
[5/9, 75/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.293496
[5/9, 76/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.379717
[5/9, 77/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.330626
[5/9, 78/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.260180
[5/9, 79/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.269894
[5/9, 80/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.263228
[5/9, 81/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.279414
[5/9, 82/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.264186
[5/9, 83/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.325214
[5/9, 84/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.288968
[5/9, 85/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.336978
[5/9, 86/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.298889
[5/9, 87/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.281079
[5/9, 88/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.304395
[5/9, 89/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.266071
[5/9, 90/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.279991
[5/9, 91/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.263172
[5/9, 92/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.420960
[5/9, 93/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.293882
[5/9, 94/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.245368
Testing - 2024-06-14 16:23:57.983305
[5/9, 1/16]
[5/9, 2/16]
[5/9, 3/16]
[5/9, 4/16]
[5/9, 5/16]
[5/9, 6/16]
[5/9, 7/16]
[5/9, 8/16]
[5/9, 9/16]
[5/9, 10/16]
[5/9, 11/16]
[5/9, 12/16]
[5/9, 13/16]
[5/9, 14/16]
[5/9, 15/16]
[5/9, 16/16]
Testing Loss: 0.0496 - Epoch Time: 0:02:13.996266
Training - 2024-06-14 16:24:09.746785
[6/9, 1/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.269079
[6/9, 2/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.294450
[6/9, 3/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.333690
[6/9, 4/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.271628
[6/9, 5/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.259773
[6/9, 6/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.253878
[6/9, 7/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.303887
[6/9, 8/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.290519
[6/9, 9/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.267002
[6/9, 10/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.258161
[6/9, 11/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.276132
[6/9, 12/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.279557
[6/9, 13/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.288510
[6/9, 14/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.297384
[6/9, 15/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.283041
[6/9, 16/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.258361
[6/9, 17/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.275651
[6/9, 18/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.309771
[6/9, 19/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.263205
[6/9, 20/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.281586
[6/9, 21/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.269578
[6/9, 22/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.274552
[6/9, 23/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.371859
[6/9, 24/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.250947
[6/9, 25/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.282991
[6/9, 26/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.291961
[6/9, 27/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.288047
[6/9, 28/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.271101
[6/9, 29/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.282512
[6/9, 30/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.288933
[6/9, 31/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.271134
[6/9, 32/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.300449
[6/9, 33/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.313738
[6/9, 34/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.244360
[6/9, 35/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.270125
[6/9, 36/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.274574
[6/9, 37/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.254194
[6/9, 38/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.276558
[6/9, 39/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.259661
[6/9, 40/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.307860
[6/9, 41/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.341585
[6/9, 42/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.488391
[6/9, 43/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.311267
[6/9, 44/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.359982
[6/9, 45/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.279007
[6/9, 46/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.270562
[6/9, 47/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.418536
[6/9, 48/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.274619
[6/9, 49/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.251230
[6/9, 50/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.322721
[6/9, 51/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.250328
[6/9, 52/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.289471
[6/9, 53/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.263643
[6/9, 54/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.275158
[6/9, 55/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.285569
[6/9, 56/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.284055
[6/9, 57/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.320259
[6/9, 58/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.325734
[6/9, 59/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.304829
[6/9, 60/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.269634
[6/9, 61/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.351649
[6/9, 62/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.298926
[6/9, 63/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.268139
[6/9, 64/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.263170
[6/9, 65/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.266652
[6/9, 66/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.267631
[6/9, 67/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.250755
[6/9, 68/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.258752
[6/9, 69/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.286461
[6/9, 70/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.268632
[6/9, 71/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.271150
[6/9, 72/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.297473
[6/9, 73/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.296369
[6/9, 74/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.347476
[6/9, 75/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.273214
[6/9, 76/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.256177
[6/9, 77/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.253271
[6/9, 78/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.264937
[6/9, 79/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.268636
[6/9, 80/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.269903
[6/9, 81/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.263209
[6/9, 82/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.311776
[6/9, 83/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.314227
[6/9, 84/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.245516
[6/9, 85/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.246751
[6/9, 86/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.325173
[6/9, 87/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.491452
[6/9, 88/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.332722
[6/9, 89/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.306281
[6/9, 90/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.353460
[6/9, 91/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.255310
[6/9, 92/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.278573
[6/9, 93/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.476022
[6/9, 94/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.211564
Testing - 2024-06-14 16:26:11.278738
[6/9, 1/16]
[6/9, 2/16]
[6/9, 3/16]
[6/9, 4/16]
[6/9, 5/16]
[6/9, 6/16]
[6/9, 7/16]
[6/9, 8/16]
[6/9, 9/16]
[6/9, 10/16]
[6/9, 11/16]
[6/9, 12/16]
[6/9, 13/16]
[6/9, 14/16]
[6/9, 15/16]
[6/9, 16/16]
Testing Loss: 0.0485 - Epoch Time: 0:02:12.957021
Training - 2024-06-14 16:26:22.704302
[7/9, 1/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.269223
[7/9, 2/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.249715
[7/9, 3/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.257250
[7/9, 4/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.268635
[7/9, 5/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.319204
[7/9, 6/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.240321
[7/9, 7/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.259182
[7/9, 8/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.257813
[7/9, 9/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.254750
[7/9, 10/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.267100
[7/9, 11/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.258175
[7/9, 12/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.257688
[7/9, 13/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.261648
[7/9, 14/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.251721
[7/9, 15/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.261663
[7/9, 16/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.260659
[7/9, 17/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.257333
[7/9, 18/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.268175
[7/9, 19/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.246250
[7/9, 20/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.284568
[7/9, 21/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.249793
[7/9, 22/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.288994
[7/9, 23/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.254812
[7/9, 24/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.234584
[7/9, 25/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.257230
[7/9, 26/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.310447
[7/9, 27/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.278017
[7/9, 28/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.274098
[7/9, 29/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.271180
[7/9, 30/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.352499
[7/9, 31/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.552200
[7/9, 32/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.338576
[7/9, 33/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.277566
[7/9, 34/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.336592
[7/9, 35/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.268963
[7/9, 36/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.279031
[7/9, 37/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.280612
[7/9, 38/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.267118
[7/9, 39/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.285787
[7/9, 40/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.285563
[7/9, 41/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.283546
[7/9, 42/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.270098
[7/9, 43/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.263170
[7/9, 44/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.387256
[7/9, 45/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.266137
[7/9, 46/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.269603
[7/9, 47/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.278006
[7/9, 48/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.304895
[7/9, 49/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.338194
[7/9, 50/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.259696
[7/9, 51/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.275802
[7/9, 52/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.252807
[7/9, 53/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.260687
[7/9, 54/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.300341
[7/9, 55/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.303815
[7/9, 56/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.318235
[7/9, 57/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.263687
[7/9, 58/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.268096
[7/9, 59/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.262738
[7/9, 60/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.267663
[7/9, 61/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.282463
[7/9, 62/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.282058
[7/9, 63/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.302392
[7/9, 64/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.342037
[7/9, 65/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.285988
[7/9, 66/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.246337
[7/9, 67/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.250761
[7/9, 68/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.286570
[7/9, 69/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.274073
[7/9, 70/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.263271
[7/9, 71/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.250734
[7/9, 72/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.252705
[7/9, 73/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.307373
[7/9, 74/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.272112
[7/9, 75/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.254748
[7/9, 76/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.279029
[7/9, 77/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.472068
[7/9, 78/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.327649
[7/9, 79/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.277511
[7/9, 80/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.417006
[7/9, 81/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.363329
[7/9, 82/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.267624
[7/9, 83/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.268101
[7/9, 84/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.254736
[7/9, 85/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.293890
[7/9, 86/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.280523
[7/9, 87/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.251801
[7/9, 88/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.264183
[7/9, 89/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.296904
[7/9, 90/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.313778
[7/9, 91/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.276572
[7/9, 92/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.524131
[7/9, 93/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.246836
[7/9, 94/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.224999
Testing - 2024-06-14 16:28:23.732521
[7/9, 1/16]
[7/9, 2/16]
[7/9, 3/16]
[7/9, 4/16]
[7/9, 5/16]
[7/9, 6/16]
[7/9, 7/16]
[7/9, 8/16]
[7/9, 9/16]
[7/9, 10/16]
[7/9, 11/16]
[7/9, 12/16]
[7/9, 13/16]
[7/9, 14/16]
[7/9, 15/16]
[7/9, 16/16]
Testing Loss: 0.0446 - Epoch Time: 0:02:12.675214
Training - 2024-06-14 16:28:35.379516
[8/9, 1/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.250839
[8/9, 2/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.302357
[8/9, 3/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.318361
[8/9, 4/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.288978
[8/9, 5/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.263749
[8/9, 6/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.259227
[8/9, 7/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.322250
[8/9, 8/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.262961
[8/9, 9/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.286980
[8/9, 10/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.271739
[8/9, 11/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.262173
[8/9, 12/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.273598
[8/9, 13/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.270131
[8/9, 14/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.267624
[8/9, 15/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.282781
[8/9, 16/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.315776
[8/9, 17/94] Training Loss: 0.0427 - Iteration Time: 0:00:01.259728
[8/9, 18/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.305344
[8/9, 19/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.286503
[8/9, 20/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.317186
[8/9, 21/94] Training Loss: 0.0439 - Iteration Time: 0:00:01.334166
[8/9, 22/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.471045
[8/9, 23/94] Training Loss: 0.0427 - Iteration Time: 0:00:01.293924
[8/9, 24/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.350072
[8/9, 25/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.298884
[8/9, 26/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.270086
[8/9, 27/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.294881
[8/9, 28/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.305338
[8/9, 29/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.259162
[8/9, 30/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.285001
[8/9, 31/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.267609
[8/9, 32/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.326156
[8/9, 33/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.301898
[8/9, 34/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.251283
[8/9, 35/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.248279
[8/9, 36/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.347044
[8/9, 37/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.272090
[8/9, 38/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.258710
[8/9, 39/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.253735
[8/9, 40/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.250239
[8/9, 41/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.256242
[8/9, 42/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.307804
[8/9, 43/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.352154
[8/9, 44/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.335687
[8/9, 45/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.270578
[8/9, 46/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.262695
[8/9, 47/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.417217
[8/9, 48/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.271133
[8/9, 49/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.272164
[8/9, 50/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.271106
[8/9, 51/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.260245
[8/9, 52/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.351943
[8/9, 53/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.342060
[8/9, 54/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.310943
[8/9, 55/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.265707
[8/9, 56/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.286046
[8/9, 57/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.280525
[8/9, 58/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.293051
[8/9, 59/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.290424
[8/9, 60/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.276003
[8/9, 61/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.265682
[8/9, 62/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.270165
[8/9, 63/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.259204
[8/9, 64/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.270174
[8/9, 65/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.247818
[8/9, 66/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.387960
[8/9, 67/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.502514
[8/9, 68/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.274543
[8/9, 69/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.334848
[8/9, 70/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.332147
[8/9, 71/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.259687
[8/9, 72/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.260173
[8/9, 73/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.279342
[8/9, 74/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.299845
[8/9, 75/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.283458
[8/9, 76/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.320710
[8/9, 77/94] Training Loss: 0.0439 - Iteration Time: 0:00:01.321234
[8/9, 78/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.318828
[8/9, 79/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.262639
[8/9, 80/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.263662
[8/9, 81/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.350976
[8/9, 82/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.251215
[8/9, 83/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.280014
[8/9, 84/94] Training Loss: 0.0409 - Iteration Time: 0:00:01.258196
[8/9, 85/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.258702
[8/9, 86/94] Training Loss: 0.0427 - Iteration Time: 0:00:01.264621
[8/9, 87/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.256683
[8/9, 88/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.260201
[8/9, 89/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.290961
[8/9, 90/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.256215
[8/9, 91/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.271124
[8/9, 92/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.272084
[8/9, 93/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.259728
[8/9, 94/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.219509
Testing - 2024-06-14 16:30:36.816637
[8/9, 1/16]
[8/9, 2/16]
[8/9, 3/16]
[8/9, 4/16]
[8/9, 5/16]
[8/9, 6/16]
[8/9, 7/16]
[8/9, 8/16]
[8/9, 9/16]
[8/9, 10/16]
[8/9, 11/16]
[8/9, 12/16]
[8/9, 13/16]
[8/9, 14/16]
[8/9, 15/16]
[8/9, 16/16]
Testing Loss: 0.0421 - Epoch Time: 0:02:13.127500
Training - 2024-06-14 16:30:48.507512
[9/9, 1/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.413126
[9/9, 2/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.299842
[9/9, 3/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.310390
[9/9, 4/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.240417
[9/9, 5/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.249760
[9/9, 6/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.256793
[9/9, 7/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.276049
[9/9, 8/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.285504
[9/9, 9/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.258777
[9/9, 10/94] Training Loss: 0.0404 - Iteration Time: 0:00:01.344109
[9/9, 11/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.473529
[9/9, 12/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.282979
[9/9, 13/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.470326
[9/9, 14/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.322193
[9/9, 15/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.254735
[9/9, 16/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.259670
[9/9, 17/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.278592
[9/9, 18/94] Training Loss: 0.0394 - Iteration Time: 0:00:01.299346
[9/9, 19/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.273631
[9/9, 20/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.264650
[9/9, 21/94] Training Loss: 0.0403 - Iteration Time: 0:00:01.317799
[9/9, 22/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.262147
[9/9, 23/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.282559
[9/9, 24/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.340149
[9/9, 25/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.331081
[9/9, 26/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.273617
[9/9, 27/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.280485
[9/9, 28/94] Training Loss: 0.0394 - Iteration Time: 0:00:01.273055
[9/9, 29/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.264730
[9/9, 30/94] Training Loss: 0.0403 - Iteration Time: 0:00:01.260185
[9/9, 31/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.350004
[9/9, 32/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.272610
[9/9, 33/94] Training Loss: 0.0397 - Iteration Time: 0:00:01.294448
[9/9, 34/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.262151
[9/9, 35/94] Training Loss: 0.0400 - Iteration Time: 0:00:01.258752
[9/9, 36/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.260639
[9/9, 37/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.346598
[9/9, 38/94] Training Loss: 0.0400 - Iteration Time: 0:00:01.272591
[9/9, 39/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.249731
[9/9, 40/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.267218
[9/9, 41/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.251263
[9/9, 42/94] Training Loss: 0.0405 - Iteration Time: 0:00:01.295932
[9/9, 43/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.268146
[9/9, 44/94] Training Loss: 0.0399 - Iteration Time: 0:00:01.406031
[9/9, 45/94] Training Loss: 0.0399 - Iteration Time: 0:00:01.256230
[9/9, 46/94] Training Loss: 0.0398 - Iteration Time: 0:00:01.280995
[9/9, 47/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.244816
[9/9, 48/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.256689
[9/9, 49/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.348017
[9/9, 50/94] Training Loss: 0.0398 - Iteration Time: 0:00:01.287444
[9/9, 51/94] Training Loss: 0.0393 - Iteration Time: 0:00:01.249799
[9/9, 52/94] Training Loss: 0.0407 - Iteration Time: 0:00:01.291927
[9/9, 53/94] Training Loss: 0.0395 - Iteration Time: 0:00:01.244831
[9/9, 54/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.245863
[9/9, 55/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.309300
[9/9, 56/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.315299
[9/9, 57/94] Training Loss: 0.0397 - Iteration Time: 0:00:01.561373
[9/9, 58/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.232344
[9/9, 59/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.311271
[9/9, 60/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.332103
[9/9, 61/94] Training Loss: 0.0403 - Iteration Time: 0:00:01.243799
[9/9, 62/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.245270
[9/9, 63/94] Training Loss: 0.0409 - Iteration Time: 0:00:01.268590
[9/9, 64/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.248718
[9/9, 65/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.284511
[9/9, 66/94] Training Loss: 0.0397 - Iteration Time: 0:00:01.240795
[9/9, 67/94] Training Loss: 0.0392 - Iteration Time: 0:00:01.252714
[9/9, 68/94] Training Loss: 0.0401 - Iteration Time: 0:00:01.266126
[9/9, 69/94] Training Loss: 0.0398 - Iteration Time: 0:00:01.346008
[9/9, 70/94] Training Loss: 0.0399 - Iteration Time: 0:00:01.261175
[9/9, 71/94] Training Loss: 0.0402 - Iteration Time: 0:00:01.308774
[9/9, 72/94] Training Loss: 0.0392 - Iteration Time: 0:00:01.268112
[9/9, 73/94] Training Loss: 0.0391 - Iteration Time: 0:00:01.295982
[9/9, 74/94] Training Loss: 0.0395 - Iteration Time: 0:00:01.299421
[9/9, 75/94] Training Loss: 0.0386 - Iteration Time: 0:00:01.316814
[9/9, 76/94] Training Loss: 0.0402 - Iteration Time: 0:00:01.266648
[9/9, 77/94] Training Loss: 0.0389 - Iteration Time: 0:00:01.302401
[9/9, 78/94] Training Loss: 0.0394 - Iteration Time: 0:00:01.260702
[9/9, 79/94] Training Loss: 0.0390 - Iteration Time: 0:00:01.280550
[9/9, 80/94] Training Loss: 0.0406 - Iteration Time: 0:00:01.434427
[9/9, 81/94] Training Loss: 0.0401 - Iteration Time: 0:00:01.435891
[9/9, 82/94] Training Loss: 0.0388 - Iteration Time: 0:00:01.394689
[9/9, 83/94] Training Loss: 0.0391 - Iteration Time: 0:00:01.426404
[9/9, 84/94] Training Loss: 0.0397 - Iteration Time: 0:00:01.474604
[9/9, 85/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.461677
[9/9, 86/94] Training Loss: 0.0387 - Iteration Time: 0:00:01.393250
[9/9, 87/94] Training Loss: 0.0405 - Iteration Time: 0:00:01.397161
[9/9, 88/94] Training Loss: 0.0393 - Iteration Time: 0:00:01.649649
[9/9, 89/94] Training Loss: 0.0380 - Iteration Time: 0:00:02.349565
[9/9, 90/94] Training Loss: 0.0407 - Iteration Time: 0:00:02.669582
[9/9, 91/94] Training Loss: 0.0404 - Iteration Time: 0:00:02.037943
[9/9, 92/94] Training Loss: 0.0395 - Iteration Time: 0:00:01.547457
[9/9, 93/94] Training Loss: 0.0398 - Iteration Time: 0:00:01.568851
[9/9, 94/94] Training Loss: 0.0379 - Iteration Time: 0:00:01.412540
Testing - 2024-06-14 16:32:55.338646
[9/9, 1/16]
[9/9, 2/16]
[9/9, 3/16]
[9/9, 4/16]
[9/9, 5/16]
[9/9, 6/16]
[9/9, 7/16]
[9/9, 8/16]
[9/9, 9/16]
[9/9, 10/16]
[9/9, 11/16]
[9/9, 12/16]
[9/9, 13/16]
[9/9, 14/16]
[9/9, 15/16]
[9/9, 16/16]
Testing Loss: 0.0393 - Epoch Time: 0:02:19.680858
Training and Testing Finished - Time: 0:20:29.563134
Assembling test data for t-sne projection
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 4
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 4
Applying t-SNE