Making Datasets...
Making Dataloaders...
Defining network...
5/5: Training network...
[1/1, 10/1875] train_loss: 1.0892875790596008
[1/1, 20/1875] train_loss: 1.1068125844001768
[1/1, 30/1875] train_loss: 1.0371467232704163
[1/1, 40/1875] train_loss: 1.007518392801285
[1/1, 50/1875] train_loss: 1.051230537891388
[1/1, 60/1875] train_loss: 1.0317342400550842
[1/1, 70/1875] train_loss: 1.0265373528003692
[1/1, 80/1875] train_loss: 0.9506420969963075
[1/1, 90/1875] train_loss: 0.9563649594783784
[1/1, 100/1875] train_loss: 0.9589354515075683
[1/1, 110/1875] train_loss: 0.9491766035556793
[1/1, 120/1875] train_loss: 0.9470214545726777
[1/1, 130/1875] train_loss: 0.8801395893096925
[1/1, 140/1875] train_loss: 0.8866003453731536
[1/1, 150/1875] train_loss: 0.892229700088501
[1/1, 160/1875] train_loss: 0.8997258365154265
[1/1, 170/1875] train_loss: 0.911181926727295
[1/1, 180/1875] train_loss: 0.8298280835151672
[1/1, 190/1875] train_loss: 0.873609894514084
[1/1, 200/1875] train_loss: 0.8486669957637787
[1/1, 210/1875] train_loss: 0.8284903883934022
[1/1, 220/1875] train_loss: 0.8198257446289062
[1/1, 230/1875] train_loss: 0.8052798509597778
[1/1, 240/1875] train_loss: 0.8257273733615875
[1/1, 250/1875] train_loss: 0.8241025984287261
[1/1, 260/1875] train_loss: 0.7870416343212128
[1/1, 270/1875] train_loss: 0.7827791750431061
[1/1, 280/1875] train_loss: 0.7839059114456175
[1/1, 290/1875] train_loss: 0.7565676271915436
[1/1, 300/1875] train_loss: 0.7451554715633393
[1/1, 310/1875] train_loss: 0.7443984150886537
[1/1, 320/1875] train_loss: 0.7255953431129456
[1/1, 330/1875] train_loss: 0.7188618004322053
[1/1, 340/1875] train_loss: 0.7300593912601472
[1/1, 350/1875] train_loss: 0.7203434944152831
[1/1, 360/1875] train_loss: 0.716474324464798
[1/1, 370/1875] train_loss: 0.6818257629871368
[1/1, 380/1875] train_loss: 0.6679739773273468
[1/1, 390/1875] train_loss: 0.6633276641368866
[1/1, 400/1875] train_loss: 0.6636542916297912
[1/1, 410/1875] train_loss: 0.6626004040241241
[1/1, 420/1875] train_loss: 0.6382203638553618
[1/1, 430/1875] train_loss: 0.6041190266609191
[1/1, 440/1875] train_loss: 0.6102801203727722
[1/1, 450/1875] train_loss: 0.6045406341552735
[1/1, 460/1875] train_loss: 0.6011092662811279
[1/1, 470/1875] train_loss: 0.609406167268753
[1/1, 480/1875] train_loss: 0.5744458854198455
[1/1, 490/1875] train_loss: 0.5978888928890229
[1/1, 500/1875] train_loss: 0.6123954653739929
[1/1, 510/1875] train_loss: 0.5906336843967437
[1/1, 520/1875] train_loss: 0.55986710190773
[1/1, 530/1875] train_loss: 0.5685559660196305
[1/1, 540/1875] train_loss: 0.5456335932016373
[1/1, 550/1875] train_loss: 0.5521655917167664
[1/1, 560/1875] train_loss: 0.5449247241020202
[1/1, 570/1875] train_loss: 0.5584223687648773
[1/1, 580/1875] train_loss: 0.5510774433612824
[1/1, 590/1875] train_loss: 0.5508730173110962
[1/1, 600/1875] train_loss: 0.5254211485385895
[1/1, 610/1875] train_loss: 0.5501108318567276
[1/1, 620/1875] train_loss: 0.5297219097614289
[1/1, 630/1875] train_loss: 0.5216219425201416
[1/1, 640/1875] train_loss: 0.5253972113132477
[1/1, 650/1875] train_loss: 0.5016073137521744
[1/1, 660/1875] train_loss: 0.5137058168649673
[1/1, 670/1875] train_loss: 0.50153389275074
[1/1, 680/1875] train_loss: 0.5184120655059814
[1/1, 690/1875] train_loss: 0.48436005711555474
[1/1, 700/1875] train_loss: 0.49387824833393107
[1/1, 710/1875] train_loss: 0.48794667422771454
[1/1, 720/1875] train_loss: 0.49949772953987126
[1/1, 730/1875] train_loss: 0.48536202013492585
[1/1, 740/1875] train_loss: 0.4835039526224136
[1/1, 750/1875] train_loss: 0.48422591984272
[1/1, 760/1875] train_loss: 0.48400614857673635
[1/1, 770/1875] train_loss: 0.44738044738769533
[1/1, 780/1875] train_loss: 0.45367151796817784
[1/1, 790/1875] train_loss: 0.4591507971286774
[1/1, 800/1875] train_loss: 0.4578319758176803
[1/1, 810/1875] train_loss: 0.44407552480697626
[1/1, 820/1875] train_loss: 0.44931707382202146
[1/1, 830/1875] train_loss: 0.46086368858814236
[1/1, 840/1875] train_loss: 0.4467681407928466
[1/1, 850/1875] train_loss: 0.4361260145902633
[1/1, 860/1875] train_loss: 0.4332110553979873
[1/1, 870/1875] train_loss: 0.44796690344810486
[1/1, 880/1875] train_loss: 0.44351052939891816
[1/1, 890/1875] train_loss: 0.4183844715356827
[1/1, 900/1875] train_loss: 0.4199150055646897
[1/1, 910/1875] train_loss: 0.42568315267562873
[1/1, 920/1875] train_loss: 0.42316168248653413
[1/1, 930/1875] train_loss: 0.41156148016452787
[1/1, 940/1875] train_loss: 0.4041291266679764
[1/1, 950/1875] train_loss: 0.40803999602794644
[1/1, 960/1875] train_loss: 0.39962920844554906
[1/1, 970/1875] train_loss: 0.3968718409538269
[1/1, 980/1875] train_loss: 0.39903567433357245
[1/1, 990/1875] train_loss: 0.39569199979305264
[1/1, 1000/1875] train_loss: 0.38565933108329775
[1/1, 1010/1875] train_loss: 0.4017984241247177
[1/1, 1020/1875] train_loss: 0.3802540242671966
[1/1, 1030/1875] train_loss: 0.3724150240421295
[1/1, 1040/1875] train_loss: 0.38541135191917425
[1/1, 1050/1875] train_loss: 0.37838950753211975
[1/1, 1060/1875] train_loss: 0.3722043663263321
[1/1, 1070/1875] train_loss: 0.3839095324277878
[1/1, 1080/1875] train_loss: 0.3832424610853195
[1/1, 1090/1875] train_loss: 0.3769568115472793
[1/1, 1100/1875] train_loss: 0.3690053731203079
[1/1, 1110/1875] train_loss: 0.37753057479858393
[1/1, 1120/1875] train_loss: 0.3624734073877335
[1/1, 1130/1875] train_loss: 0.35975477099418646
[1/1, 1140/1875] train_loss: 0.35831280350685124
[1/1, 1150/1875] train_loss: 0.33779486715793605
[1/1, 1160/1875] train_loss: 0.3421031177043915
[1/1, 1170/1875] train_loss: 0.33621088564395907
[1/1, 1180/1875] train_loss: 0.3458031296730042
[1/1, 1190/1875] train_loss: 0.3376133948564529
[1/1, 1200/1875] train_loss: 0.34151544868946077
[1/1, 1210/1875] train_loss: 0.3321400344371796
[1/1, 1220/1875] train_loss: 0.3289131104946137
[1/1, 1230/1875] train_loss: 0.3290929049253463
[1/1, 1240/1875] train_loss: 0.3300697028636932
[1/1, 1250/1875] train_loss: 0.31567195951938626
[1/1, 1260/1875] train_loss: 0.3253407835960388
[1/1, 1270/1875] train_loss: 0.3236872524023056
[1/1, 1280/1875] train_loss: 0.31234479546546934
[1/1, 1290/1875] train_loss: 0.30691046118736265
[1/1, 1300/1875] train_loss: 0.29887138307094574
[1/1, 1310/1875] train_loss: 0.318443512916565
[1/1, 1320/1875] train_loss: 0.31196719110012056
[1/1, 1330/1875] train_loss: 0.3039266616106034
[1/1, 1340/1875] train_loss: 0.3025990515947342
[1/1, 1350/1875] train_loss: 0.2982154399156571
[1/1, 1360/1875] train_loss: 0.2905539959669113
[1/1, 1370/1875] train_loss: 0.28916894197463994
[1/1, 1380/1875] train_loss: 0.2875734806060791
[1/1, 1390/1875] train_loss: 0.29771868586540223
[1/1, 1400/1875] train_loss: 0.2926529347896576
[1/1, 1410/1875] train_loss: 0.2877079635858536
[1/1, 1420/1875] train_loss: 0.27689272016286853
[1/1, 1430/1875] train_loss: 0.2873236179351807
[1/1, 1440/1875] train_loss: 0.2818598359823227
[1/1, 1450/1875] train_loss: 0.27574969679117206
[1/1, 1460/1875] train_loss: 0.28440442979335784
[1/1, 1470/1875] train_loss: 0.28295178413391114
[1/1, 1480/1875] train_loss: 0.27061752080917356
[1/1, 1490/1875] train_loss: 0.27090279161930086
[1/1, 1500/1875] train_loss: 0.2714485481381416
[1/1, 1510/1875] train_loss: 0.25848263651132586
[1/1, 1520/1875] train_loss: 0.2681827381253243
[1/1, 1530/1875] train_loss: 0.2805920362472535
[1/1, 1540/1875] train_loss: 0.26433068960905076
[1/1, 1550/1875] train_loss: 0.2657641321420669
[1/1, 1560/1875] train_loss: 0.2649965226650238
[1/1, 1570/1875] train_loss: 0.25860250145196917
[1/1, 1580/1875] train_loss: 0.26187341958284377
[1/1, 1590/1875] train_loss: 0.25413559973239896
[1/1, 1600/1875] train_loss: 0.27359238117933277
[1/1, 1610/1875] train_loss: 0.2609242096543312
[1/1, 1620/1875] train_loss: 0.259833362698555
[1/1, 1630/1875] train_loss: 0.24695824533700944
[1/1, 1640/1875] train_loss: 0.2547683402895927
[1/1, 1650/1875] train_loss: 0.2451015144586563
[1/1, 1660/1875] train_loss: 0.24112875312566756
[1/1, 1670/1875] train_loss: 0.2533317878842354
[1/1, 1680/1875] train_loss: 0.2399115264415741
[1/1, 1690/1875] train_loss: 0.247913333773613
[1/1, 1700/1875] train_loss: 0.2467400565743446
[1/1, 1710/1875] train_loss: 0.24322785586118698
[1/1, 1720/1875] train_loss: 0.25282068550586706
[1/1, 1730/1875] train_loss: 0.23760766535997394
[1/1, 1740/1875] train_loss: 0.23802015334367752
[1/1, 1750/1875] train_loss: 0.24072906821966175
[1/1, 1760/1875] train_loss: 0.2476651832461357
[1/1, 1770/1875] train_loss: 0.239213290810585
[1/1, 1780/1875] train_loss: 0.24511113315820696
[1/1, 1790/1875] train_loss: 0.24851060360670088
[1/1, 1800/1875] train_loss: 0.24002668708562852
[1/1, 1810/1875] train_loss: 0.2377564787864685
[1/1, 1820/1875] train_loss: 0.24345422238111494
[1/1, 1830/1875] train_loss: 0.22840799540281298
[1/1, 1840/1875] train_loss: 0.2294654622673988
[1/1, 1850/1875] train_loss: 0.2348709046840668
[1/1, 1860/1875] train_loss: 0.23072140961885454
[1/1, 1870/1875] train_loss: 0.2332499995827675
5/5: Testing network...
test_loss: 0.0002313095778702928
Training Finished
tensor([9, 8, 8, 9, 3, 2, 6, 1, 5, 1, 9, 9, 6, 7, 2, 3, 2, 0, 5, 9, 0, 9, 1, 0,
        7, 9, 8, 4, 9, 2, 8, 1])
9 added
8 added
3 added
2 added
6 added
1 added
5 added
7 added
0 added
4 added