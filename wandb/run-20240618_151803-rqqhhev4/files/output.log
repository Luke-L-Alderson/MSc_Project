Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 15:18:04.747434
Scaler Value: 0.20833333333333331
Training - 2024-06-18 15:18:04.748426
[1/9, 10/94] Training Loss: 0.4008 - Iteration Time: 0:00:01.580623
[1/9, 20/94] Training Loss: 0.3929 - Iteration Time: 0:00:01.678924
[1/9, 30/94] Training Loss: 0.3940 - Iteration Time: 0:00:01.604634
[1/9, 40/94] Training Loss: 0.3953 - Iteration Time: 0:00:01.653123
[1/9, 50/94] Training Loss: 0.3924 - Iteration Time: 0:00:01.546589
[1/9, 60/94] Training Loss: 0.3885 - Iteration Time: 0:00:01.550587
[1/9, 70/94] Training Loss: 0.3846 - Iteration Time: 0:00:01.582201
[1/9, 80/94] Training Loss: 0.3870 - Iteration Time: 0:00:01.543760
[1/9, 90/94] Training Loss: 0.3842 - Iteration Time: 0:00:01.562924
Testing - 2024-06-18 15:20:35.853324
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.3711 - Epoch Time: 0:02:45.940797
Training - 2024-06-18 15:20:50.689721
[2/9, 10/94] Training Loss: 0.3871 - Iteration Time: 0:00:01.526989
[2/9, 20/94] Training Loss: 0.3762 - Iteration Time: 0:00:01.544372
[2/9, 30/94] Training Loss: 0.3776 - Iteration Time: 0:00:01.601166
[2/9, 40/94] Training Loss: 0.3766 - Iteration Time: 0:00:01.555302
[2/9, 50/94] Training Loss: 0.3728 - Iteration Time: 0:00:01.531968
[2/9, 60/94] Training Loss: 0.3742 - Iteration Time: 0:00:01.656437
[2/9, 70/94] Training Loss: 0.3705 - Iteration Time: 0:00:01.631478
[2/9, 80/94] Training Loss: 0.3654 - Iteration Time: 0:00:01.566817
[2/9, 90/94] Training Loss: 0.3675 - Iteration Time: 0:00:01.581621
Testing - 2024-06-18 15:23:22.371834
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.3628 - Epoch Time: 0:02:46.899544
Training - 2024-06-18 15:23:37.589761
[3/9, 10/94] Training Loss: 0.3650 - Iteration Time: 0:00:01.419429
[3/9, 20/94] Training Loss: 0.3674 - Iteration Time: 0:00:01.391086
[3/9, 30/94] Training Loss: 0.3637 - Iteration Time: 0:00:01.578972
[3/9, 40/94] Training Loss: 0.3657 - Iteration Time: 0:00:01.696162
[3/9, 50/94] Training Loss: 0.3652 - Iteration Time: 0:00:01.562956
[3/9, 60/94] Training Loss: 0.3631 - Iteration Time: 0:00:01.553160
[3/9, 70/94] Training Loss: 0.3596 - Iteration Time: 0:00:01.532803
[3/9, 80/94] Training Loss: 0.3616 - Iteration Time: 0:00:01.700423
[3/9, 90/94] Training Loss: 0.3608 - Iteration Time: 0:00:01.534319
Testing - 2024-06-18 15:26:04.474112
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.3473 - Epoch Time: 0:02:41.688966
Training - 2024-06-18 15:26:19.279223
[4/9, 10/94] Training Loss: 0.3571 - Iteration Time: 0:00:01.772849
[4/9, 20/94] Training Loss: 0.3590 - Iteration Time: 0:00:02.004464
[4/9, 30/94] Training Loss: 0.3567 - Iteration Time: 0:00:01.485863
[4/9, 40/94] Training Loss: 0.3531 - Iteration Time: 0:00:01.797453
[4/9, 50/94] Training Loss: 0.3548 - Iteration Time: 0:00:01.500661
[4/9, 60/94] Training Loss: 0.3520 - Iteration Time: 0:00:01.543179
[4/9, 70/94] Training Loss: 0.3553 - Iteration Time: 0:00:01.504556
[4/9, 80/94] Training Loss: 0.3536 - Iteration Time: 0:00:01.466403
[4/9, 90/94] Training Loss: 0.3481 - Iteration Time: 0:00:01.476699
Testing - 2024-06-18 15:28:48.598785
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.3415 - Epoch Time: 0:02:43.477479
Training - 2024-06-18 15:29:02.757198
[5/9, 10/94] Training Loss: 0.3486 - Iteration Time: 0:00:01.473403
[5/9, 20/94] Training Loss: 0.3497 - Iteration Time: 0:00:01.465027
[5/9, 30/94] Training Loss: 0.3426 - Iteration Time: 0:00:01.500794
[5/9, 40/94] Training Loss: 0.3432 - Iteration Time: 0:00:01.657274
[5/9, 50/94] Training Loss: 0.3429 - Iteration Time: 0:00:01.493816
[5/9, 60/94] Training Loss: 0.3418 - Iteration Time: 0:00:01.488761
[5/9, 70/94] Training Loss: 0.3394 - Iteration Time: 0:00:01.475027
[5/9, 80/94] Training Loss: 0.3344 - Iteration Time: 0:00:01.587336
[5/9, 90/94] Training Loss: 0.3379 - Iteration Time: 0:00:01.450018
Testing - 2024-06-18 15:31:24.305215
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.3280 - Epoch Time: 0:02:35.699488
Training - 2024-06-18 15:31:38.457181
[6/9, 10/94] Training Loss: 0.3357 - Iteration Time: 0:00:01.445433
[6/9, 20/94] Training Loss: 0.3314 - Iteration Time: 0:00:01.482032
[6/9, 30/94] Training Loss: 0.3316 - Iteration Time: 0:00:01.455818
[6/9, 40/94] Training Loss: 0.3324 - Iteration Time: 0:00:01.519955
[6/9, 50/94] Training Loss: 0.3300 - Iteration Time: 0:00:01.455987
[6/9, 60/94] Training Loss: 0.3298 - Iteration Time: 0:00:01.497528
[6/9, 70/94] Training Loss: 0.3316 - Iteration Time: 0:00:01.454961
[6/9, 80/94] Training Loss: 0.3291 - Iteration Time: 0:00:01.493691
[6/9, 90/94] Training Loss: 0.3279 - Iteration Time: 0:00:01.523134
Testing - 2024-06-18 15:34:00.946629
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.3134 - Epoch Time: 0:02:36.689380
Training - 2024-06-18 15:34:15.146561
[7/9, 10/94] Training Loss: 0.3255 - Iteration Time: 0:00:01.526873
[7/9, 20/94] Training Loss: 0.3228 - Iteration Time: 0:00:01.454225
[7/9, 30/94] Training Loss: 0.3215 - Iteration Time: 0:00:01.592177
[7/9, 40/94] Training Loss: 0.3189 - Iteration Time: 0:00:01.633173
[7/9, 50/94] Training Loss: 0.3182 - Iteration Time: 0:00:01.483738
[7/9, 60/94] Training Loss: 0.3113 - Iteration Time: 0:00:01.471148
[7/9, 70/94] Training Loss: 0.3137 - Iteration Time: 0:00:01.483229
[7/9, 80/94] Training Loss: 0.3137 - Iteration Time: 0:00:01.463957
[7/9, 90/94] Training Loss: 0.3107 - Iteration Time: 0:00:01.510091
Testing - 2024-06-18 15:36:36.613760
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.3006 - Epoch Time: 0:02:35.399593
Training - 2024-06-18 15:36:50.546154
[8/9, 10/94] Training Loss: 0.3118 - Iteration Time: 0:00:01.498889
[8/9, 20/94] Training Loss: 0.3075 - Iteration Time: 0:00:01.463019
[8/9, 30/94] Training Loss: 0.3074 - Iteration Time: 0:00:01.500650
[8/9, 40/94] Training Loss: 0.3058 - Iteration Time: 0:00:01.447674
[8/9, 50/94] Training Loss: 0.3043 - Iteration Time: 0:00:01.496727
[8/9, 60/94] Training Loss: 0.3056 - Iteration Time: 0:00:01.452825
[8/9, 70/94] Training Loss: 0.3013 - Iteration Time: 0:00:01.614223
[8/9, 80/94] Training Loss: 0.3022 - Iteration Time: 0:00:01.449984
[8/9, 90/94] Training Loss: 0.2991 - Iteration Time: 0:00:01.491923
Testing - 2024-06-18 15:39:12.287433
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.2926 - Epoch Time: 0:02:35.778273
Training - 2024-06-18 15:39:26.324923
[9/9, 10/94] Training Loss: 0.2980 - Iteration Time: 0:00:01.448235
[9/9, 20/94] Training Loss: 0.2972 - Iteration Time: 0:00:01.501943
[9/9, 30/94] Training Loss: 0.2971 - Iteration Time: 0:00:01.448452
[9/9, 40/94] Training Loss: 0.2922 - Iteration Time: 0:00:01.620218
[9/9, 50/94] Training Loss: 0.2912 - Iteration Time: 0:00:01.458487
[9/9, 60/94] Training Loss: 0.2939 - Iteration Time: 0:00:01.509833
[9/9, 70/94] Training Loss: 0.2920 - Iteration Time: 0:00:01.445442
[9/9, 80/94] Training Loss: 0.2910 - Iteration Time: 0:00:01.481275
[9/9, 90/94] Training Loss: 0.2938 - Iteration Time: 0:00:01.462343
Testing - 2024-06-18 15:41:48.044798
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.2821 - Epoch Time: 0:02:35.863435
Training and Testing Finished - Time: 0:23:57.441420
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
-- 1/16 --
-- 2/16 --
-- 3/16 --
-- 4/16 --
-- 5/16 --
-- 6/16 --
-- 7/16 --
-- 8/16 --
-- 9/16 --
-- 10/16 --
-- 11/16 --
-- 12/16 --
-- 13/16 --
-- 14/16 --
-- 15/16 --
-- 16/16 --
   Labels      0    1      2      3      4  ...   94   95   96   97     98     99
0       2  0.120  0.0  0.135  0.075  0.100  ...  0.0  0.0  0.0  0.0  0.075  0.075
1       4  0.115  0.0  0.075  0.105  0.025  ...  0.0  0.0  0.0  0.0  0.060  0.055
2       7  0.145  0.0  0.130  0.100  0.065  ...  0.0  0.0  0.0  0.0  0.075  0.045
3       3  0.105  0.0  0.060  0.150  0.070  ...  0.0  0.0  0.0  0.0  0.060  0.065
4       7  0.145  0.0  0.105  0.085  0.070  ...  0.0  0.0  0.0  0.0  0.075  0.000
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP