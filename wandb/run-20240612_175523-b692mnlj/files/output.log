Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-12 17:55:24.939112
Training - 2024-06-12 17:55:24.939608
[1/9, 10/94] Training Loss: 179.92 - Iteration Time: 0:00:01.290365
[1/9, 20/94] Training Loss: 170.51 - Iteration Time: 0:00:01.276552
[1/9, 30/94] Training Loss: 168.30 - Iteration Time: 0:00:01.292904
[1/9, 40/94] Training Loss: 166.31 - Iteration Time: 0:00:01.260689
[1/9, 50/94] Training Loss: 161.80 - Iteration Time: 0:00:01.249735
[1/9, 60/94] Training Loss: 156.25 - Iteration Time: 0:00:01.256264
[1/9, 70/94] Training Loss: 150.57 - Iteration Time: 0:00:01.359942
[1/9, 80/94] Training Loss: 147.92 - Iteration Time: 0:00:01.251730
[1/9, 90/94] Training Loss: 141.15 - Iteration Time: 0:00:01.540999
Testing - 2024-06-12 17:57:28.877670
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 132.82 - Epoch Time: 0:02:15.969852
Training - 2024-06-12 17:57:40.909460
[2/9, 10/94] Training Loss: 137.89 - Iteration Time: 0:00:01.242831
[2/9, 20/94] Training Loss: 128.13 - Iteration Time: 0:00:01.256188
[2/9, 30/94] Training Loss: 126.17 - Iteration Time: 0:00:01.329102
[2/9, 40/94] Training Loss: 122.67 - Iteration Time: 0:00:01.248235
[2/9, 50/94] Training Loss: 118.17 - Iteration Time: 0:00:01.417476
[2/9, 60/94] Training Loss: 116.61 - Iteration Time: 0:00:01.256227
[2/9, 70/94] Training Loss: 109.92 - Iteration Time: 0:00:01.327600
[2/9, 80/94] Training Loss: 104.62 - Iteration Time: 0:00:01.294453
[2/9, 90/94] Training Loss: 103.85 - Iteration Time: 0:00:01.271063
Testing - 2024-06-12 17:59:44.130558
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 88.15 - Epoch Time: 0:02:15.133011
Training - 2024-06-12 17:59:56.042471
[3/9, 10/94] Training Loss: 98.41 - Iteration Time: 0:00:01.289447
[3/9, 20/94] Training Loss: 98.99 - Iteration Time: 0:00:01.296929
[3/9, 30/94] Training Loss: 93.71 - Iteration Time: 0:00:01.310794
[3/9, 40/94] Training Loss: 92.21 - Iteration Time: 0:00:01.273586
[3/9, 50/94] Training Loss: 89.85 - Iteration Time: 0:00:01.556396
[3/9, 60/94] Training Loss: 86.43 - Iteration Time: 0:00:01.255772
[3/9, 70/94] Training Loss: 82.03 - Iteration Time: 0:00:01.299434
[3/9, 80/94] Training Loss: 81.42 - Iteration Time: 0:00:01.301922
[3/9, 90/94] Training Loss: 80.12 - Iteration Time: 0:00:01.311980
Testing - 2024-06-12 18:01:59.209165
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 79.16 - Epoch Time: 0:02:15.444488
Training - 2024-06-12 18:02:11.486959
[4/9, 10/94] Training Loss: 75.58 - Iteration Time: 0:00:01.538945
[4/9, 20/94] Training Loss: 76.38 - Iteration Time: 0:00:01.268669
[4/9, 30/94] Training Loss: 73.87 - Iteration Time: 0:00:01.269180
[4/9, 40/94] Training Loss: 71.76 - Iteration Time: 0:00:01.284032
[4/9, 50/94] Training Loss: 71.06 - Iteration Time: 0:00:01.277772
[4/9, 60/94] Training Loss: 68.67 - Iteration Time: 0:00:01.243851
[4/9, 70/94] Training Loss: 69.13 - Iteration Time: 0:00:01.318206
[4/9, 80/94] Training Loss: 66.95 - Iteration Time: 0:00:01.267706
[4/9, 90/94] Training Loss: 64.96 - Iteration Time: 0:00:01.276615
Testing - 2024-06-12 18:04:14.366788
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 65.74 - Epoch Time: 0:02:14.803840
Training - 2024-06-12 18:04:26.290799
[5/9, 10/94] Training Loss: 63.96 - Iteration Time: 0:00:01.265694
[5/9, 20/94] Training Loss: 63.78 - Iteration Time: 0:00:01.252727
[5/9, 30/94] Training Loss: 60.01 - Iteration Time: 0:00:01.346531
[5/9, 40/94] Training Loss: 59.75 - Iteration Time: 0:00:01.277072
[5/9, 50/94] Training Loss: 60.16 - Iteration Time: 0:00:01.324252
[5/9, 60/94] Training Loss: 59.13 - Iteration Time: 0:00:01.275023
[5/9, 70/94] Training Loss: 58.50 - Iteration Time: 0:00:01.259202
[5/9, 80/94] Training Loss: 56.06 - Iteration Time: 0:00:01.316772
[5/9, 90/94] Training Loss: 56.03 - Iteration Time: 0:00:01.258341
Testing - 2024-06-12 18:06:29.441234
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 54.95 - Epoch Time: 0:02:15.101683
Training - 2024-06-12 18:06:41.392977
[6/9, 10/94] Training Loss: 55.70 - Iteration Time: 0:00:01.257863
[6/9, 20/94] Training Loss: 54.28 - Iteration Time: 0:00:01.287977
[6/9, 30/94] Training Loss: 53.99 - Iteration Time: 0:00:01.272628
[6/9, 40/94] Training Loss: 53.69 - Iteration Time: 0:00:01.328234
[6/9, 50/94] Training Loss: 53.69 - Iteration Time: 0:00:01.258243
[6/9, 60/94] Training Loss: 53.04 - Iteration Time: 0:00:01.290009
[6/9, 70/94] Training Loss: 52.36 - Iteration Time: 0:00:01.320850
[6/9, 80/94] Training Loss: 51.03 - Iteration Time: 0:00:01.239851
[6/9, 90/94] Training Loss: 50.87 - Iteration Time: 0:00:01.350018
Testing - 2024-06-12 18:08:44.641881
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 49.93 - Epoch Time: 0:02:15.025390
Training - 2024-06-12 18:08:56.418863
[7/9, 10/94] Training Loss: 48.80 - Iteration Time: 0:00:01.367335
[7/9, 20/94] Training Loss: 48.47 - Iteration Time: 0:00:01.277647
[7/9, 30/94] Training Loss: 47.93 - Iteration Time: 0:00:01.284115
[7/9, 40/94] Training Loss: 46.62 - Iteration Time: 0:00:01.252205
[7/9, 50/94] Training Loss: 46.08 - Iteration Time: 0:00:01.333736
[7/9, 60/94] Training Loss: 43.46 - Iteration Time: 0:00:01.298966
[7/9, 70/94] Training Loss: 44.89 - Iteration Time: 0:00:01.256250
[7/9, 80/94] Training Loss: 44.48 - Iteration Time: 0:00:01.257233
[7/9, 90/94] Training Loss: 43.95 - Iteration Time: 0:00:01.259655
Testing - 2024-06-12 18:10:58.833477
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 43.22 - Epoch Time: 0:02:14.675518
Training - 2024-06-12 18:11:11.094381
[8/9, 10/94] Training Loss: 43.84 - Iteration Time: 0:00:01.265707
[8/9, 20/94] Training Loss: 41.84 - Iteration Time: 0:00:01.241364
[8/9, 30/94] Training Loss: 41.76 - Iteration Time: 0:00:01.270610
[8/9, 40/94] Training Loss: 40.70 - Iteration Time: 0:00:01.266201
[8/9, 50/94] Training Loss: 40.68 - Iteration Time: 0:00:01.326793
[8/9, 60/94] Training Loss: 41.16 - Iteration Time: 0:00:01.269693
[8/9, 70/94] Training Loss: 40.29 - Iteration Time: 0:00:01.316291
[8/9, 80/94] Training Loss: 40.47 - Iteration Time: 0:00:01.296903
[8/9, 90/94] Training Loss: 39.33 - Iteration Time: 0:00:01.278158
Testing - 2024-06-12 18:13:13.486717
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 39.84 - Epoch Time: 0:02:14.110733
Training - 2024-06-12 18:13:25.205610
[9/9, 10/94] Training Loss: 38.18 - Iteration Time: 0:00:01.326162
[9/9, 20/94] Training Loss: 38.13 - Iteration Time: 0:00:01.271153
[9/9, 30/94] Training Loss: 37.49 - Iteration Time: 0:00:01.701792
[9/9, 40/94] Training Loss: 36.71 - Iteration Time: 0:00:01.254742
[9/9, 50/94] Training Loss: 36.21 - Iteration Time: 0:00:01.247768
[9/9, 60/94] Training Loss: 36.23 - Iteration Time: 0:00:01.263194
[9/9, 70/94] Training Loss: 35.86 - Iteration Time: 0:00:01.247312
[9/9, 80/94] Training Loss: 35.07 - Iteration Time: 0:00:01.344532
[9/9, 90/94] Training Loss: 36.19 - Iteration Time: 0:00:01.242399
Testing - 2024-06-12 18:15:27.761651
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 34.48 - Epoch Time: 0:02:14.530292
Training and Testing Finished - Time: 0:20:14.797314
Assembling test data for t-sne projection
-- 10/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - {labels[input_index]}