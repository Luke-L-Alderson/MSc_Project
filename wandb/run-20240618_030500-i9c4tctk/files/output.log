Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 03:05:01.911068
Scaler Value: 0.050505050505050504
Training - 2024-06-18 03:05:01.911565
[1/9, 10/94] Training Loss: 0.9336 - Iteration Time: 0:00:01.434427
[1/9, 20/94] Training Loss: 0.9104 - Iteration Time: 0:00:01.412977
[1/9, 30/94] Training Loss: 0.8952 - Iteration Time: 0:00:01.415885
[1/9, 40/94] Training Loss: 0.8789 - Iteration Time: 0:00:01.412381
[1/9, 50/94] Training Loss: 0.8682 - Iteration Time: 0:00:01.416011
[1/9, 60/94] Training Loss: 0.8593 - Iteration Time: 0:00:01.425338
[1/9, 70/94] Training Loss: 0.8505 - Iteration Time: 0:00:01.397122
[1/9, 80/94] Training Loss: 0.8422 - Iteration Time: 0:00:01.424966
[1/9, 90/94] Training Loss: 0.8366 - Iteration Time: 0:00:01.416970
Testing - 2024-06-18 03:07:17.727554
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.8345 - Epoch Time: 0:02:29.111352
Training - 2024-06-18 03:07:31.023413
[2/9, 10/94] Training Loss: 0.8246 - Iteration Time: 0:00:01.390067
[2/9, 20/94] Training Loss: 0.8177 - Iteration Time: 0:00:01.404525
[2/9, 30/94] Training Loss: 0.8119 - Iteration Time: 0:00:01.423909
[2/9, 40/94] Training Loss: 0.8044 - Iteration Time: 0:00:01.387573
[2/9, 50/94] Training Loss: 0.7965 - Iteration Time: 0:00:01.432333
[2/9, 60/94] Training Loss: 0.7854 - Iteration Time: 0:00:01.404116
[2/9, 70/94] Training Loss: 0.7766 - Iteration Time: 0:00:01.431792
[2/9, 80/94] Training Loss: 0.7690 - Iteration Time: 0:00:01.485855
[2/9, 90/94] Training Loss: 0.7578 - Iteration Time: 0:00:01.577133
Testing - 2024-06-18 03:09:45.706435
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.7520 - Epoch Time: 0:02:27.876094
Training - 2024-06-18 03:09:58.900003
[3/9, 10/94] Training Loss: 0.7466 - Iteration Time: 0:00:01.480370
[3/9, 20/94] Training Loss: 0.7377 - Iteration Time: 0:00:01.413909
[3/9, 30/94] Training Loss: 0.7289 - Iteration Time: 0:00:01.399041
[3/9, 40/94] Training Loss: 0.7210 - Iteration Time: 0:00:01.460411
[3/9, 50/94] Training Loss: 0.7098 - Iteration Time: 0:00:01.396545
[3/9, 60/94] Training Loss: 0.7001 - Iteration Time: 0:00:01.619923
[3/9, 70/94] Training Loss: 0.6954 - Iteration Time: 0:00:01.429292
[3/9, 80/94] Training Loss: 0.6905 - Iteration Time: 0:00:01.400499
[3/9, 90/94] Training Loss: 0.6869 - Iteration Time: 0:00:01.396521
Testing - 2024-06-18 03:12:15.620256
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.6835 - Epoch Time: 0:02:29.973586
Training - 2024-06-18 03:12:28.874085
[4/9, 10/94] Training Loss: 0.6797 - Iteration Time: 0:00:01.387479
[4/9, 20/94] Training Loss: 0.6745 - Iteration Time: 0:00:01.432244
[4/9, 30/94] Training Loss: 0.6684 - Iteration Time: 0:00:01.382692
[4/9, 40/94] Training Loss: 0.6605 - Iteration Time: 0:00:01.559515
[4/9, 50/94] Training Loss: 0.6538 - Iteration Time: 0:00:01.389114
[4/9, 60/94] Training Loss: 0.6466 - Iteration Time: 0:00:01.378929
[4/9, 70/94] Training Loss: 0.6394 - Iteration Time: 0:00:01.383618
[4/9, 80/94] Training Loss: 0.6349 - Iteration Time: 0:00:01.422905
[4/9, 90/94] Training Loss: 0.6304 - Iteration Time: 0:00:01.489298
Testing - 2024-06-18 03:14:43.046409
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.6261 - Epoch Time: 0:02:27.321716
Training - 2024-06-18 03:14:56.196297
[5/9, 10/94] Training Loss: 0.6233 - Iteration Time: 0:00:01.395062
[5/9, 20/94] Training Loss: 0.6203 - Iteration Time: 0:00:01.430310
[5/9, 30/94] Training Loss: 0.6160 - Iteration Time: 0:00:01.428771
[5/9, 40/94] Training Loss: 0.6116 - Iteration Time: 0:00:01.398553
[5/9, 50/94] Training Loss: 0.6059 - Iteration Time: 0:00:01.385657
[5/9, 60/94] Training Loss: 0.6019 - Iteration Time: 0:00:01.414879
[5/9, 70/94] Training Loss: 0.5973 - Iteration Time: 0:00:01.416930
[5/9, 80/94] Training Loss: 0.5925 - Iteration Time: 0:00:01.401121
[5/9, 90/94] Training Loss: 0.5881 - Iteration Time: 0:00:01.415414
Testing - 2024-06-18 03:17:10.927521
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.5848 - Epoch Time: 0:02:28.126800
Training - 2024-06-18 03:17:24.323593
[6/9, 10/94] Training Loss: 0.5826 - Iteration Time: 0:00:01.419245
[6/9, 20/94] Training Loss: 0.5779 - Iteration Time: 0:00:01.430670
[6/9, 30/94] Training Loss: 0.5724 - Iteration Time: 0:00:01.396879
[6/9, 40/94] Training Loss: 0.5685 - Iteration Time: 0:00:01.407851
[6/9, 50/94] Training Loss: 0.5610 - Iteration Time: 0:00:01.388895
[6/9, 60/94] Training Loss: 0.5570 - Iteration Time: 0:00:01.383006
[6/9, 70/94] Training Loss: 0.5528 - Iteration Time: 0:00:01.442033
[6/9, 80/94] Training Loss: 0.5496 - Iteration Time: 0:00:01.382081
[6/9, 90/94] Training Loss: 0.5474 - Iteration Time: 0:00:01.394387
Testing - 2024-06-18 03:19:39.271979
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.5476 - Epoch Time: 0:02:28.040252
Training - 2024-06-18 03:19:52.363845
[7/9, 10/94] Training Loss: 0.5445 - Iteration Time: 0:00:01.431621
[7/9, 20/94] Training Loss: 0.5421 - Iteration Time: 0:00:01.428662
[7/9, 30/94] Training Loss: 0.5379 - Iteration Time: 0:00:01.376105
[7/9, 40/94] Training Loss: 0.5350 - Iteration Time: 0:00:01.372570
[7/9, 50/94] Training Loss: 0.5304 - Iteration Time: 0:00:01.439560
[7/9, 60/94] Training Loss: 0.5253 - Iteration Time: 0:00:01.397368
[7/9, 70/94] Training Loss: 0.5240 - Iteration Time: 0:00:01.418252
[7/9, 80/94] Training Loss: 0.5204 - Iteration Time: 0:00:01.421734
[7/9, 90/94] Training Loss: 0.5178 - Iteration Time: 0:00:01.465408
Testing - 2024-06-18 03:22:07.211566
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.5168 - Epoch Time: 0:02:28.155509
Training - 2024-06-18 03:22:20.519354
[8/9, 10/94] Training Loss: 0.5132 - Iteration Time: 0:00:01.430183
[8/9, 20/94] Training Loss: 0.5109 - Iteration Time: 0:00:01.404352
[8/9, 30/94] Training Loss: 0.5090 - Iteration Time: 0:00:01.406805
[8/9, 40/94] Training Loss: 0.5066 - Iteration Time: 0:00:01.399373
[8/9, 50/94] Training Loss: 0.5057 - Iteration Time: 0:00:01.429619
[8/9, 60/94] Training Loss: 0.5044 - Iteration Time: 0:00:01.421163
[8/9, 70/94] Training Loss: 0.5015 - Iteration Time: 0:00:01.441658
[8/9, 80/94] Training Loss: 0.4992 - Iteration Time: 0:00:01.598002
[8/9, 90/94] Training Loss: 0.4978 - Iteration Time: 0:00:01.416754
Testing - 2024-06-18 03:24:35.729593
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.4986 - Epoch Time: 0:02:28.442152
Training - 2024-06-18 03:24:48.961506
[9/9, 10/94] Training Loss: 0.4958 - Iteration Time: 0:00:01.410752
[9/9, 20/94] Training Loss: 0.4943 - Iteration Time: 0:00:01.432616
[9/9, 30/94] Training Loss: 0.4913 - Iteration Time: 0:00:01.394897
[9/9, 40/94] Training Loss: 0.4890 - Iteration Time: 0:00:01.397355
[9/9, 50/94] Training Loss: 0.4865 - Iteration Time: 0:00:01.459431
[9/9, 60/94] Training Loss: 0.4852 - Iteration Time: 0:00:01.399007
[9/9, 70/94] Training Loss: 0.4817 - Iteration Time: 0:00:01.407848
[9/9, 80/94] Training Loss: 0.4742 - Iteration Time: 0:00:01.397408
[9/9, 90/94] Training Loss: 0.4730 - Iteration Time: 0:00:01.391957
Testing - 2024-06-18 03:27:03.901150
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.4726 - Epoch Time: 0:02:28.195233
Training and Testing Finished - Time: 0:22:15.246167
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0    1      2    3    4    5  ...     93   94   95   96   97   98   99
0       2  0.0  0.0  0.225  0.0  0.0  0.0  ...  0.045  0.0  0.0  0.0  0.0  0.0  0.0
1       4  0.0  0.0  0.300  0.0  0.0  0.0  ...  0.135  0.0  0.0  0.0  0.0  0.0  0.0
2       7  0.0  0.0  0.215  0.0  0.0  0.0  ...  0.110  0.0  0.0  0.0  0.0  0.0  0.0
3       3  0.0  0.0  0.305  0.0  0.0  0.0  ...  0.110  0.0  0.0  0.0  0.0  0.0  0.0
4       7  0.0  0.0  0.270  0.0  0.0  0.0  ...  0.060  0.0  0.0  0.0  0.0  0.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP