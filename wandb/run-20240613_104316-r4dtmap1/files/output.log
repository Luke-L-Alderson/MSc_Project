Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-13 10:43:17.961814
Training - 2024-06-13 10:43:17.962311
[1/6, 10/94] Training Loss: 5.18 - Iteration Time: 0:00:01.270640
[1/6, 20/94] Training Loss: 5.05 - Iteration Time: 0:00:01.310926
[1/6, 30/94] Training Loss: 5.07 - Iteration Time: 0:00:01.315952
[1/6, 40/94] Training Loss: 5.08 - Iteration Time: 0:00:01.333694
[1/6, 50/94] Training Loss: 5.04 - Iteration Time: 0:00:01.277933
[1/6, 60/94] Training Loss: 4.97 - Iteration Time: 0:00:01.292827
[1/6, 70/94] Training Loss: 4.92 - Iteration Time: 0:00:01.311850
[1/6, 80/94] Training Loss: 4.94 - Iteration Time: 0:00:01.303634
[1/6, 90/94] Training Loss: 4.89 - Iteration Time: 0:00:01.347651
Testing - 2024-06-13 10:45:24.173454
[1/6, 2/16]
[1/6, 4/16]
[1/6, 6/16]
[1/6, 8/16]
[1/6, 10/16]
[1/6, 12/16]
[1/6, 14/16]
[1/6, 16/16]
Testing Loss: 4.68 - Epoch Time: 0:02:18.174795
Training - 2024-06-13 10:45:36.137106
[2/6, 10/94] Training Loss: 4.90 - Iteration Time: 0:00:01.311488
[2/6, 20/94] Training Loss: 4.74 - Iteration Time: 0:00:01.571793
[2/6, 30/94] Training Loss: 4.75 - Iteration Time: 0:00:01.263051
[2/6, 40/94] Training Loss: 4.71 - Iteration Time: 0:00:01.292112
[2/6, 50/94] Training Loss: 4.65 - Iteration Time: 0:00:01.278936
[2/6, 60/94] Training Loss: 4.66 - Iteration Time: 0:00:01.287552
[2/6, 70/94] Training Loss: 4.59 - Iteration Time: 0:00:01.284883
[2/6, 80/94] Training Loss: 4.50 - Iteration Time: 0:00:01.316246
[2/6, 90/94] Training Loss: 4.53 - Iteration Time: 0:00:01.311684
Testing - 2024-06-13 10:47:41.311352
[2/6, 2/16]
[2/6, 4/16]
[2/6, 6/16]
[2/6, 8/16]
[2/6, 10/16]
[2/6, 12/16]
[2/6, 14/16]
[2/6, 16/16]
Testing Loss: 4.40 - Epoch Time: 0:02:17.134447
Training - 2024-06-13 10:47:53.271553
[3/6, 10/94] Training Loss: 4.46 - Iteration Time: 0:00:01.308634
[3/6, 20/94] Training Loss: 4.48 - Iteration Time: 0:00:01.275552
[3/6, 30/94] Training Loss: 4.38 - Iteration Time: 0:00:01.288708
[3/6, 40/94] Training Loss: 4.37 - Iteration Time: 0:00:01.292471
[3/6, 50/94] Training Loss: 4.35 - Iteration Time: 0:00:01.278540
[3/6, 60/94] Training Loss: 4.30 - Iteration Time: 0:00:01.361648
[3/6, 70/94] Training Loss: 4.22 - Iteration Time: 0:00:01.251082
[3/6, 80/94] Training Loss: 4.22 - Iteration Time: 0:00:01.272675
[3/6, 90/94] Training Loss: 4.19 - Iteration Time: 0:00:01.378075
Testing - 2024-06-13 10:49:58.375693
[3/6, 2/16]
[3/6, 4/16]
[3/6, 6/16]
[3/6, 8/16]
[3/6, 10/16]
[3/6, 12/16]
[3/6, 14/16]
[3/6, 16/16]
Testing Loss: 4.04 - Epoch Time: 0:02:17.681150
Training - 2024-06-13 10:50:10.953708
[4/6, 10/94] Training Loss: 4.09 - Iteration Time: 0:00:01.238008
[4/6, 20/94] Training Loss: 4.12 - Iteration Time: 0:00:01.329979
[4/6, 30/94] Training Loss: 4.05 - Iteration Time: 0:00:01.293856
[4/6, 40/94] Training Loss: 4.00 - Iteration Time: 0:00:01.238146
[4/6, 50/94] Training Loss: 3.99 - Iteration Time: 0:00:01.297264
[4/6, 60/94] Training Loss: 3.93 - Iteration Time: 0:00:01.727220
[4/6, 70/94] Training Loss: 3.96 - Iteration Time: 0:00:01.281872
[4/6, 80/94] Training Loss: 3.90 - Iteration Time: 0:00:01.272382
[4/6, 90/94] Training Loss: 3.82 - Iteration Time: 0:00:01.290377
Testing - 2024-06-13 10:52:16.748299
[4/6, 2/16]
[4/6, 4/16]
[4/6, 6/16]
[4/6, 8/16]
[4/6, 10/16]
[4/6, 12/16]
[4/6, 14/16]
[4/6, 16/16]
Testing Loss: 3.75 - Epoch Time: 0:02:17.993516
Training - 2024-06-13 10:52:28.947720
[5/6, 10/94] Training Loss: 3.77 - Iteration Time: 0:00:01.635030
[5/6, 20/94] Training Loss: 3.76 - Iteration Time: 0:00:01.333012
[5/6, 30/94] Training Loss: 3.67 - Iteration Time: 0:00:01.365510
[5/6, 40/94] Training Loss: 3.63 - Iteration Time: 0:00:01.266259
[5/6, 50/94] Training Loss: 3.63 - Iteration Time: 0:00:01.367334
[5/6, 60/94] Training Loss: 3.59 - Iteration Time: 0:00:01.337071
[5/6, 70/94] Training Loss: 3.56 - Iteration Time: 0:00:01.312776
[5/6, 80/94] Training Loss: 3.47 - Iteration Time: 0:00:01.298214
[5/6, 90/94] Training Loss: 3.46 - Iteration Time: 0:00:01.266032
Testing - 2024-06-13 10:54:36.749179
[5/6, 2/16]
[5/6, 4/16]
[5/6, 6/16]
[5/6, 8/16]
[5/6, 10/16]
[5/6, 12/16]
[5/6, 14/16]
[5/6, 16/16]
Testing Loss: 3.36 - Epoch Time: 0:02:19.534464
Training - 2024-06-13 10:54:48.482184
[6/6, 10/94] Training Loss: 3.44 - Iteration Time: 0:00:01.638739
[6/6, 20/94] Training Loss: 3.38 - Iteration Time: 0:00:01.406192
[6/6, 30/94] Training Loss: 3.38 - Iteration Time: 0:00:01.338608
[6/6, 40/94] Training Loss: 3.38 - Iteration Time: 0:00:01.350935
[6/6, 50/94] Training Loss: 3.35 - Iteration Time: 0:00:01.253371
[6/6, 60/94] Training Loss: 3.33 - Iteration Time: 0:00:01.241112
[6/6, 70/94] Training Loss: 3.31 - Iteration Time: 0:00:01.377075
[6/6, 80/94] Training Loss: 3.29 - Iteration Time: 0:00:01.315844
[6/6, 90/94] Training Loss: 3.27 - Iteration Time: 0:00:01.315751
Testing - 2024-06-13 10:56:54.947874
[6/6, 2/16]
[6/6, 4/16]
[6/6, 6/16]
[6/6, 8/16]
[6/6, 10/16]
[6/6, 12/16]
[6/6, 14/16]
[6/6, 16/16]
Testing Loss: 3.09 - Epoch Time: 0:02:18.698695
Training and Testing Finished - Time: 0:13:49.219560
Assembling test data for t-sne projection
-- 10/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 5
WARNING    c:\users\lukea\documents\masters project code\msc_project\main.py:184: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax = plt.subplots()
 [py.warnings]
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - {labels[input_index]}