Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 13:21:32.738675
Scaler Value: 100000
Training - 2024-06-18 13:21:32.739172
[1/9, 10/94] Training Loss: 55463.3582 - Iteration Time: 0:00:01.343594
[1/9, 20/94] Training Loss: 49299.7457 - Iteration Time: 0:00:01.614951
[1/9, 30/94] Training Loss: 49672.2848 - Iteration Time: 0:00:01.434432
[1/9, 40/94] Training Loss: 49726.3754 - Iteration Time: 0:00:01.542055
[1/9, 50/94] Training Loss: 49846.7461 - Iteration Time: 0:00:01.413569
[1/9, 60/94] Training Loss: 49999.0215 - Iteration Time: 0:00:01.373366
[1/9, 70/94] Training Loss: 50301.9703 - Iteration Time: 0:00:01.360119
[1/9, 80/94] Training Loss: 50529.5035 - Iteration Time: 0:00:01.357458
[1/9, 90/94] Training Loss: 50628.8301 - Iteration Time: 0:00:01.478626
Testing - 2024-06-18 13:23:48.296682
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 50624.2070 - Epoch Time: 0:02:28.796375
Training - 2024-06-18 13:24:01.536043
[2/9, 10/94] Training Loss: 50869.0113 - Iteration Time: 0:00:01.469085
[2/9, 20/94] Training Loss: 50728.5785 - Iteration Time: 0:00:01.380731
[2/9, 30/94] Training Loss: 50956.1102 - Iteration Time: 0:00:01.654691
[2/9, 40/94] Training Loss: 50973.3641 - Iteration Time: 0:00:01.375256
[2/9, 50/94] Training Loss: 51087.8316 - Iteration Time: 0:00:01.354431
[2/9, 60/94] Training Loss: 51193.4797 - Iteration Time: 0:00:01.355524
[2/9, 70/94] Training Loss: 51352.9238 - Iteration Time: 0:00:01.317298
[2/9, 80/94] Training Loss: 51734.8656 - Iteration Time: 0:00:01.423906
[2/9, 90/94] Training Loss: 51706.2957 - Iteration Time: 0:00:01.390693
Testing - 2024-06-18 13:26:14.634472
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 51330.3887 - Epoch Time: 0:02:26.327471
Training - 2024-06-18 13:26:27.864011
[3/9, 10/94] Training Loss: 51566.4227 - Iteration Time: 0:00:01.375330
[3/9, 20/94] Training Loss: 51730.5484 - Iteration Time: 0:00:01.449326
[3/9, 30/94] Training Loss: 51725.5539 - Iteration Time: 0:00:01.472058
[3/9, 40/94] Training Loss: 51737.1102 - Iteration Time: 0:00:01.364403
[3/9, 50/94] Training Loss: 52041.0703 - Iteration Time: 0:00:01.381807
[3/9, 60/94] Training Loss: 52116.9777 - Iteration Time: 0:00:01.449254
[3/9, 70/94] Training Loss: 52048.5793 - Iteration Time: 0:00:01.374762
[3/9, 80/94] Training Loss: 52122.1973 - Iteration Time: 0:00:01.375284
[3/9, 90/94] Training Loss: 52329.1098 - Iteration Time: 0:00:01.520724
Testing - 2024-06-18 13:28:42.455438
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 52138.5391 - Epoch Time: 0:02:27.634269
Training - 2024-06-18 13:28:55.498777
[4/9, 10/94] Training Loss: 52341.7973 - Iteration Time: 0:00:01.392158
[4/9, 20/94] Training Loss: 52447.4367 - Iteration Time: 0:00:01.333121
[4/9, 30/94] Training Loss: 52545.4176 - Iteration Time: 0:00:01.450861
[4/9, 40/94] Training Loss: 52530.7969 - Iteration Time: 0:00:01.356978
[4/9, 50/94] Training Loss: 52636.8328 - Iteration Time: 0:00:01.355975
[4/9, 60/94] Training Loss: 52515.9734 - Iteration Time: 0:00:01.378868
[4/9, 70/94] Training Loss: 52829.0578 - Iteration Time: 0:00:01.512642
[4/9, 80/94] Training Loss: 52556.8855 - Iteration Time: 0:00:01.381811
[4/9, 90/94] Training Loss: 52847.1477 - Iteration Time: 0:00:01.463178
Testing - 2024-06-18 13:31:09.410692
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 52430.2695 - Epoch Time: 0:02:27.627998
Training - 2024-06-18 13:31:23.127271
[5/9, 10/94] Training Loss: 52913.7078 - Iteration Time: 0:00:01.425988
[5/9, 20/94] Training Loss: 52824.1742 - Iteration Time: 0:00:01.424889
[5/9, 30/94] Training Loss: 52934.0988 - Iteration Time: 0:00:01.428427
[5/9, 40/94] Training Loss: 53073.6109 - Iteration Time: 0:00:01.438299
[5/9, 50/94] Training Loss: 53016.1234 - Iteration Time: 0:00:01.541527
[5/9, 60/94] Training Loss: 53279.3625 - Iteration Time: 0:00:01.535027
[5/9, 70/94] Training Loss: 53038.2762 - Iteration Time: 0:00:01.399103
[5/9, 80/94] Training Loss: 53194.2379 - Iteration Time: 0:00:01.419522
[5/9, 90/94] Training Loss: 53190.0012 - Iteration Time: 0:00:01.780167
Testing - 2024-06-18 13:33:43.163862
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 53077.8633 - Epoch Time: 0:02:34.139950
Training - 2024-06-18 13:33:57.267221
[6/9, 10/94] Training Loss: 53274.6641 - Iteration Time: 0:00:01.485458
[6/9, 20/94] Training Loss: 53259.8098 - Iteration Time: 0:00:01.402618
[6/9, 30/94] Training Loss: 53377.1574 - Iteration Time: 0:00:01.384260
[6/9, 40/94] Training Loss: 53359.1711 - Iteration Time: 0:00:01.415043
[6/9, 50/94] Training Loss: 53734.1965 - Iteration Time: 0:00:01.386228
[6/9, 60/94] Training Loss: 53240.9527 - Iteration Time: 0:00:01.468599
[6/9, 70/94] Training Loss: 53592.9516 - Iteration Time: 0:00:01.414994
[6/9, 80/94] Training Loss: 53611.2543 - Iteration Time: 0:00:01.410600
[6/9, 90/94] Training Loss: 53707.0848 - Iteration Time: 0:00:01.432358
Testing - 2024-06-18 13:36:15.029684
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 53008.2246 - Epoch Time: 0:02:31.365122
Training - 2024-06-18 13:36:28.632343
[7/9, 10/94] Training Loss: 53724.3684 - Iteration Time: 0:00:01.425991
[7/9, 20/94] Training Loss: 53773.0773 - Iteration Time: 0:00:01.453691
[7/9, 30/94] Training Loss: 53508.1687 - Iteration Time: 0:00:01.535529
[7/9, 40/94] Training Loss: 54114.4582 - Iteration Time: 0:00:01.432376
[7/9, 50/94] Training Loss: 53917.5738 - Iteration Time: 0:00:01.397224
[7/9, 60/94] Training Loss: 54009.3137 - Iteration Time: 0:00:01.394656
[7/9, 70/94] Training Loss: 54133.4336 - Iteration Time: 0:00:01.406061
[7/9, 80/94] Training Loss: 54095.3660 - Iteration Time: 0:00:01.486949
[7/9, 90/94] Training Loss: 53997.4984 - Iteration Time: 0:00:01.433864
Testing - 2024-06-18 13:38:45.932287
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 54513.3398 - Epoch Time: 0:02:31.636408
Training - 2024-06-18 13:39:00.268751
[8/9, 10/94] Training Loss: 54219.8520 - Iteration Time: 0:00:01.580712
[8/9, 20/94] Training Loss: 54332.0641 - Iteration Time: 0:00:01.482992
[8/9, 30/94] Training Loss: 54323.0492 - Iteration Time: 0:00:01.469095
[8/9, 40/94] Training Loss: 54231.4004 - Iteration Time: 0:00:01.510728
[8/9, 50/94] Training Loss: 54496.3375 - Iteration Time: 0:00:01.434398
[8/9, 60/94] Training Loss: 54135.8551 - Iteration Time: 0:00:01.381283
[8/9, 70/94] Training Loss: 54358.6410 - Iteration Time: 0:00:01.428475
[8/9, 80/94] Training Loss: 54423.5766 - Iteration Time: 0:00:01.489443
[8/9, 90/94] Training Loss: 54417.0191 - Iteration Time: 0:00:01.470546
Testing - 2024-06-18 13:41:21.497094
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 58950.1016 - Epoch Time: 0:02:35.549630
Training - 2024-06-18 13:41:35.818381
[9/9, 10/94] Training Loss: 53394.8941 - Iteration Time: 0:00:01.467568
[9/9, 20/94] Training Loss: 53556.5926 - Iteration Time: 0:00:01.398631
[9/9, 30/94] Training Loss: 53697.7848 - Iteration Time: 0:00:01.453164
[9/9, 40/94] Training Loss: 54305.3215 - Iteration Time: 0:00:01.591602
[9/9, 50/94] Training Loss: 54479.1207 - Iteration Time: 0:00:01.418502
[9/9, 60/94] Training Loss: 54669.9000 - Iteration Time: 0:00:01.470632
[9/9, 70/94] Training Loss: 54625.2941 - Iteration Time: 0:00:01.471527
[9/9, 80/94] Training Loss: 55025.6168 - Iteration Time: 0:00:01.396618
[9/9, 90/94] Training Loss: 54954.6746 - Iteration Time: 0:00:01.441311
Testing - 2024-06-18 13:43:55.492391
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 54729.6133 - Epoch Time: 0:02:34.661696
Training and Testing Finished - Time: 0:22:37.741900
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
-- 1/16 --
-- 2/16 --
-- 3/16 --
-- 4/16 --
-- 5/16 --
-- 6/16 --
-- 7/16 --
-- 8/16 --
-- 9/16 --
-- 10/16 --
-- 11/16 --
-- 12/16 --
-- 13/16 --
-- 14/16 --
-- 15/16 --
-- 16/16 --
   Labels      0    1    2      3      4  ...   94   95   96   97     98   99
0       2  0.110  0.0  0.0  0.110  0.110  ...  0.0  0.0  0.0  0.0  0.090  0.0
1       4  0.110  0.0  0.0  0.105  0.115  ...  0.0  0.0  0.0  0.0  0.090  0.0
2       7  0.115  0.0  0.0  0.110  0.110  ...  0.0  0.0  0.0  0.0  0.090  0.0
3       3  0.115  0.0  0.0  0.110  0.110  ...  0.0  0.0  0.0  0.0  0.090  0.0
4       7  0.115  0.0  0.0  0.110  0.110  ...  0.0  0.0  0.0  0.0  0.085  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP