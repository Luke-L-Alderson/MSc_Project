Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 05:47:34.752739
Scaler Value: 0.1
Training - 2024-06-18 05:47:34.753731
[1/9, 10/94] Training Loss: 2.8343 - Iteration Time: 0:00:01.429462
[1/9, 20/94] Training Loss: 2.6776 - Iteration Time: 0:00:01.441785
[1/9, 30/94] Training Loss: 2.6044 - Iteration Time: 0:00:01.386731
[1/9, 40/94] Training Loss: 2.5610 - Iteration Time: 0:00:01.385658
[1/9, 50/94] Training Loss: 2.5221 - Iteration Time: 0:00:01.435367
[1/9, 60/94] Training Loss: 2.4843 - Iteration Time: 0:00:01.555907
[1/9, 70/94] Training Loss: 2.4451 - Iteration Time: 0:00:01.414056
[1/9, 80/94] Training Loss: 2.3922 - Iteration Time: 0:00:01.400123
[1/9, 90/94] Training Loss: 2.3570 - Iteration Time: 0:00:01.394663
Testing - 2024-06-18 05:49:50.694658
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 2.3360 - Epoch Time: 0:02:29.655297
Training - 2024-06-18 05:50:04.409524
[2/9, 10/94] Training Loss: 2.3123 - Iteration Time: 0:00:01.393634
[2/9, 20/94] Training Loss: 2.2773 - Iteration Time: 0:00:01.434374
[2/9, 30/94] Training Loss: 2.2343 - Iteration Time: 0:00:01.392636
[2/9, 40/94] Training Loss: 2.2072 - Iteration Time: 0:00:01.536589
[2/9, 50/94] Training Loss: 2.1764 - Iteration Time: 0:00:01.407636
[2/9, 60/94] Training Loss: 2.1484 - Iteration Time: 0:00:01.511717
[2/9, 70/94] Training Loss: 2.1211 - Iteration Time: 0:00:01.416954
[2/9, 80/94] Training Loss: 2.1053 - Iteration Time: 0:00:01.402072
[2/9, 90/94] Training Loss: 2.0897 - Iteration Time: 0:00:01.431386
Testing - 2024-06-18 05:52:19.522418
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 2.0721 - Epoch Time: 0:02:28.442914
Training - 2024-06-18 05:52:32.852438
[3/9, 10/94] Training Loss: 2.0584 - Iteration Time: 0:00:01.411529
[3/9, 20/94] Training Loss: 2.0375 - Iteration Time: 0:00:01.550971
[3/9, 30/94] Training Loss: 2.0204 - Iteration Time: 0:00:01.372305
[3/9, 40/94] Training Loss: 1.9944 - Iteration Time: 0:00:01.410173
[3/9, 50/94] Training Loss: 1.9666 - Iteration Time: 0:00:01.401613
[3/9, 60/94] Training Loss: 1.9501 - Iteration Time: 0:00:01.428497
[3/9, 70/94] Training Loss: 1.9257 - Iteration Time: 0:00:01.503294
[3/9, 80/94] Training Loss: 1.8948 - Iteration Time: 0:00:01.470674
[3/9, 90/94] Training Loss: 1.8698 - Iteration Time: 0:00:01.420441
Testing - 2024-06-18 05:54:48.259249
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 1.8534 - Epoch Time: 0:02:28.943889
Training - 2024-06-18 05:55:01.796823
[4/9, 10/94] Training Loss: 1.8430 - Iteration Time: 0:00:01.441800
[4/9, 20/94] Training Loss: 1.8215 - Iteration Time: 0:00:01.406037
[4/9, 30/94] Training Loss: 1.7952 - Iteration Time: 0:00:01.415503
[4/9, 40/94] Training Loss: 1.7804 - Iteration Time: 0:00:01.412567
[4/9, 50/94] Training Loss: 1.7671 - Iteration Time: 0:00:01.424912
[4/9, 60/94] Training Loss: 1.7482 - Iteration Time: 0:00:01.432801
[4/9, 70/94] Training Loss: 1.7248 - Iteration Time: 0:00:01.423446
[4/9, 80/94] Training Loss: 1.7020 - Iteration Time: 0:00:01.462146
[4/9, 90/94] Training Loss: 1.6856 - Iteration Time: 0:00:01.403590
Testing - 2024-06-18 05:57:17.177265
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 1.6800 - Epoch Time: 0:02:28.782446
Training - 2024-06-18 05:57:30.579269
[5/9, 10/94] Training Loss: 1.6756 - Iteration Time: 0:00:01.386292
[5/9, 20/94] Training Loss: 1.6678 - Iteration Time: 0:00:01.419470
[5/9, 30/94] Training Loss: 1.6614 - Iteration Time: 0:00:01.392144
[5/9, 40/94] Training Loss: 1.6551 - Iteration Time: 0:00:01.481980
[5/9, 50/94] Training Loss: 1.6438 - Iteration Time: 0:00:01.390677
[5/9, 60/94] Training Loss: 1.6249 - Iteration Time: 0:00:01.379802
[5/9, 70/94] Training Loss: 1.6041 - Iteration Time: 0:00:01.408572
[5/9, 80/94] Training Loss: 1.5923 - Iteration Time: 0:00:01.385678
[5/9, 90/94] Training Loss: 1.5824 - Iteration Time: 0:00:01.407011
Testing - 2024-06-18 05:59:45.179042
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 1.5806 - Epoch Time: 0:02:27.758021
Training - 2024-06-18 05:59:58.337290
[6/9, 10/94] Training Loss: 1.5705 - Iteration Time: 0:00:01.416465
[6/9, 20/94] Training Loss: 1.5548 - Iteration Time: 0:00:01.529097
[6/9, 30/94] Training Loss: 1.5450 - Iteration Time: 0:00:01.444278
[6/9, 40/94] Training Loss: 1.5351 - Iteration Time: 0:00:01.401094
[6/9, 50/94] Training Loss: 1.5191 - Iteration Time: 0:00:01.418976
[6/9, 60/94] Training Loss: 1.5067 - Iteration Time: 0:00:01.419444
[6/9, 70/94] Training Loss: 1.4943 - Iteration Time: 0:00:01.402625
[6/9, 80/94] Training Loss: 1.4862 - Iteration Time: 0:00:01.431321
[6/9, 90/94] Training Loss: 1.4701 - Iteration Time: 0:00:01.427938
Testing - 2024-06-18 06:02:13.771115
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 1.4609 - Epoch Time: 0:02:28.973826
Training - 2024-06-18 06:02:27.311116
[7/9, 10/94] Training Loss: 1.4538 - Iteration Time: 0:00:01.425993
[7/9, 20/94] Training Loss: 1.4453 - Iteration Time: 0:00:01.414507
[7/9, 30/94] Training Loss: 1.4313 - Iteration Time: 0:00:01.412969
[7/9, 40/94] Training Loss: 1.4232 - Iteration Time: 0:00:01.462692
[7/9, 50/94] Training Loss: 1.4115 - Iteration Time: 0:00:01.402545
[7/9, 60/94] Training Loss: 1.4071 - Iteration Time: 0:00:01.429866
[7/9, 70/94] Training Loss: 1.3958 - Iteration Time: 0:00:01.431841
[7/9, 80/94] Training Loss: 1.3821 - Iteration Time: 0:00:01.392134
[7/9, 90/94] Training Loss: 1.3733 - Iteration Time: 0:00:01.413527
Testing - 2024-06-18 06:04:43.354442
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 1.3634 - Epoch Time: 0:02:29.280620
Training - 2024-06-18 06:04:56.591736
[8/9, 10/94] Training Loss: 1.3552 - Iteration Time: 0:00:01.413090
[8/9, 20/94] Training Loss: 1.3467 - Iteration Time: 0:00:01.451211
[8/9, 30/94] Training Loss: 1.3340 - Iteration Time: 0:00:01.398112
[8/9, 40/94] Training Loss: 1.3273 - Iteration Time: 0:00:01.409002
[8/9, 50/94] Training Loss: 1.3217 - Iteration Time: 0:00:01.548463
[8/9, 60/94] Training Loss: 1.3152 - Iteration Time: 0:00:01.439901
[8/9, 70/94] Training Loss: 1.3132 - Iteration Time: 0:00:01.421441
[8/9, 80/94] Training Loss: 1.3090 - Iteration Time: 0:00:01.417050
[8/9, 90/94] Training Loss: 1.3009 - Iteration Time: 0:00:01.402073
Testing - 2024-06-18 06:07:13.473964
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 1.2950 - Epoch Time: 0:02:30.324940
Training - 2024-06-18 06:07:26.916676
[9/9, 10/94] Training Loss: 1.2909 - Iteration Time: 0:00:01.410964
[9/9, 20/94] Training Loss: 1.2851 - Iteration Time: 0:00:01.392272
[9/9, 30/94] Training Loss: 1.2781 - Iteration Time: 0:00:01.443247
[9/9, 40/94] Training Loss: 1.2731 - Iteration Time: 0:00:01.387676
[9/9, 50/94] Training Loss: 1.2684 - Iteration Time: 0:00:01.392160
[9/9, 60/94] Training Loss: 1.2649 - Iteration Time: 0:00:01.432380
[9/9, 70/94] Training Loss: 1.2614 - Iteration Time: 0:00:01.403258
[9/9, 80/94] Training Loss: 1.2553 - Iteration Time: 0:00:01.468063
[9/9, 90/94] Training Loss: 1.2500 - Iteration Time: 0:00:01.468524
Testing - 2024-06-18 06:09:44.528917
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 1.2508 - Epoch Time: 0:02:32.734689
Training and Testing Finished - Time: 0:22:24.898626
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0    1      2      3    4  ...     94   95   96   97   98   99
0       2  0.0  0.0  0.295  0.210  0.0  ...  0.145  0.0  0.0  0.0  0.0  0.0
1       4  0.0  0.0  0.325  0.215  0.0  ...  0.145  0.0  0.0  0.0  0.0  0.0
2       7  0.0  0.0  0.305  0.225  0.0  ...  0.160  0.0  0.0  0.0  0.0  0.0
3       3  0.0  0.0  0.320  0.170  0.0  ...  0.140  0.0  0.0  0.0  0.0  0.0
4       7  0.0  0.0  0.325  0.220  0.0  ...  0.165  0.0  0.0  0.0  0.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP