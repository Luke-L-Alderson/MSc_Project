Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 09:28:05.959211
Scaler Value: 0.20833333333333331
Training - 2024-06-18 09:28:05.960699
[1/9, 10/94] Training Loss: 0.4009 - Iteration Time: 0:00:01.555393
[1/9, 20/94] Training Loss: 0.3926 - Iteration Time: 0:00:01.529582
[1/9, 30/94] Training Loss: 0.3938 - Iteration Time: 0:00:01.647207
[1/9, 40/94] Training Loss: 0.3947 - Iteration Time: 0:00:01.617930
[1/9, 50/94] Training Loss: 0.3920 - Iteration Time: 0:00:01.551401
[1/9, 60/94] Training Loss: 0.3886 - Iteration Time: 0:00:01.487401
[1/9, 70/94] Training Loss: 0.3849 - Iteration Time: 0:00:01.510709
[1/9, 80/94] Training Loss: 0.3872 - Iteration Time: 0:00:01.364931
[1/9, 90/94] Training Loss: 0.3847 - Iteration Time: 0:00:01.403078
Testing - 2024-06-18 09:30:31.642282
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.3695 - Epoch Time: 0:02:38.426757
Training - 2024-06-18 09:30:44.387951
[2/9, 10/94] Training Loss: 0.3876 - Iteration Time: 0:00:01.339033
[2/9, 20/94] Training Loss: 0.3779 - Iteration Time: 0:00:01.357467
[2/9, 30/94] Training Loss: 0.3793 - Iteration Time: 0:00:01.427330
[2/9, 40/94] Training Loss: 0.3782 - Iteration Time: 0:00:01.388250
[2/9, 50/94] Training Loss: 0.3743 - Iteration Time: 0:00:01.360881
[2/9, 60/94] Training Loss: 0.3764 - Iteration Time: 0:00:01.422420
[2/9, 70/94] Training Loss: 0.3725 - Iteration Time: 0:00:01.374287
[2/9, 80/94] Training Loss: 0.3684 - Iteration Time: 0:00:01.360385
[2/9, 90/94] Training Loss: 0.3709 - Iteration Time: 0:00:01.404066
Testing - 2024-06-18 09:32:55.791254
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.3614 - Epoch Time: 0:02:24.337376
Training - 2024-06-18 09:33:08.725327
[3/9, 10/94] Training Loss: 0.3657 - Iteration Time: 0:00:01.387721
[3/9, 20/94] Training Loss: 0.3700 - Iteration Time: 0:00:01.347067
[3/9, 30/94] Training Loss: 0.3651 - Iteration Time: 0:00:01.362377
[3/9, 40/94] Training Loss: 0.3662 - Iteration Time: 0:00:01.399571
[3/9, 50/94] Training Loss: 0.3666 - Iteration Time: 0:00:01.439873
[3/9, 60/94] Training Loss: 0.3654 - Iteration Time: 0:00:01.411460
[3/9, 70/94] Training Loss: 0.3601 - Iteration Time: 0:00:01.506735
[3/9, 80/94] Training Loss: 0.3657 - Iteration Time: 0:00:01.502711
[3/9, 90/94] Training Loss: 0.3627 - Iteration Time: 0:00:01.377824
Testing - 2024-06-18 09:35:24.746649
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.3469 - Epoch Time: 0:02:29.256372
Training - 2024-06-18 09:35:37.981699
[4/9, 10/94] Training Loss: 0.3550 - Iteration Time: 0:00:01.381740
[4/9, 20/94] Training Loss: 0.3569 - Iteration Time: 0:00:01.399104
[4/9, 30/94] Training Loss: 0.3547 - Iteration Time: 0:00:01.522668
[4/9, 40/94] Training Loss: 0.3527 - Iteration Time: 0:00:01.601469
[4/9, 50/94] Training Loss: 0.3538 - Iteration Time: 0:00:01.481439
[4/9, 60/94] Training Loss: 0.3510 - Iteration Time: 0:00:01.479893
[4/9, 70/94] Training Loss: 0.3567 - Iteration Time: 0:00:01.451232
[4/9, 80/94] Training Loss: 0.3536 - Iteration Time: 0:00:01.488383
[4/9, 90/94] Training Loss: 0.3499 - Iteration Time: 0:00:01.372279
Testing - 2024-06-18 09:37:57.523337
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.3435 - Epoch Time: 0:02:32.664104
Training - 2024-06-18 09:38:10.645803
[5/9, 10/94] Training Loss: 0.3476 - Iteration Time: 0:00:01.370796
[5/9, 20/94] Training Loss: 0.3487 - Iteration Time: 0:00:01.455670
[5/9, 30/94] Training Loss: 0.3433 - Iteration Time: 0:00:01.380709
[5/9, 40/94] Training Loss: 0.3444 - Iteration Time: 0:00:01.379223
[5/9, 50/94] Training Loss: 0.3467 - Iteration Time: 0:00:01.357427
[5/9, 60/94] Training Loss: 0.3452 - Iteration Time: 0:00:01.337582
[5/9, 70/94] Training Loss: 0.3430 - Iteration Time: 0:00:01.353903
[5/9, 80/94] Training Loss: 0.3371 - Iteration Time: 0:00:01.426349
[5/9, 90/94] Training Loss: 0.3385 - Iteration Time: 0:00:01.409449
Testing - 2024-06-18 09:40:21.954367
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.3302 - Epoch Time: 0:02:24.303940
Training - 2024-06-18 09:40:34.949743
[6/9, 10/94] Training Loss: 0.3395 - Iteration Time: 0:00:01.387234
[6/9, 20/94] Training Loss: 0.3339 - Iteration Time: 0:00:01.469042
[6/9, 30/94] Training Loss: 0.3321 - Iteration Time: 0:00:01.358868
[6/9, 40/94] Training Loss: 0.3338 - Iteration Time: 0:00:01.382222
[6/9, 50/94] Training Loss: 0.3307 - Iteration Time: 0:00:01.345047
[6/9, 60/94] Training Loss: 0.3309 - Iteration Time: 0:00:01.349498
[6/9, 70/94] Training Loss: 0.3304 - Iteration Time: 0:00:01.367813
[6/9, 80/94] Training Loss: 0.3280 - Iteration Time: 0:00:01.392648
[6/9, 90/94] Training Loss: 0.3270 - Iteration Time: 0:00:01.369336
Testing - 2024-06-18 09:42:45.493050
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.3107 - Epoch Time: 0:02:23.254343
Training - 2024-06-18 09:42:58.204086
[7/9, 10/94] Training Loss: 0.3228 - Iteration Time: 0:00:01.343543
[7/9, 20/94] Training Loss: 0.3216 - Iteration Time: 0:00:01.410965
[7/9, 30/94] Training Loss: 0.3215 - Iteration Time: 0:00:01.366348
[7/9, 40/94] Training Loss: 0.3180 - Iteration Time: 0:00:01.370338
[7/9, 50/94] Training Loss: 0.3175 - Iteration Time: 0:00:01.368310
[7/9, 60/94] Training Loss: 0.3108 - Iteration Time: 0:00:01.362424
[7/9, 70/94] Training Loss: 0.3134 - Iteration Time: 0:00:01.370832
[7/9, 80/94] Training Loss: 0.3138 - Iteration Time: 0:00:01.336061
[7/9, 90/94] Training Loss: 0.3118 - Iteration Time: 0:00:01.367345
Testing - 2024-06-18 09:45:09.526186
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.3001 - Epoch Time: 0:02:24.113884
Training - 2024-06-18 09:45:22.317970
[8/9, 10/94] Training Loss: 0.3135 - Iteration Time: 0:00:01.338573
[8/9, 20/94] Training Loss: 0.3088 - Iteration Time: 0:00:01.352673
[8/9, 30/94] Training Loss: 0.3081 - Iteration Time: 0:00:01.346519
[8/9, 40/94] Training Loss: 0.3053 - Iteration Time: 0:00:01.377755
[8/9, 50/94] Training Loss: 0.3049 - Iteration Time: 0:00:01.375774
[8/9, 60/94] Training Loss: 0.3058 - Iteration Time: 0:00:01.367316
[8/9, 70/94] Training Loss: 0.3032 - Iteration Time: 0:00:01.361864
[8/9, 80/94] Training Loss: 0.3044 - Iteration Time: 0:00:01.341571
[8/9, 90/94] Training Loss: 0.3018 - Iteration Time: 0:00:01.491982
Testing - 2024-06-18 09:47:32.482098
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.2924 - Epoch Time: 0:02:23.204390
Training - 2024-06-18 09:47:45.522856
[9/9, 10/94] Training Loss: 0.2995 - Iteration Time: 0:00:01.359471
[9/9, 20/94] Training Loss: 0.2995 - Iteration Time: 0:00:01.367858
[9/9, 30/94] Training Loss: 0.2989 - Iteration Time: 0:00:01.452235
[9/9, 40/94] Training Loss: 0.2948 - Iteration Time: 0:00:01.386678
[9/9, 50/94] Training Loss: 0.2937 - Iteration Time: 0:00:01.382256
[9/9, 60/94] Training Loss: 0.2957 - Iteration Time: 0:00:01.840166
[9/9, 70/94] Training Loss: 0.2926 - Iteration Time: 0:00:01.852791
[9/9, 80/94] Training Loss: 0.2913 - Iteration Time: 0:00:01.748115
[9/9, 90/94] Training Loss: 0.2949 - Iteration Time: 0:00:01.533706
Testing - 2024-06-18 09:50:15.285333
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.2799 - Epoch Time: 0:02:44.080364
Training and Testing Finished - Time: 0:22:23.644009
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0    1      2      3    4  ...     94   95   96   97     98   99
0       2  0.0  0.0  0.130  0.085  0.0  ...  0.015  0.0  0.0  0.0  0.070  0.0
1       4  0.0  0.0  0.055  0.100  0.0  ...  0.005  0.0  0.0  0.0  0.065  0.0
2       7  0.0  0.0  0.090  0.115  0.0  ...  0.020  0.0  0.0  0.0  0.085  0.0
3       3  0.0  0.0  0.065  0.145  0.0  ...  0.005  0.0  0.0  0.0  0.065  0.0
4       7  0.0  0.0  0.065  0.115  0.0  ...  0.025  0.0  0.0  0.0  0.075  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP