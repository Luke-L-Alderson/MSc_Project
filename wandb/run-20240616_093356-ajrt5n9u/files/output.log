Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-16 09:33:58.610195
Scaler Value: 0.013513513513513514
Training - 2024-06-16 09:33:58.611187
[1/9, 10/94] Training Loss: 17.9638 - Iteration Time: 0:00:01.367338
[1/9, 20/94] Training Loss: 13.4899 - Iteration Time: 0:00:01.371367
[1/9, 30/94] Training Loss: 8.1206 - Iteration Time: 0:00:01.378219
[1/9, 40/94] Training Loss: 6.2707 - Iteration Time: 0:00:01.380181
[1/9, 50/94] Training Loss: 5.7073 - Iteration Time: 0:00:01.374261
[1/9, 60/94] Training Loss: 5.4650 - Iteration Time: 0:00:01.377792
[1/9, 70/94] Training Loss: 5.3336 - Iteration Time: 0:00:01.353897
[1/9, 80/94] Training Loss: 5.3375 - Iteration Time: 0:00:01.368293
[1/9, 90/94] Training Loss: 5.2710 - Iteration Time: 0:00:01.403495
Testing - 2024-06-16 09:36:13.348872
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 5.0487 - Epoch Time: 0:02:27.937572
Training - 2024-06-16 09:36:26.548759
[2/9, 10/94] Training Loss: 5.3018 - Iteration Time: 0:00:01.382183
[2/9, 20/94] Training Loss: 5.1712 - Iteration Time: 0:00:01.384748
[2/9, 30/94] Training Loss: 5.1875 - Iteration Time: 0:00:01.359380
[2/9, 40/94] Training Loss: 5.1874 - Iteration Time: 0:00:01.387147
[2/9, 50/94] Training Loss: 5.1462 - Iteration Time: 0:00:01.573666
[2/9, 60/94] Training Loss: 5.2019 - Iteration Time: 0:00:01.374324
[2/9, 70/94] Training Loss: 5.1416 - Iteration Time: 0:00:01.381256
[2/9, 80/94] Training Loss: 5.0799 - Iteration Time: 0:00:01.392595
[2/9, 90/94] Training Loss: 5.1301 - Iteration Time: 0:00:01.376196
Testing - 2024-06-16 09:38:40.045899
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 5.0057 - Epoch Time: 0:02:26.737729
Training - 2024-06-16 09:38:53.286488
[3/9, 10/94] Training Loss: 5.0788 - Iteration Time: 0:00:01.441768
[3/9, 20/94] Training Loss: 5.1478 - Iteration Time: 0:00:01.474950
[3/9, 30/94] Training Loss: 5.0697 - Iteration Time: 0:00:01.439724
[3/9, 40/94] Training Loss: 5.0871 - Iteration Time: 0:00:01.445677
[3/9, 50/94] Training Loss: 5.1231 - Iteration Time: 0:00:01.394646
[3/9, 60/94] Training Loss: 5.0839 - Iteration Time: 0:00:01.441376
[3/9, 70/94] Training Loss: 5.0333 - Iteration Time: 0:00:01.409484
[3/9, 80/94] Training Loss: 5.0858 - Iteration Time: 0:00:01.354887
[3/9, 90/94] Training Loss: 5.0760 - Iteration Time: 0:00:01.548398
Testing - 2024-06-16 09:41:09.882903
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 4.9080 - Epoch Time: 0:02:29.673274
Training - 2024-06-16 09:41:22.959762
[4/9, 10/94] Training Loss: 5.0119 - Iteration Time: 0:00:01.380740
[4/9, 20/94] Training Loss: 5.0822 - Iteration Time: 0:00:01.406495
[4/9, 30/94] Training Loss: 5.0441 - Iteration Time: 0:00:01.519128
[4/9, 40/94] Training Loss: 5.0110 - Iteration Time: 0:00:01.403558
[4/9, 50/94] Training Loss: 5.0402 - Iteration Time: 0:00:01.414446
[4/9, 60/94] Training Loss: 5.0200 - Iteration Time: 0:00:01.406985
[4/9, 70/94] Training Loss: 5.0855 - Iteration Time: 0:00:01.637714
[4/9, 80/94] Training Loss: 5.0733 - Iteration Time: 0:00:01.363860
[4/9, 90/94] Training Loss: 5.0182 - Iteration Time: 0:00:01.449291
Testing - 2024-06-16 09:43:36.522885
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 4.9584 - Epoch Time: 0:02:26.745547
Training - 2024-06-16 09:43:49.705806
[5/9, 10/94] Training Loss: 5.0155 - Iteration Time: 0:00:01.394592
[5/9, 20/94] Training Loss: 5.0649 - Iteration Time: 0:00:01.377352
[5/9, 30/94] Training Loss: 4.9991 - Iteration Time: 0:00:01.367394
[5/9, 40/94] Training Loss: 5.0114 - Iteration Time: 0:00:01.395621
[5/9, 50/94] Training Loss: 5.0548 - Iteration Time: 0:00:01.461649
[5/9, 60/94] Training Loss: 5.0354 - Iteration Time: 0:00:01.374908
[5/9, 70/94] Training Loss: 5.0294 - Iteration Time: 0:00:01.467112
[5/9, 80/94] Training Loss: 4.9552 - Iteration Time: 0:00:01.401567
[5/9, 90/94] Training Loss: 4.9925 - Iteration Time: 0:00:01.386741
Testing - 2024-06-16 09:46:03.874484
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 4.8521 - Epoch Time: 0:02:27.485103
Training - 2024-06-16 09:46:17.190909
[6/9, 10/94] Training Loss: 5.0265 - Iteration Time: 0:00:01.543065
[6/9, 20/94] Training Loss: 4.9585 - Iteration Time: 0:00:01.357869
[6/9, 30/94] Training Loss: 4.9741 - Iteration Time: 0:00:01.427842
[6/9, 40/94] Training Loss: 4.9919 - Iteration Time: 0:00:01.358461
[6/9, 50/94] Training Loss: 4.9810 - Iteration Time: 0:00:01.387951
[6/9, 60/94] Training Loss: 4.9691 - Iteration Time: 0:00:01.396589
[6/9, 70/94] Training Loss: 5.0080 - Iteration Time: 0:00:01.435300
[6/9, 80/94] Training Loss: 5.0122 - Iteration Time: 0:00:01.361364
[6/9, 90/94] Training Loss: 5.0351 - Iteration Time: 0:00:01.405024
Testing - 2024-06-16 09:48:30.961119
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 4.7114 - Epoch Time: 0:02:27.039463
Training - 2024-06-16 09:48:44.230372
[7/9, 10/94] Training Loss: 4.9906 - Iteration Time: 0:00:01.380293
[7/9, 20/94] Training Loss: 4.9902 - Iteration Time: 0:00:01.363295
[7/9, 30/94] Training Loss: 5.0220 - Iteration Time: 0:00:01.389250
[7/9, 40/94] Training Loss: 4.9922 - Iteration Time: 0:00:01.402084
[7/9, 50/94] Training Loss: 4.9672 - Iteration Time: 0:00:01.389712
[7/9, 60/94] Training Loss: 4.9009 - Iteration Time: 0:00:01.359367
[7/9, 70/94] Training Loss: 4.9650 - Iteration Time: 0:00:01.429353
[7/9, 80/94] Training Loss: 4.9569 - Iteration Time: 0:00:01.462633
[7/9, 90/94] Training Loss: 4.9724 - Iteration Time: 0:00:01.384733
Testing - 2024-06-16 09:50:57.842450
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 4.7293 - Epoch Time: 0:02:27.139634
Training - 2024-06-16 09:51:11.370501
[8/9, 10/94] Training Loss: 5.0153 - Iteration Time: 0:00:01.380867
[8/9, 20/94] Training Loss: 4.9345 - Iteration Time: 0:00:01.403024
[8/9, 30/94] Training Loss: 4.9623 - Iteration Time: 0:00:01.399119
[8/9, 40/94] Training Loss: 4.9496 - Iteration Time: 0:00:01.365864
[8/9, 50/94] Training Loss: 4.9381 - Iteration Time: 0:00:01.433824
[8/9, 60/94] Training Loss: 4.9707 - Iteration Time: 0:00:01.360859
[8/9, 70/94] Training Loss: 4.9671 - Iteration Time: 0:00:01.350437
[8/9, 80/94] Training Loss: 5.0019 - Iteration Time: 0:00:01.381325
[8/9, 90/94] Training Loss: 4.9623 - Iteration Time: 0:00:01.381698
Testing - 2024-06-16 09:53:25.280438
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 4.7552 - Epoch Time: 0:02:27.427132
Training - 2024-06-16 09:53:38.797633
[9/9, 10/94] Training Loss: 4.9352 - Iteration Time: 0:00:01.489918
[9/9, 20/94] Training Loss: 4.9750 - Iteration Time: 0:00:01.389697
[9/9, 30/94] Training Loss: 4.9720 - Iteration Time: 0:00:01.401575
[9/9, 40/94] Training Loss: 4.9210 - Iteration Time: 0:00:01.353073
[9/9, 50/94] Training Loss: 4.9083 - Iteration Time: 0:00:01.376282
[9/9, 60/94] Training Loss: 4.9615 - Iteration Time: 0:00:01.370821
[9/9, 70/94] Training Loss: 4.9403 - Iteration Time: 0:00:01.370777
[9/9, 80/94] Training Loss: 4.9219 - Iteration Time: 0:00:01.427949
[9/9, 90/94] Training Loss: 5.0121 - Iteration Time: 0:00:01.374806
Testing - 2024-06-16 09:55:51.872134
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 4.7211 - Epoch Time: 0:02:26.525549
Training and Testing Finished - Time: 0:22:06.713482
Assembling test data for t-sne projection
-- 1/16 --
-- 2/16 --
-- 3/16 --
-- 4/16 --
-- 5/16 --
-- 6/16 --
-- 7/16 --
-- 8/16 --
-- 9/16 --
-- 10/16 --
-- 11/16 --
-- 12/16 --
-- 13/16 --
-- 14/16 --
-- 15/16 --
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying t-SNE
WARNING    C:\Users\lukea\anaconda3\envs\diss\Lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(
 [py.warnings]
  File "C:\Users\lukea\anaconda3\envs\diss\Lib\site-packages\joblib\externals\loky\backend\context.py", line 282, in _count_physical_cores
    raise ValueError(f"found {cpu_count_physical} physical cores < 1")
Applying UMAP
Applying PCA