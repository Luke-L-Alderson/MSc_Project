Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Subsets
Training: 6000
Testing: 1000
Making Dataloaders
Defining network
2024-06-12 10:11:14.281233
Training - 2024-06-12 10:11:14.281728
[1/9, 10/94] Training Loss: 7.33 - Iteration Time: 0:00:01.193176
[1/9, 20/94] Training Loss: 2.57 - Iteration Time: 0:00:01.212033
[1/9, 30/94] Training Loss: 1.79 - Iteration Time: 0:00:01.255694
[1/9, 40/94] Training Loss: 1.69 - Iteration Time: 0:00:01.184269
[1/9, 50/94] Training Loss: 1.62 - Iteration Time: 0:00:01.292420
[1/9, 60/94] Training Loss: 1.60 - Iteration Time: 0:00:01.302363
[1/9, 70/94] Training Loss: 1.56 - Iteration Time: 0:00:01.267111
[1/9, 80/94] Training Loss: 1.52 - Iteration Time: 0:00:01.313751
[1/9, 90/94] Training Loss: 1.56 - Iteration Time: 0:00:01.272548
Testing - 2024-06-12 10:13:16.068023
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 1.68 - Epoch Time: 0:02:13.530302
Training - 2024-06-12 10:13:27.812030
[2/9, 10/94] Training Loss: 1.54 - Iteration Time: 0:00:01.308788
[2/9, 20/94] Training Loss: 1.54 - Iteration Time: 0:00:01.242316
[2/9, 30/94] Training Loss: 1.52 - Iteration Time: 0:00:01.302330
[2/9, 40/94] Training Loss: 1.52 - Iteration Time: 0:00:01.327151
[2/9, 50/94] Training Loss: 1.56 - Iteration Time: 0:00:01.258175
[2/9, 60/94] Training Loss: 1.54 - Iteration Time: 0:00:01.276568
[2/9, 70/94] Training Loss: 1.56 - Iteration Time: 0:00:01.263657
[2/9, 80/94] Training Loss: 1.49 - Iteration Time: 0:00:01.341552
[2/9, 90/94] Training Loss: 1.48 - Iteration Time: 0:00:01.207587
Testing - 2024-06-12 10:15:29.183367
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 1.61 - Epoch Time: 0:02:12.761215
Training - 2024-06-12 10:15:40.573741
[3/9, 10/94] Training Loss: 1.51 - Iteration Time: 0:00:01.365872
[3/9, 20/94] Training Loss: 1.43 - Iteration Time: 0:00:01.204553
[3/9, 30/94] Training Loss: 1.41 - Iteration Time: 0:00:01.246287
[3/9, 40/94] Training Loss: 1.49 - Iteration Time: 0:00:01.306422
[3/9, 50/94] Training Loss: 1.47 - Iteration Time: 0:00:01.225413
[3/9, 60/94] Training Loss: 1.47 - Iteration Time: 0:00:01.292407
[3/9, 70/94] Training Loss: 1.46 - Iteration Time: 0:00:01.177309
[3/9, 80/94] Training Loss: 1.51 - Iteration Time: 0:00:01.190683
[3/9, 90/94] Training Loss: 1.46 - Iteration Time: 0:00:01.248291
Testing - 2024-06-12 10:17:40.003920
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 1.49 - Epoch Time: 0:02:10.989400
Training - 2024-06-12 10:17:51.564145
[4/9, 10/94] Training Loss: 1.36 - Iteration Time: 0:00:01.409486
[4/9, 20/94] Training Loss: 1.37 - Iteration Time: 0:00:01.260867
[4/9, 30/94] Training Loss: 1.41 - Iteration Time: 0:00:01.277500
[4/9, 40/94] Training Loss: 1.39 - Iteration Time: 0:00:01.364227
[4/9, 50/94] Training Loss: 1.36 - Iteration Time: 0:00:01.282972
[4/9, 60/94] Training Loss: 1.37 - Iteration Time: 0:00:01.320666
[4/9, 70/94] Training Loss: 1.37 - Iteration Time: 0:00:01.282035
[4/9, 80/94] Training Loss: 1.35 - Iteration Time: 0:00:01.340503
[4/9, 90/94] Training Loss: 1.37 - Iteration Time: 0:00:01.273551
Testing - 2024-06-12 10:19:51.825178
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 1.35 - Epoch Time: 0:02:11.831225
Training - 2024-06-12 10:20:03.395867
[5/9, 10/94] Training Loss: 1.32 - Iteration Time: 0:00:01.260173
[5/9, 20/94] Training Loss: 1.31 - Iteration Time: 0:00:01.264127
[5/9, 30/94] Training Loss: 1.26 - Iteration Time: 0:00:01.188783
[5/9, 40/94] Training Loss: 1.28 - Iteration Time: 0:00:01.269625
[5/9, 50/94] Training Loss: 1.30 - Iteration Time: 0:00:01.287460
[5/9, 60/94] Training Loss: 1.31 - Iteration Time: 0:00:01.289904
[5/9, 70/94] Training Loss: 1.30 - Iteration Time: 0:00:01.248744
[5/9, 80/94] Training Loss: 1.28 - Iteration Time: 0:00:01.253734
[5/9, 90/94] Training Loss: 1.23 - Iteration Time: 0:00:01.340125
Testing - 2024-06-12 10:22:03.168111
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 1.32 - Epoch Time: 0:02:11.296499
Training - 2024-06-12 10:22:14.692366
[6/9, 10/94] Training Loss: 1.27 - Iteration Time: 0:00:01.266143
[6/9, 20/94] Training Loss: 1.25 - Iteration Time: 0:00:01.263150
[6/9, 30/94] Training Loss: 1.23 - Iteration Time: 0:00:01.275024
[6/9, 40/94] Training Loss: 1.17 - Iteration Time: 0:00:01.250236
[6/9, 50/94] Training Loss: 1.19 - Iteration Time: 0:00:01.282497
[6/9, 60/94] Training Loss: 1.18 - Iteration Time: 0:00:01.248722
[6/9, 70/94] Training Loss: 1.17 - Iteration Time: 0:00:01.261649
[6/9, 80/94] Training Loss: 1.13 - Iteration Time: 0:00:01.291473
[6/9, 90/94] Training Loss: 1.17 - Iteration Time: 0:00:01.356902
Testing - 2024-06-12 10:24:13.653904
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 1.12 - Epoch Time: 0:02:10.406353
Training - 2024-06-12 10:24:25.099216
[7/9, 10/94] Training Loss: 1.15 - Iteration Time: 0:00:01.203597
[7/9, 20/94] Training Loss: 1.14 - Iteration Time: 0:00:01.356205
[7/9, 30/94] Training Loss: 1.10 - Iteration Time: 0:00:01.194698
[7/9, 40/94] Training Loss: 1.08 - Iteration Time: 0:00:01.214002
[7/9, 50/94] Training Loss: 1.08 - Iteration Time: 0:00:01.270620
[7/9, 60/94] Training Loss: 1.11 - Iteration Time: 0:00:01.242362
[7/9, 70/94] Training Loss: 1.08 - Iteration Time: 0:00:01.297000
[7/9, 80/94] Training Loss: 1.10 - Iteration Time: 0:00:01.275010
[7/9, 90/94] Training Loss: 1.08 - Iteration Time: 0:00:01.242310
Testing - 2024-06-12 10:26:24.291962
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 1.13 - Epoch Time: 0:02:10.644420
Training - 2024-06-12 10:26:35.744132
[8/9, 10/94] Training Loss: 1.06 - Iteration Time: 0:00:01.259661
[8/9, 20/94] Training Loss: 1.01 - Iteration Time: 0:00:01.368336
[8/9, 30/94] Training Loss: 1.04 - Iteration Time: 0:00:01.314721
[8/9, 40/94] Training Loss: 1.02 - Iteration Time: 0:00:01.332668
[8/9, 50/94] Training Loss: 1.01 - Iteration Time: 0:00:01.290910
[8/9, 60/94] Training Loss: 1.00 - Iteration Time: 0:00:01.198142
[8/9, 70/94] Training Loss: 0.97 - Iteration Time: 0:00:01.262745
[8/9, 80/94] Training Loss: 0.98 - Iteration Time: 0:00:01.349009
[8/9, 90/94] Training Loss: 0.93 - Iteration Time: 0:00:01.220945
Testing - 2024-06-12 10:28:36.438552
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 1.00 - Epoch Time: 0:02:12.283617
Training - 2024-06-12 10:28:48.028244
[9/9, 10/94] Training Loss: 0.95 - Iteration Time: 0:00:01.321210
[9/9, 20/94] Training Loss: 0.93 - Iteration Time: 0:00:01.332166
[9/9, 30/94] Training Loss: 0.92 - Iteration Time: 0:00:01.240309
[9/9, 40/94] Training Loss: 0.91 - Iteration Time: 0:00:01.241342
[9/9, 50/94] Training Loss: 0.89 - Iteration Time: 0:00:01.231027
[9/9, 60/94] Training Loss: 0.88 - Iteration Time: 0:00:01.231489
[9/9, 70/94] Training Loss: 0.87 - Iteration Time: 0:00:01.199117
[9/9, 80/94] Training Loss: 0.86 - Iteration Time: 0:00:01.204104
[9/9, 90/94] Training Loss: 0.88 - Iteration Time: 0:00:01.248720
Testing - 2024-06-12 10:30:47.630610
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.84 - Epoch Time: 0:02:10.994919
Training and Testing Finished - Time: 0:19:44.741930
Assembling test data for t-sne projection
-- 10/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation
WARNING    c:\users\lukea\documents\masters project code\msc_project\main.py:208: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig = plt.figure(facecolor="w", figsize=(10, 5))
 [py.warnings]