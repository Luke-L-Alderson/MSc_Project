Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-17 12:23:10.445774
Scaler Value: 0.013513513513513514
Training - 2024-06-17 12:23:10.446766
[1/9, 10/94] Training Loss: 17.9523 - Iteration Time: 0:00:01.455597
[1/9, 20/94] Training Loss: 13.6427 - Iteration Time: 0:00:01.494741
[1/9, 30/94] Training Loss: 8.4562 - Iteration Time: 0:00:01.438725
[1/9, 40/94] Training Loss: 6.5491 - Iteration Time: 0:00:01.499226
[1/9, 50/94] Training Loss: 5.8516 - Iteration Time: 0:00:01.455715
[1/9, 60/94] Training Loss: 5.5262 - Iteration Time: 0:00:01.500244
[1/9, 70/94] Training Loss: 5.3523 - Iteration Time: 0:00:01.486839
[1/9, 80/94] Training Loss: 5.3336 - Iteration Time: 0:00:01.390070
[1/9, 90/94] Training Loss: 5.2629 - Iteration Time: 0:00:01.516106
Testing - 2024-06-17 12:25:33.717826
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 5.0383 - Epoch Time: 0:02:37.058049
Training - 2024-06-17 12:25:47.504815
[2/9, 10/94] Training Loss: 5.2879 - Iteration Time: 0:00:01.426152
[2/9, 20/94] Training Loss: 5.1592 - Iteration Time: 0:00:01.473485
[2/9, 30/94] Training Loss: 5.1760 - Iteration Time: 0:00:01.460086
[2/9, 40/94] Training Loss: 5.1757 - Iteration Time: 0:00:01.460042
[2/9, 50/94] Training Loss: 5.1362 - Iteration Time: 0:00:01.694258
[2/9, 60/94] Training Loss: 5.1890 - Iteration Time: 0:00:01.486326
[2/9, 70/94] Training Loss: 5.1278 - Iteration Time: 0:00:01.458541
[2/9, 80/94] Training Loss: 5.0600 - Iteration Time: 0:00:01.442363
[2/9, 90/94] Training Loss: 5.1158 - Iteration Time: 0:00:01.397983
Testing - 2024-06-17 12:28:10.408419
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 4.9905 - Epoch Time: 0:02:37.005511
Training - 2024-06-17 12:28:24.510823
[3/9, 10/94] Training Loss: 5.0656 - Iteration Time: 0:00:01.442787
[3/9, 20/94] Training Loss: 5.1349 - Iteration Time: 0:00:01.432419
[3/9, 30/94] Training Loss: 5.0536 - Iteration Time: 0:00:01.457542
[3/9, 40/94] Training Loss: 5.0764 - Iteration Time: 0:00:01.505208
[3/9, 50/94] Training Loss: 5.1047 - Iteration Time: 0:00:01.499759
[3/9, 60/94] Training Loss: 5.0656 - Iteration Time: 0:00:01.482007
[3/9, 70/94] Training Loss: 5.0252 - Iteration Time: 0:00:01.445766
[3/9, 80/94] Training Loss: 5.0739 - Iteration Time: 0:00:01.475947
[3/9, 90/94] Training Loss: 5.0664 - Iteration Time: 0:00:01.578170
Testing - 2024-06-17 12:30:45.892142
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 4.9008 - Epoch Time: 0:02:37.843175
Training - 2024-06-17 12:31:02.354495
[4/9, 10/94] Training Loss: 5.0012 - Iteration Time: 0:00:01.493876
[4/9, 20/94] Training Loss: 5.0679 - Iteration Time: 0:00:01.487884
[4/9, 30/94] Training Loss: 5.0338 - Iteration Time: 0:00:01.469978
[4/9, 40/94] Training Loss: 4.9957 - Iteration Time: 0:00:01.453660
[4/9, 50/94] Training Loss: 5.0266 - Iteration Time: 0:00:01.453124
[4/9, 60/94] Training Loss: 5.0054 - Iteration Time: 0:00:01.484937
[4/9, 70/94] Training Loss: 5.0786 - Iteration Time: 0:00:01.751824
[4/9, 80/94] Training Loss: 5.0588 - Iteration Time: 0:00:01.479973
[4/9, 90/94] Training Loss: 5.0088 - Iteration Time: 0:00:01.516127
Testing - 2024-06-17 12:33:29.073593
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 4.9547 - Epoch Time: 0:02:41.808300
Training - 2024-06-17 12:33:44.162795
[5/9, 10/94] Training Loss: 5.0110 - Iteration Time: 0:00:01.522823
[5/9, 20/94] Training Loss: 5.0556 - Iteration Time: 0:00:01.494817
[5/9, 30/94] Training Loss: 4.9929 - Iteration Time: 0:00:01.508260
[5/9, 40/94] Training Loss: 5.0056 - Iteration Time: 0:00:01.488845
[5/9, 50/94] Training Loss: 5.0527 - Iteration Time: 0:00:01.556332
[5/9, 60/94] Training Loss: 5.0291 - Iteration Time: 0:00:01.601045
[5/9, 70/94] Training Loss: 5.0301 - Iteration Time: 0:00:01.662964
[5/9, 80/94] Training Loss: 4.9484 - Iteration Time: 0:00:01.470520
[5/9, 90/94] Training Loss: 4.9899 - Iteration Time: 0:00:01.592175
Testing - 2024-06-17 12:36:10.442441
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 4.8464 - Epoch Time: 0:02:40.240175
Training - 2024-06-17 12:36:24.402970
[6/9, 10/94] Training Loss: 5.0173 - Iteration Time: 0:00:01.594689
[6/9, 20/94] Training Loss: 4.9580 - Iteration Time: 0:00:01.459081
[6/9, 30/94] Training Loss: 4.9755 - Iteration Time: 0:00:01.554378
[6/9, 40/94] Training Loss: 4.9921 - Iteration Time: 0:00:01.478432
[6/9, 50/94] Training Loss: 4.9739 - Iteration Time: 0:00:01.646658
[6/9, 60/94] Training Loss: 4.9708 - Iteration Time: 0:00:01.477431
[6/9, 70/94] Training Loss: 5.0142 - Iteration Time: 0:00:01.487867
[6/9, 80/94] Training Loss: 5.0074 - Iteration Time: 0:00:01.562323
[6/9, 90/94] Training Loss: 5.0243 - Iteration Time: 0:00:01.534085
Testing - 2024-06-17 12:38:49.962666
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 4.7115 - Epoch Time: 0:02:40.059252
Training - 2024-06-17 12:39:04.462717
[7/9, 10/94] Training Loss: 4.9892 - Iteration Time: 0:00:01.519630
[7/9, 20/94] Training Loss: 4.9870 - Iteration Time: 0:00:01.484983
[7/9, 30/94] Training Loss: 5.0219 - Iteration Time: 0:00:01.452238
[7/9, 40/94] Training Loss: 4.9893 - Iteration Time: 0:00:01.545828
[7/9, 50/94] Training Loss: 4.9654 - Iteration Time: 0:00:01.576179
[7/9, 60/94] Training Loss: 4.8925 - Iteration Time: 0:00:01.547915
[7/9, 70/94] Training Loss: 4.9638 - Iteration Time: 0:00:01.681359
[7/9, 80/94] Training Loss: 4.9466 - Iteration Time: 0:00:01.618360
[7/9, 90/94] Training Loss: 4.9678 - Iteration Time: 0:00:01.530092
Testing - 2024-06-17 12:41:30.746435
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 4.7293 - Epoch Time: 0:02:41.198679
Training - 2024-06-17 12:41:45.661895
[8/9, 10/94] Training Loss: 5.0074 - Iteration Time: 0:00:01.609955
[8/9, 20/94] Training Loss: 4.9303 - Iteration Time: 0:00:01.515694
[8/9, 30/94] Training Loss: 4.9590 - Iteration Time: 0:00:01.562331
[8/9, 40/94] Training Loss: 4.9432 - Iteration Time: 0:00:01.458691
[8/9, 50/94] Training Loss: 4.9317 - Iteration Time: 0:00:01.587616
[8/9, 60/94] Training Loss: 4.9628 - Iteration Time: 0:00:01.463572
[8/9, 70/94] Training Loss: 4.9613 - Iteration Time: 0:00:01.530527
[8/9, 80/94] Training Loss: 4.9978 - Iteration Time: 0:00:01.506788
[8/9, 90/94] Training Loss: 4.9595 - Iteration Time: 0:00:01.503794
Testing - 2024-06-17 12:44:11.125651
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 4.7569 - Epoch Time: 0:02:39.704811
Training - 2024-06-17 12:44:25.367202
[9/9, 10/94] Training Loss: 4.9333 - Iteration Time: 0:00:01.463112
[9/9, 20/94] Training Loss: 4.9744 - Iteration Time: 0:00:01.623833
[9/9, 30/94] Training Loss: 4.9728 - Iteration Time: 0:00:01.513206
[9/9, 40/94] Training Loss: 4.9184 - Iteration Time: 0:00:01.529039
[9/9, 50/94] Training Loss: 4.9062 - Iteration Time: 0:00:01.616415
[9/9, 60/94] Training Loss: 4.9571 - Iteration Time: 0:00:01.928030
[9/9, 70/94] Training Loss: 4.9399 - Iteration Time: 0:00:01.445251
[9/9, 80/94] Training Loss: 4.9224 - Iteration Time: 0:00:01.432864
[9/9, 90/94] Training Loss: 5.0079 - Iteration Time: 0:00:01.463546
Testing - 2024-06-17 12:46:55.191505
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 4.7177 - Epoch Time: 0:02:44.235305
Training and Testing Finished - Time: 0:23:59.156733
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels      0      1    2      3      4  ...     94   95   96     97   98     99
0       2  0.995  0.995  0.0  0.975  0.980  ...  0.995  0.0  0.0  0.995  0.0  0.990
1       4  0.995  0.990  0.0  0.980  0.980  ...  0.995  0.0  0.0  0.995  0.0  0.995
2       7  0.985  0.995  0.0  0.950  0.965  ...  0.995  0.0  0.0  0.995  0.0  0.995
3       3  0.995  0.995  0.0  0.970  0.965  ...  0.995  0.0  0.0  0.995  0.0  0.995
4       7  0.995  0.990  0.0  0.985  0.945  ...  0.995  0.0  0.0  0.995  0.0  0.995
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying t-SNE
Applying UMAP
Applying PCA