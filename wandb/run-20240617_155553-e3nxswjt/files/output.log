Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-17 15:55:55.288552
Scaler Value: 1000
Training - 2024-06-17 15:55:55.289544
[1/9, 10/94] Training Loss: 0.5528 - Iteration Time: 0:00:01.443025
[1/9, 20/94] Training Loss: 0.4931 - Iteration Time: 0:00:01.432764
[1/9, 30/94] Training Loss: 0.4970 - Iteration Time: 0:00:01.466864
[1/9, 40/94] Training Loss: 0.4978 - Iteration Time: 0:00:01.454192
[1/9, 50/94] Training Loss: 0.4985 - Iteration Time: 0:00:01.460358
[1/9, 60/94] Training Loss: 0.4993 - Iteration Time: 0:00:01.454897
[1/9, 70/94] Training Loss: 0.5023 - Iteration Time: 0:00:01.511233
[1/9, 80/94] Training Loss: 0.5044 - Iteration Time: 0:00:01.487513
[1/9, 90/94] Training Loss: 0.5061 - Iteration Time: 0:00:01.503142
Testing - 2024-06-17 15:58:17.638512
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.5047 - Epoch Time: 0:02:36.621388
Training - 2024-06-17 15:58:31.911428
[2/9, 10/94] Training Loss: 0.5083 - Iteration Time: 0:00:01.477727
[2/9, 20/94] Training Loss: 0.5068 - Iteration Time: 0:00:01.844375
[2/9, 30/94] Training Loss: 0.5092 - Iteration Time: 0:00:01.501412
[2/9, 40/94] Training Loss: 0.5110 - Iteration Time: 0:00:01.429838
[2/9, 50/94] Training Loss: 0.5099 - Iteration Time: 0:00:01.489251
[2/9, 60/94] Training Loss: 0.5123 - Iteration Time: 0:00:01.450129
[2/9, 70/94] Training Loss: 0.5129 - Iteration Time: 0:00:01.493965
[2/9, 80/94] Training Loss: 0.5163 - Iteration Time: 0:00:01.425909
[2/9, 90/94] Training Loss: 0.5151 - Iteration Time: 0:00:01.432517
Testing - 2024-06-17 16:00:55.329993
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.5125 - Epoch Time: 0:02:39.319483
Training - 2024-06-17 16:01:11.230911
[3/9, 10/94] Training Loss: 0.5158 - Iteration Time: 0:00:01.479483
[3/9, 20/94] Training Loss: 0.5156 - Iteration Time: 0:00:01.593252
[3/9, 30/94] Training Loss: 0.5162 - Iteration Time: 0:00:01.586038
[3/9, 40/94] Training Loss: 0.5174 - Iteration Time: 0:00:01.581875
[3/9, 50/94] Training Loss: 0.5199 - Iteration Time: 0:00:01.533930
[3/9, 60/94] Training Loss: 0.5209 - Iteration Time: 0:00:01.546305
[3/9, 70/94] Training Loss: 0.5192 - Iteration Time: 0:00:01.587342
[3/9, 80/94] Training Loss: 0.5212 - Iteration Time: 0:00:01.522170
[3/9, 90/94] Training Loss: 0.5237 - Iteration Time: 0:00:01.542936
Testing - 2024-06-17 16:03:40.414832
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.5206 - Epoch Time: 0:02:43.473116
Training - 2024-06-17 16:03:54.704027
[4/9, 10/94] Training Loss: 0.5220 - Iteration Time: 0:00:01.628770
[4/9, 20/94] Training Loss: 0.5254 - Iteration Time: 0:00:01.501163
[4/9, 30/94] Training Loss: 0.5255 - Iteration Time: 0:00:01.625649
[4/9, 40/94] Training Loss: 0.5256 - Iteration Time: 0:00:01.537610
[4/9, 50/94] Training Loss: 0.5276 - Iteration Time: 0:00:01.680407
[4/9, 60/94] Training Loss: 0.5252 - Iteration Time: 0:00:01.568869
[4/9, 70/94] Training Loss: 0.5272 - Iteration Time: 0:00:01.491172
[4/9, 80/94] Training Loss: 0.5262 - Iteration Time: 0:00:01.717594
[4/9, 90/94] Training Loss: 0.5272 - Iteration Time: 0:00:01.529507
Testing - 2024-06-17 16:06:23.570417
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.5250 - Epoch Time: 0:02:43.195547
Training - 2024-06-17 16:06:37.899574
[5/9, 10/94] Training Loss: 0.5292 - Iteration Time: 0:00:01.685655
[5/9, 20/94] Training Loss: 0.5303 - Iteration Time: 0:00:01.526678
[5/9, 30/94] Training Loss: 0.5309 - Iteration Time: 0:00:01.575211
[5/9, 40/94] Training Loss: 0.5311 - Iteration Time: 0:00:01.567169
[5/9, 50/94] Training Loss: 0.5303 - Iteration Time: 0:00:01.525450
[5/9, 60/94] Training Loss: 0.5324 - Iteration Time: 0:00:01.523536
[5/9, 70/94] Training Loss: 0.5304 - Iteration Time: 0:00:01.499528
[5/9, 80/94] Training Loss: 0.5318 - Iteration Time: 0:00:01.536174
[5/9, 90/94] Training Loss: 0.5331 - Iteration Time: 0:00:01.527270
Testing - 2024-06-17 16:09:04.381782
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.5501 - Epoch Time: 0:02:40.689995
Training - 2024-06-17 16:09:18.589569
[6/9, 10/94] Training Loss: 0.5334 - Iteration Time: 0:00:01.512868
[6/9, 20/94] Training Loss: 0.5330 - Iteration Time: 0:00:01.491922
[6/9, 30/94] Training Loss: 0.5351 - Iteration Time: 0:00:01.484510
[6/9, 40/94] Training Loss: 0.5358 - Iteration Time: 0:00:01.535688
[6/9, 50/94] Training Loss: 0.5335 - Iteration Time: 0:00:01.513499
[6/9, 60/94] Training Loss: 0.5348 - Iteration Time: 0:00:01.520454
[6/9, 70/94] Training Loss: 0.5343 - Iteration Time: 0:00:01.537785
[6/9, 80/94] Training Loss: 0.5370 - Iteration Time: 0:00:01.513064
[6/9, 90/94] Training Loss: 0.5386 - Iteration Time: 0:00:01.521446
Testing - 2024-06-17 16:11:43.898992
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.5215 - Epoch Time: 0:02:39.708279
Training - 2024-06-17 16:11:58.297848
[7/9, 10/94] Training Loss: 0.5367 - Iteration Time: 0:00:01.609830
[7/9, 20/94] Training Loss: 0.5391 - Iteration Time: 0:00:01.480904
[7/9, 30/94] Training Loss: 0.5382 - Iteration Time: 0:00:01.543519
[7/9, 40/94] Training Loss: 0.5421 - Iteration Time: 0:00:01.484385
[7/9, 50/94] Training Loss: 0.5411 - Iteration Time: 0:00:01.582973
[7/9, 60/94] Training Loss: 0.5431 - Iteration Time: 0:00:01.483737
[7/9, 70/94] Training Loss: 0.5432 - Iteration Time: 0:00:01.622318
[7/9, 80/94] Training Loss: 0.5435 - Iteration Time: 0:00:01.845662
[7/9, 90/94] Training Loss: 0.5425 - Iteration Time: 0:00:01.572106
Testing - 2024-06-17 16:14:29.186739
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.5367 - Epoch Time: 0:02:46.166570
Training - 2024-06-17 16:14:44.464914
[8/9, 10/94] Training Loss: 0.5409 - Iteration Time: 0:00:01.819541
[8/9, 20/94] Training Loss: 0.5430 - Iteration Time: 0:00:01.472312
[8/9, 30/94] Training Loss: 0.5444 - Iteration Time: 0:00:01.484863
[8/9, 40/94] Training Loss: 0.5413 - Iteration Time: 0:00:01.529465
[8/9, 50/94] Training Loss: 0.5446 - Iteration Time: 0:00:01.800396
[8/9, 60/94] Training Loss: 0.5441 - Iteration Time: 0:00:01.527033
[8/9, 70/94] Training Loss: 0.5430 - Iteration Time: 0:00:01.523863
[8/9, 80/94] Training Loss: 0.5462 - Iteration Time: 0:00:01.492931
[8/9, 90/94] Training Loss: 0.5449 - Iteration Time: 0:00:01.496577
Testing - 2024-06-17 16:17:11.194423
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.5519 - Epoch Time: 0:02:41.073520
Training - 2024-06-17 16:17:25.538930
[9/9, 10/94] Training Loss: 0.5469 - Iteration Time: 0:00:01.680570
[9/9, 20/94] Training Loss: 0.5459 - Iteration Time: 0:00:01.830778
[9/9, 30/94] Training Loss: 0.5459 - Iteration Time: 0:00:01.676232
[9/9, 40/94] Training Loss: 0.5493 - Iteration Time: 0:00:01.498307
[9/9, 50/94] Training Loss: 0.5483 - Iteration Time: 0:00:01.496556
[9/9, 60/94] Training Loss: 0.5481 - Iteration Time: 0:00:01.593203
[9/9, 70/94] Training Loss: 0.5479 - Iteration Time: 0:00:01.476217
[9/9, 80/94] Training Loss: 0.5479 - Iteration Time: 0:00:01.528519
[9/9, 90/94] Training Loss: 0.5498 - Iteration Time: 0:00:01.500514
Testing - 2024-06-17 16:19:55.143755
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.5288 - Epoch Time: 0:02:44.104051
Training and Testing Finished - Time: 0:24:14.354927
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels      0    1    2      3    4  ...   94   95   96   97     98   99
0       2  0.110  0.0  0.0  0.110  0.0  ...  0.0  0.0  0.0  0.0  0.120  0.0
1       4  0.105  0.0  0.0  0.115  0.0  ...  0.0  0.0  0.0  0.0  0.125  0.0
2       7  0.105  0.0  0.0  0.115  0.0  ...  0.0  0.0  0.0  0.0  0.120  0.0
3       3  0.105  0.0  0.0  0.110  0.0  ...  0.0  0.0  0.0  0.0  0.125  0.0
4       7  0.110  0.0  0.0  0.115  0.0  ...  0.0  0.0  0.0  0.0  0.120  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP
Applying PCA