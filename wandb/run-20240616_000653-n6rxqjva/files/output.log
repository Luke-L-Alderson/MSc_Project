Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-16 00:06:55.041493
Scaler Value: 0.013513513513513514
Training - 2024-06-16 00:06:55.041493
[1/9, 10/94] Training Loss: 17.9574 - Iteration Time: 0:00:01.382243
[1/9, 20/94] Training Loss: 13.4670 - Iteration Time: 0:00:01.322635
[1/9, 30/94] Training Loss: 8.0975 - Iteration Time: 0:00:01.325158
[1/9, 40/94] Training Loss: 6.2522 - Iteration Time: 0:00:01.315769
[1/9, 50/94] Training Loss: 5.6861 - Iteration Time: 0:00:01.421857
[1/9, 60/94] Training Loss: 5.4441 - Iteration Time: 0:00:01.349456
[1/9, 70/94] Training Loss: 5.3080 - Iteration Time: 0:00:01.362121
[1/9, 80/94] Training Loss: 5.3120 - Iteration Time: 0:00:01.326179
[1/9, 90/94] Training Loss: 5.2481 - Iteration Time: 0:00:01.365833
Testing - 2024-06-16 00:09:05.571754
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 5.0380 - Epoch Time: 0:02:23.613016
Training - 2024-06-16 00:09:18.654509
[2/9, 10/94] Training Loss: 5.2844 - Iteration Time: 0:00:01.380474
[2/9, 20/94] Training Loss: 5.1517 - Iteration Time: 0:00:01.330113
[2/9, 30/94] Training Loss: 5.1673 - Iteration Time: 0:00:01.372312
[2/9, 40/94] Training Loss: 5.1686 - Iteration Time: 0:00:01.418480
[2/9, 50/94] Training Loss: 5.1295 - Iteration Time: 0:00:01.411957
[2/9, 60/94] Training Loss: 5.1821 - Iteration Time: 0:00:01.335581
[2/9, 70/94] Training Loss: 5.1217 - Iteration Time: 0:00:01.348433
[2/9, 80/94] Training Loss: 5.0535 - Iteration Time: 0:00:01.411956
[2/9, 90/94] Training Loss: 5.1068 - Iteration Time: 0:00:01.337111
Testing - 2024-06-16 00:11:29.391102
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 4.9872 - Epoch Time: 0:02:23.785386
Training - 2024-06-16 00:11:42.440391
[3/9, 10/94] Training Loss: 5.0568 - Iteration Time: 0:00:01.336063
[3/9, 20/94] Training Loss: 5.1260 - Iteration Time: 0:00:01.342563
[3/9, 30/94] Training Loss: 5.0568 - Iteration Time: 0:00:01.427866
[3/9, 40/94] Training Loss: 5.0688 - Iteration Time: 0:00:01.340062
[3/9, 50/94] Training Loss: 5.1058 - Iteration Time: 0:00:01.334072
[3/9, 60/94] Training Loss: 5.0697 - Iteration Time: 0:00:01.380729
[3/9, 70/94] Training Loss: 5.0229 - Iteration Time: 0:00:01.318183
[3/9, 80/94] Training Loss: 5.0700 - Iteration Time: 0:00:01.601340
[3/9, 90/94] Training Loss: 5.0612 - Iteration Time: 0:00:01.338596
Testing - 2024-06-16 00:13:53.039776
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 4.8979 - Epoch Time: 0:02:24.038360
Training - 2024-06-16 00:14:06.478751
[4/9, 10/94] Training Loss: 5.0015 - Iteration Time: 0:00:01.365331
[4/9, 20/94] Training Loss: 5.0661 - Iteration Time: 0:00:01.423391
[4/9, 30/94] Training Loss: 5.0361 - Iteration Time: 0:00:01.351454
[4/9, 40/94] Training Loss: 4.9954 - Iteration Time: 0:00:01.527545
[4/9, 50/94] Training Loss: 5.0277 - Iteration Time: 0:00:01.333058
[4/9, 60/94] Training Loss: 5.0107 - Iteration Time: 0:00:01.383681
[4/9, 70/94] Training Loss: 5.0755 - Iteration Time: 0:00:01.328718
[4/9, 80/94] Training Loss: 5.0584 - Iteration Time: 0:00:01.325236
[4/9, 90/94] Training Loss: 5.0033 - Iteration Time: 0:00:01.410956
Testing - 2024-06-16 00:16:16.473838
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 4.9463 - Epoch Time: 0:02:23.048778
Training - 2024-06-16 00:16:29.527529
[5/9, 10/94] Training Loss: 5.0088 - Iteration Time: 0:00:01.415915
[5/9, 20/94] Training Loss: 5.0542 - Iteration Time: 0:00:01.343613
[5/9, 30/94] Training Loss: 4.9894 - Iteration Time: 0:00:01.357384
[5/9, 40/94] Training Loss: 5.0022 - Iteration Time: 0:00:01.348732
[5/9, 50/94] Training Loss: 5.0401 - Iteration Time: 0:00:01.366910
[5/9, 60/94] Training Loss: 5.0225 - Iteration Time: 0:00:01.389595
[5/9, 70/94] Training Loss: 5.0214 - Iteration Time: 0:00:01.308690
[5/9, 80/94] Training Loss: 4.9457 - Iteration Time: 0:00:01.386163
[5/9, 90/94] Training Loss: 4.9875 - Iteration Time: 0:00:01.344498
Testing - 2024-06-16 00:18:40.690143
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 4.8461 - Epoch Time: 0:02:24.054312
Training - 2024-06-16 00:18:53.581841
[6/9, 10/94] Training Loss: 5.0164 - Iteration Time: 0:00:01.341067
[6/9, 20/94] Training Loss: 4.9516 - Iteration Time: 0:00:01.328261
[6/9, 30/94] Training Loss: 4.9695 - Iteration Time: 0:00:01.341980
[6/9, 40/94] Training Loss: 4.9825 - Iteration Time: 0:00:01.362428
[6/9, 50/94] Training Loss: 4.9727 - Iteration Time: 0:00:01.631292
[6/9, 60/94] Training Loss: 4.9624 - Iteration Time: 0:00:01.445185
[6/9, 70/94] Training Loss: 5.0078 - Iteration Time: 0:00:01.471970
[6/9, 80/94] Training Loss: 4.9973 - Iteration Time: 0:00:01.327611
[6/9, 90/94] Training Loss: 5.0247 - Iteration Time: 0:00:01.317185
Testing - 2024-06-16 00:21:05.000400
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 4.6912 - Epoch Time: 0:02:24.302204
Training - 2024-06-16 00:21:17.884542
