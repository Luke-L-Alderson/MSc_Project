Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 3000
Testing: 10000 -> 500
Making Subsets
Training: 3000
Testing: 500
Making Dataloaders
Defining network
2024-06-05 11:08:09.799140
Training!
0:00:00.001488
0:00:00.001488
0:00:00.044641
0:00:00.045137
0:00:00.183045
0:00:00.183541
0:00:01.137912
0:00:01.162218
0:00:01.697074
0:00:01.722370
tensor(17.4480, device='cuda:0', grad_fn=<DivBackward0>)
tensor(17.4480, device='cuda:0')
0:00:01.751635
0:00:01.766019
0:00:01.766515
0:00:01.886070
0:00:01.886566
0:00:02.495863
0:00:02.501319
0:00:02.976798
0:00:02.977790
tensor(14.5501, device='cuda:0', grad_fn=<DivBackward0>)
tensor(14.5501, device='cuda:0')
0:00:02.980272
0:00:02.998145
0:00:02.998641
0:00:03.112265
0:00:03.113258
0:00:03.837604
0:00:03.843060
0:00:04.323858
0:00:04.325346
tensor(10.8432, device='cuda:0', grad_fn=<DivBackward0>)
tensor(10.8432, device='cuda:0')
0:00:04.327826
[1/1, 3/47] Training Loss: 14.28040885925293
0:00:04.348658
0:00:04.348658
0:00:04.465733
0:00:04.466725
0:00:05.049338
0:00:05.054794
0:00:05.510247
0:00:05.511240
tensor(10.0879, device='cuda:0', grad_fn=<DivBackward0>)
tensor(10.0879, device='cuda:0')
0:00:05.513719
0:00:05.535047
0:00:05.535543
0:00:05.656602
0:00:05.657098
0:00:06.265386
0:00:06.270842
0:00:06.727769
0:00:06.728760
tensor(7.9785, device='cuda:0', grad_fn=<DivBackward0>)
tensor(7.9785, device='cuda:0')
0:00:06.731240
0:00:06.749096
0:00:06.749592
0:00:06.859227
0:00:06.859723
0:00:07.460706
0:00:07.466161
0:00:07.942458
0:00:07.943450
tensor(6.4013, device='cuda:0', grad_fn=<DivBackward0>)
tensor(6.4013, device='cuda:0')
0:00:07.945930
[1/1, 6/47] Training Loss: 8.155900001525879
0:00:07.963786
0:00:07.963786
0:00:08.091280
0:00:08.091776
0:00:08.680227
0:00:08.686178
0:00:09.133682
0:00:09.134674
tensor(6.4151, device='cuda:0', grad_fn=<DivBackward0>)
tensor(6.4151, device='cuda:0')
0:00:09.137650
0:00:09.154514
0:00:09.154514
0:00:09.267139
0:00:09.267635
0:00:09.864490
0:00:09.869946
0:00:10.310056
0:00:10.311047
tensor(5.4067, device='cuda:0', grad_fn=<DivBackward0>)
tensor(5.4067, device='cuda:0')
0:00:10.313527
0:00:10.330392
0:00:10.330888
0:00:10.443001
0:00:10.443994
0:00:11.013027
0:00:11.018978
0:00:11.476917
0:00:11.477909
tensor(4.2018, device='cuda:0', grad_fn=<DivBackward0>)
tensor(4.2018, device='cuda:0')
0:00:11.480389
[1/1, 9/47] Training Loss: 5.341194152832031
0:00:11.498279
0:00:11.498279
0:00:11.619946
0:00:11.620443
0:00:12.207374
0:00:12.212829
0:00:12.656876
0:00:12.657869
tensor(3.9041, device='cuda:0', grad_fn=<DivBackward0>)
tensor(3.9041, device='cuda:0')
0:00:12.660349
0:00:12.680685
0:00:12.681180
0:00:12.803713
0:00:12.804209
0:00:13.383201
0:00:13.388657
0:00:13.826435
0:00:13.827426
tensor(3.3639, device='cuda:0', grad_fn=<DivBackward0>)
tensor(3.3639, device='cuda:0')
0:00:13.829907
0:00:13.847267
0:00:13.847267
0:00:13.958387
0:00:13.958884
0:00:14.537141
0:00:14.542596
0:00:14.989106
0:00:14.990098
tensor(2.9330, device='cuda:0', grad_fn=<DivBackward0>)
tensor(2.9330, device='cuda:0')
0:00:14.992082
[1/1, 12/47] Training Loss: 3.4003233909606934
0:00:15.009939
0:00:15.010435
0:00:15.124562
0:00:15.125059
0:00:15.710496
0:00:15.715951
0:00:16.178522
0:00:16.179515
tensor(2.7773, device='cuda:0', grad_fn=<DivBackward0>)
tensor(2.7773, device='cuda:0')
0:00:16.181995
0:00:16.199355
0:00:16.199851
0:00:16.312983
0:00:16.313479
0:00:16.904851
0:00:16.910308
0:00:17.388605
0:00:17.389597
tensor(2.4222, device='cuda:0', grad_fn=<DivBackward0>)
tensor(2.4222, device='cuda:0')
0:00:17.391582
0:00:17.408447
0:00:17.408944
0:00:17.528016
0:00:17.528512
0:00:18.124554
0:00:18.131038
0:00:18.579524
0:00:18.580515
tensor(2.1840, device='cuda:0', grad_fn=<DivBackward0>)
tensor(2.1840, device='cuda:0')
0:00:18.582499
[1/1, 15/47] Training Loss: 2.4611849784851074
0:00:18.608788
0:00:18.608788
0:00:18.720980
0:00:18.721477
0:00:19.309879
0:00:19.315336
0:00:19.762345
0:00:19.763337
tensor(2.0868, device='cuda:0', grad_fn=<DivBackward0>)
tensor(2.0868, device='cuda:0')
0:00:19.765816
0:00:19.782681
0:00:19.783177
0:00:19.905708
0:00:19.906701
0:00:20.490369
0:00:20.495826
0:00:20.938367
0:00:20.939359
tensor(1.8832, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.8832, device='cuda:0')
0:00:20.941839
0:00:20.959199
0:00:20.959199
0:00:21.073298
0:00:21.073794
0:00:21.657776
0:00:21.663231
0:00:22.111692
0:00:22.112683
tensor(1.7318, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.7318, device='cuda:0')
0:00:22.114667
[1/1, 18/47] Training Loss: 1.900606393814087
0:00:22.134081
0:00:22.134081
0:00:22.253821
0:00:22.254814
0:00:22.826320
0:00:22.831775
0:00:23.287710
0:00:23.288701
tensor(1.6274, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.6274, device='cuda:0')
0:00:23.290685
0:00:23.308542
0:00:23.309038
0:00:23.434545
0:00:23.435042
0:00:24.033348
0:00:24.038816
0:00:24.491489
0:00:24.492977
tensor(1.6002, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.6002, device='cuda:0')
0:00:24.495457
0:00:24.512322
0:00:24.512817
0:00:24.633367
0:00:24.634359
0:00:25.220244
0:00:25.228678
0:00:25.694559
0:00:25.696047
tensor(1.4783, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.4783, device='cuda:0')
0:00:25.698031
[1/1, 21/47] Training Loss: 1.5686330795288086
0:00:25.721839
0:00:25.722335
0:00:25.852319
0:00:25.852815
0:00:26.463087
0:00:26.468542
0:00:26.920172
0:00:26.921164
tensor(1.3851, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.3851, device='cuda:0')
0:00:26.923644
0:00:26.940510
0:00:26.941005
0:00:27.058096
0:00:27.058592
0:00:27.645531
0:00:27.650988
0:00:28.103413
0:00:28.104405
tensor(1.3864, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.3864, device='cuda:0')
0:00:28.106389
0:00:28.123752
0:00:28.123752
0:00:28.247402
0:00:28.247899
0:00:28.828967
0:00:28.834424
0:00:29.278520
0:00:29.279512
tensor(1.2761, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.2761, device='cuda:0')
0:00:29.281496
[1/1, 24/47] Training Loss: 1.3492109775543213
0:00:29.299353
0:00:29.299849
0:00:29.414963
0:00:29.415459
0:00:30.009303
0:00:30.014758
0:00:30.479173
0:00:30.480167
tensor(1.2522, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.2522, device='cuda:0')
0:00:30.482150
0:00:30.499015
0:00:30.499510
0:00:30.612118
0:00:30.612614
0:00:31.190250
0:00:31.195706
0:00:31.642702
0:00:31.643693
tensor(1.2340, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.2340, device='cuda:0')
0:00:31.646173
0:00:31.663567
0:00:31.663567
0:00:31.801472
0:00:31.802464
0:00:32.412239
0:00:32.417695
0:00:32.891997
0:00:32.893484
tensor(1.1621, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.1621, device='cuda:0')
0:00:32.895964
[1/1, 27/47] Training Loss: 1.2161052227020264
0:00:32.914812
0:00:32.915308
0:00:33.045505
0:00:33.045999
0:00:33.659747
0:00:33.665699
0:00:34.181683
0:00:34.183171
tensor(1.2080, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.2080, device='cuda:0')
0:00:34.185651
0:00:34.203011
0:00:34.203506
0:00:34.335972
0:00:34.336965
0:00:35.002749
0:00:35.012175
0:00:35.606099
0:00:35.607587
tensor(1.1860, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.1860, device='cuda:0')
0:00:35.610067
0:00:35.627924
0:00:35.628419
0:00:35.766364
0:00:35.767356
0:00:36.445054
0:00:36.451505
0:00:37.008685
0:00:37.010172
tensor(1.1303, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.1303, device='cuda:0')
0:00:37.012652
[1/1, 30/47] Training Loss: 1.174772024154663
0:00:37.035470
0:00:37.035470
0:00:37.163958
0:00:37.164962
0:00:37.855870
0:00:37.862317
0:00:38.366402
0:00:38.367406
tensor(1.0953, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0953, device='cuda:0')
0:00:38.369888
0:00:38.387744
0:00:38.387744
0:00:38.506805
0:00:38.507300
0:00:39.093196
0:00:39.098651
0:00:39.544164
0:00:39.545156
tensor(1.2057, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.2057, device='cuda:0')
0:00:39.547636
0:00:39.565509
0:00:39.566036
0:00:39.678699
0:00:39.679691
0:00:40.310791
0:00:40.316742
0:00:40.801948
0:00:40.803437
tensor(1.0444, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0444, device='cuda:0')
0:00:40.806413
[1/1, 33/47] Training Loss: 1.1151498556137085
0:00:40.825262
0:00:40.825757
0:00:40.946303
0:00:40.946799
0:00:41.542645
0:00:41.549093
0:00:42.049275
0:00:42.050763
tensor(1.0260, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0260, device='cuda:0')
0:00:42.053244
0:00:42.070111
0:00:42.070111
0:00:42.197172
0:00:42.197667
0:00:42.804948
0:00:42.810403
0:00:43.256419
0:00:43.257410
tensor(1.0809, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0809, device='cuda:0')
0:00:43.259890
0:00:43.276756
0:00:43.277252
0:00:43.407733
0:00:43.408726
0:00:43.989349
0:00:43.994805
0:00:44.445803
0:00:44.446795
tensor(1.1037, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.1037, device='cuda:0')
0:00:44.449275
[1/1, 36/47] Training Loss: 1.070162057876587
0:00:44.467629
0:00:44.467629
0:00:44.582736
0:00:44.583728
0:00:45.165652
0:00:45.171138
0:00:45.625576
0:00:45.626568
tensor(1.0325, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0325, device='cuda:0')
0:00:45.629048
0:00:45.651369
0:00:45.651369
0:00:45.778887
0:00:45.779386
0:00:46.377373
0:00:46.382828
0:00:46.849195
0:00:46.850187
tensor(1.1056, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.1056, device='cuda:0')
0:00:46.852667
0:00:46.869531
0:00:46.869531
0:00:46.985630
0:00:46.986128
0:00:47.589925
0:00:47.595877
0:00:48.076241
0:00:48.077233
tensor(0.9944, device='cuda:0', grad_fn=<DivBackward0>)
tensor(0.9944, device='cuda:0')
0:00:48.079713
[1/1, 39/47] Training Loss: 1.0441734790802002
0:00:48.097145
0:00:48.097641
0:00:48.234175
0:00:48.234671
0:00:48.891069
0:00:48.897020
0:00:49.351966
0:00:49.353454
tensor(0.9762, device='cuda:0', grad_fn=<DivBackward0>)
tensor(0.9762, device='cuda:0')
0:00:49.356430
0:00:49.372303
0:00:49.372303
0:00:49.491376
0:00:49.492368
0:00:50.086700
0:00:50.092168
0:00:50.586889
0:00:50.588377
tensor(1.0865, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0865, device='cuda:0')
0:00:50.590856
0:00:50.608231
0:00:50.608231
0:00:50.725323
0:00:50.725819
0:00:51.347463
0:00:51.353414
0:00:51.909077
0:00:51.911060
tensor(1.0515, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0515, device='cuda:0')
0:00:51.915029
[1/1, 42/47] Training Loss: 1.0380659103393555
0:00:51.941813
0:00:51.942309
0:00:52.083193
0:00:52.083689
0:00:52.691605
0:00:52.696564
0:00:53.143565
0:00:53.144557
tensor(1.0162, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0162, device='cuda:0')
0:00:53.147037
0:00:53.161917
0:00:53.162413
0:00:53.280519
0:00:53.281512
0:00:53.972089
0:00:53.978041
0:00:54.434515
0:00:54.435506
tensor(1.0418, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0418, device='cuda:0')
0:00:54.437986
0:00:54.457828
0:00:54.458323
0:00:54.575399
0:00:54.575895
0:00:55.161534
0:00:55.166990
0:00:55.604092
0:00:55.605083
tensor(1.0487, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0487, device='cuda:0')
0:00:55.607563
[1/1, 45/47] Training Loss: 1.0355299711227417
0:00:55.625420
0:00:55.625420
0:00:55.743009
0:00:55.744001
0:00:56.321507
0:00:56.326962
0:00:56.773096
0:00:56.774089
tensor(0.9113, device='cuda:0', grad_fn=<DivBackward0>)
tensor(0.9113, device='cuda:0')
0:00:56.776569
0:00:56.794922
0:00:56.795418
0:00:56.902573
0:00:56.903069
0:00:57.729178
0:00:57.735129
0:00:58.256223
0:00:58.257711
tensor(1.0257, device='cuda:0', grad_fn=<DivBackward0>)
tensor(1.0257, device='cuda:0')
0:00:58.260689
Testing!