Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 36000
Testing: 10000 -> 6000
Making Subsets
Training: 36000
Testing: 6000
Making Dataloaders
Defining network
Training!
[1/3, 29/563] Training Loss: 1.0650372464081337
[1/3, 58/563] Training Loss: 1.023660304217503
[1/3, 87/563] Training Loss: 0.9792640435284582
[1/3, 116/563] Training Loss: 0.9448146367895192
[1/3, 145/563] Training Loss: 0.925503919864523
[1/3, 174/563] Training Loss: 0.9066467901756023
[1/3, 203/563] Training Loss: 0.9110856878346411
[1/3, 232/563] Training Loss: 0.8660773347164022
[1/3, 261/563] Training Loss: 0.849791222605212
[1/3, 290/563] Training Loss: 0.8553391448382673
[1/3, 319/563] Training Loss: 0.8238031453099744
[1/3, 348/563] Training Loss: 0.8191408597189804
[1/3, 377/563] Training Loss: 0.804019048296172
[1/3, 406/563] Training Loss: 0.8009787715714554
[1/3, 435/563] Training Loss: 0.7692871628136471
[1/3, 464/563] Training Loss: 0.7361324244532091
[1/3, 493/563] Training Loss: 0.734381957300778
[1/3, 522/563] Training Loss: 0.6999696965875297
[1/3, 551/563] Training Loss: 0.681077320000221
Testing!
[1/3, 1/94]
[1/3, 6/94]
[1/3, 11/94]
[1/3, 16/94]
[1/3, 21/94]
[1/3, 26/94]
[1/3, 31/94]
[1/3, 36/94]
[1/3, 41/94]
[1/3, 46/94]
[1/3, 51/94]
[1/3, 56/94]
[1/3, 61/94]
[1/3, 66/94]
[1/3, 71/94]
[1/3, 76/94]
[1/3, 81/94]
[1/3, 86/94]
[1/3, 91/94]
Testing Loss: 0.6530005392275359
Training!
[2/3, 29/563] Training Loss: 0.6712127184045726
[2/3, 58/563] Training Loss: 0.6482534038609472
[2/3, 87/563] Training Loss: 0.6464726945449566
[2/3, 116/563] Training Loss: 0.6446749465218906
[2/3, 145/563] Training Loss: 0.6147465048165157
[2/3, 174/563] Training Loss: 0.6007786742572127
[2/3, 203/563] Training Loss: 0.5685250861891384
[2/3, 232/563] Training Loss: 0.5598512702974779
[2/3, 261/563] Training Loss: 0.5402003300601038
[2/3, 290/563] Training Loss: 0.526497266415892
[2/3, 319/563] Training Loss: 0.4970743327305235
[2/3, 348/563] Training Loss: 0.4896488754913725
[2/3, 377/563] Training Loss: 0.46548095242730503
[2/3, 406/563] Training Loss: 0.45288707675604983
[2/3, 435/563] Training Loss: 0.4362151797475486
[2/3, 464/563] Training Loss: 0.4179710396404924
[2/3, 493/563] Training Loss: 0.42135348710520515
[2/3, 522/563] Training Loss: 0.41021362255359517
[2/3, 551/563] Training Loss: 0.4186395530042977
Testing!
[2/3, 1/94]
[2/3, 6/94]
[2/3, 11/94]
[2/3, 16/94]
[2/3, 21/94]
[2/3, 26/94]
[2/3, 31/94]
[2/3, 36/94]
[2/3, 41/94]
[2/3, 46/94]
[2/3, 51/94]
[2/3, 56/94]
[2/3, 61/94]
[2/3, 66/94]
[2/3, 71/94]
[2/3, 76/94]
[2/3, 81/94]
[2/3, 86/94]
[2/3, 91/94]
Testing Loss: 0.5212218361465555
Training!
[3/3, 29/563] Training Loss: 0.4030742162260516
[3/3, 58/563] Training Loss: 0.4061301638340128
[3/3, 87/563] Training Loss: 0.396120555441955
[3/3, 116/563] Training Loss: 0.3878381858611929
[3/3, 145/563] Training Loss: 0.38008684639273016
[3/3, 174/563] Training Loss: 0.3790574454028031
[3/3, 203/563] Training Loss: 0.377871711706293
[3/3, 232/563] Training Loss: 0.3670889252218707
[3/3, 261/563] Training Loss: 0.3683429103473137
[3/3, 290/563] Training Loss: 0.3585074122609763
[3/3, 319/563] Training Loss: 0.34426530476274164
[3/3, 348/563] Training Loss: 0.35241115915364235
[3/3, 377/563] Training Loss: 0.349207053924429
[3/3, 406/563] Training Loss: 0.3478508324458681
[3/3, 435/563] Training Loss: 0.3402782020897701
[3/3, 464/563] Training Loss: 0.3331671316048195
[3/3, 493/563] Training Loss: 0.33671536938897495
[3/3, 522/563] Training Loss: 0.32741927175686275
[3/3, 551/563] Training Loss: 0.33327330391982507
Testing!
[3/3, 1/94]
[3/3, 6/94]
[3/3, 11/94]
[3/3, 16/94]
[3/3, 21/94]
[3/3, 26/94]
[3/3, 31/94]
[3/3, 36/94]
[3/3, 41/94]
[3/3, 46/94]
[3/3, 51/94]
[3/3, 56/94]
[3/3, 61/94]
[3/3, 66/94]
[3/3, 71/94]
[3/3, 76/94]
[3/3, 81/94]
[3/3, 86/94]
[3/3, 91/94]
Testing Loss: 0.44911556970654876
Training and Testing Finished
Assembling test data for t-sne projection
Batch: 1/94
Batch: 2/94
Batch: 3/94
Batch: 4/94
Batch: 5/94
Batch: 6/94
Batch: 7/94
Batch: 8/94
Batch: 9/94
Batch: 10/94
Batch: 11/94
Batch: 12/94
Batch: 13/94
Batch: 14/94
Batch: 15/94
Batch: 16/94
Batch: 17/94
Batch: 18/94
Batch: 19/94
Batch: 20/94
Batch: 21/94
Batch: 22/94
Batch: 23/94
Batch: 24/94
Batch: 25/94
Batch: 26/94
Batch: 27/94
Batch: 28/94
Batch: 29/94
Batch: 30/94
Batch: 31/94
Batch: 32/94
Batch: 33/94
Batch: 34/94
Batch: 35/94
Batch: 36/94
Batch: 37/94
Batch: 38/94
Batch: 39/94
Batch: 40/94
Batch: 41/94
Batch: 42/94
Batch: 43/94
Batch: 44/94
Batch: 45/94
Batch: 46/94
Batch: 47/94
Batch: 48/94
Batch: 49/94
Batch: 50/94
Batch: 51/94
Batch: 52/94
Batch: 53/94
Batch: 54/94
Batch: 55/94
Batch: 56/94
Batch: 57/94
Batch: 58/94
Batch: 59/94
Batch: 60/94
Batch: 61/94
Batch: 62/94
Batch: 63/94
Batch: 64/94
Batch: 65/94
Batch: 66/94
Batch: 67/94
Batch: 68/94
Batch: 69/94
Batch: 70/94
Batch: 71/94
Batch: 72/94
Batch: 73/94
Batch: 74/94
Batch: 75/94
Batch: 76/94
Batch: 77/94
Batch: 78/94
Batch: 79/94
Batch: 80/94
Batch: 81/94
Batch: 82/94
Batch: 83/94
Batch: 84/94
Batch: 85/94
Batch: 86/94
Batch: 87/94
Batch: 88/94
Batch: 89/94
Batch: 90/94
Batch: 91/94
Batch: 92/94
Batch: 93/94
Batch: 94/94
Features: (6000, 100)
All Labels: (6000,)
All Original Images: (6000, 28, 28)
All Reconstructed Images: (6000, 28, 28)
Applying t-SNE
Plotting Results Grid
9 added
2 added
3 added
0 added
4 added
7 added
8 added
1 added
6 added
5 added
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation