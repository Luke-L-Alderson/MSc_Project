Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 01:09:30.681734
Scaler Value: 0.1020408163265306
Training - 2024-06-18 01:09:30.682726
[1/9, 10/94] Training Loss: 0.9727 - Iteration Time: 0:00:01.391614
[1/9, 20/94] Training Loss: 0.9527 - Iteration Time: 0:00:01.394094
[1/9, 30/94] Training Loss: 0.9375 - Iteration Time: 0:00:01.400130
[1/9, 40/94] Training Loss: 0.9241 - Iteration Time: 0:00:01.426879
[1/9, 50/94] Training Loss: 0.9110 - Iteration Time: 0:00:01.465612
[1/9, 60/94] Training Loss: 0.9028 - Iteration Time: 0:00:01.411527
[1/9, 70/94] Training Loss: 0.8912 - Iteration Time: 0:00:01.430817
[1/9, 80/94] Training Loss: 0.8833 - Iteration Time: 0:00:01.501728
[1/9, 90/94] Training Loss: 0.8760 - Iteration Time: 0:00:01.507712
Testing - 2024-06-18 01:11:47.378582
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.8718 - Epoch Time: 0:02:29.901913
Training - 2024-06-18 01:12:00.585135
[2/9, 10/94] Training Loss: 0.8659 - Iteration Time: 0:00:01.405076
[2/9, 20/94] Training Loss: 0.8606 - Iteration Time: 0:00:01.384221
[2/9, 30/94] Training Loss: 0.8523 - Iteration Time: 0:00:01.583607
[2/9, 40/94] Training Loss: 0.8421 - Iteration Time: 0:00:01.393126
[2/9, 50/94] Training Loss: 0.8317 - Iteration Time: 0:00:01.401532
[2/9, 60/94] Training Loss: 0.8241 - Iteration Time: 0:00:01.483446
[2/9, 70/94] Training Loss: 0.8194 - Iteration Time: 0:00:01.393067
[2/9, 80/94] Training Loss: 0.8138 - Iteration Time: 0:00:01.382157
[2/9, 90/94] Training Loss: 0.8087 - Iteration Time: 0:00:01.386211
Testing - 2024-06-18 01:14:15.478882
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.8056 - Epoch Time: 0:02:28.273873
Training - 2024-06-18 01:14:28.859504
[3/9, 10/94] Training Loss: 0.8011 - Iteration Time: 0:00:01.382162
[3/9, 20/94] Training Loss: 0.7969 - Iteration Time: 0:00:01.439704
[3/9, 30/94] Training Loss: 0.7937 - Iteration Time: 0:00:01.403033
[3/9, 40/94] Training Loss: 0.7904 - Iteration Time: 0:00:01.558842
[3/9, 50/94] Training Loss: 0.7828 - Iteration Time: 0:00:01.409493
[3/9, 60/94] Training Loss: 0.7768 - Iteration Time: 0:00:01.395035
[3/9, 70/94] Training Loss: 0.7707 - Iteration Time: 0:00:01.412926
[3/9, 80/94] Training Loss: 0.7621 - Iteration Time: 0:00:01.393660
[3/9, 90/94] Training Loss: 0.7536 - Iteration Time: 0:00:01.396562
Testing - 2024-06-18 01:16:43.393611
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.7498 - Epoch Time: 0:02:27.644900
Training - 2024-06-18 01:16:56.504404
[4/9, 10/94] Training Loss: 0.7455 - Iteration Time: 0:00:01.419856
[4/9, 20/94] Training Loss: 0.7407 - Iteration Time: 0:00:01.426416
[4/9, 30/94] Training Loss: 0.7356 - Iteration Time: 0:00:01.401112
[4/9, 40/94] Training Loss: 0.7306 - Iteration Time: 0:00:01.376701
[4/9, 50/94] Training Loss: 0.7254 - Iteration Time: 0:00:01.390096
[4/9, 60/94] Training Loss: 0.7179 - Iteration Time: 0:00:01.373935
[4/9, 70/94] Training Loss: 0.7116 - Iteration Time: 0:00:01.407537
[4/9, 80/94] Training Loss: 0.7048 - Iteration Time: 0:00:01.420390
[4/9, 90/94] Training Loss: 0.6989 - Iteration Time: 0:00:01.395297
Testing - 2024-06-18 01:19:11.489169
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.6943 - Epoch Time: 0:02:28.456151
Training - 2024-06-18 01:19:24.960555
[5/9, 10/94] Training Loss: 0.6937 - Iteration Time: 0:00:01.416031
[5/9, 20/94] Training Loss: 0.6918 - Iteration Time: 0:00:01.448695
[5/9, 30/94] Training Loss: 0.6904 - Iteration Time: 0:00:01.432385
[5/9, 40/94] Training Loss: 0.6874 - Iteration Time: 0:00:01.399706
[5/9, 50/94] Training Loss: 0.6851 - Iteration Time: 0:00:01.392634
[5/9, 60/94] Training Loss: 0.6841 - Iteration Time: 0:00:01.405120
[5/9, 70/94] Training Loss: 0.6797 - Iteration Time: 0:00:01.387231
[5/9, 80/94] Training Loss: 0.6781 - Iteration Time: 0:00:01.378306
[5/9, 90/94] Training Loss: 0.6754 - Iteration Time: 0:00:01.421835
Testing - 2024-06-18 01:21:39.978534
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.6752 - Epoch Time: 0:02:28.256159
Training - 2024-06-18 01:21:53.217210
[6/9, 10/94] Training Loss: 0.6730 - Iteration Time: 0:00:01.424454
[6/9, 20/94] Training Loss: 0.6681 - Iteration Time: 0:00:01.572323
[6/9, 30/94] Training Loss: 0.6630 - Iteration Time: 0:00:01.505264
[6/9, 40/94] Training Loss: 0.6576 - Iteration Time: 0:00:01.401528
[6/9, 50/94] Training Loss: 0.6514 - Iteration Time: 0:00:01.527126
[6/9, 60/94] Training Loss: 0.6460 - Iteration Time: 0:00:01.487875
[6/9, 70/94] Training Loss: 0.6417 - Iteration Time: 0:00:01.498850
[6/9, 80/94] Training Loss: 0.6403 - Iteration Time: 0:00:01.511009
[6/9, 90/94] Training Loss: 0.6371 - Iteration Time: 0:00:01.581710
Testing - 2024-06-18 01:24:16.505705
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.6345 - Epoch Time: 0:02:37.174915
Training - 2024-06-18 01:24:30.392125
[7/9, 10/94] Training Loss: 0.6300 - Iteration Time: 0:00:01.500278
[7/9, 20/94] Training Loss: 0.6267 - Iteration Time: 0:00:01.401604
[7/9, 30/94] Training Loss: 0.6213 - Iteration Time: 0:00:01.391165
[7/9, 40/94] Training Loss: 0.6193 - Iteration Time: 0:00:01.390802
[7/9, 50/94] Training Loss: 0.6166 - Iteration Time: 0:00:01.420376
[7/9, 60/94] Training Loss: 0.6127 - Iteration Time: 0:00:01.407510
[7/9, 70/94] Training Loss: 0.6085 - Iteration Time: 0:00:01.427946
[7/9, 80/94] Training Loss: 0.6051 - Iteration Time: 0:00:01.475979
[7/9, 90/94] Training Loss: 0.6025 - Iteration Time: 0:00:01.391705
Testing - 2024-06-18 01:26:45.556909
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.6007 - Epoch Time: 0:02:28.456779
Training - 2024-06-18 01:26:58.849399
[8/9, 10/94] Training Loss: 0.5987 - Iteration Time: 0:00:01.426358
[8/9, 20/94] Training Loss: 0.5966 - Iteration Time: 0:00:01.437891
[8/9, 30/94] Training Loss: 0.5963 - Iteration Time: 0:00:01.400205
[8/9, 40/94] Training Loss: 0.5931 - Iteration Time: 0:00:01.393083
[8/9, 50/94] Training Loss: 0.5912 - Iteration Time: 0:00:01.446888
[8/9, 60/94] Training Loss: 0.5894 - Iteration Time: 0:00:01.386611
[8/9, 70/94] Training Loss: 0.5861 - Iteration Time: 0:00:01.411991
[8/9, 80/94] Training Loss: 0.5824 - Iteration Time: 0:00:01.385228
[8/9, 90/94] Training Loss: 0.5817 - Iteration Time: 0:00:01.455131
Testing - 2024-06-18 01:29:13.413950
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.5823 - Epoch Time: 0:02:27.786918
Training - 2024-06-18 01:29:26.636317
[9/9, 10/94] Training Loss: 0.5815 - Iteration Time: 0:00:01.431777
[9/9, 20/94] Training Loss: 0.5796 - Iteration Time: 0:00:01.401580
[9/9, 30/94] Training Loss: 0.5793 - Iteration Time: 0:00:01.477467
[9/9, 40/94] Training Loss: 0.5770 - Iteration Time: 0:00:01.436810
[9/9, 50/94] Training Loss: 0.5756 - Iteration Time: 0:00:01.442684
[9/9, 60/94] Training Loss: 0.5730 - Iteration Time: 0:00:01.386150
[9/9, 70/94] Training Loss: 0.5677 - Iteration Time: 0:00:01.432789
[9/9, 80/94] Training Loss: 0.5646 - Iteration Time: 0:00:01.396077
[9/9, 90/94] Training Loss: 0.5633 - Iteration Time: 0:00:01.395619
Testing - 2024-06-18 01:31:41.416115
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.5630 - Epoch Time: 0:02:28.033228
Training and Testing Finished - Time: 0:22:23.988307
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0    1      2      3    4    5  ...   93   94   95   96   97   98   99
0       2  0.0  0.0  0.155  0.105  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0
1       4  0.0  0.0  0.200  0.070  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0
2       7  0.0  0.0  0.175  0.085  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0
3       3  0.0  0.0  0.225  0.010  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0
4       7  0.0  0.0  0.190  0.080  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP