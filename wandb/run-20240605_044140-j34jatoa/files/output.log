Starting Sweep: Batch Size: 32, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 12000
Testing: 10000 -> 2000
Making Subsets
Training: 12000
Testing: 2000
Making Dataloaders
Defining network
Training!
[1/3, 19/375] Training Loss: 11.070716481459769
[1/3, 38/375] Training Loss: 3.9466558883064673
[1/3, 57/375] Training Loss: 1.8872697165137844
[1/3, 76/375] Training Loss: 1.3210060439611737
[1/3, 95/375] Training Loss: 1.0411693108709235
[1/3, 114/375] Training Loss: 0.9024658109012403
[1/3, 133/375] Training Loss: 0.8258229368611386
[1/3, 152/375] Training Loss: 0.7651231602618569
[1/3, 171/375] Training Loss: 0.7491379882159986
[1/3, 190/375] Training Loss: 0.719104362161536
[1/3, 209/375] Training Loss: 0.6829741565804732
[1/3, 228/375] Training Loss: 0.686007371074275
[1/3, 247/375] Training Loss: 0.692299158949601
[1/3, 266/375] Training Loss: 0.67526838653966
[1/3, 285/375] Training Loss: 0.6491043881366128
[1/3, 304/375] Training Loss: 0.6742626554087588
[1/3, 323/375] Training Loss: 0.6379213270388151
[1/3, 342/375] Training Loss: 0.643610417842865
[1/3, 361/375] Training Loss: 0.6318799225907576
Testing!
[1/3, 1/63]
[1/3, 5/63]
[1/3, 9/63]
[1/3, 13/63]
[1/3, 17/63]
[1/3, 21/63]
[1/3, 25/63]
[1/3, 29/63]
[1/3, 33/63]
[1/3, 37/63]
[1/3, 41/63]
[1/3, 45/63]
[1/3, 49/63]
[1/3, 53/63]
[1/3, 57/63]
[1/3, 61/63]
Testing Loss: 0.5954941110685468
Training!
[2/3, 19/375] Training Loss: 0.6200350522994995
[2/3, 38/375] Training Loss: 0.6153828438959623
[2/3, 57/375] Training Loss: 0.602045664661809
[2/3, 76/375] Training Loss: 0.6042155058760392
[2/3, 95/375] Training Loss: 0.6044552765394512
[2/3, 114/375] Training Loss: 0.5915885850002891
[2/3, 133/375] Training Loss: 0.557549492308968
[2/3, 152/375] Training Loss: 0.5448175370693207
[2/3, 171/375] Training Loss: 0.5258097758418635
[2/3, 190/375] Training Loss: 0.5047289180128198
[2/3, 209/375] Training Loss: 0.5017573786409277
[2/3, 228/375] Training Loss: 0.4912162125110626
[2/3, 247/375] Training Loss: 0.481606640313801
[2/3, 266/375] Training Loss: 0.462517007401115
[2/3, 285/375] Training Loss: 0.438111884029288
[2/3, 304/375] Training Loss: 0.45285619716895253
[2/3, 323/375] Training Loss: 0.4315134537847419
[2/3, 342/375] Training Loss: 0.4244812366209532
[2/3, 361/375] Training Loss: 0.4163675716048793
Testing!
[2/3, 1/63]
[2/3, 5/63]
[2/3, 9/63]
[2/3, 13/63]
[2/3, 17/63]
[2/3, 21/63]
[2/3, 25/63]
[2/3, 29/63]
[2/3, 33/63]
[2/3, 37/63]
[2/3, 41/63]
[2/3, 45/63]
[2/3, 49/63]
[2/3, 53/63]
[2/3, 57/63]
[2/3, 61/63]
Testing Loss: 0.4912912903819233
Training!
[3/3, 19/375] Training Loss: 0.4071707976491828
[3/3, 38/375] Training Loss: 0.39625133025018794
[3/3, 57/375] Training Loss: 0.3942380986715618
[3/3, 76/375] Training Loss: 0.39331984049395513
[3/3, 95/375] Training Loss: 0.38582566223646464
[3/3, 114/375] Training Loss: 0.3709723980803239
[3/3, 133/375] Training Loss: 0.3848718843962017
[3/3, 152/375] Training Loss: 0.37055818814980357
[3/3, 171/375] Training Loss: 0.3734594050206636
[3/3, 190/375] Training Loss: 0.35819651892310694
[3/3, 209/375] Training Loss: 0.35586519147220413
[3/3, 228/375] Training Loss: 0.3606544764418351
[3/3, 247/375] Training Loss: 0.34733644441554423
[3/3, 266/375] Training Loss: 0.35153523244355855
[3/3, 285/375] Training Loss: 0.35044351690693903
[3/3, 304/375] Training Loss: 0.3470832501587115
[3/3, 323/375] Training Loss: 0.3411274332749216
[3/3, 342/375] Training Loss: 0.3402017543190404
[3/3, 361/375] Training Loss: 0.33867118703691584
Testing!
[3/3, 1/63]
[3/3, 5/63]
[3/3, 9/63]
[3/3, 13/63]
[3/3, 17/63]
[3/3, 21/63]
[3/3, 25/63]
[3/3, 29/63]
[3/3, 33/63]
[3/3, 37/63]
[3/3, 41/63]
[3/3, 45/63]
[3/3, 49/63]
[3/3, 53/63]
[3/3, 57/63]
[3/3, 61/63]
Testing Loss: 0.4310546116903424
Training and Testing Finished
Assembling test data for t-sne projection
Batch: 1/63
Batch: 2/63
Batch: 3/63
Batch: 4/63
Batch: 5/63
Batch: 6/63
Batch: 7/63
Batch: 8/63
Batch: 9/63
Batch: 10/63
Batch: 11/63
Batch: 12/63
Batch: 13/63
Batch: 14/63
Batch: 15/63
Batch: 16/63
Batch: 17/63
Batch: 18/63
Batch: 19/63
Batch: 20/63
Batch: 21/63
Batch: 22/63
Batch: 23/63
Batch: 24/63
Batch: 25/63
Batch: 26/63
Batch: 27/63
Batch: 28/63
Batch: 29/63
Batch: 30/63
Batch: 31/63
Batch: 32/63
Batch: 33/63
Batch: 34/63
Batch: 35/63
Batch: 36/63
Batch: 37/63
Batch: 38/63
Batch: 39/63
Batch: 40/63
Batch: 41/63
Batch: 42/63
Batch: 43/63
Batch: 44/63
Batch: 45/63
Batch: 46/63
Batch: 47/63
Batch: 48/63
Batch: 49/63
Batch: 50/63
Batch: 51/63
Batch: 52/63
Batch: 53/63
Batch: 54/63
Batch: 55/63
Batch: 56/63
Batch: 57/63
Batch: 58/63
Batch: 59/63
Batch: 60/63
Batch: 61/63
Batch: 62/63
Batch: 63/63
Features: (2000, 100)
All Labels: (2000,)
All Original Images: (2000, 28, 28)
All Reconstructed Images: (2000, 28, 28)
Applying t-SNE
Plotting Results Grid
8 added
4 added
2 added
0 added
9 added
7 added
3 added
1 added
6 added
5 added
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation