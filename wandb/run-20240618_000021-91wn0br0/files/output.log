Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 00:00:22.412660
Scaler Value: 0.050505050505050504
Training - 2024-06-18 00:00:22.413157
[1/9, 10/94] Training Loss: 0.3435 - Iteration Time: 0:00:01.401494
[1/9, 20/94] Training Loss: 0.3361 - Iteration Time: 0:00:01.395635
[1/9, 30/94] Training Loss: 0.3356 - Iteration Time: 0:00:01.407986
[1/9, 40/94] Training Loss: 0.3358 - Iteration Time: 0:00:01.395601
[1/9, 50/94] Training Loss: 0.3325 - Iteration Time: 0:00:01.428306
[1/9, 60/94] Training Loss: 0.3290 - Iteration Time: 0:00:01.392058
[1/9, 70/94] Training Loss: 0.3255 - Iteration Time: 0:00:01.564248
[1/9, 80/94] Training Loss: 0.3271 - Iteration Time: 0:00:01.391600
[1/9, 90/94] Training Loss: 0.3225 - Iteration Time: 0:00:01.467527
Testing - 2024-06-18 00:02:37.993558
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.3089 - Epoch Time: 0:02:29.003991
Training - 2024-06-18 00:02:51.417644
[2/9, 10/94] Training Loss: 0.3239 - Iteration Time: 0:00:01.503193
[2/9, 20/94] Training Loss: 0.3135 - Iteration Time: 0:00:01.412948
[2/9, 30/94] Training Loss: 0.3121 - Iteration Time: 0:00:01.408060
[2/9, 40/94] Training Loss: 0.3100 - Iteration Time: 0:00:01.441835
[2/9, 50/94] Training Loss: 0.3060 - Iteration Time: 0:00:01.424790
[2/9, 60/94] Training Loss: 0.3069 - Iteration Time: 0:00:01.391571
[2/9, 70/94] Training Loss: 0.3017 - Iteration Time: 0:00:01.407955
[2/9, 80/94] Training Loss: 0.2967 - Iteration Time: 0:00:01.421968
[2/9, 90/94] Training Loss: 0.2983 - Iteration Time: 0:00:01.633731
Testing - 2024-06-18 00:05:08.130230
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.2877 - Epoch Time: 0:02:30.158521
Training - 2024-06-18 00:05:21.576165
[3/9, 10/94] Training Loss: 0.2928 - Iteration Time: 0:00:01.406043
[3/9, 20/94] Training Loss: 0.2943 - Iteration Time: 0:00:01.440182
[3/9, 30/94] Training Loss: 0.2880 - Iteration Time: 0:00:01.406945
[3/9, 40/94] Training Loss: 0.2878 - Iteration Time: 0:00:01.525675
[3/9, 50/94] Training Loss: 0.2873 - Iteration Time: 0:00:01.396511
[3/9, 60/94] Training Loss: 0.2840 - Iteration Time: 0:00:01.387111
[3/9, 70/94] Training Loss: 0.2780 - Iteration Time: 0:00:01.513624
[3/9, 80/94] Training Loss: 0.2782 - Iteration Time: 0:00:01.426399
[3/9, 90/94] Training Loss: 0.2761 - Iteration Time: 0:00:01.383205
Testing - 2024-06-18 00:07:36.901898
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.2660 - Epoch Time: 0:02:28.542159
Training - 2024-06-18 00:07:50.118820
[4/9, 10/94] Training Loss: 0.2700 - Iteration Time: 0:00:01.390584
[4/9, 20/94] Training Loss: 0.2730 - Iteration Time: 0:00:01.411906
[4/9, 30/94] Training Loss: 0.2694 - Iteration Time: 0:00:01.414533
[4/9, 40/94] Training Loss: 0.2664 - Iteration Time: 0:00:01.382164
[4/9, 50/94] Training Loss: 0.2664 - Iteration Time: 0:00:01.708102
[4/9, 60/94] Training Loss: 0.2627 - Iteration Time: 0:00:01.421324
[4/9, 70/94] Training Loss: 0.2656 - Iteration Time: 0:00:01.414943
[4/9, 80/94] Training Loss: 0.2621 - Iteration Time: 0:00:01.407500
[4/9, 90/94] Training Loss: 0.2583 - Iteration Time: 0:00:01.408563
Testing - 2024-06-18 00:10:05.504591
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.2538 - Epoch Time: 0:02:28.758624
Training - 2024-06-18 00:10:18.877444
[5/9, 10/94] Training Loss: 0.2555 - Iteration Time: 0:00:01.422419
[5/9, 20/94] Training Loss: 0.2549 - Iteration Time: 0:00:01.430851
[5/9, 30/94] Training Loss: 0.2489 - Iteration Time: 0:00:01.550892
[5/9, 40/94] Training Loss: 0.2485 - Iteration Time: 0:00:01.470563
[5/9, 50/94] Training Loss: 0.2480 - Iteration Time: 0:00:01.437275
[5/9, 60/94] Training Loss: 0.2463 - Iteration Time: 0:00:01.391176
[5/9, 70/94] Training Loss: 0.2436 - Iteration Time: 0:00:01.494882
[5/9, 80/94] Training Loss: 0.2377 - Iteration Time: 0:00:01.413974
[5/9, 90/94] Training Loss: 0.2373 - Iteration Time: 0:00:01.411997
Testing - 2024-06-18 00:12:36.073905
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.2299 - Epoch Time: 0:02:30.449191
Training - 2024-06-18 00:12:49.327131
[6/9, 10/94] Training Loss: 0.2354 - Iteration Time: 0:00:01.407101
[6/9, 20/94] Training Loss: 0.2308 - Iteration Time: 0:00:01.428964
[6/9, 30/94] Training Loss: 0.2281 - Iteration Time: 0:00:01.399068
[6/9, 40/94] Training Loss: 0.2274 - Iteration Time: 0:00:01.430473
[6/9, 50/94] Training Loss: 0.2252 - Iteration Time: 0:00:01.499349
[6/9, 60/94] Training Loss: 0.2232 - Iteration Time: 0:00:01.410429
[6/9, 70/94] Training Loss: 0.2232 - Iteration Time: 0:00:01.413942
[6/9, 80/94] Training Loss: 0.2208 - Iteration Time: 0:00:01.425829
[6/9, 90/94] Training Loss: 0.2211 - Iteration Time: 0:00:01.492868
Testing - 2024-06-18 00:15:05.372836
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.2074 - Epoch Time: 0:02:29.368811
Training - 2024-06-18 00:15:18.695942
[7/9, 10/94] Training Loss: 0.2160 - Iteration Time: 0:00:01.467513
[7/9, 20/94] Training Loss: 0.2153 - Iteration Time: 0:00:01.427429
[7/9, 30/94] Training Loss: 0.2144 - Iteration Time: 0:00:01.568791
[7/9, 40/94] Training Loss: 0.2117 - Iteration Time: 0:00:01.447792
[7/9, 50/94] Training Loss: 0.2096 - Iteration Time: 0:00:01.445757
[7/9, 60/94] Training Loss: 0.2046 - Iteration Time: 0:00:01.427357
[7/9, 70/94] Training Loss: 0.2072 - Iteration Time: 0:00:01.396591
[7/9, 80/94] Training Loss: 0.2058 - Iteration Time: 0:00:01.393173
[7/9, 90/94] Training Loss: 0.2050 - Iteration Time: 0:00:01.394224
Testing - 2024-06-18 00:17:34.306800
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.1943 - Epoch Time: 0:02:29.218131
Training - 2024-06-18 00:17:47.914073
[8/9, 10/94] Training Loss: 0.2031 - Iteration Time: 0:00:01.457717
[8/9, 20/94] Training Loss: 0.1983 - Iteration Time: 0:00:01.410946
[8/9, 30/94] Training Loss: 0.1980 - Iteration Time: 0:00:01.424338
[8/9, 40/94] Training Loss: 0.1954 - Iteration Time: 0:00:01.477948
[8/9, 50/94] Training Loss: 0.1951 - Iteration Time: 0:00:01.376101
[8/9, 60/94] Training Loss: 0.1948 - Iteration Time: 0:00:01.371285
[8/9, 70/94] Training Loss: 0.1914 - Iteration Time: 0:00:01.399689
[8/9, 80/94] Training Loss: 0.1917 - Iteration Time: 0:00:01.556819
[8/9, 90/94] Training Loss: 0.1892 - Iteration Time: 0:00:01.646615
Testing - 2024-06-18 00:20:07.956138
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.1830 - Epoch Time: 0:02:33.870970
Training - 2024-06-18 00:20:21.785043
[9/9, 10/94] Training Loss: 0.1879 - Iteration Time: 0:00:01.407466
[9/9, 20/94] Training Loss: 0.1875 - Iteration Time: 0:00:01.427327
[9/9, 30/94] Training Loss: 0.1866 - Iteration Time: 0:00:01.481001
[9/9, 40/94] Training Loss: 0.1847 - Iteration Time: 0:00:01.426396
[9/9, 50/94] Training Loss: 0.1826 - Iteration Time: 0:00:01.408469
[9/9, 60/94] Training Loss: 0.1838 - Iteration Time: 0:00:01.389636
[9/9, 70/94] Training Loss: 0.1814 - Iteration Time: 0:00:01.582145
[9/9, 80/94] Training Loss: 0.1795 - Iteration Time: 0:00:01.416053
[9/9, 90/94] Training Loss: 0.1832 - Iteration Time: 0:00:01.403663
Testing - 2024-06-18 00:22:38.325720
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.1736 - Epoch Time: 0:02:29.850954
Training and Testing Finished - Time: 0:22:29.223337
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels      0    1      2    3    4  ...     94     95   96    97     98     99
0       2  0.305  0.0  0.235  0.0  0.0  ...  0.045  0.115  0.0  0.18  0.155  0.095
1       4  0.160  0.0  0.215  0.0  0.0  ...  0.010  0.030  0.0  0.07  0.140  0.010
2       7  0.155  0.0  0.260  0.0  0.0  ...  0.030  0.125  0.0  0.21  0.150  0.085
3       3  0.200  0.0  0.080  0.0  0.0  ...  0.090  0.040  0.0  0.27  0.105  0.115
4       7  0.060  0.0  0.245  0.0  0.0  ...  0.110  0.070  0.0  0.12  0.190  0.040
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP