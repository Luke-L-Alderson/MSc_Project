Starting Sweep: Batch Size: 32, Learning Rate: 0.001
Making datasets and defining subsets
Training: 60000 -> 60000
Testing: 10000 -> 10000
Making Dataloaders
Defining network
Training!
[1/6, 94/1875] Training Loss: 2.033861319435404
[1/6, 188/1875] Training Loss: 0.6137442588806152
[1/6, 282/1875] Training Loss: 0.5832447780573622
[1/6, 376/1875] Training Loss: 0.5614862086925101
[1/6, 470/1875] Training Loss: 0.5283350548211564
[1/6, 564/1875] Training Loss: 0.5181134799693493
[1/6, 658/1875] Training Loss: 0.5124629422071132
[1/6, 752/1875] Training Loss: 0.5098832623755678
[1/6, 846/1875] Training Loss: 0.5204099597448998
[1/6, 940/1875] Training Loss: 0.491515817160302
[1/6, 1034/1875] Training Loss: 0.4782956366209274
[1/6, 1128/1875] Training Loss: 0.4688614476868447
[1/6, 1222/1875] Training Loss: 0.471747894236382
[1/6, 1316/1875] Training Loss: 0.48120674617747045
[1/6, 1410/1875] Training Loss: 0.4696850789354203
[1/6, 1504/1875] Training Loss: 0.46324042500333584
[1/6, 1598/1875] Training Loss: 0.4461057427081656
[1/6, 1692/1875] Training Loss: 0.4404365360102755
[1/6, 1786/1875] Training Loss: 0.4302014236120468
Testing!
[1/6, 1/313]
[1/6, 17/313]
[1/6, 33/313]
[1/6, 49/313]
[1/6, 65/313]
[1/6, 81/313]
[1/6, 97/313]
[1/6, 113/313]
[1/6, 129/313]
[1/6, 145/313]
[1/6, 161/313]
[1/6, 177/313]
[1/6, 193/313]
[1/6, 209/313]
[1/6, 225/313]
[1/6, 241/313]
[1/6, 257/313]
[1/6, 273/313]
[1/6, 289/313]
[1/6, 305/313]
Testing Loss: 0.4143997968174517
Training!
[2/6, 94/1875] Training Loss: 0.4328430520093187
[2/6, 188/1875] Training Loss: 0.43533972793437065
[2/6, 282/1875] Training Loss: 0.4294031135579373
[2/6, 376/1875] Training Loss: 0.434404822423103
[2/6, 470/1875] Training Loss: 0.4162418595019807
[2/6, 564/1875] Training Loss: 0.4071256990762467
[2/6, 658/1875] Training Loss: 0.3949690622852204
[2/6, 752/1875] Training Loss: 0.38187990480280937
[2/6, 846/1875] Training Loss: 0.3819450634591123
[2/6, 940/1875] Training Loss: 0.3745143150395535
[2/6, 1034/1875] Training Loss: 0.3678905355169418
[2/6, 1128/1875] Training Loss: 0.3644796685969576
[2/6, 1222/1875] Training Loss: 0.3631038890874132
[2/6, 1316/1875] Training Loss: 0.3586640795494648
[2/6, 1410/1875] Training Loss: 0.34884183901421567
[2/6, 1504/1875] Training Loss: 0.3359014962581878
[2/6, 1598/1875] Training Loss: 0.3276583970861232
[2/6, 1692/1875] Training Loss: 0.3277880606499124
[2/6, 1786/1875] Training Loss: 0.31608457926740036
Testing!
[2/6, 1/313]
[2/6, 17/313]
[2/6, 33/313]
[2/6, 49/313]
[2/6, 65/313]
[2/6, 81/313]
[2/6, 97/313]
[2/6, 113/313]
[2/6, 129/313]
[2/6, 145/313]
[2/6, 161/313]
[2/6, 177/313]
[2/6, 193/313]
[2/6, 209/313]
[2/6, 225/313]
[2/6, 241/313]
[2/6, 257/313]
[2/6, 273/313]
[2/6, 289/313]
[2/6, 305/313]
Testing Loss: 0.3509828559821472
Training!
[3/6, 94/1875] Training Loss: 0.2964165738605438
[3/6, 188/1875] Training Loss: 0.2899988296818226
[3/6, 282/1875] Training Loss: 0.2891888675537515
[3/6, 376/1875] Training Loss: 0.28276715142295716
[3/6, 470/1875] Training Loss: 0.27750439830916995
[3/6, 564/1875] Training Loss: 0.27262618551228907
[3/6, 658/1875] Training Loss: 0.2705474746354083
[3/6, 752/1875] Training Loss: 0.26686451314611637
[3/6, 846/1875] Training Loss: 0.25952962738402346
[3/6, 940/1875] Training Loss: 0.26127314282224534
[3/6, 1034/1875] Training Loss: 0.24924637076068432
[3/6, 1128/1875] Training Loss: 0.25039977532752017
[3/6, 1222/1875] Training Loss: 0.24699534412394178
[3/6, 1316/1875] Training Loss: 0.24879126821426636
[3/6, 1410/1875] Training Loss: 0.2393799233943858
[3/6, 1504/1875] Training Loss: 0.24634245577010702
[3/6, 1598/1875] Training Loss: 0.23974655140587625
[3/6, 1692/1875] Training Loss: 0.2373233031719289
[3/6, 1786/1875] Training Loss: 0.236284021684464
Testing!
[3/6, 1/313]
[3/6, 17/313]
[3/6, 33/313]
[3/6, 49/313]
[3/6, 65/313]
[3/6, 81/313]
[3/6, 97/313]
[3/6, 113/313]
[3/6, 129/313]
[3/6, 145/313]
[3/6, 161/313]
[3/6, 177/313]
[3/6, 193/313]
[3/6, 209/313]
[3/6, 225/313]
[3/6, 241/313]
[3/6, 257/313]
[3/6, 273/313]
[3/6, 289/313]
[3/6, 305/313]
Testing Loss: 0.3055661109276116
Training!
[4/6, 94/1875] Training Loss: 0.22968073236815473
[4/6, 188/1875] Training Loss: 0.23207668658900768
[4/6, 282/1875] Training Loss: 0.2288997951657214
[4/6, 376/1875] Training Loss: 0.22437608717603885
[4/6, 470/1875] Training Loss: 0.2290686898409052
[4/6, 564/1875] Training Loss: 0.22560223540727128
[4/6, 658/1875] Training Loss: 0.22407707635392535
[4/6, 752/1875] Training Loss: 0.2271620253933237
[4/6, 846/1875] Training Loss: 0.2260192150765277
[4/6, 940/1875] Training Loss: 0.22817243049119382
[4/6, 1034/1875] Training Loss: 0.22259896470511215
[4/6, 1128/1875] Training Loss: 0.21992403680973865
[4/6, 1222/1875] Training Loss: 0.21853379207722684
[4/6, 1316/1875] Training Loss: 0.22051001118218644
[4/6, 1410/1875] Training Loss: 0.2199702743203082
[4/6, 1504/1875] Training Loss: 0.22164944955643187
[4/6, 1598/1875] Training Loss: 0.22519569844007492
[4/6, 1692/1875] Training Loss: 0.21989580338939707
[4/6, 1786/1875] Training Loss: 0.21992017487262158
Testing!
[4/6, 1/313]
[4/6, 17/313]
[4/6, 33/313]
[4/6, 49/313]
[4/6, 65/313]
[4/6, 81/313]
[4/6, 97/313]
[4/6, 113/313]
[4/6, 129/313]
[4/6, 145/313]
[4/6, 161/313]
[4/6, 177/313]
[4/6, 193/313]
[4/6, 209/313]
[4/6, 225/313]
[4/6, 241/313]
[4/6, 257/313]
[4/6, 273/313]
[4/6, 289/313]
[4/6, 305/313]
Testing Loss: 0.2808796080062166
Training!
[5/6, 94/1875] Training Loss: 0.2167019561884251
[5/6, 188/1875] Training Loss: 0.2138983816542524
[5/6, 282/1875] Training Loss: 0.21681775422172345
[5/6, 376/1875] Training Loss: 0.21162878072008173
[5/6, 470/1875] Training Loss: 0.2159450372799914
[5/6, 564/1875] Training Loss: 0.21750598178899033
[5/6, 658/1875] Training Loss: 0.2173295536256851
[5/6, 752/1875] Training Loss: 0.23700334813366544
[5/6, 846/1875] Training Loss: 0.23209199753213436
[5/6, 940/1875] Training Loss: 0.2248611274234792
[5/6, 1034/1875] Training Loss: 0.21656894097302823
[5/6, 1128/1875] Training Loss: 0.21310454163145512
[5/6, 1222/1875] Training Loss: 0.21025834549614725
[5/6, 1316/1875] Training Loss: 0.21401284254611808
[5/6, 1410/1875] Training Loss: 0.21283842956132076
[5/6, 1504/1875] Training Loss: 0.20478745645031016
[5/6, 1598/1875] Training Loss: 0.20621927447141486
[5/6, 1692/1875] Training Loss: 0.2086234300377521
[5/6, 1786/1875] Training Loss: 0.19844471901021105
Testing!
[5/6, 1/313]
[5/6, 17/313]
[5/6, 33/313]
[5/6, 49/313]
[5/6, 65/313]
[5/6, 81/313]
[5/6, 97/313]
[5/6, 113/313]
[5/6, 129/313]
[5/6, 145/313]
[5/6, 161/313]
[5/6, 177/313]
[5/6, 193/313]
[5/6, 209/313]
[5/6, 225/313]
[5/6, 241/313]
[5/6, 257/313]
[5/6, 273/313]
[5/6, 289/313]
[5/6, 305/313]
Testing Loss: 0.2627633726876229
Training!
[6/6, 94/1875] Training Loss: 0.20021189622422483
[6/6, 188/1875] Training Loss: 0.20208577859274884
[6/6, 282/1875] Training Loss: 0.20660328421186894
[6/6, 376/1875] Training Loss: 0.1956702342375796
[6/6, 470/1875] Training Loss: 0.1992385358886516
[6/6, 564/1875] Training Loss: 0.20373746182056182
[6/6, 658/1875] Training Loss: 0.19408676234331537
[6/6, 752/1875] Training Loss: 0.19562055519286622
[6/6, 846/1875] Training Loss: 0.19536472983816836
[6/6, 940/1875] Training Loss: 0.1926132633965066
[6/6, 1034/1875] Training Loss: 0.19834858020569415
[6/6, 1128/1875] Training Loss: 0.1941127707349493
[6/6, 1222/1875] Training Loss: 0.19169312414336712
[6/6, 1316/1875] Training Loss: 0.19878602598575837
[6/6, 1410/1875] Training Loss: 0.1943238762781975
[6/6, 1504/1875] Training Loss: 0.18736936358061243
[6/6, 1598/1875] Training Loss: 0.18635496528858833
[6/6, 1692/1875] Training Loss: 0.19783545380577128
[6/6, 1786/1875] Training Loss: 0.19268502849847713
Testing!
[6/6, 1/313]
[6/6, 17/313]
[6/6, 33/313]
[6/6, 49/313]
[6/6, 65/313]
[6/6, 81/313]
[6/6, 97/313]
[6/6, 113/313]
[6/6, 129/313]
[6/6, 145/313]
[6/6, 161/313]
[6/6, 177/313]
[6/6, 193/313]
[6/6, 209/313]
[6/6, 225/313]
[6/6, 241/313]
[6/6, 257/313]
[6/6, 273/313]
[6/6, 289/313]
[6/6, 305/313]
Testing Loss: 0.24835949072924754
Training and Testing Finished
Assembling test data for t-sne projection
Batch: 1/313
Batch: 2/313
Batch: 3/313
Batch: 4/313
Batch: 5/313
Batch: 6/313
Batch: 7/313
Batch: 8/313
Batch: 9/313
Batch: 10/313
Batch: 11/313
Batch: 12/313
Batch: 13/313
Batch: 14/313
Batch: 15/313
Batch: 16/313
Batch: 17/313
Batch: 18/313
Batch: 19/313
Batch: 20/313
Batch: 21/313
Batch: 22/313
Batch: 23/313
Batch: 24/313
Batch: 25/313
Batch: 26/313
Batch: 27/313
Batch: 28/313
Batch: 29/313
Batch: 30/313
Batch: 31/313
Batch: 32/313
Batch: 33/313
Batch: 34/313
Batch: 35/313
Batch: 36/313
Batch: 37/313
Batch: 38/313
Batch: 39/313
Batch: 40/313
Batch: 41/313
Batch: 42/313
Batch: 43/313
Batch: 44/313
Batch: 45/313
Batch: 46/313
Batch: 47/313
Batch: 48/313
Batch: 49/313
Batch: 50/313
Batch: 51/313
Batch: 52/313
Batch: 53/313
Batch: 54/313
Batch: 55/313
Batch: 56/313
Batch: 57/313
Batch: 58/313
Batch: 59/313
Batch: 60/313
Batch: 61/313
Batch: 62/313
Batch: 63/313
Batch: 64/313
Batch: 65/313
Batch: 66/313
Batch: 67/313
Batch: 68/313
Batch: 69/313
Batch: 70/313
Batch: 71/313
Batch: 72/313
Batch: 73/313
Batch: 74/313
Batch: 75/313
Batch: 76/313
Batch: 77/313
Batch: 78/313
Batch: 79/313
Batch: 80/313
Batch: 81/313
Batch: 82/313
Batch: 83/313
Batch: 84/313
Batch: 85/313
Batch: 86/313
Batch: 87/313
Batch: 88/313
Batch: 89/313
Batch: 90/313
Batch: 91/313
Batch: 92/313
Batch: 93/313
Batch: 94/313
Batch: 95/313
Batch: 96/313
Batch: 97/313
Batch: 98/313
Batch: 99/313
Batch: 100/313
Batch: 101/313
Batch: 102/313
Batch: 103/313
Batch: 104/313
Batch: 105/313
Batch: 106/313
Batch: 107/313
Batch: 108/313
Batch: 109/313
Batch: 110/313
Batch: 111/313
Batch: 112/313
Batch: 113/313
Batch: 114/313
Batch: 115/313
Batch: 116/313
Batch: 117/313
Batch: 118/313
Batch: 119/313
Batch: 120/313
Batch: 121/313
Batch: 122/313
Batch: 123/313
Batch: 124/313
Batch: 125/313
Batch: 126/313
Batch: 127/313
Batch: 128/313
Batch: 129/313
Batch: 130/313
Batch: 131/313
Batch: 132/313
Batch: 133/313
Batch: 134/313
Batch: 135/313
Batch: 136/313
Batch: 137/313
Batch: 138/313
Batch: 139/313
Batch: 140/313
Batch: 141/313
Batch: 142/313
Batch: 143/313
Batch: 144/313
Batch: 145/313
Batch: 146/313
Batch: 147/313
Batch: 148/313
Batch: 149/313
Batch: 150/313
Batch: 151/313
Batch: 152/313
Batch: 153/313
Batch: 154/313
Batch: 155/313
Batch: 156/313
Batch: 157/313
Batch: 158/313
Batch: 159/313
Batch: 160/313
Batch: 161/313
Batch: 162/313
Batch: 163/313
Batch: 164/313
Batch: 165/313
Batch: 166/313
Batch: 167/313
Batch: 168/313
Batch: 169/313
Batch: 170/313
Batch: 171/313
Batch: 172/313
Batch: 173/313
Batch: 174/313
Batch: 175/313
Batch: 176/313
Batch: 177/313
Batch: 178/313
Batch: 179/313
Batch: 180/313
Batch: 181/313
Batch: 182/313
Batch: 183/313
Batch: 184/313
Batch: 185/313
Batch: 186/313
Batch: 187/313
Batch: 188/313
Batch: 189/313
Batch: 190/313
Batch: 191/313
Batch: 192/313
Batch: 193/313
Batch: 194/313
Batch: 195/313
Batch: 196/313
Batch: 197/313
Batch: 198/313
Batch: 199/313
Batch: 200/313
Batch: 201/313
Batch: 202/313
Batch: 203/313
Batch: 204/313
Batch: 205/313
Batch: 206/313
Batch: 207/313
Batch: 208/313
Batch: 209/313
Batch: 210/313
Batch: 211/313
Batch: 212/313
Batch: 213/313
Batch: 214/313
Batch: 215/313
Batch: 216/313
Batch: 217/313
Batch: 218/313
Batch: 219/313
Batch: 220/313
Batch: 221/313
Batch: 222/313
Batch: 223/313
Batch: 224/313
Batch: 225/313
Batch: 226/313
Batch: 227/313
Batch: 228/313
Batch: 229/313
Batch: 230/313
Batch: 231/313
Batch: 232/313
Batch: 233/313
Batch: 234/313
Batch: 235/313
Batch: 236/313
Batch: 237/313
Batch: 238/313
Batch: 239/313
Batch: 240/313
Batch: 241/313
Batch: 242/313
Batch: 243/313
Batch: 244/313
Batch: 245/313
Batch: 246/313
Batch: 247/313
Batch: 248/313
Batch: 249/313
Batch: 250/313
Batch: 251/313
Batch: 252/313
Batch: 253/313
Batch: 254/313
Batch: 255/313
Batch: 256/313
Batch: 257/313
Batch: 258/313
Batch: 259/313
Batch: 260/313
Batch: 261/313
Batch: 262/313
Batch: 263/313
Batch: 264/313
Batch: 265/313
Batch: 266/313
Batch: 267/313
Batch: 268/313
Batch: 269/313
Batch: 270/313
Batch: 271/313
Batch: 272/313
Batch: 273/313
Batch: 274/313
Batch: 275/313
Batch: 276/313
Batch: 277/313
Batch: 278/313
Batch: 279/313
Batch: 280/313
Batch: 281/313
Batch: 282/313
Batch: 283/313
Batch: 284/313
Batch: 285/313
Batch: 286/313
Batch: 287/313
Batch: 288/313
Batch: 289/313
Batch: 290/313
Batch: 291/313
Batch: 292/313
Batch: 293/313
Batch: 294/313
Batch: 295/313
Batch: 296/313
Batch: 297/313
Batch: 298/313
Batch: 299/313
Batch: 300/313
Batch: 301/313
Batch: 302/313
Batch: 303/313
Batch: 304/313
Batch: 305/313
Batch: 306/313
Batch: 307/313
Batch: 308/313
Batch: 309/313
Batch: 310/313
Batch: 311/313
Batch: 312/313
Batch: 313/313
Features: (10000, 100)
All Labels: (10000,)
All Original Images: (10000, 28, 28)
All Reconstructed Images: (10000, 28, 28)
Applying t-SNE
Plotting Results Grid
6 added
2 added
8 added
7 added
0 added
4 added
3 added
1 added
5 added
9 added
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation