Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-12 19:57:28.079703
Training - 2024-06-12 19:57:28.080197
[1/6, 10/94] Training Loss: 180.17 - Iteration Time: 0:00:01.255747
[1/6, 20/94] Training Loss: 170.01 - Iteration Time: 0:00:01.224994
[1/6, 30/94] Training Loss: 168.32 - Iteration Time: 0:00:01.282471
[1/6, 40/94] Training Loss: 166.87 - Iteration Time: 0:00:01.247288
[1/6, 50/94] Training Loss: 161.54 - Iteration Time: 0:00:01.203596
[1/6, 60/94] Training Loss: 155.18 - Iteration Time: 0:00:01.185214
[1/6, 70/94] Training Loss: 148.08 - Iteration Time: 0:00:01.246279
[1/6, 80/94] Training Loss: 146.69 - Iteration Time: 0:00:01.514693
[1/6, 90/94] Training Loss: 141.46 - Iteration Time: 0:00:01.227402
Testing - 2024-06-12 19:59:29.995894
[1/6, 2/16]
[1/6, 4/16]
[1/6, 6/16]
[1/6, 8/16]
[1/6, 10/16]
[1/6, 12/16]
[1/6, 14/16]
[1/6, 16/16]
Testing Loss: 133.55 - Epoch Time: 0:02:13.607141
Training - 2024-06-12 19:59:41.687833
[2/6, 10/94] Training Loss: 138.90 - Iteration Time: 0:00:01.191783
[2/6, 20/94] Training Loss: 129.13 - Iteration Time: 0:00:01.204614
[2/6, 30/94] Training Loss: 126.15 - Iteration Time: 0:00:01.253219
[2/6, 40/94] Training Loss: 121.22 - Iteration Time: 0:00:01.216046
[2/6, 50/94] Training Loss: 116.04 - Iteration Time: 0:00:01.203601
[2/6, 60/94] Training Loss: 115.57 - Iteration Time: 0:00:01.242316
[2/6, 70/94] Training Loss: 110.48 - Iteration Time: 0:00:01.198640
[2/6, 80/94] Training Loss: 105.45 - Iteration Time: 0:00:01.274564
[2/6, 90/94] Training Loss: 105.10 - Iteration Time: 0:00:01.200111
Testing - 2024-06-12 20:01:39.282515
[2/6, 2/16]
[2/6, 4/16]
[2/6, 6/16]
[2/6, 8/16]
[2/6, 10/16]
[2/6, 12/16]
[2/6, 14/16]
[2/6, 16/16]
Testing Loss: 89.13 - Epoch Time: 0:02:09.172777
Training - 2024-06-12 20:01:50.860610
[3/6, 10/94] Training Loss: 99.65 - Iteration Time: 0:00:01.264636
[3/6, 20/94] Training Loss: 100.14 - Iteration Time: 0:00:01.206577
[3/6, 30/94] Training Loss: 94.17 - Iteration Time: 0:00:01.263633
[3/6, 40/94] Training Loss: 93.14 - Iteration Time: 0:00:01.192233
[3/6, 50/94] Training Loss: 92.02 - Iteration Time: 0:00:01.262629
[3/6, 60/94] Training Loss: 89.31 - Iteration Time: 0:00:01.214541
[3/6, 70/94] Training Loss: 85.94 - Iteration Time: 0:00:01.198713
[3/6, 80/94] Training Loss: 85.82 - Iteration Time: 0:00:01.257206
[3/6, 90/94] Training Loss: 85.05 - Iteration Time: 0:00:01.266081
Testing - 2024-06-12 20:03:49.964539
[3/6, 2/16]
[3/6, 4/16]
[3/6, 6/16]
[3/6, 8/16]
[3/6, 10/16]
[3/6, 12/16]
[3/6, 14/16]
[3/6, 16/16]
Testing Loss: 84.43 - Epoch Time: 0:02:10.603548
Training - 2024-06-12 20:04:01.464653
[4/6, 10/94] Training Loss: 80.89 - Iteration Time: 0:00:01.255775
[4/6, 20/94] Training Loss: 82.01 - Iteration Time: 0:00:01.218498
[4/6, 30/94] Training Loss: 79.68 - Iteration Time: 0:00:01.206616
[4/6, 40/94] Training Loss: 77.45 - Iteration Time: 0:00:01.337757
[4/6, 50/94] Training Loss: 76.92 - Iteration Time: 0:00:01.251760
[4/6, 60/94] Training Loss: 74.57 - Iteration Time: 0:00:01.193730
[4/6, 70/94] Training Loss: 76.03 - Iteration Time: 0:00:01.207609
[4/6, 80/94] Training Loss: 74.17 - Iteration Time: 0:00:01.203092
[4/6, 90/94] Training Loss: 71.63 - Iteration Time: 0:00:01.198165
Testing - 2024-06-12 20:05:59.237818
[4/6, 2/16]
[4/6, 4/16]
[4/6, 6/16]
[4/6, 8/16]
[4/6, 10/16]
[4/6, 12/16]
[4/6, 14/16]
[4/6, 16/16]
Testing Loss: 72.58 - Epoch Time: 0:02:09.283318
Training - 2024-06-12 20:06:10.747971
[5/6, 10/94] Training Loss: 70.37 - Iteration Time: 0:00:01.216549
[5/6, 20/94] Training Loss: 70.56 - Iteration Time: 0:00:01.238344
[5/6, 30/94] Training Loss: 66.90 - Iteration Time: 0:00:01.191254
[5/6, 40/94] Training Loss: 66.13 - Iteration Time: 0:00:01.229922
[5/6, 50/94] Training Loss: 66.28 - Iteration Time: 0:00:01.250271
[5/6, 60/94] Training Loss: 65.10 - Iteration Time: 0:00:01.229921
[5/6, 70/94] Training Loss: 64.17 - Iteration Time: 0:00:01.289626
[5/6, 80/94] Training Loss: 61.47 - Iteration Time: 0:00:01.253722
[5/6, 90/94] Training Loss: 61.43 - Iteration Time: 0:00:01.205607
Testing - 2024-06-12 20:08:08.494267
[5/6, 2/16]
[5/6, 4/16]
[5/6, 6/16]
[5/6, 8/16]
[5/6, 10/16]
[5/6, 12/16]
[5/6, 14/16]
[5/6, 16/16]
Testing Loss: 60.83 - Epoch Time: 0:02:09.481924
Training - 2024-06-12 20:08:20.230391
[6/6, 10/94] Training Loss: 60.30 - Iteration Time: 0:00:01.234930
[6/6, 20/94] Training Loss: 58.26 - Iteration Time: 0:00:01.240890
[6/6, 30/94] Training Loss: 57.63 - Iteration Time: 0:00:01.271573
[6/6, 40/94] Training Loss: 56.34 - Iteration Time: 0:00:01.224431
[6/6, 50/94] Training Loss: 55.52 - Iteration Time: 0:00:01.674000
[6/6, 60/94] Training Loss: 54.73 - Iteration Time: 0:00:01.263126
[6/6, 70/94] Training Loss: 54.28 - Iteration Time: 0:00:01.242299
[6/6, 80/94] Training Loss: 53.51 - Iteration Time: 0:00:01.217982
[6/6, 90/94] Training Loss: 53.62 - Iteration Time: 0:00:01.200160
Testing - 2024-06-12 20:10:21.622172
[6/6, 2/16]
[6/6, 4/16]
[6/6, 6/16]
[6/6, 8/16]
[6/6, 10/16]
[6/6, 12/16]
[6/6, 14/16]
[6/6, 16/16]
Testing Loss: 52.51 - Epoch Time: 0:02:12.993299
Training and Testing Finished - Time: 0:13:05.143987
Assembling test data for t-sne projection
-- 10/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 5
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - {labels[input_index]}