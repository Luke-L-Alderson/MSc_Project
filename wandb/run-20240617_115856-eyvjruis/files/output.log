Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-17 11:58:58.539647
Scaler Value: 0.013513513513513514
Training - 2024-06-17 11:58:58.540641
[1/9, 10/94] Training Loss: 17.9440 - Iteration Time: 0:00:01.576213
[1/9, 20/94] Training Loss: 13.2476 - Iteration Time: 0:00:01.478992
[1/9, 30/94] Training Loss: 7.9961 - Iteration Time: 0:00:01.374244
[1/9, 40/94] Training Loss: 6.3151 - Iteration Time: 0:00:01.397670
[1/9, 50/94] Training Loss: 5.7557 - Iteration Time: 0:00:01.388216
[1/9, 60/94] Training Loss: 5.5000 - Iteration Time: 0:00:01.378759
[1/9, 70/94] Training Loss: 5.3542 - Iteration Time: 0:00:01.439744
[1/9, 80/94] Training Loss: 5.3425 - Iteration Time: 0:00:01.391631
[1/9, 90/94] Training Loss: 5.2708 - Iteration Time: 0:00:01.409989
Testing - 2024-06-17 12:01:14.127975
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 5.0478 - Epoch Time: 0:02:28.614274
Training - 2024-06-17 12:01:27.154915
[2/9, 10/94] Training Loss: 5.2970 - Iteration Time: 0:00:01.447641
[2/9, 20/94] Training Loss: 5.1734 - Iteration Time: 0:00:01.381751
[2/9, 30/94] Training Loss: 5.1843 - Iteration Time: 0:00:01.466029
[2/9, 40/94] Training Loss: 5.1824 - Iteration Time: 0:00:01.398142
[2/9, 50/94] Training Loss: 5.1357 - Iteration Time: 0:00:01.381200
[2/9, 60/94] Training Loss: 5.1905 - Iteration Time: 0:00:01.379254
[2/9, 70/94] Training Loss: 5.1356 - Iteration Time: 0:00:01.371306
[2/9, 80/94] Training Loss: 5.0636 - Iteration Time: 0:00:01.427379
[2/9, 90/94] Training Loss: 5.1200 - Iteration Time: 0:00:01.560738
Testing - 2024-06-17 12:03:42.736233
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 4.9820 - Epoch Time: 0:02:29.447980
Training - 2024-06-17 12:03:56.602895
[3/9, 10/94] Training Loss: 5.0665 - Iteration Time: 0:00:01.834660
[3/9, 20/94] Training Loss: 5.1354 - Iteration Time: 0:00:01.532093
[3/9, 30/94] Training Loss: 5.0576 - Iteration Time: 0:00:01.518622
[3/9, 40/94] Training Loss: 5.0712 - Iteration Time: 0:00:01.767673
[3/9, 50/94] Training Loss: 5.1129 - Iteration Time: 0:00:01.649102
[3/9, 60/94] Training Loss: 5.0695 - Iteration Time: 0:00:01.605952
[3/9, 70/94] Training Loss: 5.0215 - Iteration Time: 0:00:01.602565
[3/9, 80/94] Training Loss: 5.0732 - Iteration Time: 0:00:01.423883
[3/9, 90/94] Training Loss: 5.0596 - Iteration Time: 0:00:01.403085
Testing - 2024-06-17 12:06:28.550139
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 4.8972 - Epoch Time: 0:02:46.676478
Training - 2024-06-17 12:06:43.279869
[4/9, 10/94] Training Loss: 5.0038 - Iteration Time: 0:00:02.839847
[4/9, 20/94] Training Loss: 5.0725 - Iteration Time: 0:00:01.599002
[4/9, 30/94] Training Loss: 5.0340 - Iteration Time: 0:00:01.547425
[4/9, 40/94] Training Loss: 5.0029 - Iteration Time: 0:00:01.427368
[4/9, 50/94] Training Loss: 5.0357 - Iteration Time: 0:00:01.443227
[4/9, 60/94] Training Loss: 5.0104 - Iteration Time: 0:00:01.436774
[4/9, 70/94] Training Loss: 5.0789 - Iteration Time: 0:00:01.582670
[4/9, 80/94] Training Loss: 5.0661 - Iteration Time: 0:00:01.538015
[4/9, 90/94] Training Loss: 5.0087 - Iteration Time: 0:00:01.371301
Testing - 2024-06-17 12:09:17.200333
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 4.9600 - Epoch Time: 0:02:47.314743
Training - 2024-06-17 12:09:30.594612
[5/9, 10/94] Training Loss: 5.0186 - Iteration Time: 0:00:01.474497
[5/9, 20/94] Training Loss: 5.0588 - Iteration Time: 0:00:01.491346
[5/9, 30/94] Training Loss: 4.9945 - Iteration Time: 0:00:01.548853
[5/9, 40/94] Training Loss: 5.0074 - Iteration Time: 0:00:01.496800
[5/9, 50/94] Training Loss: 5.0494 - Iteration Time: 0:00:01.413003
[5/9, 60/94] Training Loss: 5.0328 - Iteration Time: 0:00:01.441252
[5/9, 70/94] Training Loss: 5.0256 - Iteration Time: 0:00:01.710129
[5/9, 80/94] Training Loss: 4.9517 - Iteration Time: 0:00:01.467517
[5/9, 90/94] Training Loss: 4.9901 - Iteration Time: 0:00:01.357398
Testing - 2024-06-17 12:11:49.933037
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 4.8577 - Epoch Time: 0:02:33.176558
Training - 2024-06-17 12:12:03.771666
[6/9, 10/94] Training Loss: 5.0173 - Iteration Time: 0:00:01.428304
[6/9, 20/94] Training Loss: 4.9546 - Iteration Time: 0:00:01.465651
[6/9, 30/94] Training Loss: 4.9724 - Iteration Time: 0:00:01.428864
[6/9, 40/94] Training Loss: 4.9853 - Iteration Time: 0:00:01.570707
[6/9, 50/94] Training Loss: 4.9747 - Iteration Time: 0:00:01.378715
[6/9, 60/94] Training Loss: 4.9702 - Iteration Time: 0:00:01.504220
[6/9, 70/94] Training Loss: 5.0090 - Iteration Time: 0:00:01.478954
[6/9, 80/94] Training Loss: 5.0064 - Iteration Time: 0:00:01.706738
[6/9, 90/94] Training Loss: 5.0221 - Iteration Time: 0:00:01.420940
Testing - 2024-06-17 12:14:23.182020
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 4.7084 - Epoch Time: 0:02:33.124148
Training - 2024-06-17 12:14:36.896309
[7/9, 10/94] Training Loss: 4.9959 - Iteration Time: 0:00:01.443201
[7/9, 20/94] Training Loss: 4.9917 - Iteration Time: 0:00:01.523631
[7/9, 30/94] Training Loss: 5.0244 - Iteration Time: 0:00:01.370340
[7/9, 40/94] Training Loss: 4.9986 - Iteration Time: 0:00:01.576736
[7/9, 50/94] Training Loss: 4.9737 - Iteration Time: 0:00:01.503744
[7/9, 60/94] Training Loss: 4.8935 - Iteration Time: 0:00:01.384735
[7/9, 70/94] Training Loss: 4.9635 - Iteration Time: 0:00:01.457646
[7/9, 80/94] Training Loss: 4.9544 - Iteration Time: 0:00:01.380276
[7/9, 90/94] Training Loss: 4.9750 - Iteration Time: 0:00:01.411403
Testing - 2024-06-17 12:16:56.750713
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 4.7227 - Epoch Time: 0:02:33.440031
Training - 2024-06-17 12:17:10.336836
[8/9, 10/94] Training Loss: 5.0158 - Iteration Time: 0:00:01.386637
[8/9, 20/94] Training Loss: 4.9334 - Iteration Time: 0:00:01.549871
[8/9, 30/94] Training Loss: 4.9628 - Iteration Time: 0:00:01.443714
[8/9, 40/94] Training Loss: 4.9503 - Iteration Time: 0:00:01.473024
[8/9, 50/94] Training Loss: 4.9345 - Iteration Time: 0:00:01.464029
[8/9, 60/94] Training Loss: 4.9673 - Iteration Time: 0:00:01.431760
[8/9, 70/94] Training Loss: 4.9658 - Iteration Time: 0:00:01.468070
[8/9, 80/94] Training Loss: 5.0014 - Iteration Time: 0:00:01.541942
[8/9, 90/94] Training Loss: 4.9625 - Iteration Time: 0:00:01.504233
Testing - 2024-06-17 12:19:29.938393
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 4.7539 - Epoch Time: 0:02:33.026207
Training - 2024-06-17 12:19:43.363043
[9/9, 10/94] Training Loss: 4.9380 - Iteration Time: 0:00:01.416914
[9/9, 20/94] Training Loss: 4.9738 - Iteration Time: 0:00:01.359919
[9/9, 30/94] Training Loss: 4.9806 - Iteration Time: 0:00:01.421844
[9/9, 40/94] Training Loss: 4.9222 - Iteration Time: 0:00:01.347904
[9/9, 50/94] Training Loss: 4.9113 - Iteration Time: 0:00:01.511672
[9/9, 60/94] Training Loss: 4.9586 - Iteration Time: 0:00:01.455091
[9/9, 70/94] Training Loss: 4.9390 - Iteration Time: 0:00:01.409469
[9/9, 80/94] Training Loss: 4.9259 - Iteration Time: 0:00:01.491828
[9/9, 90/94] Training Loss: 5.0139 - Iteration Time: 0:00:01.403511
Testing - 2024-06-17 12:22:00.151542
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 4.7158 - Epoch Time: 0:02:30.824483
Training and Testing Finished - Time: 0:23:15.647879
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels      0      1    2    3      4  ...     94   95   96     97     98     99
0       2  0.995  0.995  0.0  0.0  0.760  ...  0.995  0.0  0.0  0.995  0.995  0.990
1       4  0.995  0.990  0.0  0.0  0.740  ...  0.995  0.0  0.0  0.990  0.995  0.995
2       7  0.985  0.995  0.0  0.0  0.745  ...  0.995  0.0  0.0  0.995  0.995  0.995
3       3  0.995  0.995  0.0  0.0  0.685  ...  0.995  0.0  0.0  0.995  0.995  0.995
4       7  0.995  0.995  0.0  0.0  0.675  ...  0.990  0.0  0.0  0.995  0.995  0.995
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying t-SNE
WARNING    C:\Users\lukea\anaconda3\envs\diss\Lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(
 [py.warnings]
  File "C:\Users\lukea\anaconda3\envs\diss\Lib\site-packages\joblib\externals\loky\backend\context.py", line 282, in _count_physical_cores
    raise ValueError(f"found {cpu_count_physical} physical cores < 1")
Applying UMAP
Applying PCA