Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-17 14:53:04.505004
Scaler Value: 1000
Training - 2024-06-17 14:53:04.505996
[1/9, 10/94] Training Loss: 0.5514 - Iteration Time: 0:00:01.489907
[1/9, 20/94] Training Loss: 0.4932 - Iteration Time: 0:00:01.426994
[1/9, 30/94] Training Loss: 0.4974 - Iteration Time: 0:00:01.465903
[1/9, 40/94] Training Loss: 0.4977 - Iteration Time: 0:00:01.449144
[1/9, 50/94] Training Loss: 0.4982 - Iteration Time: 0:00:01.453682
[1/9, 60/94] Training Loss: 0.5001 - Iteration Time: 0:00:01.476810
[1/9, 70/94] Training Loss: 0.5030 - Iteration Time: 0:00:01.496657
[1/9, 80/94] Training Loss: 0.5059 - Iteration Time: 0:00:01.779563
[1/9, 90/94] Training Loss: 0.5062 - Iteration Time: 0:00:01.433107
Testing - 2024-06-17 14:55:24.412209
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.5083 - Epoch Time: 0:02:33.706669
Training - 2024-06-17 14:55:38.212665
[2/9, 10/94] Training Loss: 0.5079 - Iteration Time: 0:00:01.418962
[2/9, 20/94] Training Loss: 0.5069 - Iteration Time: 0:00:01.453434
[2/9, 30/94] Training Loss: 0.5092 - Iteration Time: 0:00:01.423142
[2/9, 40/94] Training Loss: 0.5108 - Iteration Time: 0:00:01.508193
[2/9, 50/94] Training Loss: 0.5099 - Iteration Time: 0:00:01.428106
[2/9, 60/94] Training Loss: 0.5121 - Iteration Time: 0:00:01.517879
[2/9, 70/94] Training Loss: 0.5147 - Iteration Time: 0:00:01.418973
[2/9, 80/94] Training Loss: 0.5161 - Iteration Time: 0:00:01.443041
[2/9, 90/94] Training Loss: 0.5157 - Iteration Time: 0:00:01.440842
Testing - 2024-06-17 14:57:56.957509
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.5157 - Epoch Time: 0:02:32.748845
Training - 2024-06-17 14:58:10.962006
[3/9, 10/94] Training Loss: 0.5167 - Iteration Time: 0:00:01.502951
[3/9, 20/94] Training Loss: 0.5156 - Iteration Time: 0:00:02.005908
[3/9, 30/94] Training Loss: 0.5164 - Iteration Time: 0:00:01.431767
[3/9, 40/94] Training Loss: 0.5177 - Iteration Time: 0:00:01.571097
[3/9, 50/94] Training Loss: 0.5191 - Iteration Time: 0:00:01.436609
[3/9, 60/94] Training Loss: 0.5212 - Iteration Time: 0:00:01.475969
[3/9, 70/94] Training Loss: 0.5194 - Iteration Time: 0:00:01.449838
[3/9, 80/94] Training Loss: 0.5224 - Iteration Time: 0:00:01.609121
[3/9, 90/94] Training Loss: 0.5239 - Iteration Time: 0:00:01.614189
Testing - 2024-06-17 15:00:36.405334
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.5199 - Epoch Time: 0:02:40.147187
Training - 2024-06-17 15:00:51.109701
[4/9, 10/94] Training Loss: 0.5226 - Iteration Time: 0:00:01.481224
[4/9, 20/94] Training Loss: 0.5252 - Iteration Time: 0:00:01.484275
[4/9, 30/94] Training Loss: 0.5256 - Iteration Time: 0:00:01.497876
[4/9, 40/94] Training Loss: 0.5254 - Iteration Time: 0:00:01.450539
[4/9, 50/94] Training Loss: 0.5270 - Iteration Time: 0:00:01.522025
[4/9, 60/94] Training Loss: 0.5243 - Iteration Time: 0:00:01.459390
[4/9, 70/94] Training Loss: 0.5265 - Iteration Time: 0:00:02.536020
[4/9, 80/94] Training Loss: 0.5263 - Iteration Time: 0:00:01.458579
[4/9, 90/94] Training Loss: 0.5268 - Iteration Time: 0:00:01.455189
Testing - 2024-06-17 15:03:18.603057
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.5309 - Epoch Time: 0:02:41.208239
Training - 2024-06-17 15:03:32.317940
[5/9, 10/94] Training Loss: 0.5289 - Iteration Time: 0:00:01.572495
[5/9, 20/94] Training Loss: 0.5307 - Iteration Time: 0:00:01.778992
[5/9, 30/94] Training Loss: 0.5301 - Iteration Time: 0:00:01.441516
[5/9, 40/94] Training Loss: 0.5311 - Iteration Time: 0:00:01.558030
[5/9, 50/94] Training Loss: 0.5297 - Iteration Time: 0:00:01.449687
[5/9, 60/94] Training Loss: 0.5324 - Iteration Time: 0:00:01.491590
[5/9, 70/94] Training Loss: 0.5315 - Iteration Time: 0:00:01.608220
[5/9, 80/94] Training Loss: 0.5323 - Iteration Time: 0:00:01.435403
[5/9, 90/94] Training Loss: 0.5345 - Iteration Time: 0:00:01.433518
Testing - 2024-06-17 15:05:56.587713
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.5295 - Epoch Time: 0:02:38.106991
Training - 2024-06-17 15:06:10.425427
[6/9, 10/94] Training Loss: 0.5324 - Iteration Time: 0:00:01.453548
[6/9, 20/94] Training Loss: 0.5344 - Iteration Time: 0:00:01.458435
[6/9, 30/94] Training Loss: 0.5360 - Iteration Time: 0:00:01.456213
[6/9, 40/94] Training Loss: 0.5353 - Iteration Time: 0:00:01.446815
[6/9, 50/94] Training Loss: 0.5365 - Iteration Time: 0:00:01.477081
[6/9, 60/94] Training Loss: 0.5355 - Iteration Time: 0:00:01.499418
[6/9, 70/94] Training Loss: 0.5369 - Iteration Time: 0:00:01.479662
[6/9, 80/94] Training Loss: 0.5369 - Iteration Time: 0:00:01.441376
[6/9, 90/94] Training Loss: 0.5376 - Iteration Time: 0:00:01.566607
Testing - 2024-06-17 15:08:31.809038
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.5382 - Epoch Time: 0:02:35.323075
Training - 2024-06-17 15:08:45.749013
[7/9, 10/94] Training Loss: 0.5376 - Iteration Time: 0:00:01.532873
[7/9, 20/94] Training Loss: 0.5409 - Iteration Time: 0:00:01.498869
[7/9, 30/94] Training Loss: 0.5379 - Iteration Time: 0:00:01.622453
[7/9, 40/94] Training Loss: 0.5409 - Iteration Time: 0:00:01.426396
[7/9, 50/94] Training Loss: 0.5407 - Iteration Time: 0:00:01.950671
[7/9, 60/94] Training Loss: 0.5402 - Iteration Time: 0:00:01.556026
[7/9, 70/94] Training Loss: 0.5435 - Iteration Time: 0:00:01.624964
[7/9, 80/94] Training Loss: 0.5439 - Iteration Time: 0:00:01.457947
[7/9, 90/94] Training Loss: 0.5411 - Iteration Time: 0:00:01.436195
Testing - 2024-06-17 15:11:12.079765
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.5399 - Epoch Time: 0:02:40.219841
Training - 2024-06-17 15:11:25.968854
[8/9, 10/94] Training Loss: 0.5426 - Iteration Time: 0:00:01.535531
[8/9, 20/94] Training Loss: 0.5442 - Iteration Time: 0:00:01.471479
[8/9, 30/94] Training Loss: 0.5458 - Iteration Time: 0:00:01.449307
[8/9, 40/94] Training Loss: 0.5427 - Iteration Time: 0:00:01.423738
[8/9, 50/94] Training Loss: 0.5448 - Iteration Time: 0:00:01.432815
[8/9, 60/94] Training Loss: 0.5430 - Iteration Time: 0:00:01.407684
[8/9, 70/94] Training Loss: 0.5445 - Iteration Time: 0:00:01.457655
[8/9, 80/94] Training Loss: 0.5432 - Iteration Time: 0:00:01.440739
[8/9, 90/94] Training Loss: 0.5456 - Iteration Time: 0:00:01.444190
Testing - 2024-06-17 15:13:45.772589
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.5403 - Epoch Time: 0:02:33.836980
Training - 2024-06-17 15:13:59.806329
[9/9, 10/94] Training Loss: 0.5439 - Iteration Time: 0:00:01.571357
[9/9, 20/94] Training Loss: 0.5482 - Iteration Time: 0:00:01.418770
[9/9, 30/94] Training Loss: 0.5467 - Iteration Time: 0:00:01.453701
[9/9, 40/94] Training Loss: 0.5497 - Iteration Time: 0:00:01.436068
[9/9, 50/94] Training Loss: 0.5481 - Iteration Time: 0:00:01.551016
[9/9, 60/94] Training Loss: 0.5470 - Iteration Time: 0:00:01.433401
[9/9, 70/94] Training Loss: 0.5468 - Iteration Time: 0:00:01.411019
[9/9, 80/94] Training Loss: 0.5498 - Iteration Time: 0:00:01.505095
[9/9, 90/94] Training Loss: 0.5485 - Iteration Time: 0:00:01.542022
Testing - 2024-06-17 15:16:20.492990
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.5547 - Epoch Time: 0:02:34.471274
Training and Testing Finished - Time: 0:23:29.772599
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels     0    1    2     3     4    5  ...   93   94   95   96   97    98   99
0       2  16.0  0.0  0.0  25.0  26.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  15.0  0.0
1       4  16.0  0.0  0.0  27.0  26.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  15.0  0.0
2       7  16.0  0.0  0.0  24.0  26.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  15.0  0.0
3       3  16.0  0.0  0.0  25.0  25.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  15.0  0.0
4       7  15.0  0.0  0.0  25.0  26.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  16.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP
Applying PCA