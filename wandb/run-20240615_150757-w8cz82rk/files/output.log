Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-15 15:07:58.862517
Scaler Value: 0.013513513513513514
Training - 2024-06-15 15:07:58.863013
[1/9, 1/94] Training Loss: 0.0687 - Iteration Time: 0:00:02.000824
[1/9, 2/94] Training Loss: 0.0689 - Iteration Time: 0:00:01.463177
[1/9, 3/94] Training Loss: 0.0709 - Iteration Time: 0:00:01.584134
[1/9, 4/94] Training Loss: 0.0710 - Iteration Time: 0:00:01.545321
[1/9, 5/94] Training Loss: 0.0700 - Iteration Time: 0:00:01.440777
[1/9, 6/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.471079
[1/9, 7/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.485955
[1/9, 8/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.509217
[1/9, 9/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.475745
[1/9, 10/94] Training Loss: 0.0699 - Iteration Time: 0:00:01.496845
[1/9, 11/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.527180
[1/9, 12/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.443971
[1/9, 13/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.481555
[1/9, 14/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.462061
[1/9, 15/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.478954
[1/9, 16/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.456571
[1/9, 17/94] Training Loss: 0.0695 - Iteration Time: 0:00:01.514716
[1/9, 18/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.460114
[1/9, 19/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.474435
[1/9, 20/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.450147
[1/9, 21/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.524569
[1/9, 22/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.468031
[1/9, 23/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.526334
[1/9, 24/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.552875
[1/9, 25/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.445713
[1/9, 26/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.493153
[1/9, 27/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.452209
[1/9, 28/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.500743
[1/9, 29/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.525121
[1/9, 30/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.559811
[1/9, 31/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.456112
[1/9, 32/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.489367
[1/9, 33/94] Training Loss: 0.0680 - Iteration Time: 0:00:01.590678
[1/9, 34/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.527054
[1/9, 35/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.588073
[1/9, 36/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.638209
[1/9, 37/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.464574
[1/9, 38/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.488427
[1/9, 39/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.497346
[1/9, 40/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.457133
[1/9, 41/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.507785
[1/9, 42/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.519623
[1/9, 43/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.475604
[1/9, 44/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.443772
[1/9, 45/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.479946
[1/9, 46/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.652127
[1/9, 47/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.481952
[1/9, 48/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.478004
[1/9, 49/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.566305
[1/9, 50/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.625900
[1/9, 51/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.484387
[1/9, 52/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.522193
[1/9, 53/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.507305
[1/9, 54/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.518625
[1/9, 55/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.472980
[1/9, 56/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.518169
[1/9, 57/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.545985
[1/9, 58/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.493850
[1/9, 59/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.509181
[1/9, 60/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.445762
[1/9, 61/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.508671
[1/9, 62/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.501846
[1/9, 63/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.567301
[1/9, 64/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.545412
[1/9, 65/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.475986
[1/9, 66/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.454670
[1/9, 67/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.550505
[1/9, 68/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.467593
[1/9, 69/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.615397
[1/9, 70/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.438823
[1/9, 71/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.460622
[1/9, 72/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.463663
[1/9, 73/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.458625
[1/9, 74/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.507385
[1/9, 75/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.621511
[1/9, 76/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.574670
[1/9, 77/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.501243
[1/9, 78/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.496331
[1/9, 79/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.515127
[1/9, 80/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.479926
[1/9, 81/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.472097
[1/9, 82/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.445195
[1/9, 83/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.522631
[1/9, 84/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.524077
[1/9, 85/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.467073
[1/9, 86/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.582765
[1/9, 87/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.606481
[1/9, 88/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.486876
[1/9, 89/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.440240
[1/9, 90/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.440285
[1/9, 91/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.505266
[1/9, 92/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.563781
[1/9, 93/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.452724
[1/9, 94/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.611168
Testing - 2024-06-15 15:10:29.941562
[1/9, 1/16]
[1/9, 2/16]
[1/9, 3/16]
[1/9, 4/16]
[1/9, 5/16]
[1/9, 6/16]
[1/9, 7/16]
[1/9, 8/16]
[1/9, 9/16]
[1/9, 10/16]
[1/9, 11/16]
[1/9, 12/16]
[1/9, 13/16]
[1/9, 14/16]
[1/9, 15/16]
[1/9, 16/16]
Testing Loss: 0.0605 - Epoch Time: 0:02:54.115759
Training - 2024-06-15 15:10:52.978772
[2/9, 1/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.511131
[2/9, 2/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.510220
[2/9, 3/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.468964
[2/9, 4/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.450163
[2/9, 5/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.539455
[2/9, 6/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.632199
[2/9, 7/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.493327
[2/9, 8/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.481860
[2/9, 9/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.674403
[2/9, 10/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.457545
[2/9, 11/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.497729
[2/9, 12/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.423809
[2/9, 13/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.477421
[2/9, 14/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.488810
[2/9, 15/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.476450
[2/9, 16/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.474884
[2/9, 17/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.496260
[2/9, 18/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.492279
[2/9, 19/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.509693
[2/9, 20/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.511120
[2/9, 21/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.554408
[2/9, 22/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.448630
[2/9, 23/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.466051
[2/9, 24/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.497223
[2/9, 25/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.467979
[2/9, 26/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.453117
[2/9, 27/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.438202
[2/9, 28/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.461019
[2/9, 29/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.503235
[2/9, 30/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.482861
[2/9, 31/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.562740
[2/9, 32/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.595999
[2/9, 33/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.791687
[2/9, 34/94] Training Loss: 0.0621 - Iteration Time: 0:00:02.427141
[2/9, 35/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.961245
[2/9, 36/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.569682
[2/9, 37/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.931929
[2/9, 38/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.625840
[2/9, 39/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.515651
[2/9, 40/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.531480
[2/9, 41/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.492819
[2/9, 42/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.468947
[2/9, 43/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.514116
[2/9, 44/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.526049
[2/9, 45/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.564794
[2/9, 46/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.560259
[2/9, 47/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.550874
[2/9, 48/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.445766
[2/9, 49/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.495294
[2/9, 50/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.500286
[2/9, 51/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.474465
[2/9, 52/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.490859
[2/9, 53/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.429846
[2/9, 54/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.453126
[2/9, 55/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.486474
[2/9, 56/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.433343
[2/9, 57/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.443239
[2/9, 58/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.509637
[2/9, 59/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.641147
[2/9, 60/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.446835
[2/9, 61/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.452088
[2/9, 62/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.475431
[2/9, 63/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.448135
[2/9, 64/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.418587
[2/9, 65/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.461574
[2/9, 66/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.467979
[2/9, 67/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.478412
[2/9, 68/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.587049
[2/9, 69/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.544467
[2/9, 70/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.697156
[2/9, 71/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.745353
[2/9, 72/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.929928
[2/9, 73/94] Training Loss: 0.0614 - Iteration Time: 0:00:02.195877
[2/9, 74/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.875350
[2/9, 75/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.805207
[2/9, 76/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.606690
[2/9, 77/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.732606
[2/9, 78/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.751659
[2/9, 79/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.604042
[2/9, 80/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.645204
[2/9, 81/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.538539
[2/9, 82/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.724983
[2/9, 83/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.588092
[2/9, 84/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.486411
[2/9, 85/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.489350
[2/9, 86/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.491448
[2/9, 87/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.486361
[2/9, 88/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.480430
[2/9, 89/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.525059
[2/9, 90/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.830179
[2/9, 91/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.653514
[2/9, 92/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.659600
[2/9, 93/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.549881
[2/9, 94/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.501743
Testing - 2024-06-15 15:13:20.292178
[2/9, 1/16]
[2/9, 2/16]
[2/9, 3/16]
[2/9, 4/16]
[2/9, 5/16]
[2/9, 6/16]
[2/9, 7/16]
[2/9, 8/16]
[2/9, 9/16]
[2/9, 10/16]
[2/9, 11/16]
[2/9, 12/16]
[2/9, 13/16]
[2/9, 14/16]
[2/9, 15/16]
[2/9, 16/16]
Testing Loss: 0.0620 - Epoch Time: 0:02:43.101889
Training - 2024-06-15 15:13:36.081159
[3/9, 1/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.550867
[3/9, 2/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.441043
[3/9, 3/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.519572
[3/9, 4/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.495950
[3/9, 5/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.523084
[3/9, 6/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.533885
[3/9, 7/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.490064
[3/9, 8/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.482920
[3/9, 9/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.512983
[3/9, 10/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.608008
[3/9, 11/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.567300
[3/9, 12/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.647316
[3/9, 13/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.567578
[3/9, 14/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.516396
[3/9, 15/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.674139
[3/9, 16/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.668934
[3/9, 17/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.666363
[3/9, 18/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.772427
[3/9, 19/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.665792
[3/9, 20/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.651076
[3/9, 21/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.534380
[3/9, 22/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.474521
[3/9, 23/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.492435
[3/9, 24/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.483289
[3/9, 25/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.468357
[3/9, 26/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.499359
[3/9, 27/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.629260
[3/9, 28/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.410937
[3/9, 29/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.451701
[3/9, 30/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.512128
[3/9, 31/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.451339
[3/9, 32/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.452464
[3/9, 33/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.614463
[3/9, 34/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.628065
[3/9, 35/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.591659
[3/9, 36/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.679369
[3/9, 37/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.643929
[3/9, 38/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.476396
[3/9, 39/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.458159
[3/9, 40/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.501500
[3/9, 41/94] Training Loss: 0.0644 - Iteration Time: 0:00:02.204012
[3/9, 42/94] Training Loss: 0.0614 - Iteration Time: 0:00:02.460050
[3/9, 43/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.963438
[3/9, 44/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.664876
[3/9, 45/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.502923
[3/9, 46/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.574240
[3/9, 47/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.751955
[3/9, 48/94] Training Loss: 0.0628 - Iteration Time: 0:00:02.223037
[3/9, 49/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.665506
[3/9, 50/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.639809
[3/9, 51/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.654515
[3/9, 52/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.634102
[3/9, 53/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.894724
[3/9, 54/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.692607
[3/9, 55/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.697239
[3/9, 56/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.627859
[3/9, 57/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.597905
[3/9, 58/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.597313
[3/9, 59/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.588350
[3/9, 60/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.766842
[3/9, 61/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.661342
[3/9, 62/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.826622
[3/9, 63/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.720697
[3/9, 64/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.728618
[3/9, 65/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.642826
[3/9, 66/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.579862
[3/9, 67/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.526167
[3/9, 68/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.630353
[3/9, 69/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.515555
[3/9, 70/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.589450
[3/9, 71/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.662709
[3/9, 72/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.590839
[3/9, 73/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.741097
[3/9, 74/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.665236
[3/9, 75/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.563042
[3/9, 76/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.585088
[3/9, 77/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.731009
[3/9, 78/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.709330
[3/9, 79/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.717605
[3/9, 80/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.655032
[3/9, 81/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.643829
[3/9, 82/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.631126
[3/9, 83/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.735224
[3/9, 84/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.567491
[3/9, 85/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.611554
[3/9, 86/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.697995
[3/9, 87/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.671527
[3/9, 88/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.547067
[3/9, 89/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.750152
[3/9, 90/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.875718
[3/9, 91/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.597265
[3/9, 92/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.558018
[3/9, 93/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.653537
[3/9, 94/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.587420
Testing - 2024-06-15 15:16:09.760824
[3/9, 1/16]
[3/9, 2/16]
[3/9, 3/16]
[3/9, 4/16]
[3/9, 5/16]
[3/9, 6/16]
[3/9, 7/16]
[3/9, 8/16]
[3/9, 9/16]
[3/9, 10/16]
[3/9, 11/16]
[3/9, 12/16]
[3/9, 13/16]
[3/9, 14/16]
[3/9, 15/16]
[3/9, 16/16]
Testing Loss: 0.0618 - Epoch Time: 0:02:48.100167
Training - 2024-06-15 15:16:24.181823
[4/9, 1/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.539681
[4/9, 2/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.529618
[4/9, 3/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.494807
[4/9, 4/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.533686
[4/9, 5/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.569766
[4/9, 6/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.644497
[4/9, 7/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.613921
[4/9, 8/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.464138
[4/9, 9/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.457933
[4/9, 10/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.617267
[4/9, 11/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.567071
[4/9, 12/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.776894
[4/9, 13/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.835322
[4/9, 14/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.536896
[4/9, 15/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.526962
[4/9, 16/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.803432
[4/9, 17/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.585129
[4/9, 18/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.642334
[4/9, 19/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.531439
[4/9, 20/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.541331
[4/9, 21/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.775656
[4/9, 22/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.678531
[4/9, 23/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.751173
[4/9, 24/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.935666
[4/9, 25/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.751004
[4/9, 26/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.649524
[4/9, 27/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.530040
[4/9, 28/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.520072
[4/9, 29/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.608469
[4/9, 30/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.583644
[4/9, 31/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.619283
[4/9, 32/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.571811
[4/9, 33/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.575637
[4/9, 34/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.546549
[4/9, 35/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.525070
[4/9, 36/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.542551
[4/9, 37/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.512179
[4/9, 38/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.882888
[4/9, 39/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.727125
[4/9, 40/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.658039
[4/9, 41/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.668908
[4/9, 42/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.650520
[4/9, 43/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.795054
[4/9, 44/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.660444
[4/9, 45/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.708001
[4/9, 46/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.569782
[4/9, 47/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.739729
[4/9, 48/94] Training Loss: 0.0614 - Iteration Time: 0:00:02.091686
[4/9, 49/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.801211
[4/9, 50/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.846647
[4/9, 51/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.983657
[4/9, 52/94] Training Loss: 0.0634 - Iteration Time: 0:00:02.161322
[4/9, 53/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.748593
[4/9, 54/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.647010
[4/9, 55/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.627211
[4/9, 56/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.722506
[4/9, 57/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.675565
[4/9, 58/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.640287
[4/9, 59/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.632071
[4/9, 60/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.772793
[4/9, 61/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.560454
[4/9, 62/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.631979
[4/9, 63/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.565019
[4/9, 64/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.546129
[4/9, 65/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.620986
[4/9, 66/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.486401
[4/9, 67/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.505540
[4/9, 68/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.471913
[4/9, 69/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.622493
[4/9, 70/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.497283
[4/9, 71/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.601765
[4/9, 72/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.709515
[4/9, 73/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.649100
[4/9, 74/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.650736
[4/9, 75/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.701978
[4/9, 76/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.771328
[4/9, 77/94] Training Loss: 0.0624 - Iteration Time: 0:00:02.052782
[4/9, 78/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.950708
[4/9, 79/94] Training Loss: 0.0597 - Iteration Time: 0:00:02.016339
[4/9, 80/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.760168
[4/9, 81/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.734415
[4/9, 82/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.695829
[4/9, 83/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.760700
[4/9, 84/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.828345
[4/9, 85/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.692089
[4/9, 86/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.989348
[4/9, 87/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.790298
[4/9, 88/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.792200
[4/9, 89/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.672443
[4/9, 90/94] Training Loss: 0.0624 - Iteration Time: 0:00:02.480313
[4/9, 91/94] Training Loss: 0.0587 - Iteration Time: 0:00:02.976245
[4/9, 92/94] Training Loss: 0.0625 - Iteration Time: 0:00:02.494933
[4/9, 93/94] Training Loss: 0.0629 - Iteration Time: 0:00:02.428812
[4/9, 94/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.971970
Testing - 2024-06-15 15:19:05.856451
[4/9, 1/16]
[4/9, 2/16]
[4/9, 3/16]
[4/9, 4/16]
[4/9, 5/16]
[4/9, 6/16]
[4/9, 7/16]
[4/9, 8/16]
[4/9, 9/16]
[4/9, 10/16]
[4/9, 11/16]
[4/9, 12/16]
[4/9, 13/16]
[4/9, 14/16]
[4/9, 15/16]
[4/9, 16/16]
Testing Loss: 0.0600 - Epoch Time: 0:02:59.407581
Training - 2024-06-15 15:19:23.589404
[5/9, 1/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.846455
[5/9, 2/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.686643
[5/9, 3/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.684641
[5/9, 4/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.607105
[5/9, 5/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.640893
[5/9, 6/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.674119
[5/9, 7/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.809694
[5/9, 8/94] Training Loss: 0.0601 - Iteration Time: 0:00:02.269615
[5/9, 9/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.797114
[5/9, 10/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.700526
[5/9, 11/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.729073
[5/9, 12/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.775010
[5/9, 13/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.565611
[5/9, 14/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.588165
[5/9, 15/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.581564
[5/9, 16/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.617004
[5/9, 17/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.548360
[5/9, 18/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.629202
[5/9, 19/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.697183
[5/9, 20/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.709095
[5/9, 21/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.628929
[5/9, 22/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.699570
[5/9, 23/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.942328
[5/9, 24/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.841552
[5/9, 25/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.854002
[5/9, 26/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.639656
[5/9, 27/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.702710
[5/9, 28/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.623256
[5/9, 29/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.646652
[5/9, 30/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.682446
[5/9, 31/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.654244
[5/9, 32/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.860405
[5/9, 33/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.738555
[5/9, 34/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.651682
[5/9, 35/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.700631
[5/9, 36/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.715217
[5/9, 37/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.732460
[5/9, 38/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.845041
[5/9, 39/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.705842
[5/9, 40/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.726021
[5/9, 41/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.938334
[5/9, 42/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.790646
[5/9, 43/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.896659
[5/9, 44/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.768267
[5/9, 45/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.729911
[5/9, 46/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.804870
[5/9, 47/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.770817
[5/9, 48/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.645353
[5/9, 49/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.651235
[5/9, 50/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.641840
[5/9, 51/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.633166
[5/9, 52/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.677847
[5/9, 53/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.794558
[5/9, 54/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.691982
[5/9, 55/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.651615
[5/9, 56/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.803549
[5/9, 57/94] Training Loss: 0.0597 - Iteration Time: 0:00:02.154175
[5/9, 58/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.818857
[5/9, 59/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.685073
[5/9, 60/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.996940
[5/9, 61/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.932077
[5/9, 62/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.808153
[5/9, 63/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.866964
[5/9, 64/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.841097
[5/9, 65/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.838282
[5/9, 66/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.665461
[5/9, 67/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.682670
[5/9, 68/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.849049
[5/9, 69/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.729972
[5/9, 70/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.937639
[5/9, 71/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.817359
[5/9, 72/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.774649
[5/9, 73/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.877788
[5/9, 74/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.731493
[5/9, 75/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.842149
[5/9, 76/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.745561
[5/9, 77/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.623376
[5/9, 78/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.762303
[5/9, 79/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.650859
[5/9, 80/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.754767
[5/9, 81/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.773693
[5/9, 82/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.630961
[5/9, 83/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.620318
[5/9, 84/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.721166
[5/9, 85/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.630113
[5/9, 86/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.688286
[5/9, 87/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.726980
[5/9, 88/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.673439
[5/9, 89/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.696792
[5/9, 90/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.714311
[5/9, 91/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.864892
[5/9, 92/94] Training Loss: 0.0592 - Iteration Time: 0:00:02.183984
[5/9, 93/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.775255
[5/9, 94/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.720542
Testing - 2024-06-15 15:22:08.139719
[5/9, 1/16]
[5/9, 2/16]
[5/9, 3/16]
[5/9, 4/16]
[5/9, 5/16]
[5/9, 6/16]
[5/9, 7/16]
[5/9, 8/16]
[5/9, 9/16]
[5/9, 10/16]
[5/9, 11/16]
[5/9, 12/16]
[5/9, 13/16]
[5/9, 14/16]
[5/9, 15/16]
[5/9, 16/16]
Testing Loss: 0.0583 - Epoch Time: 0:03:00.382106
Training - 2024-06-15 15:22:23.972005
[6/9, 1/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.720213
[6/9, 2/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.659022
[6/9, 3/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.615391
[6/9, 4/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.573441
[6/9, 5/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.609231
[6/9, 6/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.606401
