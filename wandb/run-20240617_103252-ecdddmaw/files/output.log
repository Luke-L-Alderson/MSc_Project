Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-17 10:32:53.344973
Scaler Value: 0.013513513513513514
Training - 2024-06-17 10:32:53.345966
[1/9, 10/94] Training Loss: 17.9494 - Iteration Time: 0:00:01.460553
[1/9, 20/94] Training Loss: 13.5127 - Iteration Time: 0:00:01.409392
[1/9, 30/94] Training Loss: 8.1893 - Iteration Time: 0:00:01.467497
[1/9, 40/94] Training Loss: 6.3596 - Iteration Time: 0:00:01.417406
[1/9, 50/94] Training Loss: 5.7511 - Iteration Time: 0:00:01.462537
[1/9, 60/94] Training Loss: 5.4752 - Iteration Time: 0:00:01.436753
[1/9, 70/94] Training Loss: 5.3261 - Iteration Time: 0:00:01.455587
[1/9, 80/94] Training Loss: 5.3252 - Iteration Time: 0:00:01.476952
[1/9, 90/94] Training Loss: 5.2547 - Iteration Time: 0:00:01.503236
Testing - 2024-06-17 10:35:13.898007
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 5.0380 - Epoch Time: 0:02:34.474134
Training - 2024-06-17 10:35:27.820596
[2/9, 10/94] Training Loss: 5.2883 - Iteration Time: 0:00:01.541405
[2/9, 20/94] Training Loss: 5.1598 - Iteration Time: 0:00:01.423348
[2/9, 30/94] Training Loss: 5.1781 - Iteration Time: 0:00:01.398029
[2/9, 40/94] Training Loss: 5.1775 - Iteration Time: 0:00:01.420345
[2/9, 50/94] Training Loss: 5.1366 - Iteration Time: 0:00:01.407028
[2/9, 60/94] Training Loss: 5.1930 - Iteration Time: 0:00:01.461026
[2/9, 70/94] Training Loss: 5.1362 - Iteration Time: 0:00:01.444681
[2/9, 80/94] Training Loss: 5.0677 - Iteration Time: 0:00:01.419381
[2/9, 90/94] Training Loss: 5.1222 - Iteration Time: 0:00:01.431803
Testing - 2024-06-17 10:37:47.563240
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 4.9934 - Epoch Time: 0:02:34.132830
Training - 2024-06-17 10:38:01.953426
[3/9, 10/94] Training Loss: 5.0741 - Iteration Time: 0:00:01.500752
[3/9, 20/94] Training Loss: 5.1384 - Iteration Time: 0:00:01.450612
[3/9, 30/94] Training Loss: 5.0623 - Iteration Time: 0:00:01.474473
[3/9, 40/94] Training Loss: 5.0833 - Iteration Time: 0:00:01.461555
[3/9, 50/94] Training Loss: 5.1167 - Iteration Time: 0:00:01.447713
[3/9, 60/94] Training Loss: 5.0780 - Iteration Time: 0:00:01.483365
[3/9, 70/94] Training Loss: 5.0327 - Iteration Time: 0:00:01.478987
[3/9, 80/94] Training Loss: 5.0838 - Iteration Time: 0:00:01.677435
[3/9, 90/94] Training Loss: 5.0752 - Iteration Time: 0:00:01.407043
Testing - 2024-06-17 10:40:23.449516
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 4.9167 - Epoch Time: 0:02:35.958588
Training - 2024-06-17 10:40:37.912511
[4/9, 10/94] Training Loss: 5.0144 - Iteration Time: 0:00:01.381736
[4/9, 20/94] Training Loss: 5.0836 - Iteration Time: 0:00:01.499379
[4/9, 30/94] Training Loss: 5.0421 - Iteration Time: 0:00:01.465023
[4/9, 40/94] Training Loss: 5.0028 - Iteration Time: 0:00:01.447651
[4/9, 50/94] Training Loss: 5.0368 - Iteration Time: 0:00:01.447745
[4/9, 60/94] Training Loss: 5.0174 - Iteration Time: 0:00:01.438207
[4/9, 70/94] Training Loss: 5.0844 - Iteration Time: 0:00:01.457157
[4/9, 80/94] Training Loss: 5.0666 - Iteration Time: 0:00:01.575651
[4/9, 90/94] Training Loss: 5.0097 - Iteration Time: 0:00:01.424162
Testing - 2024-06-17 10:42:58.038808
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 4.9494 - Epoch Time: 0:02:34.544363
Training - 2024-06-17 10:43:12.456874
[5/9, 10/94] Training Loss: 5.0164 - Iteration Time: 0:00:01.454134
[5/9, 20/94] Training Loss: 5.0671 - Iteration Time: 0:00:01.438727
[5/9, 30/94] Training Loss: 4.9981 - Iteration Time: 0:00:01.490879
[5/9, 40/94] Training Loss: 5.0140 - Iteration Time: 0:00:01.686399
[5/9, 50/94] Training Loss: 5.0563 - Iteration Time: 0:00:01.505204
[5/9, 60/94] Training Loss: 5.0336 - Iteration Time: 0:00:01.611332
[5/9, 70/94] Training Loss: 5.0279 - Iteration Time: 0:00:01.472976
[5/9, 80/94] Training Loss: 4.9597 - Iteration Time: 0:00:01.533003
[5/9, 90/94] Training Loss: 5.0003 - Iteration Time: 0:00:01.445187
Testing - 2024-06-17 10:45:34.556656
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 4.8496 - Epoch Time: 0:02:36.037841
Training - 2024-06-17 10:45:48.494715
[6/9, 10/94] Training Loss: 5.0294 - Iteration Time: 0:00:01.519148
[6/9, 20/94] Training Loss: 4.9636 - Iteration Time: 0:00:01.446165
[6/9, 30/94] Training Loss: 4.9825 - Iteration Time: 0:00:01.466999
[6/9, 40/94] Training Loss: 4.9980 - Iteration Time: 0:00:01.417920
[6/9, 50/94] Training Loss: 4.9869 - Iteration Time: 0:00:01.684401
[6/9, 60/94] Training Loss: 4.9708 - Iteration Time: 0:00:01.440742
[6/9, 70/94] Training Loss: 5.0158 - Iteration Time: 0:00:01.617352
[6/9, 80/94] Training Loss: 5.0156 - Iteration Time: 0:00:01.916575
[6/9, 90/94] Training Loss: 5.0363 - Iteration Time: 0:00:01.505818
Testing - 2024-06-17 10:48:12.730342
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 4.7274 - Epoch Time: 0:02:37.905629
Training - 2024-06-17 10:48:26.400344
[7/9, 10/94] Training Loss: 4.9969 - Iteration Time: 0:00:01.430838
[7/9, 20/94] Training Loss: 5.0002 - Iteration Time: 0:00:01.446670
[7/9, 30/94] Training Loss: 5.0294 - Iteration Time: 0:00:01.435868
[7/9, 40/94] Training Loss: 5.0047 - Iteration Time: 0:00:01.452230
[7/9, 50/94] Training Loss: 4.9780 - Iteration Time: 0:00:01.455107
[7/9, 60/94] Training Loss: 4.9071 - Iteration Time: 0:00:01.462048
[7/9, 70/94] Training Loss: 4.9785 - Iteration Time: 0:00:01.483529
[7/9, 80/94] Training Loss: 4.9663 - Iteration Time: 0:00:01.447171
[7/9, 90/94] Training Loss: 4.9813 - Iteration Time: 0:00:01.436270
Testing - 2024-06-17 10:50:46.380243
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 4.7457 - Epoch Time: 0:02:33.519735
Training - 2024-06-17 10:50:59.920576
[8/9, 10/94] Training Loss: 5.0198 - Iteration Time: 0:00:01.415930
[8/9, 20/94] Training Loss: 4.9448 - Iteration Time: 0:00:01.452183
[8/9, 30/94] Training Loss: 4.9721 - Iteration Time: 0:00:01.378312
[8/9, 40/94] Training Loss: 4.9573 - Iteration Time: 0:00:01.375295
[8/9, 50/94] Training Loss: 4.9470 - Iteration Time: 0:00:01.391179
[8/9, 60/94] Training Loss: 4.9793 - Iteration Time: 0:00:01.422351
[8/9, 70/94] Training Loss: 4.9723 - Iteration Time: 0:00:01.372726
[8/9, 80/94] Training Loss: 5.0107 - Iteration Time: 0:00:01.411479
[8/9, 90/94] Training Loss: 4.9754 - Iteration Time: 0:00:01.408476
Testing - 2024-06-17 10:53:15.807523
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 4.7703 - Epoch Time: 0:02:29.272826
Training - 2024-06-17 10:53:29.193899
[9/9, 10/94] Training Loss: 4.9511 - Iteration Time: 0:00:01.372247
[9/9, 20/94] Training Loss: 4.9838 - Iteration Time: 0:00:01.389107
[9/9, 30/94] Training Loss: 4.9863 - Iteration Time: 0:00:01.401024
[9/9, 40/94] Training Loss: 4.9335 - Iteration Time: 0:00:01.419470
[9/9, 50/94] Training Loss: 4.9186 - Iteration Time: 0:00:01.487904
[9/9, 60/94] Training Loss: 4.9714 - Iteration Time: 0:00:01.557818
[9/9, 70/94] Training Loss: 4.9490 - Iteration Time: 0:00:01.571705
[9/9, 80/94] Training Loss: 4.9360 - Iteration Time: 0:00:01.430303
[9/9, 90/94] Training Loss: 5.0208 - Iteration Time: 0:00:01.442765
Testing - 2024-06-17 10:55:48.995079
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 4.7175 - Epoch Time: 0:02:34.210098
Training and Testing Finished - Time: 0:23:10.059520
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels      0      1    2      3      4  ...     94   95   96     97   98     99
0       2  199.0  199.0  0.0  198.0  198.0  ...  199.0  0.0  0.0  199.0  0.0  198.0
1       4  199.0  198.0  0.0  199.0  196.0  ...  199.0  0.0  0.0  198.0  0.0  199.0
2       7  197.0  199.0  0.0  197.0  193.0  ...  199.0  0.0  0.0  199.0  0.0  199.0
3       3  199.0  197.0  0.0  199.0  195.0  ...  199.0  0.0  0.0  199.0  0.0  199.0
4       7  199.0  198.0  0.0  199.0  193.0  ...  199.0  0.0  0.0  199.0  0.0  199.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying t-SNE
Applying UMAP
Applying PCA