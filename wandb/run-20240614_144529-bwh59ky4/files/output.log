Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-14 14:45:30.983213
Scaler Value: 0.013513513513513514
Training - 2024-06-14 14:45:30.984205
[1/9, 1/94] Training Loss: 0.0696 - Iteration Time: 0:00:01.738091
[1/9, 2/94] Training Loss: 0.0698 - Iteration Time: 0:00:01.285013
[1/9, 3/94] Training Loss: 0.0719 - Iteration Time: 0:00:01.294400
[1/9, 4/94] Training Loss: 0.0718 - Iteration Time: 0:00:01.268652
[1/9, 5/94] Training Loss: 0.0708 - Iteration Time: 0:00:01.263662
[1/9, 6/94] Training Loss: 0.0695 - Iteration Time: 0:00:01.292409
[1/9, 7/94] Training Loss: 0.0693 - Iteration Time: 0:00:01.297948
[1/9, 8/94] Training Loss: 0.0691 - Iteration Time: 0:00:01.282056
[1/9, 9/94] Training Loss: 0.0692 - Iteration Time: 0:00:01.310751
[1/9, 10/94] Training Loss: 0.0712 - Iteration Time: 0:00:01.322320
[1/9, 11/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.274716
[1/9, 12/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.264156
[1/9, 13/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.256729
[1/9, 14/94] Training Loss: 0.0700 - Iteration Time: 0:00:01.316835
[1/9, 15/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.308254
[1/9, 16/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.430522
[1/9, 17/94] Training Loss: 0.0716 - Iteration Time: 0:00:01.282049
[1/9, 18/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.337600
[1/9, 19/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.332644
[1/9, 20/94] Training Loss: 0.0689 - Iteration Time: 0:00:01.335238
[1/9, 21/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.268150
[1/9, 22/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.267110
[1/9, 23/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.262661
[1/9, 24/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.244297
[1/9, 25/94] Training Loss: 0.0704 - Iteration Time: 0:00:01.301332
[1/9, 26/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.337054
[1/9, 27/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.280500
[1/9, 28/94] Training Loss: 0.0680 - Iteration Time: 0:00:01.314269
[1/9, 29/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.313705
[1/9, 30/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.278517
[1/9, 31/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.264631
[1/9, 32/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.276515
[1/9, 33/94] Training Loss: 0.0709 - Iteration Time: 0:00:01.284964
[1/9, 34/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.327668
[1/9, 35/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.302315
[1/9, 36/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.257175
[1/9, 37/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.249771
[1/9, 38/94] Training Loss: 0.0680 - Iteration Time: 0:00:01.263111
[1/9, 39/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.297374
[1/9, 40/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.293942
[1/9, 41/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.272555
[1/9, 42/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.266604
[1/9, 43/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.272534
[1/9, 44/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.269112
[1/9, 45/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.405531
[1/9, 46/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.270557
[1/9, 47/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.270635
[1/9, 48/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.276064
[1/9, 49/94] Training Loss: 0.0696 - Iteration Time: 0:00:01.294887
[1/9, 50/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.321695
[1/9, 51/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.319244
[1/9, 52/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.294421
[1/9, 53/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.276560
[1/9, 54/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.281033
[1/9, 55/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.272525
[1/9, 56/94] Training Loss: 0.0691 - Iteration Time: 0:00:01.273104
[1/9, 57/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.268075
[1/9, 58/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.267642
[1/9, 59/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.289496
[1/9, 60/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.307300
[1/9, 61/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.288985
[1/9, 62/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.322699
[1/9, 63/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.410960
[1/9, 64/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.296395
[1/9, 65/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.336588
[1/9, 66/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.330095
[1/9, 67/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.287965
[1/9, 68/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.261178
[1/9, 69/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.288416
[1/9, 70/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.267103
[1/9, 71/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.245272
[1/9, 72/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.329638
[1/9, 73/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.266097
[1/9, 74/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.256166
[1/9, 75/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.271110
[1/9, 76/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.316771
[1/9, 77/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.238822
[1/9, 78/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.285528
[1/9, 79/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.278555
[1/9, 80/94] Training Loss: 0.0691 - Iteration Time: 0:00:01.257721
[1/9, 81/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.271638
[1/9, 82/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.335688
[1/9, 83/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.248763
[1/9, 84/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.339150
[1/9, 85/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.303882
[1/9, 86/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.273554
[1/9, 87/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.260679
[1/9, 88/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.299931
[1/9, 89/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.258318
[1/9, 90/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.252730
[1/9, 91/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.271052
[1/9, 92/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.286450
[1/9, 93/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.440264
[1/9, 94/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.366121
Testing - 2024-06-14 14:47:43.001564
[1/9, 1/16]
[1/9, 2/16]
[1/9, 3/16]
[1/9, 4/16]
[1/9, 5/16]
[1/9, 6/16]
[1/9, 7/16]
[1/9, 8/16]
[1/9, 9/16]
[1/9, 10/16]
[1/9, 11/16]
[1/9, 12/16]
[1/9, 13/16]
[1/9, 14/16]
[1/9, 15/16]
[1/9, 16/16]
Testing Loss: 0.0610 - Epoch Time: 0:02:32.980270
Training - 2024-06-14 14:48:03.964475
[2/9, 1/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.475595
[2/9, 2/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.333760
[2/9, 3/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.279049
[2/9, 4/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.274193
[2/9, 5/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.266171
[2/9, 6/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.299508
[2/9, 7/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.342043
[2/9, 8/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.264182
[2/9, 9/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.291463
[2/9, 10/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.265118
[2/9, 11/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.272585
[2/9, 12/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.277067
[2/9, 13/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.271188
[2/9, 14/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.360928
[2/9, 15/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.253256
[2/9, 16/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.331624
[2/9, 17/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.241822
[2/9, 18/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.275049
[2/9, 19/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.257178
[2/9, 20/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.317226
[2/9, 21/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.267123
[2/9, 22/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.287449
[2/9, 23/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.282970
[2/9, 24/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.334554
[2/9, 25/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.287484
[2/9, 26/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.279533
[2/9, 27/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.279036
[2/9, 28/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.265630
[2/9, 29/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.273632
[2/9, 30/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.285516
[2/9, 31/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.266610
[2/9, 32/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.273044
[2/9, 33/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.302887
[2/9, 34/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.265128
[2/9, 35/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.300360
[2/9, 36/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.285012
[2/9, 37/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.264660
[2/9, 38/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.267599
[2/9, 39/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.266113
[2/9, 40/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.266139
[2/9, 41/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.284972
[2/9, 42/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.268090
[2/9, 43/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.256184
[2/9, 44/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.304798
[2/9, 45/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.414012
[2/9, 46/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.450229
[2/9, 47/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.326624
[2/9, 48/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.396112
[2/9, 49/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.317247
[2/9, 50/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.317684
[2/9, 51/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.258171
[2/9, 52/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.267127
[2/9, 53/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.275066
[2/9, 54/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.278038
[2/9, 55/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.266126
[2/9, 56/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.285020
[2/9, 57/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.334125
[2/9, 58/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.364842
[2/9, 59/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.276653
[2/9, 60/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.296365
[2/9, 61/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.288938
[2/9, 62/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.281005
[2/9, 63/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.264216
[2/9, 64/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.247314
[2/9, 65/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.273586
[2/9, 66/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.274576
[2/9, 67/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.284058
[2/9, 68/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.278143
[2/9, 69/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.285006
[2/9, 70/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.262214
[2/9, 71/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.247311
[2/9, 72/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.326155
[2/9, 73/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.265237
[2/9, 74/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.303340
[2/9, 75/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.314263
[2/9, 76/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.280513
[2/9, 77/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.281793
[2/9, 78/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.287482
[2/9, 79/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.345628
[2/9, 80/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.275122
[2/9, 81/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.263150
[2/9, 82/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.255304
[2/9, 83/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.258756
[2/9, 84/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.279600
[2/9, 85/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.284511
[2/9, 86/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.257171
[2/9, 87/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.277117
[2/9, 88/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.270694
[2/9, 89/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.266605
[2/9, 90/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.308407
[2/9, 91/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.398619
[2/9, 92/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.402525
[2/9, 93/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.310767
[2/9, 94/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.339115
Testing - 2024-06-14 14:50:05.677506
[2/9, 1/16]
[2/9, 2/16]
[2/9, 3/16]
[2/9, 4/16]
[2/9, 5/16]
[2/9, 6/16]
[2/9, 7/16]
[2/9, 8/16]
[2/9, 9/16]
[2/9, 10/16]
[2/9, 11/16]
[2/9, 12/16]
[2/9, 13/16]
[2/9, 14/16]
[2/9, 15/16]
[2/9, 16/16]
Testing Loss: 0.0609 - Epoch Time: 0:02:13.440553
Training - 2024-06-14 14:50:17.405028
[3/9, 1/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.289912
[3/9, 2/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.302344
[3/9, 3/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.253681
[3/9, 4/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.261697
[3/9, 5/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.297366
[3/9, 6/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.357967
[3/9, 7/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.259739
[3/9, 8/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.264662
[3/9, 9/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.268103
[3/9, 10/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.339062
[3/9, 11/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.280006
[3/9, 12/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.311752
[3/9, 13/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.275532
[3/9, 14/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.289998
[3/9, 15/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.286499
[3/9, 16/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.273569
[3/9, 17/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.260635
[3/9, 18/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.265671
[3/9, 19/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.270072
[3/9, 20/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.271099
[3/9, 21/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.291418
[3/9, 22/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.319264
[3/9, 23/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.258241
[3/9, 24/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.301844
[3/9, 25/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.302400
[3/9, 26/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.276568
[3/9, 27/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.320248
[3/9, 28/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.243371
[3/9, 29/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.313254
[3/9, 30/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.279482
[3/9, 31/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.287531
[3/9, 32/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.262217
[3/9, 33/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.264659
[3/9, 34/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.320774
[3/9, 35/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.338636
[3/9, 36/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.422973
[3/9, 37/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.323684
[3/9, 38/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.361494
[3/9, 39/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.287436
[3/9, 40/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.264103
[3/9, 41/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.277049
[3/9, 42/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.269150
[3/9, 43/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.239288
[3/9, 44/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.386644
[3/9, 45/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.272073
[3/9, 46/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.357882
[3/9, 47/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.284948
[3/9, 48/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.298372
[3/9, 49/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.295848
[3/9, 50/94] Training Loss: 0.0595 - Iteration Time: 0:00:01.300843
[3/9, 51/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.268072
[3/9, 52/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.249783
[3/9, 53/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.279510
[3/9, 54/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.353421
[3/9, 55/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.267264
[3/9, 56/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.267106
[3/9, 57/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.247239
[3/9, 58/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.266240
[3/9, 59/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.289987
[3/9, 60/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.272517
[3/9, 61/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.370928
[3/9, 62/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.276065
[3/9, 63/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.279467
[3/9, 64/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.269101
[3/9, 65/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.267574
[3/9, 66/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.328565
[3/9, 67/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.263128
[3/9, 68/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.270559
[3/9, 69/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.288032
[3/9, 70/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.321782
[3/9, 71/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.344502
[3/9, 72/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.314789
[3/9, 73/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.282995
[3/9, 74/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.317212
[3/9, 75/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.296888
[3/9, 76/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.277608
[3/9, 77/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.286062
[3/9, 78/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.246892
[3/9, 79/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.260240
[3/9, 80/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.379726
[3/9, 81/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.469069
[3/9, 82/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.267725
[3/9, 83/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.415914
[3/9, 84/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.367804
[3/9, 85/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.285537
[3/9, 86/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.273523
[3/9, 87/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.263158
[3/9, 88/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.285435
[3/9, 89/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.324194
[3/9, 90/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.280492
[3/9, 91/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.275019
[3/9, 92/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.271600
[3/9, 93/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.391199
[3/9, 94/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.230377
Testing - 2024-06-14 14:52:19.299216
[3/9, 1/16]
[3/9, 2/16]
[3/9, 3/16]
[3/9, 4/16]
[3/9, 5/16]
[3/9, 6/16]
[3/9, 7/16]
[3/9, 8/16]
[3/9, 9/16]
[3/9, 10/16]
[3/9, 11/16]
[3/9, 12/16]
[3/9, 13/16]
[3/9, 14/16]
[3/9, 15/16]
[3/9, 16/16]
Testing Loss: 0.0572 - Epoch Time: 0:02:13.268485
Training - 2024-06-14 14:52:30.673513
[4/9, 1/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.282968
[4/9, 2/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.284545
[4/9, 3/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.264679
[4/9, 4/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.280575
[4/9, 5/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.245245
[4/9, 6/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.325174
[4/9, 7/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.281059
[4/9, 8/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.287921
[4/9, 9/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.287978
[4/9, 10/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.269137
[4/9, 11/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.276031
[4/9, 12/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.279520
[4/9, 13/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.258671
[4/9, 14/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.276584
[4/9, 15/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.272122
[4/9, 16/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.266119
[4/9, 17/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.251712
[4/9, 18/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.337613
[4/9, 19/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.307286
[4/9, 20/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.250762
[4/9, 21/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.255722
[4/9, 22/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.280526
[4/9, 23/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.298412
[4/9, 24/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.329641
[4/9, 25/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.406083
[4/9, 26/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.312855
[4/9, 27/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.340074
[4/9, 28/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.372392
[4/9, 29/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.294462
[4/9, 30/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.301394
[4/9, 31/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.268692
[4/9, 32/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.271559
[4/9, 33/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.254727
[4/9, 34/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.354480
[4/9, 35/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.264182
[4/9, 36/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.287929
[4/9, 37/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.264604
[4/9, 38/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.287499
[4/9, 39/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.257654
[4/9, 40/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.268097
[4/9, 41/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.440290
[4/9, 42/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.304304
[4/9, 43/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.298861
[4/9, 44/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.337052
[4/9, 45/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.296880
[4/9, 46/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.300424
[4/9, 47/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.348953
[4/9, 48/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.291435
[4/9, 49/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.272598
[4/9, 50/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.400111
[4/9, 51/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.316733
[4/9, 52/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.257473
[4/9, 53/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.305820
[4/9, 54/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.268061
[4/9, 55/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.265605
[4/9, 56/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.260661
[4/9, 57/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.323741
[4/9, 58/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.312767
[4/9, 59/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.254209
[4/9, 60/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.301860
[4/9, 61/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.285001
[4/9, 62/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.284452
[4/9, 63/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.281995
[4/9, 64/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.254209
[4/9, 65/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.279503
[4/9, 66/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.271583
[4/9, 67/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.284954
[4/9, 68/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.295909
[4/9, 69/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.309787
[4/9, 70/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.431812
[4/9, 71/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.297981
[4/9, 72/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.285968
[4/9, 73/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.412964
[4/9, 74/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.302901
[4/9, 75/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.268115
[4/9, 76/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.273067
[4/9, 77/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.286523
[4/9, 78/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.262709
[4/9, 79/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.248268
[4/9, 80/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.262173
[4/9, 81/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.331153
[4/9, 82/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.258693
[4/9, 83/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.246402
[4/9, 84/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.249344
[4/9, 85/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.272651
[4/9, 86/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.260251
[4/9, 87/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.240839
[4/9, 88/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.273074
[4/9, 89/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.410590
[4/9, 90/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.249301
[4/9, 91/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.269128
[4/9, 92/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.287006
[4/9, 93/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.318670
[4/9, 94/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.243825
Testing - 2024-06-14 14:54:32.267157
[4/9, 1/16]
[4/9, 2/16]
[4/9, 3/16]
[4/9, 4/16]
[4/9, 5/16]
[4/9, 6/16]
[4/9, 7/16]
[4/9, 8/16]
[4/9, 9/16]
[4/9, 10/16]
[4/9, 11/16]
[4/9, 12/16]
[4/9, 13/16]
[4/9, 14/16]
[4/9, 15/16]
[4/9, 16/16]
Testing Loss: 0.0524 - Epoch Time: 0:02:13.070212
Training - 2024-06-14 14:54:43.744221
[5/9, 1/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.256650
[5/9, 2/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.259187
[5/9, 3/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.278504
[5/9, 4/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.278038
[5/9, 5/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.266616
[5/9, 6/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.238806
[5/9, 7/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.298396
[5/9, 8/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.288965
[5/9, 9/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.275015
[5/9, 10/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.283017
[5/9, 11/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.297926
[5/9, 12/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.271521
[5/9, 13/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.282996
[5/9, 14/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.340034
[5/9, 15/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.481928
[5/9, 16/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.339555
[5/9, 17/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.373774
[5/9, 18/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.304774
[5/9, 19/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.279071
[5/9, 20/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.277037
[5/9, 21/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.281481
[5/9, 22/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.298857
[5/9, 23/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.271072
[5/9, 24/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.278599
[5/9, 25/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.256189
[5/9, 26/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.316229
[5/9, 27/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.273606
[5/9, 28/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.271132
[5/9, 29/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.290933
[5/9, 30/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.289487
[5/9, 31/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.346018
[5/9, 32/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.256661
[5/9, 33/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.259190
[5/9, 34/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.347107
[5/9, 35/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.292492
[5/9, 36/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.285610
[5/9, 37/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.270164
[5/9, 38/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.277060
[5/9, 39/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.299384
[5/9, 40/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.311287
[5/9, 41/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.327715
[5/9, 42/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.266607
[5/9, 43/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.415052
[5/9, 44/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.278115
[5/9, 45/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.245265
[5/9, 46/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.300430
[5/9, 47/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.262231
[5/9, 48/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.263207
[5/9, 49/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.292404
[5/9, 50/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.268683
[5/9, 51/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.302848
[5/9, 52/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.257670
[5/9, 53/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.271558
[5/9, 54/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.305288
[5/9, 55/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.276552
[5/9, 56/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.314710
[5/9, 57/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.279990
[5/9, 58/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.297390
[5/9, 59/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.256715
[5/9, 60/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.463050
[5/9, 61/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.327152
[5/9, 62/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.278024
[5/9, 63/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.385690
[5/9, 64/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.362861
[5/9, 65/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.371294
[5/9, 66/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.343066
[5/9, 67/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.269113
[5/9, 68/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.286484
[5/9, 69/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.280022
[5/9, 70/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.293950
[5/9, 71/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.351963
[5/9, 72/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.299849
[5/9, 73/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.275674
[5/9, 74/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.292434
[5/9, 75/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.298826
[5/9, 76/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.335609
[5/9, 77/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.254239
[5/9, 78/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.278506
[5/9, 79/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.240806
[5/9, 80/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.281475
[5/9, 81/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.330129
[5/9, 82/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.318710
[5/9, 83/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.279985
[5/9, 84/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.279517
[5/9, 85/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.288413
[5/9, 86/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.303807
[5/9, 87/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.282007
[5/9, 88/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.287971
[5/9, 89/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.297868
[5/9, 90/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.336156
[5/9, 91/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.254846
[5/9, 92/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.314734
[5/9, 93/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.265183
[5/9, 94/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.229013
Testing - 2024-06-14 14:56:45.705216
[5/9, 1/16]
[5/9, 2/16]
[5/9, 3/16]
[5/9, 4/16]
[5/9, 5/16]
[5/9, 6/16]
[5/9, 7/16]
[5/9, 8/16]
[5/9, 9/16]
[5/9, 10/16]
[5/9, 11/16]
[5/9, 12/16]
[5/9, 13/16]
[5/9, 14/16]
[5/9, 15/16]
[5/9, 16/16]
Testing Loss: 0.0497 - Epoch Time: 0:02:13.425289
Training - 2024-06-14 14:56:57.170005
[6/9, 1/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.364503
[6/9, 2/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.443344
[6/9, 3/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.409598
[6/9, 4/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.400232
[6/9, 5/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.288129
[6/9, 6/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.340667
[6/9, 7/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.338616
[6/9, 8/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.287085
[6/9, 9/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.262150
[6/9, 10/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.332229
[6/9, 11/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.303381
[6/9, 12/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.315279
[6/9, 13/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.279039
[6/9, 14/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.318750
[6/9, 15/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.291424
[6/9, 16/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.259729
[6/9, 17/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.275051
[6/9, 18/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.289445
[6/9, 19/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.267139
[6/9, 20/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.279024
[6/9, 21/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.317836
[6/9, 22/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.387740
[6/9, 23/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.292478
[6/9, 24/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.321763
[6/9, 25/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.328689
[6/9, 26/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.289003
[6/9, 27/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.308921
[6/9, 28/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.284544
[6/9, 29/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.282013
[6/9, 30/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.305348
[6/9, 31/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.282537
[6/9, 32/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.305794
[6/9, 33/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.283582
[6/9, 34/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.324673
[6/9, 35/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.255741
[6/9, 36/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.323717
[6/9, 37/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.335625
[6/9, 38/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.286543
[6/9, 39/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.342562
[6/9, 40/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.272100
[6/9, 41/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.281549
[6/9, 42/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.298002
[6/9, 43/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.296446
[6/9, 44/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.265709
[6/9, 45/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.296543
[6/9, 46/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.292023
[6/9, 47/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.256746
[6/9, 48/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.277101
[6/9, 49/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.412475
[6/9, 50/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.340161
[6/9, 51/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.450226
[6/9, 52/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.368434
[6/9, 53/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.301901
[6/9, 54/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.299492
[6/9, 55/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.294485
[6/9, 56/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.274247
[6/9, 57/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.272675
[6/9, 58/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.277115
[6/9, 59/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.346531
[6/9, 60/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.276588
[6/9, 61/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.331623
[6/9, 62/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.315773
[6/9, 63/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.266688
[6/9, 64/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.336594
[6/9, 65/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.288534
[6/9, 66/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.277599
[6/9, 67/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.384232
[6/9, 68/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.281546
[6/9, 69/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.271148
[6/9, 70/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.278138
[6/9, 71/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.286464
[6/9, 72/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.272143
[6/9, 73/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.269684
[6/9, 74/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.266177
[6/9, 75/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.272584
[6/9, 76/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.289018
[6/9, 77/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.287944
[6/9, 78/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.278584
[6/9, 79/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.295024
[6/9, 80/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.327632
[6/9, 81/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.446736
[6/9, 82/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.347581
[6/9, 83/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.388221
[6/9, 84/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.395110
[6/9, 85/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.641275
[6/9, 86/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.973160
[6/9, 87/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.950868
[6/9, 88/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.851119
[6/9, 89/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.625816
[6/9, 90/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.469567
[6/9, 91/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.462104
[6/9, 92/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.369888
[6/9, 93/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.507805
[6/9, 94/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.633864
Testing - 2024-06-14 14:59:03.859936
[6/9, 1/16]
[6/9, 2/16]
[6/9, 3/16]
[6/9, 4/16]
[6/9, 5/16]
[6/9, 6/16]
[6/9, 7/16]
[6/9, 8/16]
[6/9, 9/16]
[6/9, 10/16]
[6/9, 11/16]
[6/9, 12/16]
[6/9, 13/16]
[6/9, 14/16]
[6/9, 15/16]
[6/9, 16/16]
Testing Loss: 0.0492 - Epoch Time: 0:02:18.848984
Training - 2024-06-14 14:59:16.018989
[7/9, 1/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.305816
[7/9, 2/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.429404
[7/9, 3/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.348089
[7/9, 4/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.337676
[7/9, 5/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.368913
[7/9, 6/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.399137
[7/9, 7/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.340554
[7/9, 8/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.328700
[7/9, 9/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.339205
[7/9, 10/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.324762
[7/9, 11/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.372346
[7/9, 12/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.345044
[7/9, 13/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.361430
[7/9, 14/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.371844
[7/9, 15/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.289487
[7/9, 16/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.294479
[7/9, 17/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.266195
[7/9, 18/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.292782
[7/9, 19/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.283571
[7/9, 20/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.255767
[7/9, 21/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.266654
[7/9, 22/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.296480
[7/9, 23/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.340610
[7/9, 24/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.255804
[7/9, 25/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.269675
[7/9, 26/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.274110
[7/9, 27/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.325607
[7/9, 28/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.277091
[7/9, 29/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.310361
[7/9, 30/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.317626
[7/9, 31/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.283547
[7/9, 32/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.257290
[7/9, 33/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.269133
[7/9, 34/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.488872
[7/9, 35/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.408131
[7/9, 36/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.268655
[7/9, 37/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.373782
[7/9, 38/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.364389
[7/9, 39/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.282537
[7/9, 40/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.282588
[7/9, 41/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.255792
[7/9, 42/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.284464
[7/9, 43/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.376352
[7/9, 44/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.389706
[7/9, 45/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.332625
[7/9, 46/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.345571
[7/9, 47/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.343031
[7/9, 48/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.276524
[7/9, 49/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.278598
[7/9, 50/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.276570
[7/9, 51/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.263684
[7/9, 52/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.368482
[7/9, 53/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.285969
[7/9, 54/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.340629
[7/9, 55/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.305360
[7/9, 56/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.294395
[7/9, 57/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.284483
[7/9, 58/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.278583
[7/9, 59/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.264163
[7/9, 60/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.278042
[7/9, 61/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.285525
[7/9, 62/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.294952
[7/9, 63/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.254213
[7/9, 64/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.280039
[7/9, 65/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.288967
[7/9, 66/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.264242
[7/9, 67/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.277572
[7/9, 68/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.318772
[7/9, 69/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.259703
[7/9, 70/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.286536
[7/9, 71/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.248277
[7/9, 72/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.296924
[7/9, 73/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.279539
[7/9, 74/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.274112
[7/9, 75/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.268660
[7/9, 76/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.259760
[7/9, 77/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.268693
[7/9, 78/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.275554
[7/9, 79/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.309811
[7/9, 80/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.409135
[7/9, 81/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.489418
[7/9, 82/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.280857
[7/9, 83/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.292972
[7/9, 84/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.389273
[7/9, 85/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.338024
[7/9, 86/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.305916
[7/9, 87/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.309410
[7/9, 88/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.296478
[7/9, 89/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.436454
[7/9, 90/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.276145
[7/9, 91/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.333184
[7/9, 92/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.366018
[7/9, 93/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.290660
[7/9, 94/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.231052
Testing - 2024-06-14 15:01:19.435255
[7/9, 1/16]
[7/9, 2/16]
[7/9, 3/16]
[7/9, 4/16]
[7/9, 5/16]
[7/9, 6/16]
[7/9, 7/16]
[7/9, 8/16]
[7/9, 9/16]
[7/9, 10/16]
[7/9, 11/16]
[7/9, 12/16]
[7/9, 13/16]
[7/9, 14/16]
[7/9, 15/16]
[7/9, 16/16]
Testing Loss: 0.0459 - Epoch Time: 0:02:15.102437
Training - 2024-06-14 15:01:31.121426
[8/9, 1/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.333602
[8/9, 2/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.290495
[8/9, 3/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.274072
[8/9, 4/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.314789
[8/9, 5/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.328674
[8/9, 6/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.299398
[8/9, 7/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.268642
[8/9, 8/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.291922
[8/9, 9/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.269792
[8/9, 10/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.286981
[8/9, 11/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.263673
[8/9, 12/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.275638
[8/9, 13/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.306366
[8/9, 14/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.255324
[8/9, 15/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.280994
[8/9, 16/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.266206
[8/9, 17/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.270590
[8/9, 18/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.258242
[8/9, 19/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.279002
[8/9, 20/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.270713
[8/9, 21/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.275616
[8/9, 22/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.331143
[8/9, 23/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.325721
[8/9, 24/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.377834
[8/9, 25/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.309796
[8/9, 26/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.371913
[8/9, 27/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.398627
[8/9, 28/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.301871
[8/9, 29/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.291009
[8/9, 30/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.342601
[8/9, 31/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.325712
[8/9, 32/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.298006
[8/9, 33/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.272621
[8/9, 34/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.292382
[8/9, 35/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.271162
[8/9, 36/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.358041
[8/9, 37/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.286978
[8/9, 38/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.285550
[8/9, 39/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.388216
[8/9, 40/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.260220
[8/9, 41/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.288988
[8/9, 42/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.274140
[8/9, 43/94] Training Loss: 0.0439 - Iteration Time: 0:00:01.303418
[8/9, 44/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.291992
[8/9, 45/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.312330
[8/9, 46/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.275119
[8/9, 47/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.284545
[8/9, 48/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.266676
[8/9, 49/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.278559
[8/9, 50/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.311772
[8/9, 51/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.326688
[8/9, 52/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.298504
[8/9, 53/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.283491
[8/9, 54/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.258224
[8/9, 55/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.256187
[8/9, 56/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.262679
[8/9, 57/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.275057
[8/9, 58/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.268162
[8/9, 59/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.261625
[8/9, 60/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.260747
[8/9, 61/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.340650
[8/9, 62/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.337114
[8/9, 63/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.283563
[8/9, 64/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.354447
[8/9, 65/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.253728
[8/9, 66/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.269652
[8/9, 67/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.325673
[8/9, 68/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.272107
[8/9, 69/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.372408
[8/9, 70/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.334177
[8/9, 71/94] Training Loss: 0.0440 - Iteration Time: 0:00:01.413475
[8/9, 72/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.302946
[8/9, 73/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.373808
[8/9, 74/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.291011
[8/9, 75/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.342559
[8/9, 76/94] Training Loss: 0.0437 - Iteration Time: 0:00:01.350543
[8/9, 77/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.254235
[8/9, 78/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.279083
[8/9, 79/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.275109
[8/9, 80/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.284039
[8/9, 81/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.296461
[8/9, 82/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.261250
[8/9, 83/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.319268
[8/9, 84/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.289496
[8/9, 85/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.266626
[8/9, 86/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.285561
[8/9, 87/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.271568
[8/9, 88/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.445752
[8/9, 89/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.336246
[8/9, 90/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.249899
[8/9, 91/94] Training Loss: 0.0441 - Iteration Time: 0:00:01.266266
[8/9, 92/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.266363
[8/9, 93/94] Training Loss: 0.0439 - Iteration Time: 0:00:01.262669
[8/9, 94/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.270140
Testing - 2024-06-14 15:03:33.298627
[8/9, 1/16]
[8/9, 2/16]
[8/9, 3/16]
[8/9, 4/16]
[8/9, 5/16]
[8/9, 6/16]
[8/9, 7/16]
[8/9, 8/16]
[8/9, 9/16]
[8/9, 10/16]
[8/9, 11/16]
[8/9, 12/16]
[8/9, 13/16]
[8/9, 14/16]
[8/9, 15/16]
[8/9, 16/16]
Testing Loss: 0.0441 - Epoch Time: 0:02:13.767742
Training - 2024-06-14 15:03:44.889664
[9/9, 1/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.368932
[9/9, 2/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.350971
[9/9, 3/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.295042
[9/9, 4/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.301369
[9/9, 5/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.335119
[9/9, 6/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.264191
[9/9, 7/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.304833
[9/9, 8/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.305835
[9/9, 9/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.276079
[9/9, 10/94] Training Loss: 0.0425 - Iteration Time: 0:00:01.296962
[9/9, 11/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.289012
[9/9, 12/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.395616
[9/9, 13/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.435885
[9/9, 14/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.276127
[9/9, 15/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.307353
[9/9, 16/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.470146
[9/9, 17/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.290453
[9/9, 18/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.291008
[9/9, 19/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.354984
[9/9, 20/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.304381
[9/9, 21/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.308844
[9/9, 22/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.364931
[9/9, 23/94] Training Loss: 0.0430 - Iteration Time: 0:00:01.325221
[9/9, 24/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.266129
[9/9, 25/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.272637
[9/9, 26/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.270599
[9/9, 27/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.273129
[9/9, 28/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.286524
[9/9, 29/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.288035
[9/9, 30/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.270690
[9/9, 31/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.270128
[9/9, 32/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.265192
[9/9, 33/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.269678
[9/9, 34/94] Training Loss: 0.0433 - Iteration Time: 0:00:01.289971
[9/9, 35/94] Training Loss: 0.0414 - Iteration Time: 0:00:01.265206
[9/9, 36/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.269690
[9/9, 37/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.274558
[9/9, 38/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.260185
[9/9, 39/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.507368
[9/9, 40/94] Training Loss: 0.0431 - Iteration Time: 0:00:01.290019
[9/9, 41/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.254753
[9/9, 42/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.276106
[9/9, 43/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.287960
[9/9, 44/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.266734
[9/9, 45/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.262136
[9/9, 46/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.283087
[9/9, 47/94] Training Loss: 0.0428 - Iteration Time: 0:00:01.334168
[9/9, 48/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.305953
[9/9, 49/94] Training Loss: 0.0435 - Iteration Time: 0:00:01.329248
[9/9, 50/94] Training Loss: 0.0418 - Iteration Time: 0:00:01.257829
[9/9, 51/94] Training Loss: 0.0407 - Iteration Time: 0:00:01.303404
[9/9, 52/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.280571
[9/9, 53/94] Training Loss: 0.0413 - Iteration Time: 0:00:01.268662
[9/9, 54/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.272693
[9/9, 55/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.279066
[9/9, 56/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.300884
[9/9, 57/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.342555
[9/9, 58/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.307393
[9/9, 59/94] Training Loss: 0.0432 - Iteration Time: 0:00:01.455214
[9/9, 60/94] Training Loss: 0.0426 - Iteration Time: 0:00:01.313376
[9/9, 61/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.333633
[9/9, 62/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.347055
[9/9, 63/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.310351
[9/9, 64/94] Training Loss: 0.0424 - Iteration Time: 0:00:01.298367
[9/9, 65/94] Training Loss: 0.0429 - Iteration Time: 0:00:01.260698
[9/9, 66/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.285520
[9/9, 67/94] Training Loss: 0.0407 - Iteration Time: 0:00:01.278537
[9/9, 68/94] Training Loss: 0.0420 - Iteration Time: 0:00:01.270588
[9/9, 69/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.341705
[9/9, 70/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.312275
[9/9, 71/94] Training Loss: 0.0417 - Iteration Time: 0:00:01.296876
[9/9, 72/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.340586
[9/9, 73/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.282518
[9/9, 74/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.278100
[9/9, 75/94] Training Loss: 0.0403 - Iteration Time: 0:00:01.260681
[9/9, 76/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.285462
[9/9, 77/94] Training Loss: 0.0410 - Iteration Time: 0:00:01.265199
[9/9, 78/94] Training Loss: 0.0411 - Iteration Time: 0:00:01.285042
[9/9, 79/94] Training Loss: 0.0403 - Iteration Time: 0:00:01.302902
[9/9, 80/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.268145
[9/9, 81/94] Training Loss: 0.0416 - Iteration Time: 0:00:01.439370
[9/9, 82/94] Training Loss: 0.0405 - Iteration Time: 0:00:01.291972
[9/9, 83/94] Training Loss: 0.0408 - Iteration Time: 0:00:01.290458
[9/9, 84/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.348066
[9/9, 85/94] Training Loss: 0.0427 - Iteration Time: 0:00:01.291011
[9/9, 86/94] Training Loss: 0.0402 - Iteration Time: 0:00:01.265107
[9/9, 87/94] Training Loss: 0.0422 - Iteration Time: 0:00:01.263647
[9/9, 88/94] Training Loss: 0.0412 - Iteration Time: 0:00:01.300359
[9/9, 89/94] Training Loss: 0.0398 - Iteration Time: 0:00:01.295506
[9/9, 90/94] Training Loss: 0.0421 - Iteration Time: 0:00:01.285001
[9/9, 91/94] Training Loss: 0.0423 - Iteration Time: 0:00:01.275586
[9/9, 92/94] Training Loss: 0.0415 - Iteration Time: 0:00:01.273592
[9/9, 93/94] Training Loss: 0.0419 - Iteration Time: 0:00:01.303369
[9/9, 94/94] Training Loss: 0.0394 - Iteration Time: 0:00:01.242837
Testing - 2024-06-14 15:05:47.429341
[9/9, 1/16]
[9/9, 2/16]
[9/9, 3/16]
[9/9, 4/16]
[9/9, 5/16]
[9/9, 6/16]
[9/9, 7/16]
[9/9, 8/16]
[9/9, 9/16]
[9/9, 10/16]
[9/9, 11/16]
[9/9, 12/16]
[9/9, 13/16]
[9/9, 14/16]
[9/9, 15/16]
[9/9, 16/16]
Testing Loss: 0.0409 - Epoch Time: 0:02:14.171080
Training and Testing Finished - Time: 0:20:28.078026
Assembling test data for t-sne projection
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 4
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 4
Applying t-SNE