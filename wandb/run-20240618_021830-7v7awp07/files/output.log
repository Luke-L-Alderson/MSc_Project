Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 02:18:31.540233
Scaler Value: 0.05
Training - 2024-06-18 02:18:31.541225
[1/9, 10/94] Training Loss: 0.7043 - Iteration Time: 0:00:01.426864
[1/9, 20/94] Training Loss: 0.6812 - Iteration Time: 0:00:01.491862
[1/9, 30/94] Training Loss: 0.6698 - Iteration Time: 0:00:01.426319
[1/9, 40/94] Training Loss: 0.6625 - Iteration Time: 0:00:01.433776
[1/9, 50/94] Training Loss: 0.6537 - Iteration Time: 0:00:01.449843
[1/9, 60/94] Training Loss: 0.6453 - Iteration Time: 0:00:01.393744
[1/9, 70/94] Training Loss: 0.6353 - Iteration Time: 0:00:01.387585
[1/9, 80/94] Training Loss: 0.6334 - Iteration Time: 0:00:01.414896
[1/9, 90/94] Training Loss: 0.6265 - Iteration Time: 0:00:01.424331
Testing - 2024-06-18 02:20:48.398047
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.6126 - Epoch Time: 0:02:30.654693
Training - 2024-06-18 02:21:02.195918
[2/9, 10/94] Training Loss: 0.6253 - Iteration Time: 0:00:01.435257
[2/9, 20/94] Training Loss: 0.6128 - Iteration Time: 0:00:01.476953
[2/9, 30/94] Training Loss: 0.6057 - Iteration Time: 0:00:01.581170
[2/9, 40/94] Training Loss: 0.5972 - Iteration Time: 0:00:01.459583
[2/9, 50/94] Training Loss: 0.5901 - Iteration Time: 0:00:01.426290
[2/9, 60/94] Training Loss: 0.5880 - Iteration Time: 0:00:01.413412
[2/9, 70/94] Training Loss: 0.5807 - Iteration Time: 0:00:01.453657
[2/9, 80/94] Training Loss: 0.5702 - Iteration Time: 0:00:01.439690
[2/9, 90/94] Training Loss: 0.5675 - Iteration Time: 0:00:01.408451
Testing - 2024-06-18 02:23:18.987154
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.5533 - Epoch Time: 0:02:30.344287
Training - 2024-06-18 02:23:32.540701
[3/9, 10/94] Training Loss: 0.5574 - Iteration Time: 0:00:01.399009
[3/9, 20/94] Training Loss: 0.5522 - Iteration Time: 0:00:01.464110
[3/9, 30/94] Training Loss: 0.5416 - Iteration Time: 0:00:01.392571
[3/9, 40/94] Training Loss: 0.5374 - Iteration Time: 0:00:01.390611
[3/9, 50/94] Training Loss: 0.5311 - Iteration Time: 0:00:01.390103
[3/9, 60/94] Training Loss: 0.5244 - Iteration Time: 0:00:01.419856
[3/9, 70/94] Training Loss: 0.5165 - Iteration Time: 0:00:01.425991
[3/9, 80/94] Training Loss: 0.5131 - Iteration Time: 0:00:01.405976
[3/9, 90/94] Training Loss: 0.5067 - Iteration Time: 0:00:01.420836
Testing - 2024-06-18 02:25:48.508408
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.4963 - Epoch Time: 0:02:29.586136
Training - 2024-06-18 02:26:02.127333
[4/9, 10/94] Training Loss: 0.4987 - Iteration Time: 0:00:01.388660
[4/9, 20/94] Training Loss: 0.4987 - Iteration Time: 0:00:01.403573
[4/9, 30/94] Training Loss: 0.4937 - Iteration Time: 0:00:01.421884
[4/9, 40/94] Training Loss: 0.4887 - Iteration Time: 0:00:01.422842
[4/9, 50/94] Training Loss: 0.4825 - Iteration Time: 0:00:01.410927
[4/9, 60/94] Training Loss: 0.4755 - Iteration Time: 0:00:02.104062
[4/9, 70/94] Training Loss: 0.4743 - Iteration Time: 0:00:01.553896
[4/9, 80/94] Training Loss: 0.4704 - Iteration Time: 0:00:01.726967
[4/9, 90/94] Training Loss: 0.4649 - Iteration Time: 0:00:01.441706
Testing - 2024-06-18 02:28:23.796241
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.4557 - Epoch Time: 0:02:35.380545
Training - 2024-06-18 02:28:37.508375
[5/9, 10/94] Training Loss: 0.4568 - Iteration Time: 0:00:01.399057
[5/9, 20/94] Training Loss: 0.4560 - Iteration Time: 0:00:01.448612
[5/9, 30/94] Training Loss: 0.4496 - Iteration Time: 0:00:01.450723
[5/9, 40/94] Training Loss: 0.4470 - Iteration Time: 0:00:01.401024
[5/9, 50/94] Training Loss: 0.4413 - Iteration Time: 0:00:01.414426
[5/9, 60/94] Training Loss: 0.4328 - Iteration Time: 0:00:01.469990
[5/9, 70/94] Training Loss: 0.4271 - Iteration Time: 0:00:01.431377
[5/9, 80/94] Training Loss: 0.4183 - Iteration Time: 0:00:01.429415
[5/9, 90/94] Training Loss: 0.4165 - Iteration Time: 0:00:01.446176
Testing - 2024-06-18 02:30:53.778785
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.4099 - Epoch Time: 0:02:29.882837
Training - 2024-06-18 02:31:07.391212
[6/9, 10/94] Training Loss: 0.4123 - Iteration Time: 0:00:01.450233
[6/9, 20/94] Training Loss: 0.4094 - Iteration Time: 0:00:01.439712
[6/9, 30/94] Training Loss: 0.4081 - Iteration Time: 0:00:01.448649
[6/9, 40/94] Training Loss: 0.4070 - Iteration Time: 0:00:01.443750
[6/9, 50/94] Training Loss: 0.4044 - Iteration Time: 0:00:01.381182
[6/9, 60/94] Training Loss: 0.4015 - Iteration Time: 0:00:01.406467
[6/9, 70/94] Training Loss: 0.3990 - Iteration Time: 0:00:01.412919
[6/9, 80/94] Training Loss: 0.3959 - Iteration Time: 0:00:01.443231
[6/9, 90/94] Training Loss: 0.3932 - Iteration Time: 0:00:01.399606
Testing - 2024-06-18 02:33:23.616155
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.3820 - Epoch Time: 0:02:29.925190
Training - 2024-06-18 02:33:37.316898
[7/9, 10/94] Training Loss: 0.3867 - Iteration Time: 0:00:01.379158
[7/9, 20/94] Training Loss: 0.3849 - Iteration Time: 0:00:01.439685
[7/9, 30/94] Training Loss: 0.3824 - Iteration Time: 0:00:01.420931
[7/9, 40/94] Training Loss: 0.3786 - Iteration Time: 0:00:01.412531
[7/9, 50/94] Training Loss: 0.3771 - Iteration Time: 0:00:01.402660
[7/9, 60/94] Training Loss: 0.3722 - Iteration Time: 0:00:01.468972
[7/9, 70/94] Training Loss: 0.3743 - Iteration Time: 0:00:01.443186
[7/9, 80/94] Training Loss: 0.3711 - Iteration Time: 0:00:01.417504
[7/9, 90/94] Training Loss: 0.3700 - Iteration Time: 0:00:01.425876
Testing - 2024-06-18 02:35:53.105418
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.3608 - Epoch Time: 0:02:29.387850
Training - 2024-06-18 02:36:06.705245
[8/9, 10/94] Training Loss: 0.3685 - Iteration Time: 0:00:01.379728
[8/9, 20/94] Training Loss: 0.3650 - Iteration Time: 0:00:01.441694
[8/9, 30/94] Training Loss: 0.3637 - Iteration Time: 0:00:01.412486
[8/9, 40/94] Training Loss: 0.3623 - Iteration Time: 0:00:01.411951
[8/9, 50/94] Training Loss: 0.3616 - Iteration Time: 0:00:01.438718
[8/9, 60/94] Training Loss: 0.3606 - Iteration Time: 0:00:01.430756
[8/9, 70/94] Training Loss: 0.3593 - Iteration Time: 0:00:01.663002
[8/9, 80/94] Training Loss: 0.3586 - Iteration Time: 0:00:01.557323
[8/9, 90/94] Training Loss: 0.3559 - Iteration Time: 0:00:01.421401
Testing - 2024-06-18 02:38:23.437126
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.3505 - Epoch Time: 0:02:30.287308
Training - 2024-06-18 02:38:36.993048
[9/9, 10/94] Training Loss: 0.3529 - Iteration Time: 0:00:01.506337
[9/9, 20/94] Training Loss: 0.3523 - Iteration Time: 0:00:01.434809
[9/9, 30/94] Training Loss: 0.3519 - Iteration Time: 0:00:01.498467
[9/9, 40/94] Training Loss: 0.3494 - Iteration Time: 0:00:01.439310
[9/9, 50/94] Training Loss: 0.3489 - Iteration Time: 0:00:01.433883
[9/9, 60/94] Training Loss: 0.3500 - Iteration Time: 0:00:01.481440
[9/9, 70/94] Training Loss: 0.3463 - Iteration Time: 0:00:01.438745
[9/9, 80/94] Training Loss: 0.3431 - Iteration Time: 0:00:01.464010
[9/9, 90/94] Training Loss: 0.3448 - Iteration Time: 0:00:01.454148
Testing - 2024-06-18 02:40:54.481740
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.3374 - Epoch Time: 0:02:31.243578
Training and Testing Finished - Time: 0:22:36.696393
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0      1      2    3    4  ...   94   95   96   97   98   99
0       2  0.0  0.120  0.340  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0
1       4  0.0  0.170  0.270  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0
2       7  0.0  0.080  0.315  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0
3       3  0.0  0.080  0.215  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0
4       7  0.0  0.145  0.295  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP