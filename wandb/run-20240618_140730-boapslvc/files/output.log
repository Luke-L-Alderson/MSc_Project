Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 14:07:32.208172
Scaler Value: 0.5555555555555556
Training - 2024-06-18 14:07:32.208668
[1/9, 10/94] Training Loss: 0.5547 - Iteration Time: 0:00:01.343534
[1/9, 20/94] Training Loss: 0.5323 - Iteration Time: 0:00:01.390659
[1/9, 30/94] Training Loss: 0.5364 - Iteration Time: 0:00:01.397632
[1/9, 40/94] Training Loss: 0.5378 - Iteration Time: 0:00:01.403598
[1/9, 50/94] Training Loss: 0.5364 - Iteration Time: 0:00:01.358397
[1/9, 60/94] Training Loss: 0.5339 - Iteration Time: 0:00:01.362379
[1/9, 70/94] Training Loss: 0.5314 - Iteration Time: 0:00:01.345030
[1/9, 80/94] Training Loss: 0.5358 - Iteration Time: 0:00:01.391164
[1/9, 90/94] Training Loss: 0.5346 - Iteration Time: 0:00:01.359974
Testing - 2024-06-18 14:09:44.777836
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.5218 - Epoch Time: 0:02:25.397164
Training - 2024-06-18 14:09:57.606328
[2/9, 10/94] Training Loss: 0.5389 - Iteration Time: 0:00:01.406636
[2/9, 20/94] Training Loss: 0.5288 - Iteration Time: 0:00:01.530058
[2/9, 30/94] Training Loss: 0.5322 - Iteration Time: 0:00:01.376350
[2/9, 40/94] Training Loss: 0.5334 - Iteration Time: 0:00:01.975194
[2/9, 50/94] Training Loss: 0.5303 - Iteration Time: 0:00:01.444320
[2/9, 60/94] Training Loss: 0.5364 - Iteration Time: 0:00:01.415493
[2/9, 70/94] Training Loss: 0.5323 - Iteration Time: 0:00:01.486473
[2/9, 80/94] Training Loss: 0.5277 - Iteration Time: 0:00:01.377307
[2/9, 90/94] Training Loss: 0.5312 - Iteration Time: 0:00:01.357946
Testing - 2024-06-18 14:12:14.965748
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.5212 - Epoch Time: 0:02:30.236467
Training - 2024-06-18 14:12:27.842795
[3/9, 10/94] Training Loss: 0.5281 - Iteration Time: 0:00:01.390983
[3/9, 20/94] Training Loss: 0.5315 - Iteration Time: 0:00:01.374288
[3/9, 30/94] Training Loss: 0.5284 - Iteration Time: 0:00:01.373304
[3/9, 40/94] Training Loss: 0.5276 - Iteration Time: 0:00:01.352495
[3/9, 50/94] Training Loss: 0.5308 - Iteration Time: 0:00:01.373346
[3/9, 60/94] Training Loss: 0.5284 - Iteration Time: 0:00:01.343544
[3/9, 70/94] Training Loss: 0.5294 - Iteration Time: 0:00:01.352499
[3/9, 80/94] Training Loss: 0.5331 - Iteration Time: 0:00:01.372888
[3/9, 90/94] Training Loss: 0.5317 - Iteration Time: 0:00:01.419931
Testing - 2024-06-18 14:14:39.488128
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.5066 - Epoch Time: 0:02:24.610100
Training - 2024-06-18 14:14:52.453391
[4/9, 10/94] Training Loss: 0.5235 - Iteration Time: 0:00:01.409516
[4/9, 20/94] Training Loss: 0.5277 - Iteration Time: 0:00:01.391702
[4/9, 30/94] Training Loss: 0.5262 - Iteration Time: 0:00:01.376829
[4/9, 40/94] Training Loss: 0.5236 - Iteration Time: 0:00:01.349971
[4/9, 50/94] Training Loss: 0.5247 - Iteration Time: 0:00:01.535568
[4/9, 60/94] Training Loss: 0.5225 - Iteration Time: 0:00:01.366879
[4/9, 70/94] Training Loss: 0.5277 - Iteration Time: 0:00:01.448340
[4/9, 80/94] Training Loss: 0.5264 - Iteration Time: 0:00:01.368366
[4/9, 90/94] Training Loss: 0.5223 - Iteration Time: 0:00:01.375814
Testing - 2024-06-18 14:17:04.721911
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.5137 - Epoch Time: 0:02:25.114639
Training - 2024-06-18 14:17:17.568030
[5/9, 10/94] Training Loss: 0.5226 - Iteration Time: 0:00:01.357435
[5/9, 20/94] Training Loss: 0.5323 - Iteration Time: 0:00:01.364883
[5/9, 30/94] Training Loss: 0.5245 - Iteration Time: 0:00:01.351587
[5/9, 40/94] Training Loss: 0.5224 - Iteration Time: 0:00:01.383781
[5/9, 50/94] Training Loss: 0.5275 - Iteration Time: 0:00:01.332640
[5/9, 60/94] Training Loss: 0.5224 - Iteration Time: 0:00:01.382754
[5/9, 70/94] Training Loss: 0.5281 - Iteration Time: 0:00:01.366353
[5/9, 80/94] Training Loss: 0.5187 - Iteration Time: 0:00:01.412663
[5/9, 90/94] Training Loss: 0.5228 - Iteration Time: 0:00:01.402177
Testing - 2024-06-18 14:19:29.105729
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.5145 - Epoch Time: 0:02:24.562684
Training - 2024-06-18 14:19:42.130714
[6/9, 10/94] Training Loss: 0.5263 - Iteration Time: 0:00:01.371827
[6/9, 20/94] Training Loss: 0.5186 - Iteration Time: 0:00:01.409024
[6/9, 30/94] Training Loss: 0.5198 - Iteration Time: 0:00:01.390689
[6/9, 40/94] Training Loss: 0.5206 - Iteration Time: 0:00:01.384789
[6/9, 50/94] Training Loss: 0.5206 - Iteration Time: 0:00:01.359732
[6/9, 60/94] Training Loss: 0.5194 - Iteration Time: 0:00:01.394131
[6/9, 70/94] Training Loss: 0.5224 - Iteration Time: 0:00:01.426358
[6/9, 80/94] Training Loss: 0.5241 - Iteration Time: 0:00:01.384790
[6/9, 90/94] Training Loss: 0.5243 - Iteration Time: 0:00:01.381767
Testing - 2024-06-18 14:21:54.038630
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.5029 - Epoch Time: 0:02:25.005634
Training - 2024-06-18 14:22:07.136348
[7/9, 10/94] Training Loss: 0.5202 - Iteration Time: 0:00:01.396279
[7/9, 20/94] Training Loss: 0.5211 - Iteration Time: 0:00:01.416361
[7/9, 30/94] Training Loss: 0.5212 - Iteration Time: 0:00:01.339106
[7/9, 40/94] Training Loss: 0.5186 - Iteration Time: 0:00:01.445248
[7/9, 50/94] Training Loss: 0.5168 - Iteration Time: 0:00:01.364342
[7/9, 60/94] Training Loss: 0.5123 - Iteration Time: 0:00:01.415477
[7/9, 70/94] Training Loss: 0.5207 - Iteration Time: 0:00:01.388170
[7/9, 80/94] Training Loss: 0.5250 - Iteration Time: 0:00:01.357913
[7/9, 90/94] Training Loss: 0.5224 - Iteration Time: 0:00:01.375369
Testing - 2024-06-18 14:24:18.590573
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.5018 - Epoch Time: 0:02:24.575294
Training - 2024-06-18 14:24:31.711642
[8/9, 10/94] Training Loss: 0.5207 - Iteration Time: 0:00:01.344030
[8/9, 20/94] Training Loss: 0.5166 - Iteration Time: 0:00:01.405567
[8/9, 30/94] Training Loss: 0.5144 - Iteration Time: 0:00:01.370357
[8/9, 40/94] Training Loss: 0.5149 - Iteration Time: 0:00:01.417556
[8/9, 50/94] Training Loss: 0.5165 - Iteration Time: 0:00:01.543033
[8/9, 60/94] Training Loss: 0.5168 - Iteration Time: 0:00:01.491368
[8/9, 70/94] Training Loss: 0.5312 - Iteration Time: 0:00:01.619909
[8/9, 80/94] Training Loss: 0.5249 - Iteration Time: 0:00:01.521628
[8/9, 90/94] Training Loss: 0.5187 - Iteration Time: 0:00:01.421963
Testing - 2024-06-18 14:26:54.180638
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.5018 - Epoch Time: 0:02:36.036820
Training - 2024-06-18 14:27:07.748958
[9/9, 10/94] Training Loss: 0.5160 - Iteration Time: 0:00:01.718117
[9/9, 20/94] Training Loss: 0.5155 - Iteration Time: 0:00:01.480494
[9/9, 30/94] Training Loss: 0.5150 - Iteration Time: 0:00:01.627319
[9/9, 40/94] Training Loss: 0.5131 - Iteration Time: 0:00:01.552920
[9/9, 50/94] Training Loss: 0.5125 - Iteration Time: 0:00:01.553462
[9/9, 60/94] Training Loss: 0.5124 - Iteration Time: 0:00:01.496803
[9/9, 70/94] Training Loss: 0.5120 - Iteration Time: 0:00:01.437831
[9/9, 80/94] Training Loss: 0.5123 - Iteration Time: 0:00:01.454204
[9/9, 90/94] Training Loss: 0.5163 - Iteration Time: 0:00:01.539076
Testing - 2024-06-18 14:29:32.978756
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.4962 - Epoch Time: 0:02:38.679524
Training and Testing Finished - Time: 0:22:14.220806
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
-- 1/16 --
-- 2/16 --
-- 3/16 --
-- 4/16 --
-- 5/16 --
-- 6/16 --
-- 7/16 --
-- 8/16 --
-- 9/16 --
-- 10/16 --
-- 11/16 --
-- 12/16 --
-- 13/16 --
-- 14/16 --
-- 15/16 --
-- 16/16 --
   Labels      0    1      2      3      4  ...   94   95   96     97     98   99
0       2  0.135  0.0  0.115  0.205  0.130  ...  0.0  0.0  0.0  0.050  0.120  0.0
1       4  0.145  0.0  0.110  0.205  0.115  ...  0.0  0.0  0.0  0.045  0.115  0.0
2       7  0.140  0.0  0.120  0.205  0.125  ...  0.0  0.0  0.0  0.050  0.125  0.0
3       3  0.135  0.0  0.110  0.210  0.125  ...  0.0  0.0  0.0  0.060  0.125  0.0
4       7  0.135  0.0  0.110  0.195  0.125  ...  0.0  0.0  0.0  0.040  0.120  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP