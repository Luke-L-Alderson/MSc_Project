Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 06:57:07.423202
Scaler Value: 0.025125628140703515
Training - 2024-06-18 06:57:07.423697
[1/9, 10/94] Training Loss: 0.9076 - Iteration Time: 0:00:01.374770
[1/9, 20/94] Training Loss: 0.8532 - Iteration Time: 0:00:01.477018
[1/9, 30/94] Training Loss: 0.8254 - Iteration Time: 0:00:01.412549
[1/9, 40/94] Training Loss: 0.8083 - Iteration Time: 0:00:01.410496
[1/9, 50/94] Training Loss: 0.7897 - Iteration Time: 0:00:01.441708
[1/9, 60/94] Training Loss: 0.7788 - Iteration Time: 0:00:01.632803
[1/9, 70/94] Training Loss: 0.7662 - Iteration Time: 0:00:01.403551
[1/9, 80/94] Training Loss: 0.7563 - Iteration Time: 0:00:01.404995
[1/9, 90/94] Training Loss: 0.7454 - Iteration Time: 0:00:01.409500
Testing - 2024-06-18 06:59:23.808718
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.7386 - Epoch Time: 0:02:29.811509
Training - 2024-06-18 06:59:37.235206
[2/9, 10/94] Training Loss: 0.7303 - Iteration Time: 0:00:01.417501
[2/9, 20/94] Training Loss: 0.7207 - Iteration Time: 0:00:01.405029
[2/9, 30/94] Training Loss: 0.7140 - Iteration Time: 0:00:01.619346
[2/9, 40/94] Training Loss: 0.7084 - Iteration Time: 0:00:01.407017
[2/9, 50/94] Training Loss: 0.7024 - Iteration Time: 0:00:01.423881
[2/9, 60/94] Training Loss: 0.6953 - Iteration Time: 0:00:01.445660
[2/9, 70/94] Training Loss: 0.6907 - Iteration Time: 0:00:01.403089
[2/9, 80/94] Training Loss: 0.6859 - Iteration Time: 0:00:01.410467
[2/9, 90/94] Training Loss: 0.6791 - Iteration Time: 0:00:01.426470
Testing - 2024-06-18 07:01:53.087302
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.6741 - Epoch Time: 0:02:29.531219
Training - 2024-06-18 07:02:06.766425
[3/9, 10/94] Training Loss: 0.6680 - Iteration Time: 0:00:01.402031
[3/9, 20/94] Training Loss: 0.6605 - Iteration Time: 0:00:01.392589
[3/9, 30/94] Training Loss: 0.6535 - Iteration Time: 0:00:01.420878
[3/9, 40/94] Training Loss: 0.6477 - Iteration Time: 0:00:01.411022
[3/9, 50/94] Training Loss: 0.6421 - Iteration Time: 0:00:01.410485
[3/9, 60/94] Training Loss: 0.6359 - Iteration Time: 0:00:01.481934
[3/9, 70/94] Training Loss: 0.6303 - Iteration Time: 0:00:01.399535
[3/9, 80/94] Training Loss: 0.6248 - Iteration Time: 0:00:01.537598
[3/9, 90/94] Training Loss: 0.6150 - Iteration Time: 0:00:01.412986
Testing - 2024-06-18 07:04:22.557682
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.6108 - Epoch Time: 0:02:29.277839
Training - 2024-06-18 07:04:36.044264
[4/9, 10/94] Training Loss: 0.6027 - Iteration Time: 0:00:01.405993
[4/9, 20/94] Training Loss: 0.5972 - Iteration Time: 0:00:01.441249
[4/9, 30/94] Training Loss: 0.5937 - Iteration Time: 0:00:01.408290
[4/9, 40/94] Training Loss: 0.5905 - Iteration Time: 0:00:01.440738
[4/9, 50/94] Training Loss: 0.5874 - Iteration Time: 0:00:01.382732
[4/9, 60/94] Training Loss: 0.5850 - Iteration Time: 0:00:01.544995
[4/9, 70/94] Training Loss: 0.5814 - Iteration Time: 0:00:01.639656
[4/9, 80/94] Training Loss: 0.5765 - Iteration Time: 0:00:01.393586
[4/9, 90/94] Training Loss: 0.5722 - Iteration Time: 0:00:01.436761
Testing - 2024-06-18 07:06:53.441001
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.5702 - Epoch Time: 0:02:31.051557
Training - 2024-06-18 07:07:07.096318
[5/9, 10/94] Training Loss: 0.5668 - Iteration Time: 0:00:01.466088
[5/9, 20/94] Training Loss: 0.5627 - Iteration Time: 0:00:01.408495
[5/9, 30/94] Training Loss: 0.5609 - Iteration Time: 0:00:01.391195
[5/9, 40/94] Training Loss: 0.5584 - Iteration Time: 0:00:01.404095
[5/9, 50/94] Training Loss: 0.5541 - Iteration Time: 0:00:01.447725
[5/9, 60/94] Training Loss: 0.5512 - Iteration Time: 0:00:01.405057
[5/9, 70/94] Training Loss: 0.5435 - Iteration Time: 0:00:01.423461
[5/9, 80/94] Training Loss: 0.5372 - Iteration Time: 0:00:01.481512
[5/9, 90/94] Training Loss: 0.5297 - Iteration Time: 0:00:01.407520
Testing - 2024-06-18 07:09:22.635113
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.5287 - Epoch Time: 0:02:28.960748
Training - 2024-06-18 07:09:36.057066
[6/9, 10/94] Training Loss: 0.5226 - Iteration Time: 0:00:01.381828
[6/9, 20/94] Training Loss: 0.5196 - Iteration Time: 0:00:01.530638
[6/9, 30/94] Training Loss: 0.5175 - Iteration Time: 0:00:01.395700
[6/9, 40/94] Training Loss: 0.5140 - Iteration Time: 0:00:01.574186
[6/9, 50/94] Training Loss: 0.5101 - Iteration Time: 0:00:01.402639
[6/9, 60/94] Training Loss: 0.5052 - Iteration Time: 0:00:01.524623
[6/9, 70/94] Training Loss: 0.5004 - Iteration Time: 0:00:01.386357
[6/9, 80/94] Training Loss: 0.4983 - Iteration Time: 0:00:01.456082
[6/9, 90/94] Training Loss: 0.4931 - Iteration Time: 0:00:02.310493
Testing - 2024-06-18 07:11:50.895171
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.4916 - Epoch Time: 0:02:28.371729
Training - 2024-06-18 07:12:04.429291
[7/9, 10/94] Training Loss: 0.4896 - Iteration Time: 0:00:01.400262
[7/9, 20/94] Training Loss: 0.4886 - Iteration Time: 0:00:01.422387
[7/9, 30/94] Training Loss: 0.4856 - Iteration Time: 0:00:01.419451
[7/9, 40/94] Training Loss: 0.4840 - Iteration Time: 0:00:01.534075
[7/9, 50/94] Training Loss: 0.4820 - Iteration Time: 0:00:01.682360
[7/9, 60/94] Training Loss: 0.4816 - Iteration Time: 0:00:01.471615
[7/9, 70/94] Training Loss: 0.4803 - Iteration Time: 0:00:01.515659
[7/9, 80/94] Training Loss: 0.4788 - Iteration Time: 0:00:01.420476
[7/9, 90/94] Training Loss: 0.4779 - Iteration Time: 0:00:01.414462
Testing - 2024-06-18 07:14:25.517405
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.4787 - Epoch Time: 0:02:34.857997
Training - 2024-06-18 07:14:39.287288
[8/9, 10/94] Training Loss: 0.4771 - Iteration Time: 0:00:01.376497
[8/9, 20/94] Training Loss: 0.4746 - Iteration Time: 0:00:01.404178
[8/9, 30/94] Training Loss: 0.4724 - Iteration Time: 0:00:01.419047
[8/9, 40/94] Training Loss: 0.4696 - Iteration Time: 0:00:01.407625
[8/9, 50/94] Training Loss: 0.4675 - Iteration Time: 0:00:01.440792
[8/9, 60/94] Training Loss: 0.4653 - Iteration Time: 0:00:01.462124
[8/9, 70/94] Training Loss: 0.4629 - Iteration Time: 0:00:01.450274
[8/9, 80/94] Training Loss: 0.4593 - Iteration Time: 0:00:01.460575
[8/9, 90/94] Training Loss: 0.4581 - Iteration Time: 0:00:01.391621
Testing - 2024-06-18 07:16:54.709655
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.4585 - Epoch Time: 0:02:29.098992
Training - 2024-06-18 07:17:08.386776
[9/9, 10/94] Training Loss: 0.4564 - Iteration Time: 0:00:01.415571
[9/9, 20/94] Training Loss: 0.4552 - Iteration Time: 0:00:01.420894
[9/9, 30/94] Training Loss: 0.4535 - Iteration Time: 0:00:01.413535
[9/9, 40/94] Training Loss: 0.4528 - Iteration Time: 0:00:01.403003
[9/9, 50/94] Training Loss: 0.4516 - Iteration Time: 0:00:01.410115
[9/9, 60/94] Training Loss: 0.4516 - Iteration Time: 0:00:01.428829
[9/9, 70/94] Training Loss: 0.4499 - Iteration Time: 0:00:01.384682
[9/9, 80/94] Training Loss: 0.4482 - Iteration Time: 0:00:01.401064
[9/9, 90/94] Training Loss: 0.4449 - Iteration Time: 0:00:01.486435
Testing - 2024-06-18 07:19:24.344536
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.4423 - Epoch Time: 0:02:29.361357
Training and Testing Finished - Time: 0:22:30.325427
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels      0      1      2    3      4  ...     94     95   96     97   98   99
0       2  0.140  0.290  0.185  0.0  0.275  ...  0.335  0.280  0.0  0.075  0.0  0.0
1       4  0.085  0.410  0.205  0.0  0.440  ...  0.320  0.305  0.0  0.280  0.0  0.0
2       7  0.080  0.345  0.175  0.0  0.315  ...  0.430  0.180  0.0  0.115  0.0  0.0
3       3  0.410  0.250  0.325  0.0  0.295  ...  0.320  0.325  0.0  0.110  0.0  0.0
4       7  0.050  0.240  0.335  0.0  0.270  ...  0.360  0.260  0.0  0.090  0.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP