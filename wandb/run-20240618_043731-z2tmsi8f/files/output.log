Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 04:37:32.555260
Scaler Value: 0.05
Training - 2024-06-18 04:37:32.555756
[1/9, 10/94] Training Loss: 1.1525 - Iteration Time: 0:00:01.419966
[1/9, 20/94] Training Loss: 1.0928 - Iteration Time: 0:00:01.430013
[1/9, 30/94] Training Loss: 1.0703 - Iteration Time: 0:00:01.444899
[1/9, 40/94] Training Loss: 1.0533 - Iteration Time: 0:00:01.433865
[1/9, 50/94] Training Loss: 1.0331 - Iteration Time: 0:00:01.415520
[1/9, 60/94] Training Loss: 1.0222 - Iteration Time: 0:00:01.385283
[1/9, 70/94] Training Loss: 1.0108 - Iteration Time: 0:00:01.389752
[1/9, 80/94] Training Loss: 1.0016 - Iteration Time: 0:00:01.473065
[1/9, 90/94] Training Loss: 0.9883 - Iteration Time: 0:00:01.423913
Testing - 2024-06-18 04:39:48.743496
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 0.9651 - Epoch Time: 0:02:29.814349
Training - 2024-06-18 04:40:02.370105
[2/9, 10/94] Training Loss: 0.9725 - Iteration Time: 0:00:01.414565
[2/9, 20/94] Training Loss: 0.9564 - Iteration Time: 0:00:01.451210
[2/9, 30/94] Training Loss: 0.9428 - Iteration Time: 0:00:01.427408
[2/9, 40/94] Training Loss: 0.9295 - Iteration Time: 0:00:01.452263
[2/9, 50/94] Training Loss: 0.9115 - Iteration Time: 0:00:01.458197
[2/9, 60/94] Training Loss: 0.9071 - Iteration Time: 0:00:01.466148
[2/9, 70/94] Training Loss: 0.8973 - Iteration Time: 0:00:01.432392
[2/9, 80/94] Training Loss: 0.8854 - Iteration Time: 0:00:01.410104
[2/9, 90/94] Training Loss: 0.8780 - Iteration Time: 0:00:01.418012
Testing - 2024-06-18 04:42:19.468483
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.8603 - Epoch Time: 0:02:30.625409
Training - 2024-06-18 04:42:32.995514
[3/9, 10/94] Training Loss: 0.8598 - Iteration Time: 0:00:01.429882
[3/9, 20/94] Training Loss: 0.8535 - Iteration Time: 0:00:01.551452
[3/9, 30/94] Training Loss: 0.8420 - Iteration Time: 0:00:01.464089
[3/9, 40/94] Training Loss: 0.8357 - Iteration Time: 0:00:01.432390
[3/9, 50/94] Training Loss: 0.8254 - Iteration Time: 0:00:01.417977
[3/9, 60/94] Training Loss: 0.8062 - Iteration Time: 0:00:01.423965
[3/9, 70/94] Training Loss: 0.7891 - Iteration Time: 0:00:01.422975
[3/9, 80/94] Training Loss: 0.7838 - Iteration Time: 0:00:01.413536
[3/9, 90/94] Training Loss: 0.7773 - Iteration Time: 0:00:01.413507
Testing - 2024-06-18 04:44:49.271045
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.7662 - Epoch Time: 0:02:30.042116
Training - 2024-06-18 04:45:03.038126
[4/9, 10/94] Training Loss: 0.7682 - Iteration Time: 0:00:01.439812
[4/9, 20/94] Training Loss: 0.7608 - Iteration Time: 0:00:01.462625
[4/9, 30/94] Training Loss: 0.7468 - Iteration Time: 0:00:01.426399
[4/9, 40/94] Training Loss: 0.7356 - Iteration Time: 0:00:01.455210
[4/9, 50/94] Training Loss: 0.7296 - Iteration Time: 0:00:01.410548
[4/9, 60/94] Training Loss: 0.7203 - Iteration Time: 0:00:01.409542
[4/9, 70/94] Training Loss: 0.7142 - Iteration Time: 0:00:01.394149
[4/9, 80/94] Training Loss: 0.7061 - Iteration Time: 0:00:01.445264
[4/9, 90/94] Training Loss: 0.6953 - Iteration Time: 0:00:01.381295
Testing - 2024-06-18 04:47:18.847702
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.6872 - Epoch Time: 0:02:29.300591
Training - 2024-06-18 04:47:32.338717
[5/9, 10/94] Training Loss: 0.6871 - Iteration Time: 0:00:01.419940
[5/9, 20/94] Training Loss: 0.6823 - Iteration Time: 0:00:01.484528
[5/9, 30/94] Training Loss: 0.6715 - Iteration Time: 0:00:01.459181
[5/9, 40/94] Training Loss: 0.6672 - Iteration Time: 0:00:01.386192
[5/9, 50/94] Training Loss: 0.6628 - Iteration Time: 0:00:01.422411
[5/9, 60/94] Training Loss: 0.6582 - Iteration Time: 0:00:01.400628
[5/9, 70/94] Training Loss: 0.6509 - Iteration Time: 0:00:01.470595
[5/9, 80/94] Training Loss: 0.6448 - Iteration Time: 0:00:01.442784
[5/9, 90/94] Training Loss: 0.6431 - Iteration Time: 0:00:01.426401
Testing - 2024-06-18 04:49:48.565553
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.6328 - Epoch Time: 0:02:29.772689
Training - 2024-06-18 04:50:02.111903
[6/9, 10/94] Training Loss: 0.6336 - Iteration Time: 0:00:01.434841
[6/9, 20/94] Training Loss: 0.6253 - Iteration Time: 0:00:01.449283
[6/9, 30/94] Training Loss: 0.6218 - Iteration Time: 0:00:01.427470
[6/9, 40/94] Training Loss: 0.6200 - Iteration Time: 0:00:01.442755
[6/9, 50/94] Training Loss: 0.6154 - Iteration Time: 0:00:01.464122
[6/9, 60/94] Training Loss: 0.6114 - Iteration Time: 0:00:01.419497
[6/9, 70/94] Training Loss: 0.6099 - Iteration Time: 0:00:01.394673
[6/9, 80/94] Training Loss: 0.6064 - Iteration Time: 0:00:01.421441
[6/9, 90/94] Training Loss: 0.6030 - Iteration Time: 0:00:01.428404
Testing - 2024-06-18 04:52:18.069788
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.5884 - Epoch Time: 0:02:29.709762
Training - 2024-06-18 04:52:31.822163
[7/9, 10/94] Training Loss: 0.5933 - Iteration Time: 0:00:01.406617
[7/9, 20/94] Training Loss: 0.5897 - Iteration Time: 0:00:01.496838
[7/9, 30/94] Training Loss: 0.5852 - Iteration Time: 0:00:01.430879
[7/9, 40/94] Training Loss: 0.5769 - Iteration Time: 0:00:01.405569
[7/9, 50/94] Training Loss: 0.5714 - Iteration Time: 0:00:01.456216
[7/9, 60/94] Training Loss: 0.5659 - Iteration Time: 0:00:01.410032
[7/9, 70/94] Training Loss: 0.5633 - Iteration Time: 0:00:01.423445
[7/9, 80/94] Training Loss: 0.5591 - Iteration Time: 0:00:01.445280
[7/9, 90/94] Training Loss: 0.5546 - Iteration Time: 0:00:01.398177
Testing - 2024-06-18 04:54:47.956545
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.5446 - Epoch Time: 0:02:29.668808
Training - 2024-06-18 04:55:01.491467
[8/9, 10/94] Training Loss: 0.5474 - Iteration Time: 0:00:01.398626
[8/9, 20/94] Training Loss: 0.5393 - Iteration Time: 0:00:01.404115
[8/9, 30/94] Training Loss: 0.5362 - Iteration Time: 0:00:01.399630
[8/9, 40/94] Training Loss: 0.5353 - Iteration Time: 0:00:01.419982
[8/9, 50/94] Training Loss: 0.5316 - Iteration Time: 0:00:01.414021
[8/9, 60/94] Training Loss: 0.5287 - Iteration Time: 0:00:01.460180
[8/9, 70/94] Training Loss: 0.5266 - Iteration Time: 0:00:01.391710
[8/9, 80/94] Training Loss: 0.5261 - Iteration Time: 0:00:01.441343
[8/9, 90/94] Training Loss: 0.5239 - Iteration Time: 0:00:01.381259
Testing - 2024-06-18 04:57:16.955936
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.5180 - Epoch Time: 0:02:29.160901
Training - 2024-06-18 04:57:30.652865
[9/9, 10/94] Training Loss: 0.5196 - Iteration Time: 0:00:01.400165
[9/9, 20/94] Training Loss: 0.5162 - Iteration Time: 0:00:01.429903
[9/9, 30/94] Training Loss: 0.5149 - Iteration Time: 0:00:01.449883
[9/9, 40/94] Training Loss: 0.5102 - Iteration Time: 0:00:01.411122
[9/9, 50/94] Training Loss: 0.5069 - Iteration Time: 0:00:01.436819
[9/9, 60/94] Training Loss: 0.5057 - Iteration Time: 0:00:01.477479
[9/9, 70/94] Training Loss: 0.5016 - Iteration Time: 0:00:01.417018
[9/9, 80/94] Training Loss: 0.4972 - Iteration Time: 0:00:01.464671
[9/9, 90/94] Training Loss: 0.4967 - Iteration Time: 0:00:01.448833
Testing - 2024-06-18 04:59:46.323389
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.4867 - Epoch Time: 0:02:29.014832
Training and Testing Finished - Time: 0:22:27.112934
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0    1      2      3    4  ...     94     95   96   97     98   99
0       2  0.0  0.0  0.440  0.140  0.0  ...  0.105  0.045  0.0  0.0  0.005  0.0
1       4  0.0  0.0  0.420  0.080  0.0  ...  0.140  0.095  0.0  0.0  0.000  0.0
2       7  0.0  0.0  0.450  0.100  0.0  ...  0.120  0.175  0.0  0.0  0.000  0.0
3       3  0.0  0.0  0.370  0.210  0.0  ...  0.115  0.185  0.0  0.0  0.000  0.0
4       7  0.0  0.0  0.435  0.095  0.0  ...  0.155  0.115  0.0  0.0  0.000  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP