Starting Sweep: Batch Size: 32, Learning Rate: 0.001
Making datasets and defining subsets
Training: 60000 -> 36000
Testing: 10000 -> 6000
Making Subsets
Training: 36000
Testing: 6000
Making Dataloaders
Defining network
Training!
[1/3, 57/1125] Training Loss: 2.275870908770645
[1/3, 114/1125] Training Loss: 1.0498633175565486
[1/3, 171/1125] Training Loss: 1.0256570608992326
[1/3, 228/1125] Training Loss: 1.0403540207628619
[1/3, 285/1125] Training Loss: 1.0340029722765873
[1/3, 342/1125] Training Loss: 1.0314948485608686
[1/3, 399/1125] Training Loss: 1.0498020544386746
[1/3, 456/1125] Training Loss: 1.0349219430956924
[1/3, 513/1125] Training Loss: 1.027506733149813
[1/3, 570/1125] Training Loss: 1.026887924001928
[1/3, 627/1125] Training Loss: 0.9946811429241247
[1/3, 684/1125] Training Loss: 0.9973619956719247
[1/3, 741/1125] Training Loss: 0.990374671785455
[1/3, 798/1125] Training Loss: 0.9969786384649444
[1/3, 855/1125] Training Loss: 0.9850607211129707
[1/3, 912/1125] Training Loss: 0.9818753213213202
[1/3, 969/1125] Training Loss: 0.9496614912100005
[1/3, 1026/1125] Training Loss: 0.970380705699586
[1/3, 1083/1125] Training Loss: 0.9639860318418134
Testing!
[1/3, 1/188]
[1/3, 11/188]
[1/3, 21/188]
[1/3, 31/188]
[1/3, 41/188]
[1/3, 51/188]
[1/3, 61/188]
[1/3, 71/188]
[1/3, 81/188]
[1/3, 91/188]
[1/3, 101/188]
[1/3, 111/188]
[1/3, 121/188]
[1/3, 131/188]
[1/3, 141/188]
[1/3, 151/188]
[1/3, 161/188]
[1/3, 171/188]
[1/3, 181/188]
Testing Loss: 0.916068108458268
Training!
[2/3, 57/1125] Training Loss: 0.9518007636070251
[2/3, 114/1125] Training Loss: 0.9376895249935618
[2/3, 171/1125] Training Loss: 0.8772183144301698
[2/3, 228/1125] Training Loss: 0.76591126856051
[2/3, 285/1125] Training Loss: 0.6596556222229674
[2/3, 342/1125] Training Loss: 0.613356443873623
[2/3, 399/1125] Training Loss: 0.6033912076239001
[2/3, 456/1125] Training Loss: 0.5813089300665939
[2/3, 513/1125] Training Loss: 0.5594374276044076
[2/3, 570/1125] Training Loss: 0.5449268138199522
[2/3, 627/1125] Training Loss: 0.5092476036464959
[2/3, 684/1125] Training Loss: 0.4823727487472066
[2/3, 741/1125] Training Loss: 0.4709276692909107
[2/3, 798/1125] Training Loss: 0.4559367163139477
[2/3, 855/1125] Training Loss: 0.4463185934643996
[2/3, 912/1125] Training Loss: 0.43397345459252074
[2/3, 969/1125] Training Loss: 0.42018199437542963
[2/3, 1026/1125] Training Loss: 0.4089063641272093
[2/3, 1083/1125] Training Loss: 0.4014556517726497
Testing!
[2/3, 1/188]
[2/3, 11/188]
[2/3, 21/188]
[2/3, 31/188]
[2/3, 41/188]
[2/3, 51/188]
[2/3, 61/188]
[2/3, 71/188]
[2/3, 81/188]
[2/3, 91/188]
[2/3, 101/188]
[2/3, 111/188]
[2/3, 121/188]
[2/3, 131/188]
[2/3, 141/188]
[2/3, 151/188]
[2/3, 161/188]
[2/3, 171/188]
[2/3, 181/188]
Testing Loss: 0.6459274710008973
Training!
[3/3, 57/1125] Training Loss: 0.3896721502145131
[3/3, 114/1125] Training Loss: 0.388093875688419
[3/3, 171/1125] Training Loss: 0.3766827222548033
[3/3, 228/1125] Training Loss: 0.3786528230759135
[3/3, 285/1125] Training Loss: 0.3706909486076288
[3/3, 342/1125] Training Loss: 0.3670217922905035
[3/3, 399/1125] Training Loss: 0.3585423529148102
[3/3, 456/1125] Training Loss: 0.3582302750202647
[3/3, 513/1125] Training Loss: 0.3556701425920453
[3/3, 570/1125] Training Loss: 0.3513660906699666
[3/3, 627/1125] Training Loss: 0.3515144774788304
[3/3, 684/1125] Training Loss: 0.3483139349703203
[3/3, 741/1125] Training Loss: 0.3498880256686294
[3/3, 798/1125] Training Loss: 0.3443611755705716
[3/3, 855/1125] Training Loss: 0.34097992171321
[3/3, 912/1125] Training Loss: 0.33686963508003637
[3/3, 969/1125] Training Loss: 0.33374943440420585
[3/3, 1026/1125] Training Loss: 0.3362841940762704
[3/3, 1083/1125] Training Loss: 0.32999997389943975
Testing!
[3/3, 1/188]
[3/3, 11/188]
[3/3, 21/188]
[3/3, 31/188]
[3/3, 41/188]
[3/3, 51/188]
[3/3, 61/188]
[3/3, 71/188]
[3/3, 81/188]
[3/3, 91/188]
[3/3, 101/188]
[3/3, 111/188]
[3/3, 121/188]
[3/3, 131/188]
[3/3, 141/188]
[3/3, 151/188]
[3/3, 161/188]
[3/3, 171/188]
[3/3, 181/188]
Testing Loss: 0.5345094826660658
Training and Testing Finished
Assembling test data for t-sne projection
Batch: 1/188
Batch: 2/188
Batch: 3/188
Batch: 4/188
Batch: 5/188
Batch: 6/188
Batch: 7/188
Batch: 8/188
Batch: 9/188
Batch: 10/188
Batch: 11/188
Batch: 12/188
Batch: 13/188
Batch: 14/188
Batch: 15/188
Batch: 16/188
Batch: 17/188
Batch: 18/188
Batch: 19/188
Batch: 20/188
Batch: 21/188
Batch: 22/188
Batch: 23/188
Batch: 24/188
Batch: 25/188
Batch: 26/188
Batch: 27/188
Batch: 28/188
Batch: 29/188
Batch: 30/188
Batch: 31/188
Batch: 32/188
Batch: 33/188
Batch: 34/188
Batch: 35/188
Batch: 36/188
Batch: 37/188
Batch: 38/188
Batch: 39/188
Batch: 40/188
Batch: 41/188
Batch: 42/188
Batch: 43/188
Batch: 44/188
Batch: 45/188
Batch: 46/188
Batch: 47/188
Batch: 48/188
Batch: 49/188
Batch: 50/188
Batch: 51/188
Batch: 52/188
Batch: 53/188
Batch: 54/188
Batch: 55/188
Batch: 56/188
Batch: 57/188
Batch: 58/188
Batch: 59/188
Batch: 60/188
Batch: 61/188
Batch: 62/188
Batch: 63/188
Batch: 64/188
Batch: 65/188
Batch: 66/188
Batch: 67/188
Batch: 68/188
Batch: 69/188
Batch: 70/188
Batch: 71/188
Batch: 72/188
Batch: 73/188
Batch: 74/188
Batch: 75/188
Batch: 76/188
Batch: 77/188
Batch: 78/188
Batch: 79/188
Batch: 80/188
Batch: 81/188
Batch: 82/188
Batch: 83/188
Batch: 84/188
Batch: 85/188
Batch: 86/188
Batch: 87/188
Batch: 88/188
Batch: 89/188
Batch: 90/188
Batch: 91/188
Batch: 92/188
Batch: 93/188
Batch: 94/188
Batch: 95/188
Batch: 96/188
Batch: 97/188
Batch: 98/188
Batch: 99/188
Batch: 100/188
Batch: 101/188
Batch: 102/188
Batch: 103/188
Batch: 104/188
Batch: 105/188
Batch: 106/188
Batch: 107/188
Batch: 108/188
Batch: 109/188
Batch: 110/188
Batch: 111/188
Batch: 112/188
Batch: 113/188
Batch: 114/188
Batch: 115/188
Batch: 116/188
Batch: 117/188
Batch: 118/188
Batch: 119/188
Batch: 120/188
Batch: 121/188
Batch: 122/188
Batch: 123/188
Batch: 124/188
Batch: 125/188
Batch: 126/188
Batch: 127/188
Batch: 128/188
Batch: 129/188
Batch: 130/188
Batch: 131/188
Batch: 132/188
Batch: 133/188
Batch: 134/188
Batch: 135/188
Batch: 136/188
Batch: 137/188
Batch: 138/188
Batch: 139/188
Batch: 140/188
Batch: 141/188
Batch: 142/188
Batch: 143/188
Batch: 144/188
Batch: 145/188
Batch: 146/188
Batch: 147/188
Batch: 148/188
Batch: 149/188
Batch: 150/188
Batch: 151/188
Batch: 152/188
Batch: 153/188
Batch: 154/188
Batch: 155/188
Batch: 156/188
Batch: 157/188
Batch: 158/188
Batch: 159/188
Batch: 160/188
Batch: 161/188
Batch: 162/188
Batch: 163/188
Batch: 164/188
Batch: 165/188
Batch: 166/188
Batch: 167/188
Batch: 168/188
Batch: 169/188
Batch: 170/188
Batch: 171/188
Batch: 172/188
Batch: 173/188
Batch: 174/188
Batch: 175/188
Batch: 176/188
Batch: 177/188
Batch: 178/188
Batch: 179/188
Batch: 180/188
Batch: 181/188
Batch: 182/188
Batch: 183/188
Batch: 184/188
Batch: 185/188
Batch: 186/188
Batch: 187/188
Batch: 188/188
Features: (6000, 100)
All Labels: (6000,)
All Original Images: (6000, 28, 28)
All Reconstructed Images: (6000, 28, 28)
Applying t-SNE
Plotting Results Grid
7 added
9 added
1 added
3 added
0 added
8 added
6 added
5 added
4 added
2 added
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation