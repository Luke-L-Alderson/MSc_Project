Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 600
Testing: 10000 -> 100
Making Dataloaders
Defining network
2024-06-17 09:28:27.964098
Scaler Value: 0.013513513513513514
Training - 2024-06-17 09:28:27.964594
[1/1, 1/10] Training Loss: 4.9783 - Iteration Time: 0:00:01.820281
[1/1, 2/10] Training Loss: 5.0540 - Iteration Time: 0:00:01.394585
[1/1, 3/10] Training Loss: 5.1570 - Iteration Time: 0:00:01.448641
[1/1, 4/10] Training Loss: 5.2406 - Iteration Time: 0:00:01.435279
[1/1, 5/10] Training Loss: 5.0021 - Iteration Time: 0:00:01.418386
[1/1, 6/10] Training Loss: 5.0946 - Iteration Time: 0:00:01.474522
[1/1, 7/10] Training Loss: 5.0768 - Iteration Time: 0:00:01.413433
[1/1, 8/10] Training Loss: 5.0099 - Iteration Time: 0:00:01.445675
[1/1, 9/10] Training Loss: 4.8363 - Iteration Time: 0:00:01.671919
[1/1, 10/10] Training Loss: 5.0586 - Iteration Time: 0:00:01.755792
Testing - 2024-06-17 09:28:43.434072
[1/1, 1/2]
[1/1, 2/2]
Testing Loss: 5.0479 - Epoch Time: 0:00:17.330948
Training and Testing Finished - Time: 0:00:17.331444
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([64, 100])
-- 1/2 --
Code Layer Shape: torch.Size([36, 100])
-- 2/2 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 1
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 1
Applying t-SNE
WARNING    C:\Users\lukea\anaconda3\envs\diss\Lib\site-packages\IPython\core\pylabtools.py:152: UserWarning: Creating legend with loc="best" can be slow with large amounts of data.
  fig.canvas.print_figure(bytes_io, **kw)
