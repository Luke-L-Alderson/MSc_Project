Making Datasets...
Making Dataloaders...
Defining network...
5/5: Training network...
[1/1, 10/1875] train_loss: 32.11932735443115
[1/1, 20/1875] train_loss: 31.203403282165528
[1/1, 30/1875] train_loss: 30.939556121826172
[1/1, 40/1875] train_loss: 29.85079231262207
[1/1, 50/1875] train_loss: 29.887084770202637
[1/1, 60/1875] train_loss: 30.038125610351564
[1/1, 70/1875] train_loss: 29.3334457397461
[1/1, 80/1875] train_loss: 27.64413986206055
[1/1, 90/1875] train_loss: 28.530228996276854
[1/1, 100/1875] train_loss: 27.63791389465332
[1/1, 110/1875] train_loss: 27.847053718566897
[1/1, 120/1875] train_loss: 27.178259658813477
[1/1, 130/1875] train_loss: 26.367358207702637
[1/1, 140/1875] train_loss: 26.195853996276856
[1/1, 150/1875] train_loss: 26.15219955444336
[1/1, 160/1875] train_loss: 25.720455551147463
[1/1, 170/1875] train_loss: 26.121739006042475
[1/1, 180/1875] train_loss: 24.412654685974122
[1/1, 190/1875] train_loss: 25.16176223754883
[1/1, 200/1875] train_loss: 24.595049095153804
[1/1, 210/1875] train_loss: 24.16988182067871
[1/1, 220/1875] train_loss: 23.923034286499025
[1/1, 230/1875] train_loss: 24.044168090820314
[1/1, 240/1875] train_loss: 24.160845184326174
[1/1, 250/1875] train_loss: 23.18836059570312
[1/1, 260/1875] train_loss: 23.001773643493653
[1/1, 270/1875] train_loss: 22.56442127227783
[1/1, 280/1875] train_loss: 23.1631929397583
[1/1, 290/1875] train_loss: 22.25958957672119
[1/1, 300/1875] train_loss: 21.85519313812256
[1/1, 310/1875] train_loss: 21.69018611907959
[1/1, 320/1875] train_loss: 20.63793411254883
[1/1, 330/1875] train_loss: 20.775374031066892
[1/1, 340/1875] train_loss: 20.61063823699951
[1/1, 350/1875] train_loss: 20.249924087524413
[1/1, 360/1875] train_loss: 20.682835578918457
[1/1, 370/1875] train_loss: 20.089504623413085
[1/1, 380/1875] train_loss: 19.77349681854248
[1/1, 390/1875] train_loss: 19.792067527770996
[1/1, 400/1875] train_loss: 19.743199729919436
[1/1, 410/1875] train_loss: 19.351896667480467
[1/1, 420/1875] train_loss: 18.86864223480225
[1/1, 430/1875] train_loss: 18.411674880981444
[1/1, 440/1875] train_loss: 18.28789825439453
[1/1, 450/1875] train_loss: 17.62261619567871
[1/1, 460/1875] train_loss: 17.807764244079593
[1/1, 470/1875] train_loss: 17.58835668563843
[1/1, 480/1875] train_loss: 17.322727584838866
[1/1, 490/1875] train_loss: 17.473285675048828
[1/1, 500/1875] train_loss: 17.61278247833252
[1/1, 510/1875] train_loss: 16.84466257095337
[1/1, 520/1875] train_loss: 16.372540378570555
[1/1, 530/1875] train_loss: 16.468869209289547
[1/1, 540/1875] train_loss: 16.311610889434814
[1/1, 550/1875] train_loss: 16.353969383239747
[1/1, 560/1875] train_loss: 15.863520050048827
[1/1, 570/1875] train_loss: 16.054113101959228
[1/1, 580/1875] train_loss: 15.735383224487306
[1/1, 590/1875] train_loss: 15.553885746002198
[1/1, 600/1875] train_loss: 15.118379020690918
[1/1, 610/1875] train_loss: 15.504942417144775
[1/1, 620/1875] train_loss: 15.012894344329835
[1/1, 630/1875] train_loss: 14.689177799224852
[1/1, 640/1875] train_loss: 14.65007543563843
[1/1, 650/1875] train_loss: 14.361188316345215
[1/1, 660/1875] train_loss: 14.312384223937988
[1/1, 670/1875] train_loss: 14.064118003845214
[1/1, 680/1875] train_loss: 14.37638673782349
[1/1, 690/1875] train_loss: 13.893677902221679
[1/1, 700/1875] train_loss: 13.912419891357422
[1/1, 710/1875] train_loss: 13.786969470977782
[1/1, 720/1875] train_loss: 14.07778205871582
[1/1, 730/1875] train_loss: 13.788978481292723
[1/1, 740/1875] train_loss: 13.658115196228028
[1/1, 750/1875] train_loss: 13.257947635650634
[1/1, 760/1875] train_loss: 13.710985088348389
[1/1, 770/1875] train_loss: 13.139420890808104
[1/1, 780/1875] train_loss: 13.060438919067382
[1/1, 790/1875] train_loss: 12.961543178558347
[1/1, 800/1875] train_loss: 12.843992710113525
[1/1, 810/1875] train_loss: 12.710538673400876
[1/1, 820/1875] train_loss: 12.797911167144775
[1/1, 830/1875] train_loss: 13.00640115737915
[1/1, 840/1875] train_loss: 12.547484493255615
[1/1, 850/1875] train_loss: 12.698341560363769
[1/1, 860/1875] train_loss: 12.369367504119873
[1/1, 870/1875] train_loss: 12.23901433944702
[1/1, 880/1875] train_loss: 12.12219362258911
[1/1, 890/1875] train_loss: 11.811324024200438
[1/1, 900/1875] train_loss: 11.498285675048827
[1/1, 910/1875] train_loss: 11.780424690246583
[1/1, 920/1875] train_loss: 11.774549198150636
[1/1, 930/1875] train_loss: 11.727184104919433
[1/1, 940/1875] train_loss: 11.430930805206296
[1/1, 950/1875] train_loss: 11.422779560089111
[1/1, 960/1875] train_loss: 11.118988990783693
[1/1, 970/1875] train_loss: 11.161272048950195
[1/1, 980/1875] train_loss: 10.925219058990479
[1/1, 990/1875] train_loss: 11.006496715545653
[1/1, 1000/1875] train_loss: 10.87765054702759
[1/1, 1010/1875] train_loss: 10.982772350311278
[1/1, 1020/1875] train_loss: 10.728100776672363
[1/1, 1030/1875] train_loss: 10.513125419616701
[1/1, 1040/1875] train_loss: 10.727566719055176
[1/1, 1050/1875] train_loss: 10.5102557182312
[1/1, 1060/1875] train_loss: 10.532880115509034
[1/1, 1070/1875] train_loss: 10.656839752197266
[1/1, 1080/1875] train_loss: 10.580548286437988
[1/1, 1090/1875] train_loss: 10.34139404296875
[1/1, 1100/1875] train_loss: 10.61307373046875
[1/1, 1110/1875] train_loss: 10.433561611175538
[1/1, 1120/1875] train_loss: 10.467601776123047
[1/1, 1130/1875] train_loss: 10.206006717681884
[1/1, 1140/1875] train_loss: 10.09080400466919
[1/1, 1150/1875] train_loss: 9.856501007080077
[1/1, 1160/1875] train_loss: 9.863045883178712
[1/1, 1170/1875] train_loss: 9.770033359527588
[1/1, 1180/1875] train_loss: 9.833306503295898
[1/1, 1190/1875] train_loss: 9.698720455169678
[1/1, 1200/1875] train_loss: 9.621982383728028
[1/1, 1210/1875] train_loss: 9.629707145690919
[1/1, 1220/1875] train_loss: 9.528519439697265
[1/1, 1230/1875] train_loss: 9.540911865234376
[1/1, 1240/1875] train_loss: 9.396747398376464
[1/1, 1250/1875] train_loss: 9.37056360244751
[1/1, 1260/1875] train_loss: 9.551837348937989
[1/1, 1270/1875] train_loss: 9.402427387237548
[1/1, 1280/1875] train_loss: 9.286327838897707
[1/1, 1290/1875] train_loss: 9.186320114135741
[1/1, 1300/1875] train_loss: 9.08280029296875
[1/1, 1310/1875] train_loss: 9.278918075561524
[1/1, 1320/1875] train_loss: 9.206644344329833
[1/1, 1330/1875] train_loss: 9.108330440521241
[1/1, 1340/1875] train_loss: 8.964441013336183
[1/1, 1350/1875] train_loss: 8.820312404632569
[1/1, 1360/1875] train_loss: 8.674613094329834
[1/1, 1370/1875] train_loss: 8.6211651802063
[1/1, 1380/1875] train_loss: 8.65824680328369
[1/1, 1390/1875] train_loss: 8.76371955871582
[1/1, 1400/1875] train_loss: 8.605899047851562
[1/1, 1410/1875] train_loss: 8.480950832366943
[1/1, 1420/1875] train_loss: 8.474549388885498
[1/1, 1430/1875] train_loss: 8.48040065765381
[1/1, 1440/1875] train_loss: 8.365656566619872
[1/1, 1450/1875] train_loss: 8.400434446334838
[1/1, 1460/1875] train_loss: 8.2509286403656
[1/1, 1470/1875] train_loss: 8.313113784790039
[1/1, 1480/1875] train_loss: 7.919678544998169
[1/1, 1490/1875] train_loss: 8.09813838005066
[1/1, 1500/1875] train_loss: 8.117813158035279
[1/1, 1510/1875] train_loss: 7.963109636306762
[1/1, 1520/1875] train_loss: 8.037495851516724
[1/1, 1530/1875] train_loss: 8.165549135208131
[1/1, 1540/1875] train_loss: 8.00822286605835
[1/1, 1550/1875] train_loss: 7.978567361831665
[1/1, 1560/1875] train_loss: 8.154388427734375
[1/1, 1570/1875] train_loss: 7.91649374961853
[1/1, 1580/1875] train_loss: 7.777925491333008
[1/1, 1590/1875] train_loss: 7.776414823532105
[1/1, 1600/1875] train_loss: 7.862930393218995
[1/1, 1610/1875] train_loss: 7.662830591201781
[1/1, 1620/1875] train_loss: 7.719523048400879
[1/1, 1630/1875] train_loss: 7.623919630050658
[1/1, 1640/1875] train_loss: 7.697687959671021
[1/1, 1650/1875] train_loss: 7.571384572982788
[1/1, 1660/1875] train_loss: 7.5661589145660395
[1/1, 1670/1875] train_loss: 7.572090101242065
[1/1, 1680/1875] train_loss: 7.397082042694093
[1/1, 1690/1875] train_loss: 7.498058700561524
[1/1, 1700/1875] train_loss: 7.235550737380982
[1/1, 1710/1875] train_loss: 7.295447921752929
[1/1, 1720/1875] train_loss: 7.452128314971924
[1/1, 1730/1875] train_loss: 7.1371450424194345
[1/1, 1740/1875] train_loss: 7.129743194580078
[1/1, 1750/1875] train_loss: 7.201952981948852
[1/1, 1760/1875] train_loss: 7.080604219436645
[1/1, 1770/1875] train_loss: 7.102403402328491
[1/1, 1780/1875] train_loss: 7.006891632080078
[1/1, 1790/1875] train_loss: 7.302873611450194
[1/1, 1800/1875] train_loss: 6.921958589553833
[1/1, 1810/1875] train_loss: 6.910275650024415
[1/1, 1820/1875] train_loss: 7.021990442276001
[1/1, 1830/1875] train_loss: 6.91249189376831
[1/1, 1840/1875] train_loss: 6.834749555587768
[1/1, 1850/1875] train_loss: 6.911527299880982
[1/1, 1860/1875] train_loss: 6.795798635482788
[1/1, 1870/1875] train_loss: 6.7889108657836905
5/5: Testing network...
test_loss: 0.006256634739641183
Training Finished
tensor([9, 8, 8, 9, 3, 2, 6, 1, 5, 1, 9, 9, 6, 7, 2, 3, 2, 0, 5, 9, 0, 9, 1, 0,
        7, 9, 8, 4, 9, 2, 8, 1])
9 added
8 added
3 added
2 added
6 added
1 added
5 added
7 added
0 added
4 added