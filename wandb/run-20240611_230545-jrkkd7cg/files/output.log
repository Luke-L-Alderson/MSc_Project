Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 48000
Testing: 10000 -> 8000
Making Subsets
Training: 48000
Testing: 8000
Making Dataloaders
Defining network
2024-06-11 23:05:46.514662
Training - 2024-06-11 23:05:46.515656
[1/3, 75/750] Training Loss: 2.42 - Iteration Time: 0:00:01.205578
[1/3, 150/750] Training Loss: 1.20 - Iteration Time: 0:00:01.187228
[1/3, 225/750] Training Loss: 1.18 - Iteration Time: 0:00:01.212171
[1/3, 300/750] Training Loss: 1.14 - Iteration Time: 0:00:01.324206
[1/3, 375/750] Training Loss: 1.11 - Iteration Time: 0:00:01.235914
[1/3, 450/750] Training Loss: 1.06 - Iteration Time: 0:00:01.176389
[1/3, 525/750] Training Loss: 1.02 - Iteration Time: 0:00:01.197201
[1/3, 600/750] Training Loss: 0.96 - Iteration Time: 0:00:01.265700
[1/3, 675/750] Training Loss: 0.90 - Iteration Time: 0:00:01.227428
[1/3, 750/750] Training Loss: 0.85 - Iteration Time: 0:00:01.357890
Testing - 2024-06-11 23:21:14.153199
[1/3, 13/125]
[1/3, 26/125]
[1/3, 39/125]
[1/3, 52/125]
[1/3, 65/125]
[1/3, 78/125]
[1/3, 91/125]
[1/3, 104/125]
[1/3, 117/125]
Testing Loss: 0.80 - Epoch Time: 0:17:01.545499
Training - 2024-06-11 23:22:48.061651
[2/3, 75/750] Training Loss: 0.79 - Iteration Time: 0:00:01.197241
[2/3, 150/750] Training Loss: 0.75 - Iteration Time: 0:00:01.198206
[2/3, 225/750] Training Loss: 0.71 - Iteration Time: 0:00:01.242853
[2/3, 300/750] Training Loss: 0.67 - Iteration Time: 0:00:01.214057
[2/3, 375/750] Training Loss: 0.63 - Iteration Time: 0:00:01.246308
[2/3, 450/750] Training Loss: 0.60 - Iteration Time: 0:00:01.243358
[2/3, 525/750] Training Loss: 0.57 - Iteration Time: 0:00:01.190217
[2/3, 600/750] Training Loss: 0.55 - Iteration Time: 0:00:01.231398
[2/3, 675/750] Training Loss: 0.52 - Iteration Time: 0:00:01.235866
[2/3, 750/750] Training Loss: 0.48 - Iteration Time: 0:00:01.436752
Testing - 2024-06-11 23:38:14.785082
[2/3, 13/125]
[2/3, 26/125]
[2/3, 39/125]
[2/3, 52/125]
[2/3, 65/125]
[2/3, 78/125]
[2/3, 91/125]
[2/3, 104/125]
[2/3, 117/125]
Testing Loss: 0.45 - Epoch Time: 0:16:54.152016
Training - 2024-06-11 23:39:42.214163
[3/3, 75/750] Training Loss: 0.44 - Iteration Time: 0:00:01.191190
[3/3, 150/750] Training Loss: 0.41 - Iteration Time: 0:00:01.219462
[3/3, 225/750] Training Loss: 0.38 - Iteration Time: 0:00:01.179863
[3/3, 300/750] Training Loss: 0.36 - Iteration Time: 0:00:01.199136
[3/3, 375/750] Training Loss: 0.34 - Iteration Time: 0:00:01.204611
[3/3, 450/750] Training Loss: 0.33 - Iteration Time: 0:00:01.186713
[3/3, 525/750] Training Loss: 0.31 - Iteration Time: 0:00:01.246827
[3/3, 600/750] Training Loss: 0.30 - Iteration Time: 0:00:01.258217
[3/3, 675/750] Training Loss: 0.29 - Iteration Time: 0:00:01.178853
[3/3, 750/750] Training Loss: 0.27 - Iteration Time: 0:00:01.257239
Testing - 2024-06-11 23:55:04.101419
[3/3, 13/125]
[3/3, 26/125]
[3/3, 39/125]
[3/3, 52/125]
[3/3, 65/125]
[3/3, 78/125]
[3/3, 91/125]
[3/3, 104/125]
[3/3, 117/125]
Testing Loss: 0.27 - Epoch Time: 0:16:49.336319
Training and Testing Finished - Time: 0:50:45.036316
Assembling test data for t-sne projection
-- 10/125 --
-- 20/125 --
-- 30/125 --
-- 40/125 --
-- 50/125 --
-- 60/125 --
-- 70/125 --
-- 80/125 --
-- 90/125 --
-- 100/125 --
-- 110/125 --
-- 120/125 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation
WARNING    c:\users\lukea\documents\masters project code\msc_project\main.py:208: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig = plt.figure(facecolor="w", figsize=(10, 5))
 [py.warnings]