Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 24000
Testing: 10000 -> 4000
Making Subsets
Training: 24000
Testing: 4000
Making Dataloaders
Defining network
Training!
[1/6, 19/375] Training Loss: 8.499413465198717
[1/6, 38/375] Training Loss: 4.094816747464631
[1/6, 57/375] Training Loss: 2.1965649692635787
[1/6, 76/375] Training Loss: 1.4703665093371743
[1/6, 95/375] Training Loss: 1.1756663887124312
[1/6, 114/375] Training Loss: 1.025312470762353
[1/6, 133/375] Training Loss: 0.9103093649211683
[1/6, 152/375] Training Loss: 0.8574697532151875
[1/6, 171/375] Training Loss: 0.7568520558507819
[1/6, 190/375] Training Loss: 0.7085738684001722
[1/6, 209/375] Training Loss: 0.6741807649010106
[1/6, 228/375] Training Loss: 0.6507480803288912
[1/6, 247/375] Training Loss: 0.6234029155028494
[1/6, 266/375] Training Loss: 0.6014911689256367
[1/6, 285/375] Training Loss: 0.6014912379415411
[1/6, 304/375] Training Loss: 0.5818562695854589
[1/6, 323/375] Training Loss: 0.5624272886075472
[1/6, 342/375] Training Loss: 0.5689970474494132
[1/6, 361/375] Training Loss: 0.5507470055630332
Testing!
[1/6, 1/63]
[1/6, 5/63]
[1/6, 9/63]
[1/6, 13/63]
[1/6, 17/63]
[1/6, 21/63]
[1/6, 25/63]
[1/6, 29/63]
[1/6, 33/63]
[1/6, 37/63]
[1/6, 41/63]
[1/6, 45/63]
[1/6, 49/63]
[1/6, 53/63]
[1/6, 57/63]
[1/6, 61/63]
Testing Loss: 0.5263653206638992
Training!
[2/6, 19/375] Training Loss: 0.5395575526513552
[2/6, 38/375] Training Loss: 0.5533094013992109
[2/6, 57/375] Training Loss: 0.5531144204892611
[2/6, 76/375] Training Loss: 0.5422040537783974
[2/6, 95/375] Training Loss: 0.5330414003447482
[2/6, 114/375] Training Loss: 0.5479147230323992
[2/6, 133/375] Training Loss: 0.5297801071091702
[2/6, 152/375] Training Loss: 0.5212925013742948
[2/6, 171/375] Training Loss: 0.5156573574793967
[2/6, 190/375] Training Loss: 0.5267397290781924
[2/6, 209/375] Training Loss: 0.5172046799408762
[2/6, 228/375] Training Loss: 0.5170968802351701
[2/6, 247/375] Training Loss: 0.5270064379039564
[2/6, 266/375] Training Loss: 0.5087802802261553
[2/6, 285/375] Training Loss: 0.5173300692909643
[2/6, 304/375] Training Loss: 0.5138401922426725
[2/6, 323/375] Training Loss: 0.5067790182013261
[2/6, 342/375] Training Loss: 0.5125251522189692
[2/6, 361/375] Training Loss: 0.5219837505566446
Testing!
[2/6, 1/63]
[2/6, 5/63]
[2/6, 9/63]
[2/6, 13/63]
[2/6, 17/63]
[2/6, 21/63]
[2/6, 25/63]
[2/6, 29/63]
[2/6, 33/63]
[2/6, 37/63]
[2/6, 41/63]
[2/6, 45/63]
[2/6, 49/63]
[2/6, 53/63]
[2/6, 57/63]
[2/6, 61/63]
Testing Loss: 0.5045010128524154
Training!
[3/6, 19/375] Training Loss: 0.49582672275994955
[3/6, 38/375] Training Loss: 0.5102667416396894
[3/6, 57/375] Training Loss: 0.49216531766088384
[3/6, 76/375] Training Loss: 0.4983009476410715
[3/6, 95/375] Training Loss: 0.4943124714650606
[3/6, 114/375] Training Loss: 0.4744448316724677
[3/6, 133/375] Training Loss: 0.46560799134405034
[3/6, 152/375] Training Loss: 0.44405603408813477
[3/6, 171/375] Training Loss: 0.4331771449038857
[3/6, 190/375] Training Loss: 0.4130269336073022
[3/6, 209/375] Training Loss: 0.3872733006351872
[3/6, 228/375] Training Loss: 0.3896140722852004
[3/6, 247/375] Training Loss: 0.38051414646600423
[3/6, 266/375] Training Loss: 0.3655435615464261
[3/6, 285/375] Training Loss: 0.3632883602067044
[3/6, 304/375] Training Loss: 0.35084668115565654
[3/6, 323/375] Training Loss: 0.33481957724219874
[3/6, 342/375] Training Loss: 0.3281288633221074
[3/6, 361/375] Training Loss: 0.33121996804287557
Testing!
[3/6, 1/63]
[3/6, 5/63]
[3/6, 9/63]
[3/6, 13/63]
[3/6, 17/63]
[3/6, 21/63]
[3/6, 25/63]
[3/6, 29/63]
[3/6, 33/63]
[3/6, 37/63]
[3/6, 41/63]
[3/6, 45/63]
[3/6, 49/63]
[3/6, 53/63]
[3/6, 57/63]
[3/6, 61/63]
Testing Loss: 0.43660411875074107
Training!
[4/6, 19/375] Training Loss: 0.31575458300741094
[4/6, 38/375] Training Loss: 0.3091328724434501
[4/6, 57/375] Training Loss: 0.29836907669117574
[4/6, 76/375] Training Loss: 0.29929955852659124
[4/6, 95/375] Training Loss: 0.29445544198939677
[4/6, 114/375] Training Loss: 0.28928517981579427
[4/6, 133/375] Training Loss: 0.2803505486563632
[4/6, 152/375] Training Loss: 0.27921552720822784
[4/6, 171/375] Training Loss: 0.2775209302964963
[4/6, 190/375] Training Loss: 0.2700525663400951
[4/6, 209/375] Training Loss: 0.2694863551541379
[4/6, 228/375] Training Loss: 0.2727648537409933
[4/6, 247/375] Training Loss: 0.27250670131884125
[4/6, 266/375] Training Loss: 0.26313875850878266
[4/6, 285/375] Training Loss: 0.266164619671671
[4/6, 304/375] Training Loss: 0.2672718473170933
[4/6, 323/375] Training Loss: 0.2608528262690494
[4/6, 342/375] Training Loss: 0.24983151727601102
[4/6, 361/375] Training Loss: 0.2587893126826537
Testing!
[4/6, 1/63]
[4/6, 5/63]
[4/6, 9/63]
[4/6, 13/63]
[4/6, 17/63]
[4/6, 21/63]
[4/6, 25/63]
[4/6, 29/63]
[4/6, 33/63]
[4/6, 37/63]
[4/6, 41/63]
[4/6, 45/63]
[4/6, 49/63]
[4/6, 53/63]
[4/6, 57/63]
[4/6, 61/63]
Testing Loss: 0.3882270285394043
Training!
[5/6, 19/375] Training Loss: 0.24562591157461466
[5/6, 38/375] Training Loss: 0.25039927818273244
[5/6, 57/375] Training Loss: 0.24919334446129046
[5/6, 76/375] Training Loss: 0.24323380620856033
[5/6, 95/375] Training Loss: 0.24556668965440048
[5/6, 114/375] Training Loss: 0.24412715670309568
[5/6, 133/375] Training Loss: 0.24400875835042252
[5/6, 152/375] Training Loss: 0.24141536339333183
[5/6, 171/375] Training Loss: 0.24078384041786194
[5/6, 190/375] Training Loss: 0.23169771699528946
[5/6, 209/375] Training Loss: 0.2368214349997671
[5/6, 228/375] Training Loss: 0.24025638872071317
[5/6, 247/375] Training Loss: 0.2350762902121795
[5/6, 266/375] Training Loss: 0.2343266951410394
[5/6, 285/375] Training Loss: 0.23784013484653674
[5/6, 304/375] Training Loss: 0.2319936093531157
[5/6, 323/375] Training Loss: 0.22835301254924975
[5/6, 342/375] Training Loss: 0.22949329253874326
[5/6, 361/375] Training Loss: 0.2353651374578476
Testing!
[5/6, 1/63]
[5/6, 5/63]
[5/6, 9/63]
[5/6, 13/63]
[5/6, 17/63]
[5/6, 21/63]
[5/6, 25/63]
[5/6, 29/63]
[5/6, 33/63]
[5/6, 37/63]
[5/6, 41/63]
[5/6, 45/63]
[5/6, 49/63]
[5/6, 53/63]
[5/6, 57/63]
[5/6, 61/63]
Testing Loss: 0.35400036140345037
Training!
[6/6, 19/375] Training Loss: 0.23295398370215767
[6/6, 38/375] Training Loss: 0.2340091623758015
[6/6, 57/375] Training Loss: 0.22300834091086136
[6/6, 76/375] Training Loss: 0.22148848913217845
[6/6, 95/375] Training Loss: 0.22414452857092806
[6/6, 114/375] Training Loss: 0.22089666755575882
[6/6, 133/375] Training Loss: 0.21898674259060308
[6/6, 152/375] Training Loss: 0.22355801572925166
[6/6, 171/375] Training Loss: 0.22185074341924568
[6/6, 190/375] Training Loss: 0.22629898159127487
[6/6, 209/375] Training Loss: 0.22052945588764392
[6/6, 228/375] Training Loss: 0.2152960120063079
[6/6, 247/375] Training Loss: 0.22009936916200737
[6/6, 266/375] Training Loss: 0.21457042035303617
[6/6, 285/375] Training Loss: 0.21289517142270742
[6/6, 304/375] Training Loss: 0.21529077385601245
[6/6, 323/375] Training Loss: 0.2160194351484901
[6/6, 342/375] Training Loss: 0.21322552389220187
[6/6, 361/375] Training Loss: 0.20993851909511968
Testing!
[6/6, 1/63]
[6/6, 5/63]
[6/6, 9/63]
[6/6, 13/63]
[6/6, 17/63]
[6/6, 21/63]
[6/6, 25/63]
[6/6, 29/63]
[6/6, 33/63]
[6/6, 37/63]
[6/6, 41/63]
[6/6, 45/63]
[6/6, 49/63]
[6/6, 53/63]
[6/6, 57/63]
[6/6, 61/63]
Testing Loss: 0.32875376120985794
Training and Testing Finished
Assembling test data for t-sne projection
Batch: 1/63
Batch: 2/63
Batch: 3/63
Batch: 4/63
Batch: 5/63
Batch: 6/63
Batch: 7/63
Batch: 8/63
Batch: 9/63
Batch: 10/63
Batch: 11/63
Batch: 12/63
Batch: 13/63
Batch: 14/63
Batch: 15/63
Batch: 16/63
Batch: 17/63
Batch: 18/63
Batch: 19/63
Batch: 20/63
Batch: 21/63
Batch: 22/63
Batch: 23/63
Batch: 24/63
Batch: 25/63
Batch: 26/63
Batch: 27/63
Batch: 28/63
Batch: 29/63
Batch: 30/63
Batch: 31/63
Batch: 32/63
Batch: 33/63
Batch: 34/63
Batch: 35/63
Batch: 36/63
Batch: 37/63
Batch: 38/63
Batch: 39/63
Batch: 40/63
Batch: 41/63
Batch: 42/63
Batch: 43/63
Batch: 44/63
Batch: 45/63
Batch: 46/63
Batch: 47/63
Batch: 48/63
Batch: 49/63
Batch: 50/63
Batch: 51/63
Batch: 52/63
Batch: 53/63
Batch: 54/63
Batch: 55/63
Batch: 56/63
Batch: 57/63
Batch: 58/63
Batch: 59/63
Batch: 60/63
Batch: 61/63
Batch: 62/63
Batch: 63/63
Features: (4000, 100)
All Labels: (4000,)
All Original Images: (4000, 28, 28)
All Reconstructed Images: (4000, 28, 28)
Applying t-SNE
Plotting Results Grid
3 added
4 added
2 added
5 added
0 added
1 added
7 added
6 added
9 added
8 added
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation