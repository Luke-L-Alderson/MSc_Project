Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 36000
Testing: 10000 -> 6000
Making Subsets
Training: 36000
Testing: 6000
Making Dataloaders
Defining network
Training!
[1/3, 29/563] Training Loss: 77.05043450717268
[1/3, 58/563] Training Loss: 14.225493546189933
[1/3, 87/563] Training Loss: 3.571123616448764
[1/3, 116/563] Training Loss: 1.9208895913485824
[1/3, 145/563] Training Loss: 1.413463440434686
[1/3, 174/563] Training Loss: 1.2322875261306763
[1/3, 203/563] Training Loss: 1.0131678725111073
[1/3, 232/563] Training Loss: 0.9556708623623026
[1/3, 261/563] Training Loss: 0.8881019785486418
[1/3, 290/563] Training Loss: 0.8708656101391233
[1/3, 319/563] Training Loss: 0.859348973323559
[1/3, 348/563] Training Loss: 0.8429691031061369
[1/3, 377/563] Training Loss: 0.8466441651870464
[1/3, 406/563] Training Loss: 0.8127979184019154
[1/3, 435/563] Training Loss: 0.7967712981947537
[1/3, 464/563] Training Loss: 0.7403715417302889
[1/3, 493/563] Training Loss: 0.736829385675233
[1/3, 522/563] Training Loss: 0.7189719327564897
[1/3, 551/563] Training Loss: 0.7071354368637348
Testing!
[1/3, 1/94]
[1/3, 6/94]
[1/3, 11/94]
[1/3, 16/94]
[1/3, 21/94]
[1/3, 26/94]
[1/3, 31/94]
[1/3, 36/94]
[1/3, 41/94]
[1/3, 46/94]
[1/3, 51/94]
[1/3, 56/94]
[1/3, 61/94]
[1/3, 66/94]
[1/3, 71/94]
[1/3, 76/94]
[1/3, 81/94]
[1/3, 86/94]
[1/3, 91/94]
Testing Loss: 0.6783500081614445
Training!
[2/3, 29/563] Training Loss: 0.7039326984306862
[2/3, 58/563] Training Loss: 0.711143956102174
[2/3, 87/563] Training Loss: 0.6975915740276205
[2/3, 116/563] Training Loss: 0.6893176744724142
[2/3, 145/563] Training Loss: 0.6946175221739144
[2/3, 174/563] Training Loss: 0.6865265739375147
[2/3, 203/563] Training Loss: 0.6788933523770037
[2/3, 232/563] Training Loss: 0.6680900084561315
[2/3, 261/563] Training Loss: 0.6809962247980053
[2/3, 290/563] Training Loss: 0.6648403426696514
[2/3, 319/563] Training Loss: 0.6641998147142345
[2/3, 348/563] Training Loss: 0.6554489341275446
[2/3, 377/563] Training Loss: 0.6424862043610935
[2/3, 406/563] Training Loss: 0.6405575213761165
[2/3, 435/563] Training Loss: 0.6341441479222528
[2/3, 464/563] Training Loss: 0.6265791305180254
[2/3, 493/563] Training Loss: 0.6109965402504494
[2/3, 522/563] Training Loss: 0.6008544317607222
[2/3, 551/563] Training Loss: 0.5991382681090256
Testing!
[2/3, 1/94]
[2/3, 6/94]
[2/3, 11/94]
[2/3, 16/94]
[2/3, 21/94]
[2/3, 26/94]
[2/3, 31/94]
[2/3, 36/94]
[2/3, 41/94]
[2/3, 46/94]
[2/3, 51/94]
[2/3, 56/94]
[2/3, 61/94]
[2/3, 66/94]
[2/3, 71/94]
[2/3, 76/94]
[2/3, 81/94]
[2/3, 86/94]
[2/3, 91/94]
Testing Loss: 0.6196313478444754
Training!
[3/3, 29/563] Training Loss: 0.5856178361794044
[3/3, 58/563] Training Loss: 0.5806753923153055
[3/3, 87/563] Training Loss: 0.5765299221564983
[3/3, 116/563] Training Loss: 0.5758864561031605
[3/3, 145/563] Training Loss: 0.5493837523049322
[3/3, 174/563] Training Loss: 0.5638894973130062
[3/3, 203/563] Training Loss: 0.5494163745436175
[3/3, 232/563] Training Loss: 0.5536083938746617
[3/3, 261/563] Training Loss: 0.5420526050288101
[3/3, 290/563] Training Loss: 0.5462807889642387
[3/3, 319/563] Training Loss: 0.5425728467004053
[3/3, 348/563] Training Loss: 0.5312670078770868
[3/3, 377/563] Training Loss: 0.5314861998475832
[3/3, 406/563] Training Loss: 0.5226957130021063
[3/3, 435/563] Training Loss: 0.5127720966421324
[3/3, 464/563] Training Loss: 0.5189940405303034
[3/3, 493/563] Training Loss: 0.5099929797238317
[3/3, 522/563] Training Loss: 0.509700567557894
[3/3, 551/563] Training Loss: 0.5014050644019554
Testing!
[3/3, 1/94]
[3/3, 6/94]
[3/3, 11/94]
[3/3, 16/94]
[3/3, 21/94]
[3/3, 26/94]
[3/3, 31/94]
[3/3, 36/94]
[3/3, 41/94]
[3/3, 46/94]
[3/3, 51/94]
[3/3, 56/94]
[3/3, 61/94]
[3/3, 66/94]
[3/3, 71/94]
[3/3, 76/94]
[3/3, 81/94]
[3/3, 86/94]
[3/3, 91/94]
Testing Loss: 0.5732061225071288
Training and Testing Finished
Assembling test data for t-sne projection
Batch: 1/94
Batch: 2/94
Batch: 3/94
Batch: 4/94
Batch: 5/94
Batch: 6/94
Batch: 7/94
Batch: 8/94
Batch: 9/94
Batch: 10/94
Batch: 11/94
Batch: 12/94
Batch: 13/94
Batch: 14/94
Batch: 15/94
Batch: 16/94
Batch: 17/94
Batch: 18/94
Batch: 19/94
Batch: 20/94
Batch: 21/94
Batch: 22/94
Batch: 23/94
Batch: 24/94
Batch: 25/94
Batch: 26/94
Batch: 27/94
Batch: 28/94
Batch: 29/94
Batch: 30/94
Batch: 31/94
Batch: 32/94
Batch: 33/94
Batch: 34/94
Batch: 35/94
Batch: 36/94
Batch: 37/94
Batch: 38/94
Batch: 39/94
Batch: 40/94
Batch: 41/94
Batch: 42/94
Batch: 43/94
Batch: 44/94
Batch: 45/94
Batch: 46/94
Batch: 47/94
Batch: 48/94
Batch: 49/94
Batch: 50/94
Batch: 51/94
Batch: 52/94
Batch: 53/94
Batch: 54/94
Batch: 55/94
Batch: 56/94
Batch: 57/94
Batch: 58/94
Batch: 59/94
Batch: 60/94
Batch: 61/94
Batch: 62/94
Batch: 63/94
Batch: 64/94
Batch: 65/94
Batch: 66/94
Batch: 67/94
Batch: 68/94
Batch: 69/94
Batch: 70/94
Batch: 71/94
Batch: 72/94
Batch: 73/94
Batch: 74/94
Batch: 75/94
Batch: 76/94
Batch: 77/94
Batch: 78/94
Batch: 79/94
Batch: 80/94
Batch: 81/94
Batch: 82/94
Batch: 83/94
Batch: 84/94
Batch: 85/94
Batch: 86/94
Batch: 87/94
Batch: 88/94
Batch: 89/94
Batch: 90/94
Batch: 91/94
Batch: 92/94
Batch: 93/94
Batch: 94/94
Features: (6000, 100)
All Labels: (6000,)
All Original Images: (6000, 28, 28)
All Reconstructed Images: (6000, 28, 28)
Applying t-SNE
Plotting Results Grid
1 added
7 added
2 added
5 added
6 added
8 added
9 added
4 added
0 added
3 added
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation