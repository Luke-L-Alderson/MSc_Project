Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-15 15:59:34.204266
Scaler Value: 0.013513513513513514
Training - 2024-06-15 15:59:34.205258
[1/9, 10/94] Training Loss: 5.1778 - Iteration Time: 0:00:01.681841
[1/9, 20/94] Training Loss: 5.0454 - Iteration Time: 0:00:01.488328
[1/9, 30/94] Training Loss: 5.0680 - Iteration Time: 0:00:01.516121
[1/9, 40/94] Training Loss: 5.0818 - Iteration Time: 0:00:01.435274
[1/9, 50/94] Training Loss: 5.0419 - Iteration Time: 0:00:01.399015
[1/9, 60/94] Training Loss: 4.9736 - Iteration Time: 0:00:01.436756
[1/9, 70/94] Training Loss: 4.9183 - Iteration Time: 0:00:01.439279
[1/9, 80/94] Training Loss: 4.9392 - Iteration Time: 0:00:01.418917
[1/9, 90/94] Training Loss: 4.8915 - Iteration Time: 0:00:01.410001
Testing - 2024-06-15 16:01:57.643429
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 4.6825 - Epoch Time: 0:02:37.306263
Training - 2024-06-15 16:02:11.511521
[2/9, 10/94] Training Loss: 4.9068 - Iteration Time: 0:00:01.437260
[2/9, 20/94] Training Loss: 4.7486 - Iteration Time: 0:00:01.403038
[2/9, 30/94] Training Loss: 4.7471 - Iteration Time: 0:00:01.401542
[2/9, 40/94] Training Loss: 4.7145 - Iteration Time: 0:00:01.437747
[2/9, 50/94] Training Loss: 4.6482 - Iteration Time: 0:00:01.402496
[2/9, 60/94] Training Loss: 4.6636 - Iteration Time: 0:00:01.396068
[2/9, 70/94] Training Loss: 4.5983 - Iteration Time: 0:00:01.421879
[2/9, 80/94] Training Loss: 4.5166 - Iteration Time: 0:00:01.465028
[2/9, 90/94] Training Loss: 4.5325 - Iteration Time: 0:00:01.449191
Testing - 2024-06-15 16:04:28.663224
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 4.4064 - Epoch Time: 0:02:30.761967
Training - 2024-06-15 16:04:42.273984
[3/9, 10/94] Training Loss: 4.4659 - Iteration Time: 0:00:01.434744
[3/9, 20/94] Training Loss: 4.4857 - Iteration Time: 0:00:01.409933
[3/9, 30/94] Training Loss: 4.3884 - Iteration Time: 0:00:01.459621
[3/9, 40/94] Training Loss: 4.3829 - Iteration Time: 0:00:01.395136
[3/9, 50/94] Training Loss: 4.3673 - Iteration Time: 0:00:01.485863
[3/9, 60/94] Training Loss: 4.3128 - Iteration Time: 0:00:01.420872
[3/9, 70/94] Training Loss: 4.2229 - Iteration Time: 0:00:01.457104
[3/9, 80/94] Training Loss: 4.2389 - Iteration Time: 0:00:01.506725
[3/9, 90/94] Training Loss: 4.2140 - Iteration Time: 0:00:01.410429
Testing - 2024-06-15 16:06:59.945674
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 4.0694 - Epoch Time: 0:02:31.922140
Training - 2024-06-15 16:07:14.196621
[4/9, 10/94] Training Loss: 4.1230 - Iteration Time: 0:00:01.430235
[4/9, 20/94] Training Loss: 4.1714 - Iteration Time: 0:00:01.488355
[4/9, 30/94] Training Loss: 4.1066 - Iteration Time: 0:00:01.424840
[4/9, 40/94] Training Loss: 4.0600 - Iteration Time: 0:00:01.431800
[4/9, 50/94] Training Loss: 4.0663 - Iteration Time: 0:00:01.585156
[4/9, 60/94] Training Loss: 4.0005 - Iteration Time: 0:00:01.672500
[4/9, 70/94] Training Loss: 4.0184 - Iteration Time: 0:00:01.417447
[4/9, 80/94] Training Loss: 3.9451 - Iteration Time: 0:00:01.565229
[4/9, 90/94] Training Loss: 3.8568 - Iteration Time: 0:00:01.421368
Testing - 2024-06-15 16:09:36.276561
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 3.7805 - Epoch Time: 0:02:35.839597
Training - 2024-06-15 16:09:50.036218
[5/9, 10/94] Training Loss: 3.8194 - Iteration Time: 0:00:01.414407
[5/9, 20/94] Training Loss: 3.7985 - Iteration Time: 0:00:01.424324
[5/9, 30/94] Training Loss: 3.6962 - Iteration Time: 0:00:01.752917
[5/9, 40/94] Training Loss: 3.6776 - Iteration Time: 0:00:01.461036
[5/9, 50/94] Training Loss: 3.6740 - Iteration Time: 0:00:01.506179
[5/9, 60/94] Training Loss: 3.6542 - Iteration Time: 0:00:01.529117
[5/9, 70/94] Training Loss: 3.6319 - Iteration Time: 0:00:01.558801
[5/9, 80/94] Training Loss: 3.5521 - Iteration Time: 0:00:01.575655
[5/9, 90/94] Training Loss: 3.5467 - Iteration Time: 0:00:01.619959
Testing - 2024-06-15 16:12:17.637505
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 3.4224 - Epoch Time: 0:02:42.140615
Training - 2024-06-15 16:12:32.177328
[6/9, 10/94] Training Loss: 3.5345 - Iteration Time: 0:00:01.496278
[6/9, 20/94] Training Loss: 3.4783 - Iteration Time: 0:00:01.525576
[6/9, 30/94] Training Loss: 3.4698 - Iteration Time: 0:00:01.539506
[6/9, 40/94] Training Loss: 3.4728 - Iteration Time: 0:00:01.544415
[6/9, 50/94] Training Loss: 3.4473 - Iteration Time: 0:00:01.612899
[6/9, 60/94] Training Loss: 3.4162 - Iteration Time: 0:00:01.505715
[6/9, 70/94] Training Loss: 3.4012 - Iteration Time: 0:00:01.598974
[6/9, 80/94] Training Loss: 3.3682 - Iteration Time: 0:00:01.475930
[6/9, 90/94] Training Loss: 3.3498 - Iteration Time: 0:00:01.802448
Testing - 2024-06-15 16:15:03.132934
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 3.1357 - Epoch Time: 0:02:47.868996
Training - 2024-06-15 16:15:20.046820
[7/9, 10/94] Training Loss: 3.2835 - Iteration Time: 0:00:01.754261
[7/9, 20/94] Training Loss: 3.2564 - Iteration Time: 0:00:01.662038
[7/9, 30/94] Training Loss: 3.2363 - Iteration Time: 0:00:02.321413
[7/9, 40/94] Training Loss: 3.1773 - Iteration Time: 0:00:01.815819
[7/9, 50/94] Training Loss: 3.1393 - Iteration Time: 0:00:01.779564
[7/9, 60/94] Training Loss: 3.0480 - Iteration Time: 0:00:01.720028
[7/9, 70/94] Training Loss: 3.0773 - Iteration Time: 0:00:01.692330
[7/9, 80/94] Training Loss: 3.0472 - Iteration Time: 0:00:01.563779
[7/9, 90/94] Training Loss: 3.0260 - Iteration Time: 0:00:01.550841
Testing - 2024-06-15 16:17:58.806777
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 2.8647 - Epoch Time: 0:02:53.173933
Training - 2024-06-15 16:18:13.221249
[8/9, 10/94] Training Loss: 2.9958 - Iteration Time: 0:00:01.419926
[8/9, 20/94] Training Loss: 2.9406 - Iteration Time: 0:00:01.503730
[8/9, 30/94] Training Loss: 2.9346 - Iteration Time: 0:00:01.459075
[8/9, 40/94] Training Loss: 2.9034 - Iteration Time: 0:00:01.484381
[8/9, 50/94] Training Loss: 2.9062 - Iteration Time: 0:00:01.428796
[8/9, 60/94] Training Loss: 2.9096 - Iteration Time: 0:00:01.425890
[8/9, 70/94] Training Loss: 2.8827 - Iteration Time: 0:00:01.434780
[8/9, 80/94] Training Loss: 2.8747 - Iteration Time: 0:00:01.447666
[8/9, 90/94] Training Loss: 2.8572 - Iteration Time: 0:00:01.439737
Testing - 2024-06-15 16:20:33.207979
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 2.7556 - Epoch Time: 0:02:33.736478
Training - 2024-06-15 16:20:46.957727
[9/9, 10/94] Training Loss: 2.8354 - Iteration Time: 0:00:01.644176
[9/9, 20/94] Training Loss: 2.8297 - Iteration Time: 0:00:01.414970
[9/9, 30/94] Training Loss: 2.8147 - Iteration Time: 0:00:01.422885
[9/9, 40/94] Training Loss: 2.7671 - Iteration Time: 0:00:01.463031
[9/9, 50/94] Training Loss: 2.7387 - Iteration Time: 0:00:01.588047
[9/9, 60/94] Training Loss: 2.7556 - Iteration Time: 0:00:01.429838
[9/9, 70/94] Training Loss: 2.7205 - Iteration Time: 0:00:01.501468
[9/9, 80/94] Training Loss: 2.6774 - Iteration Time: 0:00:01.715602
[9/9, 90/94] Training Loss: 2.7346 - Iteration Time: 0:00:01.898136
Testing - 2024-06-15 16:23:09.176430
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 2.5872 - Epoch Time: 0:02:36.590108
Training and Testing Finished - Time: 0:23:49.344065
Assembling test data for t-sne projection
-- 1/16 --
-- 2/16 --
-- 3/16 --
-- 4/16 --
-- 5/16 --
-- 6/16 --
-- 7/16 --
-- 8/16 --
-- 9/16 --
-- 10/16 --
-- 11/16 --
-- 12/16 --
-- 13/16 --
-- 14/16 --
-- 15/16 --
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying t-SNE
WARNING    C:\Users\lukea\anaconda3\envs\diss\Lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(
 [py.warnings]
  File "C:\Users\lukea\anaconda3\envs\diss\Lib\site-packages\joblib\externals\loky\backend\context.py", line 282, in _count_physical_cores
    raise ValueError(f"found {cpu_count_physical} physical cores < 1")