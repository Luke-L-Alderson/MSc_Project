Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 05:24:10.932621
Scaler Value: 0.05
Training - 2024-06-18 05:24:10.933613
[1/9, 10/94] Training Loss: 1.3834 - Iteration Time: 0:00:01.484940
[1/9, 20/94] Training Loss: 1.3133 - Iteration Time: 0:00:01.409494
[1/9, 30/94] Training Loss: 1.2732 - Iteration Time: 0:00:01.442222
[1/9, 40/94] Training Loss: 1.2462 - Iteration Time: 0:00:01.422883
[1/9, 50/94] Training Loss: 1.2239 - Iteration Time: 0:00:01.408560
[1/9, 60/94] Training Loss: 1.2032 - Iteration Time: 0:00:01.411971
[1/9, 70/94] Training Loss: 1.1833 - Iteration Time: 0:00:01.411004
[1/9, 80/94] Training Loss: 1.1634 - Iteration Time: 0:00:01.408001
[1/9, 90/94] Training Loss: 1.1513 - Iteration Time: 0:00:01.394188
Testing - 2024-06-18 05:26:27.026110
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 1.1447 - Epoch Time: 0:02:29.840371
Training - 2024-06-18 05:26:40.774480
[2/9, 10/94] Training Loss: 1.1323 - Iteration Time: 0:00:01.426981
[2/9, 20/94] Training Loss: 1.1239 - Iteration Time: 0:00:01.421396
[2/9, 30/94] Training Loss: 1.1131 - Iteration Time: 0:00:01.404530
[2/9, 40/94] Training Loss: 1.1014 - Iteration Time: 0:00:01.442306
[2/9, 50/94] Training Loss: 1.0923 - Iteration Time: 0:00:01.429492
[2/9, 60/94] Training Loss: 1.0858 - Iteration Time: 0:00:01.424403
[2/9, 70/94] Training Loss: 1.0739 - Iteration Time: 0:00:01.398565
[2/9, 80/94] Training Loss: 1.0578 - Iteration Time: 0:00:01.395127
[2/9, 90/94] Training Loss: 1.0402 - Iteration Time: 0:00:01.427914
Testing - 2024-06-18 05:28:57.180757
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 1.0284 - Epoch Time: 0:02:30.127319
Training - 2024-06-18 05:29:10.902295
[3/9, 10/94] Training Loss: 1.0174 - Iteration Time: 0:00:01.429841
[3/9, 20/94] Training Loss: 1.0075 - Iteration Time: 0:00:01.390706
[3/9, 30/94] Training Loss: 1.0020 - Iteration Time: 0:00:01.460619
[3/9, 40/94] Training Loss: 0.9938 - Iteration Time: 0:00:01.419428
[3/9, 50/94] Training Loss: 0.9838 - Iteration Time: 0:00:01.474494
[3/9, 60/94] Training Loss: 0.9736 - Iteration Time: 0:00:01.633848
[3/9, 70/94] Training Loss: 0.9603 - Iteration Time: 0:00:01.457646
[3/9, 80/94] Training Loss: 0.9507 - Iteration Time: 0:00:01.410501
[3/9, 90/94] Training Loss: 0.9452 - Iteration Time: 0:00:01.394661
Testing - 2024-06-18 05:31:27.232763
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.9424 - Epoch Time: 0:02:29.791855
Training - 2024-06-18 05:31:40.694150
[4/9, 10/94] Training Loss: 0.9347 - Iteration Time: 0:00:01.434883
[4/9, 20/94] Training Loss: 0.9257 - Iteration Time: 0:00:01.398659
[4/9, 30/94] Training Loss: 0.9160 - Iteration Time: 0:00:01.404090
[4/9, 40/94] Training Loss: 0.9060 - Iteration Time: 0:00:01.402089
[4/9, 50/94] Training Loss: 0.8930 - Iteration Time: 0:00:01.404039
[4/9, 60/94] Training Loss: 0.8834 - Iteration Time: 0:00:01.416950
[4/9, 70/94] Training Loss: 0.8757 - Iteration Time: 0:00:01.405120
[4/9, 80/94] Training Loss: 0.8685 - Iteration Time: 0:00:01.467070
[4/9, 90/94] Training Loss: 0.8592 - Iteration Time: 0:00:01.396185
Testing - 2024-06-18 05:33:56.525713
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.8549 - Epoch Time: 0:02:29.494700
Training - 2024-06-18 05:34:10.188850
[5/9, 10/94] Training Loss: 0.8478 - Iteration Time: 0:00:01.404020
[5/9, 20/94] Training Loss: 0.8406 - Iteration Time: 0:00:01.406048
[5/9, 30/94] Training Loss: 0.8353 - Iteration Time: 0:00:01.415511
[5/9, 40/94] Training Loss: 0.8274 - Iteration Time: 0:00:01.426415
[5/9, 50/94] Training Loss: 0.8229 - Iteration Time: 0:00:01.434292
[5/9, 60/94] Training Loss: 0.8203 - Iteration Time: 0:00:01.406497
[5/9, 70/94] Training Loss: 0.8124 - Iteration Time: 0:00:01.391237
[5/9, 80/94] Training Loss: 0.8043 - Iteration Time: 0:00:01.452249
[5/9, 90/94] Training Loss: 0.7964 - Iteration Time: 0:00:01.477569
Testing - 2024-06-18 05:36:26.627247
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.7948 - Epoch Time: 0:02:29.881720
Training - 2024-06-18 05:36:40.070570
[6/9, 10/94] Training Loss: 0.7881 - Iteration Time: 0:00:01.404115
[6/9, 20/94] Training Loss: 0.7817 - Iteration Time: 0:00:01.437420
[6/9, 30/94] Training Loss: 0.7745 - Iteration Time: 0:00:01.434565
[6/9, 40/94] Training Loss: 0.7690 - Iteration Time: 0:00:01.425895
[6/9, 50/94] Training Loss: 0.7649 - Iteration Time: 0:00:01.620385
[6/9, 60/94] Training Loss: 0.7604 - Iteration Time: 0:00:01.494395
[6/9, 70/94] Training Loss: 0.7580 - Iteration Time: 0:00:01.477002
[6/9, 80/94] Training Loss: 0.7547 - Iteration Time: 0:00:01.498345
[6/9, 90/94] Training Loss: 0.7486 - Iteration Time: 0:00:01.405537
Testing - 2024-06-18 05:39:01.759807
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.7502 - Epoch Time: 0:02:35.305485
Training - 2024-06-18 05:39:15.376055
[7/9, 10/94] Training Loss: 0.7444 - Iteration Time: 0:00:01.422491
[7/9, 20/94] Training Loss: 0.7404 - Iteration Time: 0:00:01.425870
[7/9, 30/94] Training Loss: 0.7371 - Iteration Time: 0:00:01.418522
[7/9, 40/94] Training Loss: 0.7347 - Iteration Time: 0:00:01.412581
[7/9, 50/94] Training Loss: 0.7298 - Iteration Time: 0:00:01.470607
[7/9, 60/94] Training Loss: 0.7263 - Iteration Time: 0:00:01.429854
[7/9, 70/94] Training Loss: 0.7200 - Iteration Time: 0:00:01.408133
[7/9, 80/94] Training Loss: 0.7137 - Iteration Time: 0:00:01.418997
[7/9, 90/94] Training Loss: 0.7070 - Iteration Time: 0:00:01.448761
Testing - 2024-06-18 05:41:31.672705
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.7047 - Epoch Time: 0:02:29.710427
Training - 2024-06-18 05:41:45.086482
[8/9, 10/94] Training Loss: 0.7011 - Iteration Time: 0:00:01.452819
[8/9, 20/94] Training Loss: 0.6971 - Iteration Time: 0:00:01.445812
[8/9, 30/94] Training Loss: 0.6942 - Iteration Time: 0:00:01.435795
[8/9, 40/94] Training Loss: 0.6897 - Iteration Time: 0:00:01.395107
[8/9, 50/94] Training Loss: 0.6880 - Iteration Time: 0:00:01.403126
[8/9, 60/94] Training Loss: 0.6848 - Iteration Time: 0:00:01.427489
[8/9, 70/94] Training Loss: 0.6803 - Iteration Time: 0:00:01.542032
[8/9, 80/94] Training Loss: 0.6719 - Iteration Time: 0:00:01.433439
[8/9, 90/94] Training Loss: 0.6693 - Iteration Time: 0:00:01.616936
Testing - 2024-06-18 05:44:01.602335
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.6669 - Epoch Time: 0:02:30.126115
Training - 2024-06-18 05:44:15.213094
[9/9, 10/94] Training Loss: 0.6640 - Iteration Time: 0:00:01.481810
[9/9, 20/94] Training Loss: 0.6618 - Iteration Time: 0:00:01.401172
[9/9, 30/94] Training Loss: 0.6584 - Iteration Time: 0:00:01.405061
[9/9, 40/94] Training Loss: 0.6534 - Iteration Time: 0:00:01.411087
[9/9, 50/94] Training Loss: 0.6538 - Iteration Time: 0:00:01.518168
[9/9, 60/94] Training Loss: 0.6519 - Iteration Time: 0:00:01.407153
[9/9, 70/94] Training Loss: 0.6469 - Iteration Time: 0:00:01.391745
[9/9, 80/94] Training Loss: 0.6376 - Iteration Time: 0:00:01.406599
[9/9, 90/94] Training Loss: 0.6295 - Iteration Time: 0:00:01.409530
Testing - 2024-06-18 05:46:30.983408
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.6302 - Epoch Time: 0:02:29.240832
Training and Testing Finished - Time: 0:22:33.521305
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0    1      2      3    4  ...     94   95   96   97   98   99
0       2  0.0  0.0  0.140  0.165  0.0  ...  0.085  0.0  0.0  0.0  0.0  0.0
1       4  0.0  0.0  0.175  0.230  0.0  ...  0.105  0.0  0.0  0.0  0.0  0.0
2       7  0.0  0.0  0.115  0.160  0.0  ...  0.115  0.0  0.0  0.0  0.0  0.0
3       3  0.0  0.0  0.205  0.050  0.0  ...  0.115  0.0  0.0  0.0  0.0  0.0
4       7  0.0  0.0  0.160  0.195  0.0  ...  0.095  0.0  0.0  0.0  0.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP