Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-17 16:27:30.564803
Scaler Value: 0.025125628140703515
Training - 2024-06-17 16:27:30.565796
[1/9, 10/94] Training Loss: 13.4149 - Iteration Time: 0:00:01.479469
[1/9, 20/94] Training Loss: 13.0380 - Iteration Time: 0:00:01.504220
[1/9, 30/94] Training Loss: 13.0076 - Iteration Time: 0:00:01.484882
[1/9, 40/94] Training Loss: 12.9718 - Iteration Time: 0:00:01.470978
[1/9, 50/94] Training Loss: 12.7689 - Iteration Time: 0:00:01.427528
[1/9, 60/94] Training Loss: 12.5329 - Iteration Time: 0:00:01.432797
[1/9, 70/94] Training Loss: 12.2482 - Iteration Time: 0:00:01.439743
[1/9, 80/94] Training Loss: 12.1850 - Iteration Time: 0:00:01.389071
[1/9, 90/94] Training Loss: 11.9319 - Iteration Time: 0:00:01.413978
Testing - 2024-06-17 16:29:48.959325
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 11.3715 - Epoch Time: 0:02:31.888910
Training - 2024-06-17 16:30:02.454706
[2/9, 10/94] Training Loss: 11.8372 - Iteration Time: 0:00:01.409445
[2/9, 20/94] Training Loss: 11.4053 - Iteration Time: 0:00:01.395033
[2/9, 30/94] Training Loss: 11.2562 - Iteration Time: 0:00:01.389637
[2/9, 40/94] Training Loss: 11.0630 - Iteration Time: 0:00:01.410496
[2/9, 50/94] Training Loss: 10.8395 - Iteration Time: 0:00:01.525038
[2/9, 60/94] Training Loss: 10.7804 - Iteration Time: 0:00:01.386634
[2/9, 70/94] Training Loss: 10.4968 - Iteration Time: 0:00:01.445670
[2/9, 80/94] Training Loss: 10.2815 - Iteration Time: 0:00:01.387648
[2/9, 90/94] Training Loss: 10.2360 - Iteration Time: 0:00:01.408003
Testing - 2024-06-17 16:32:16.804926
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 9.8493 - Epoch Time: 0:02:27.590609
Training - 2024-06-17 16:32:30.045811
[3/9, 10/94] Training Loss: 9.9793 - Iteration Time: 0:00:01.429744
[3/9, 20/94] Training Loss: 9.9742 - Iteration Time: 0:00:01.420347
[3/9, 30/94] Training Loss: 9.6840 - Iteration Time: 0:00:01.463821
[3/9, 40/94] Training Loss: 9.6538 - Iteration Time: 0:00:01.401566
[3/9, 50/94] Training Loss: 9.6025 - Iteration Time: 0:00:01.564241
[3/9, 60/94] Training Loss: 9.4388 - Iteration Time: 0:00:01.745799
[3/9, 70/94] Training Loss: 9.2726 - Iteration Time: 0:00:01.639878
[3/9, 80/94] Training Loss: 9.2724 - Iteration Time: 0:00:01.531468
[3/9, 90/94] Training Loss: 9.1893 - Iteration Time: 0:00:01.523552
Testing - 2024-06-17 16:34:52.809013
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 8.8658 - Epoch Time: 0:02:37.546768
Training - 2024-06-17 16:35:07.593075
[4/9, 10/94] Training Loss: 8.9075 - Iteration Time: 0:00:01.505257
[4/9, 20/94] Training Loss: 8.9669 - Iteration Time: 0:00:01.525662
[4/9, 30/94] Training Loss: 8.8161 - Iteration Time: 0:00:01.512135
[4/9, 40/94] Training Loss: 8.6828 - Iteration Time: 0:00:01.540462
[4/9, 50/94] Training Loss: 8.6630 - Iteration Time: 0:00:01.548582
[4/9, 60/94] Training Loss: 8.5279 - Iteration Time: 0:00:01.557939
[4/9, 70/94] Training Loss: 8.6037 - Iteration Time: 0:00:01.566372
[4/9, 80/94] Training Loss: 8.4870 - Iteration Time: 0:00:01.584135
[4/9, 90/94] Training Loss: 8.3536 - Iteration Time: 0:00:01.472976
Testing - 2024-06-17 16:37:35.042646
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 8.1769 - Epoch Time: 0:02:41.790445
Training - 2024-06-17 16:37:49.384016
[5/9, 10/94] Training Loss: 8.2672 - Iteration Time: 0:00:01.492381
[5/9, 20/94] Training Loss: 8.2332 - Iteration Time: 0:00:01.466016
[5/9, 30/94] Training Loss: 8.0441 - Iteration Time: 0:00:01.512249
[5/9, 40/94] Training Loss: 8.0433 - Iteration Time: 0:00:01.474884
[5/9, 50/94] Training Loss: 8.0649 - Iteration Time: 0:00:01.591561
[5/9, 60/94] Training Loss: 7.9428 - Iteration Time: 0:00:01.376249
[5/9, 70/94] Training Loss: 7.8816 - Iteration Time: 0:00:01.403034
[5/9, 80/94] Training Loss: 7.6999 - Iteration Time: 0:00:01.429311
[5/9, 90/94] Training Loss: 7.6552 - Iteration Time: 0:00:01.539966
Testing - 2024-06-17 16:40:07.558832
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 7.3961 - Epoch Time: 0:02:31.669792
Training - 2024-06-17 16:40:21.054304
[6/9, 10/94] Training Loss: 7.6088 - Iteration Time: 0:00:01.410489
[6/9, 20/94] Training Loss: 7.4833 - Iteration Time: 0:00:01.450655
[6/9, 30/94] Training Loss: 7.4594 - Iteration Time: 0:00:01.426313
[6/9, 40/94] Training Loss: 7.4192 - Iteration Time: 0:00:01.411460
[6/9, 50/94] Training Loss: 7.3690 - Iteration Time: 0:00:01.397070
[6/9, 60/94] Training Loss: 7.2900 - Iteration Time: 0:00:01.426289
[6/9, 70/94] Training Loss: 7.2641 - Iteration Time: 0:00:01.471502
[6/9, 80/94] Training Loss: 7.1995 - Iteration Time: 0:00:01.445665
[6/9, 90/94] Training Loss: 7.1788 - Iteration Time: 0:00:01.410992
Testing - 2024-06-17 16:42:35.507192
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 6.7814 - Epoch Time: 0:02:27.666242
Training - 2024-06-17 16:42:48.721041
[7/9, 10/94] Training Loss: 7.0035 - Iteration Time: 0:00:01.565755
[7/9, 20/94] Training Loss: 6.9980 - Iteration Time: 0:00:01.402571
[7/9, 30/94] Training Loss: 6.9642 - Iteration Time: 0:00:01.398152
[7/9, 40/94] Training Loss: 6.8433 - Iteration Time: 0:00:01.402032
[7/9, 50/94] Training Loss: 6.7689 - Iteration Time: 0:00:01.406451
[7/9, 60/94] Training Loss: 6.5697 - Iteration Time: 0:00:01.523076
[7/9, 70/94] Training Loss: 6.6400 - Iteration Time: 0:00:01.355979
[7/9, 80/94] Training Loss: 6.5527 - Iteration Time: 0:00:01.379659
[7/9, 90/94] Training Loss: 6.5231 - Iteration Time: 0:00:01.431818
Testing - 2024-06-17 16:45:02.939561
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 6.1904 - Epoch Time: 0:02:27.639805
Training - 2024-06-17 16:45:16.361342
[8/9, 10/94] Training Loss: 6.4681 - Iteration Time: 0:00:01.397062
[8/9, 20/94] Training Loss: 6.2964 - Iteration Time: 0:00:01.396552
[8/9, 30/94] Training Loss: 6.2817 - Iteration Time: 0:00:01.906572
[8/9, 40/94] Training Loss: 6.1833 - Iteration Time: 0:00:01.446205
[8/9, 50/94] Training Loss: 6.1445 - Iteration Time: 0:00:01.446712
[8/9, 60/94] Training Loss: 6.0881 - Iteration Time: 0:00:01.472959
[8/9, 70/94] Training Loss: 6.0183 - Iteration Time: 0:00:01.489806
[8/9, 80/94] Training Loss: 6.0077 - Iteration Time: 0:00:01.457684
[8/9, 90/94] Training Loss: 5.9379 - Iteration Time: 0:00:01.393602
Testing - 2024-06-17 16:47:35.424005
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 5.8518 - Epoch Time: 0:02:32.441283
Training - 2024-06-17 16:47:48.802625
[9/9, 10/94] Training Loss: 5.9066 - Iteration Time: 0:00:01.445158
[9/9, 20/94] Training Loss: 5.9137 - Iteration Time: 0:00:01.399515
[9/9, 30/94] Training Loss: 5.8612 - Iteration Time: 0:00:01.566233
[9/9, 40/94] Training Loss: 5.8165 - Iteration Time: 0:00:01.394557
[9/9, 50/94] Training Loss: 5.7389 - Iteration Time: 0:00:01.402506
[9/9, 60/94] Training Loss: 5.7833 - Iteration Time: 0:00:01.511622
[9/9, 70/94] Training Loss: 5.7316 - Iteration Time: 0:00:01.396673
[9/9, 80/94] Training Loss: 5.6472 - Iteration Time: 0:00:01.403989
[9/9, 90/94] Training Loss: 5.7758 - Iteration Time: 0:00:01.403030
Testing - 2024-06-17 16:50:03.096943
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 5.5401 - Epoch Time: 0:02:27.507367
Training and Testing Finished - Time: 0:22:45.745189
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels      0      1      2      3  ...     95     96   97     98   99
0       2  0.395  0.190  0.305  0.110  ...  0.295  0.225  0.0  0.135  0.0
1       4  0.210  0.090  0.160  0.135  ...  0.185  0.115  0.0  0.360  0.0
2       7  0.175  0.205  0.370  0.165  ...  0.100  0.185  0.0  0.180  0.0
3       3  0.155  0.125  0.130  0.325  ...  0.210  0.085  0.0  0.175  0.0
4       7  0.155  0.220  0.325  0.125  ...  0.010  0.125  0.0  0.305  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP
Applying PCA