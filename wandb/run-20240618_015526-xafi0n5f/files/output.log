Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 01:55:27.371605
Scaler Value: 0.1
Training - 2024-06-18 01:55:27.372598
[1/9, 10/94] Training Loss: 1.1886 - Iteration Time: 0:00:01.993415
[1/9, 20/94] Training Loss: 1.1492 - Iteration Time: 0:00:01.489811
[1/9, 30/94] Training Loss: 1.1318 - Iteration Time: 0:00:01.450149
[1/9, 40/94] Training Loss: 1.1161 - Iteration Time: 0:00:01.424398
[1/9, 50/94] Training Loss: 1.0978 - Iteration Time: 0:00:01.393634
[1/9, 60/94] Training Loss: 1.0844 - Iteration Time: 0:00:01.375755
[1/9, 70/94] Training Loss: 1.0703 - Iteration Time: 0:00:01.439237
[1/9, 80/94] Training Loss: 1.0574 - Iteration Time: 0:00:01.424888
[1/9, 90/94] Training Loss: 1.0425 - Iteration Time: 0:00:01.397551
Testing - 2024-06-18 01:57:46.970046
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 1.0229 - Epoch Time: 0:02:32.841006
Training - 2024-06-18 01:58:00.214099
[2/9, 10/94] Training Loss: 1.0323 - Iteration Time: 0:00:01.361345
[2/9, 20/94] Training Loss: 1.0174 - Iteration Time: 0:00:01.410478
[2/9, 30/94] Training Loss: 1.0122 - Iteration Time: 0:00:01.436320
[2/9, 40/94] Training Loss: 1.0041 - Iteration Time: 0:00:01.382171
[2/9, 50/94] Training Loss: 0.9856 - Iteration Time: 0:00:01.398531
[2/9, 60/94] Training Loss: 0.9752 - Iteration Time: 0:00:01.501753
[2/9, 70/94] Training Loss: 0.9657 - Iteration Time: 0:00:01.396582
[2/9, 80/94] Training Loss: 0.9513 - Iteration Time: 0:00:01.460567
[2/9, 90/94] Training Loss: 0.9408 - Iteration Time: 0:00:01.398645
Testing - 2024-06-18 02:00:14.074096
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 0.9250 - Epoch Time: 0:02:27.209042
Training - 2024-06-18 02:00:27.423141
[3/9, 10/94] Training Loss: 0.9261 - Iteration Time: 0:00:01.392636
[3/9, 20/94] Training Loss: 0.9207 - Iteration Time: 0:00:01.414912
[3/9, 30/94] Training Loss: 0.9034 - Iteration Time: 0:00:01.392598
[3/9, 40/94] Training Loss: 0.8944 - Iteration Time: 0:00:01.388729
[3/9, 50/94] Training Loss: 0.8878 - Iteration Time: 0:00:01.406510
[3/9, 60/94] Training Loss: 0.8788 - Iteration Time: 0:00:01.404536
[3/9, 70/94] Training Loss: 0.8720 - Iteration Time: 0:00:01.384146
[3/9, 80/94] Training Loss: 0.8679 - Iteration Time: 0:00:01.409928
[3/9, 90/94] Training Loss: 0.8606 - Iteration Time: 0:00:01.495308
Testing - 2024-06-18 02:02:41.853724
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 0.8496 - Epoch Time: 0:02:27.675076
Training - 2024-06-18 02:02:55.098714
[4/9, 10/94] Training Loss: 0.8525 - Iteration Time: 0:00:01.465562
[4/9, 20/94] Training Loss: 0.8483 - Iteration Time: 0:00:01.403020
[4/9, 30/94] Training Loss: 0.8355 - Iteration Time: 0:00:01.398103
[4/9, 40/94] Training Loss: 0.8249 - Iteration Time: 0:00:01.396100
[4/9, 50/94] Training Loss: 0.8180 - Iteration Time: 0:00:01.428320
[4/9, 60/94] Training Loss: 0.8102 - Iteration Time: 0:00:01.414434
[4/9, 70/94] Training Loss: 0.8045 - Iteration Time: 0:00:01.454631
[4/9, 80/94] Training Loss: 0.7964 - Iteration Time: 0:00:01.579276
[4/9, 90/94] Training Loss: 0.7870 - Iteration Time: 0:00:01.416416
Testing - 2024-06-18 02:05:11.132084
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 0.7763 - Epoch Time: 0:02:29.304130
Training - 2024-06-18 02:05:24.403343
[5/9, 10/94] Training Loss: 0.7745 - Iteration Time: 0:00:01.420879
[5/9, 20/94] Training Loss: 0.7680 - Iteration Time: 0:00:01.387531
[5/9, 30/94] Training Loss: 0.7539 - Iteration Time: 0:00:01.428529
[5/9, 40/94] Training Loss: 0.7480 - Iteration Time: 0:00:01.459569
[5/9, 50/94] Training Loss: 0.7397 - Iteration Time: 0:00:01.400527
[5/9, 60/94] Training Loss: 0.7317 - Iteration Time: 0:00:01.409987
[5/9, 70/94] Training Loss: 0.7220 - Iteration Time: 0:00:01.400033
[5/9, 80/94] Training Loss: 0.7138 - Iteration Time: 0:00:01.412969
[5/9, 90/94] Training Loss: 0.7053 - Iteration Time: 0:00:01.420893
Testing - 2024-06-18 02:07:39.823274
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 0.6975 - Epoch Time: 0:02:28.490982
Training - 2024-06-18 02:07:52.894325
[6/9, 10/94] Training Loss: 0.6995 - Iteration Time: 0:00:01.395108
[6/9, 20/94] Training Loss: 0.6936 - Iteration Time: 0:00:01.429286
[6/9, 30/94] Training Loss: 0.6900 - Iteration Time: 0:00:01.433269
[6/9, 40/94] Training Loss: 0.6851 - Iteration Time: 0:00:01.384359
[6/9, 50/94] Training Loss: 0.6789 - Iteration Time: 0:00:01.481913
[6/9, 60/94] Training Loss: 0.6752 - Iteration Time: 0:00:01.417420
[6/9, 70/94] Training Loss: 0.6720 - Iteration Time: 0:00:01.415431
[6/9, 80/94] Training Loss: 0.6693 - Iteration Time: 0:00:01.405571
[6/9, 90/94] Training Loss: 0.6648 - Iteration Time: 0:00:01.465073
Testing - 2024-06-18 02:10:08.144553
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 0.6537 - Epoch Time: 0:02:28.573213
Training - 2024-06-18 02:10:21.467538
[7/9, 10/94] Training Loss: 0.6582 - Iteration Time: 0:00:01.400660
[7/9, 20/94] Training Loss: 0.6530 - Iteration Time: 0:00:01.400035
[7/9, 30/94] Training Loss: 0.6463 - Iteration Time: 0:00:01.395583
[7/9, 40/94] Training Loss: 0.6411 - Iteration Time: 0:00:01.392621
[7/9, 50/94] Training Loss: 0.6376 - Iteration Time: 0:00:01.479518
[7/9, 60/94] Training Loss: 0.6327 - Iteration Time: 0:00:01.403585
[7/9, 70/94] Training Loss: 0.6329 - Iteration Time: 0:00:01.442191
[7/9, 80/94] Training Loss: 0.6316 - Iteration Time: 0:00:01.389662
[7/9, 90/94] Training Loss: 0.6315 - Iteration Time: 0:00:01.442727
Testing - 2024-06-18 02:12:37.726591
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 0.6212 - Epoch Time: 0:02:29.421799
Training - 2024-06-18 02:12:50.889832
[8/9, 10/94] Training Loss: 0.6255 - Iteration Time: 0:00:01.419444
[8/9, 20/94] Training Loss: 0.6190 - Iteration Time: 0:00:01.416451
[8/9, 30/94] Training Loss: 0.6151 - Iteration Time: 0:00:01.412985
[8/9, 40/94] Training Loss: 0.6077 - Iteration Time: 0:00:01.385144
[8/9, 50/94] Training Loss: 0.6050 - Iteration Time: 0:00:01.523202
[8/9, 60/94] Training Loss: 0.6052 - Iteration Time: 0:00:01.460613
[8/9, 70/94] Training Loss: 0.6007 - Iteration Time: 0:00:01.596516
[8/9, 80/94] Training Loss: 0.5996 - Iteration Time: 0:00:01.374274
[8/9, 90/94] Training Loss: 0.5983 - Iteration Time: 0:00:01.457111
Testing - 2024-06-18 02:15:06.301330
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.5901 - Epoch Time: 0:02:28.626257
Training - 2024-06-18 02:15:19.516586
[9/9, 10/94] Training Loss: 0.5958 - Iteration Time: 0:00:01.429819
[9/9, 20/94] Training Loss: 0.5957 - Iteration Time: 0:00:01.414513
[9/9, 30/94] Training Loss: 0.5953 - Iteration Time: 0:00:01.525624
[9/9, 40/94] Training Loss: 0.5928 - Iteration Time: 0:00:01.402033
[9/9, 50/94] Training Loss: 0.5917 - Iteration Time: 0:00:01.401534
[9/9, 60/94] Training Loss: 0.5937 - Iteration Time: 0:00:01.410443
[9/9, 70/94] Training Loss: 0.5914 - Iteration Time: 0:00:01.385144
[9/9, 80/94] Training Loss: 0.5894 - Iteration Time: 0:00:01.421350
[9/9, 90/94] Training Loss: 0.5908 - Iteration Time: 0:00:01.406998
Testing - 2024-06-18 02:17:34.463357
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.5850 - Epoch Time: 0:02:28.391964
Training and Testing Finished - Time: 0:22:20.536945
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0      1      2    3      4  ...   94   95   96   97   98   99
0       2  0.0  0.050  0.420  0.0  0.005  ...  0.0  0.0  0.0  0.0  0.0  0.0
1       4  0.0  0.005  0.375  0.0  0.000  ...  0.0  0.0  0.0  0.0  0.0  0.0
2       7  0.0  0.070  0.410  0.0  0.005  ...  0.0  0.0  0.0  0.0  0.0  0.0
3       3  0.0  0.045  0.350  0.0  0.000  ...  0.0  0.0  0.0  0.0  0.0  0.0
4       7  0.0  0.060  0.370  0.0  0.000  ...  0.0  0.0  0.0  0.0  0.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP