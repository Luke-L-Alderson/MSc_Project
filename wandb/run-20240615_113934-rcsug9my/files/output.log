Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-15 11:39:36.383121
Scaler Value: 0.013513513513513514
Training - 2024-06-15 11:39:36.385112
[1/9, 1/94] Training Loss: 0.0694 - Iteration Time: 0:00:01.914909
[1/9, 2/94] Training Loss: 0.0695 - Iteration Time: 0:00:01.527015
[1/9, 3/94] Training Loss: 0.0710 - Iteration Time: 0:00:01.521644
[1/9, 4/94] Training Loss: 0.0709 - Iteration Time: 0:00:01.503776
[1/9, 5/94] Training Loss: 0.0698 - Iteration Time: 0:00:01.456188
[1/9, 6/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.462042
[1/9, 7/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.569280
[1/9, 8/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.501782
[1/9, 9/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.542919
[1/9, 10/94] Training Loss: 0.0711 - Iteration Time: 0:00:01.611889
[1/9, 11/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.521068
[1/9, 12/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.485358
[1/9, 13/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.471997
[1/9, 14/94] Training Loss: 0.0697 - Iteration Time: 0:00:01.490350
[1/9, 15/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.540014
[1/9, 16/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.542943
[1/9, 17/94] Training Loss: 0.0714 - Iteration Time: 0:00:01.618903
[1/9, 18/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.523577
[1/9, 19/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.487907
[1/9, 20/94] Training Loss: 0.0691 - Iteration Time: 0:00:01.441159
[1/9, 21/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.435851
[1/9, 22/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.457073
[1/9, 23/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.477436
[1/9, 24/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.461620
[1/9, 25/94] Training Loss: 0.0706 - Iteration Time: 0:00:01.492338
[1/9, 26/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.450144
[1/9, 27/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.454588
[1/9, 28/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.501392
[1/9, 29/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.434766
[1/9, 30/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.546972
[1/9, 31/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.428300
[1/9, 32/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.481424
[1/9, 33/94] Training Loss: 0.0711 - Iteration Time: 0:00:01.506750
[1/9, 34/94] Training Loss: 0.0680 - Iteration Time: 0:00:01.564267
[1/9, 35/94] Training Loss: 0.0680 - Iteration Time: 0:00:01.442185
[1/9, 36/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.488444
[1/9, 37/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.569275
[1/9, 38/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.514713
[1/9, 39/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.586106
[1/9, 40/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.462551
[1/9, 41/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.493452
[1/9, 42/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.494343
[1/9, 43/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.460113
[1/9, 44/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.427312
[1/9, 45/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.452194
[1/9, 46/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.553437
[1/9, 47/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.460630
[1/9, 48/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.434774
[1/9, 49/94] Training Loss: 0.0698 - Iteration Time: 0:00:01.586155
[1/9, 50/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.652593
[1/9, 51/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.549389
[1/9, 52/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.500767
[1/9, 53/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.443200
[1/9, 54/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.445153
[1/9, 55/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.497782
[1/9, 56/94] Training Loss: 0.0697 - Iteration Time: 0:00:01.570746
[1/9, 57/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.559851
[1/9, 58/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.404555
[1/9, 59/94] Training Loss: 0.0692 - Iteration Time: 0:00:01.439779
[1/9, 60/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.504834
[1/9, 61/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.465550
[1/9, 62/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.462544
[1/9, 63/94] Training Loss: 0.0696 - Iteration Time: 0:00:01.529640
[1/9, 64/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.429358
[1/9, 65/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.532073
[1/9, 66/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.545408
[1/9, 67/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.509176
[1/9, 68/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.433291
[1/9, 69/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.501823
[1/9, 70/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.411421
[1/9, 71/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.542933
[1/9, 72/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.497822
[1/9, 73/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.506786
[1/9, 74/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.423368
[1/9, 75/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.463609
[1/9, 76/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.418073
[1/9, 77/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.435759
[1/9, 78/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.502731
[1/9, 79/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.484924
[1/9, 80/94] Training Loss: 0.0698 - Iteration Time: 0:00:01.565814
[1/9, 81/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.516178
[1/9, 82/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.485387
[1/9, 83/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.432371
[1/9, 84/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.477519
[1/9, 85/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.456707
[1/9, 86/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.449295
[1/9, 87/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.542109
[1/9, 88/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.490901
[1/9, 89/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.619308
[1/9, 90/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.496347
[1/9, 91/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.589607
[1/9, 92/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.440759
[1/9, 93/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.455694
[1/9, 94/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.585603
Testing - 2024-06-15 11:42:08.401994
[1/9, 1/16]
[1/9, 2/16]
[1/9, 3/16]
[1/9, 4/16]
[1/9, 5/16]
[1/9, 6/16]
[1/9, 7/16]
[1/9, 8/16]
[1/9, 9/16]
[1/9, 10/16]
[1/9, 11/16]
[1/9, 12/16]
[1/9, 13/16]
[1/9, 14/16]
[1/9, 15/16]
[1/9, 16/16]
Testing Loss: 0.0620 - Epoch Time: 0:02:54.195904
Training - 2024-06-15 11:42:30.581512
[2/9, 1/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.601502
[2/9, 2/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.421353
[2/9, 3/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.427320
[2/9, 4/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.439207
[2/9, 5/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.450139
[2/9, 6/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.451149
[2/9, 7/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.425815
[2/9, 8/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.452620
[2/9, 9/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.505698
[2/9, 10/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.413917
[2/9, 11/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.431325
[2/9, 12/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.380198
[2/9, 13/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.440235
[2/9, 14/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.431267
[2/9, 15/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.403509
[2/9, 16/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.507183
[2/9, 17/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.431802
[2/9, 18/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.496258
[2/9, 19/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.425894
[2/9, 20/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.487856
[2/9, 21/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.561318
[2/9, 22/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.565295
[2/9, 23/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.440724
[2/9, 24/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.487416
[2/9, 25/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.520669
[2/9, 26/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.426389
[2/9, 27/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.428358
[2/9, 28/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.463514
[2/9, 29/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.411472
[2/9, 30/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.450246
[2/9, 31/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.471561
[2/9, 32/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.595519
[2/9, 33/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.407037
[2/9, 34/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.502335
[2/9, 35/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.501207
[2/9, 36/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.423856
[2/9, 37/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.484884
[2/9, 38/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.509150
[2/9, 39/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.475419
[2/9, 40/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.413942
[2/9, 41/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.388094
[2/9, 42/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.687832
[2/9, 43/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.487863
[2/9, 44/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.485863
[2/9, 45/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.529525
[2/9, 46/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.422839
[2/9, 47/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.394098
[2/9, 48/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.468528
[2/9, 49/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.519082
[2/9, 50/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.556936
[2/9, 51/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.423835
[2/9, 52/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.432299
[2/9, 53/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.531511
[2/9, 54/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.600500
[2/9, 55/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.511157
[2/9, 56/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.535989
[2/9, 57/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.503220
[2/9, 58/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.458080
[2/9, 59/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.510152
[2/9, 60/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.451640
[2/9, 61/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.519112
[2/9, 62/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.573190
[2/9, 63/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.470467
[2/9, 64/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.479954
[2/9, 65/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.450616
[2/9, 66/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.432774
[2/9, 67/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.425317
[2/9, 68/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.551389
[2/9, 69/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.432761
[2/9, 70/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.430798
[2/9, 71/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.553432
[2/9, 72/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.736921
[2/9, 73/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.664068
[2/9, 74/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.648777
[2/9, 75/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.502279
[2/9, 76/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.498789
[2/9, 77/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.575237
[2/9, 78/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.511650
[2/9, 79/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.499293
[2/9, 80/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.622341
[2/9, 81/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.616417
[2/9, 82/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.480450
[2/9, 83/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.479405
[2/9, 84/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.508737
[2/9, 85/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.537482
[2/9, 86/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.533492
[2/9, 87/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.662452
[2/9, 88/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.563324
[2/9, 89/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.735882
[2/9, 90/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.553403
[2/9, 91/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.469051
[2/9, 92/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.557815
[2/9, 93/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.501274
[2/9, 94/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.469564
Testing - 2024-06-15 11:44:51.380870
[2/9, 1/16]
[2/9, 2/16]
[2/9, 3/16]
[2/9, 4/16]
[2/9, 5/16]
[2/9, 6/16]
[2/9, 7/16]
[2/9, 8/16]
[2/9, 9/16]
[2/9, 10/16]
[2/9, 11/16]
[2/9, 12/16]
[2/9, 13/16]
[2/9, 14/16]
[2/9, 15/16]
[2/9, 16/16]
Testing Loss: 0.0620 - Epoch Time: 0:02:34.724738
Training - 2024-06-15 11:45:05.306250
[3/9, 1/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.472966
[3/9, 2/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.538443
[3/9, 3/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.553832
[3/9, 4/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.442216
[3/9, 5/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.486379
[3/9, 6/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.526597
[3/9, 7/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.474926
[3/9, 8/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.515664
[3/9, 9/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.451616
[3/9, 10/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.460058
[3/9, 11/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.484921
[3/9, 12/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.417407
[3/9, 13/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.491852
[3/9, 14/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.468546
[3/9, 15/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.496843
[3/9, 16/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.457717
[3/9, 17/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.492830
[3/9, 18/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.428851
[3/9, 19/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.471988
[3/9, 20/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.547429
[3/9, 21/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.426846
[3/9, 22/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.430920
[3/9, 23/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.439778
[3/9, 24/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.415404
[3/9, 25/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.437332
[3/9, 26/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.514682
[3/9, 27/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.470475
[3/9, 28/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.712617
[3/9, 29/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.707806
[3/9, 30/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.619291
[3/9, 31/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.659992
[3/9, 32/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.723899
[3/9, 33/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.705148
[3/9, 34/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.800914
[3/9, 35/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.764608
[3/9, 36/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.717051
[3/9, 37/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.838118
[3/9, 38/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.922485
[3/9, 39/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.643389
[3/9, 40/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.647595
[3/9, 41/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.628270
[3/9, 42/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.662496
[3/9, 43/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.545887
[3/9, 44/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.568212
[3/9, 45/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.561772
[3/9, 46/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.585584
[3/9, 47/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.613856
[3/9, 48/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.668937
[3/9, 49/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.633695
[3/9, 50/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.628751
[3/9, 51/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.582142
[3/9, 52/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.613373
[3/9, 53/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.577785
[3/9, 54/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.553584
[3/9, 55/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.608465
[3/9, 56/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.631780
[3/9, 57/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.631804
[3/9, 58/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.608439
[3/9, 59/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.631319
[3/9, 60/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.751141
[3/9, 61/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.661042
[3/9, 62/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.673939
[3/9, 63/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.648188
[3/9, 64/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.674410
[3/9, 65/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.625784
[3/9, 66/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.587597
[3/9, 67/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.588594
[3/9, 68/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.590105
[3/9, 69/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.648650
[3/9, 70/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.601018
[3/9, 71/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.661507
[3/9, 72/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.575690
[3/9, 73/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.666958
[3/9, 74/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.824304
[3/9, 75/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.596522
[3/9, 76/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.593060
[3/9, 77/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.583591
[3/9, 78/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.602971
[3/9, 79/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.649640
[3/9, 80/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.622312
[3/9, 81/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.600481
[3/9, 82/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.550873
[3/9, 83/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.555856
[3/9, 84/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.622308
[3/9, 85/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.533600
[3/9, 86/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.549862
[3/9, 87/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.723056
[3/9, 88/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.594084
[3/9, 89/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.610914
[3/9, 90/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.593031
[3/9, 91/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.545957
[3/9, 92/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.565250
[3/9, 93/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.597492
[3/9, 94/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.512125
Testing - 2024-06-15 11:47:34.798538
[3/9, 1/16]
[3/9, 2/16]
[3/9, 3/16]
[3/9, 4/16]
[3/9, 5/16]
[3/9, 6/16]
[3/9, 7/16]
[3/9, 8/16]
[3/9, 9/16]
[3/9, 10/16]
[3/9, 11/16]
[3/9, 12/16]
[3/9, 13/16]
[3/9, 14/16]
[3/9, 15/16]
[3/9, 16/16]
Testing Loss: 0.0565 - Epoch Time: 0:02:44.288507
Training - 2024-06-15 11:47:49.594757
[4/9, 1/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.594527
[4/9, 2/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.635641
[4/9, 3/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.611884
[4/9, 4/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.577675
[4/9, 5/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.593029
[4/9, 6/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.617338
[4/9, 7/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.662944
[4/9, 8/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.883780
[4/9, 9/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.629743
[4/9, 10/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.564332
[4/9, 11/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.584332
[4/9, 12/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.623902
[4/9, 13/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.576837
[4/9, 14/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.583134
[4/9, 15/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.601256
[4/9, 16/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.624712
[4/9, 17/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.619396
[4/9, 18/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.583114
[4/9, 19/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.598576
[4/9, 20/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.629479
[4/9, 21/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.612012
[4/9, 22/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.692737
[4/9, 23/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.690700
[4/9, 24/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.727013
[4/9, 25/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.697189
[4/9, 26/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.623247
[4/9, 27/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.584678
[4/9, 28/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.607933
[4/9, 29/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.565939
[4/9, 30/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.585179
[4/9, 31/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.594027
[4/9, 32/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.595063
[4/9, 33/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.676805
[4/9, 34/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.680292
[4/9, 35/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.600515
[4/9, 36/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.712259
[4/9, 37/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.587062
[4/9, 38/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.588573
[4/9, 39/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.713160
[4/9, 40/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.571168
[4/9, 41/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.588579
[4/9, 42/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.604978
[4/9, 43/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.592539
[4/9, 44/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.713622
[4/9, 45/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.718031
[4/9, 46/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.587112
[4/9, 47/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.585592
[4/9, 48/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.578596
[4/9, 49/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.556321
[4/9, 50/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.623250
[4/9, 51/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.591107
[4/9, 52/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.632296
[4/9, 53/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.584672
[4/9, 54/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.607451
[4/9, 55/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.566248
[4/9, 56/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.642659
[4/9, 57/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.584121
[4/9, 58/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.568776
[4/9, 59/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.595076
[4/9, 60/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.579156
[4/9, 61/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.574271
[4/9, 62/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.598561
[4/9, 63/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.602091
[4/9, 64/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.615881
[4/9, 65/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.603497
[4/9, 66/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.589578
[4/9, 67/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.599989
[4/9, 68/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.593604
[4/9, 69/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.596549
[4/9, 70/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.586079
[4/9, 71/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.720541
[4/9, 72/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.624317
[4/9, 73/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.612362
[4/9, 74/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.593036
[4/9, 75/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.572654
[4/9, 76/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.717065
[4/9, 77/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.637697
[4/9, 78/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.613901
[4/9, 79/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.552832
[4/9, 80/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.573645
[4/9, 81/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.569236
[4/9, 82/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.641184
[4/9, 83/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.771611
[4/9, 84/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.546475
[4/9, 85/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.675402
[4/9, 86/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.553319
[4/9, 87/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.555840
[4/9, 88/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.560764
[4/9, 89/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.521634
[4/9, 90/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.543910
[4/9, 91/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.558812
[4/9, 92/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.559794
[4/9, 93/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.528031
[4/9, 94/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.509677
Testing - 2024-06-15 11:50:21.167214
[4/9, 1/16]
[4/9, 2/16]
[4/9, 3/16]
[4/9, 4/16]
[4/9, 5/16]
[4/9, 6/16]
[4/9, 7/16]
[4/9, 8/16]
[4/9, 9/16]
[4/9, 10/16]
[4/9, 11/16]
[4/9, 12/16]
[4/9, 13/16]
[4/9, 14/16]
[4/9, 15/16]
[4/9, 16/16]
Testing Loss: 0.0532 - Epoch Time: 0:02:46.061174
Training - 2024-06-15 11:50:35.655931
[5/9, 1/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.547928
[5/9, 2/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.595513
[5/9, 3/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.555361
[5/9, 4/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.572209
[5/9, 5/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.673387
[5/9, 6/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.603016
[5/9, 7/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.569760
[5/9, 8/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.585156
[5/9, 9/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.508725
[5/9, 10/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.506715
[5/9, 11/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.501282
[5/9, 12/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.489883
[5/9, 13/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.529111
[5/9, 14/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.594196
[5/9, 15/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.514227
[5/9, 16/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.545982
[5/9, 17/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.751863
[5/9, 18/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.507745
[5/9, 19/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.522108
[5/9, 20/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.525118
[5/9, 21/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.514678
[5/9, 22/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.489837
[5/9, 23/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.468535
[5/9, 24/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.495812
[5/9, 25/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.520117
[5/9, 26/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.517610
[5/9, 27/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.507307
[5/9, 28/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.504728
[5/9, 29/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.492832
[5/9, 30/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.513228
[5/9, 31/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.506210
[5/9, 32/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.502730
[5/9, 33/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.492834
[5/9, 34/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.509723
[5/9, 35/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.520155
[5/9, 36/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.487870
[5/9, 37/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.715873
[5/9, 38/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.598579
[5/9, 39/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.553837
[5/9, 40/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.611877
[5/9, 41/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.531873
[5/9, 42/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.506672
[5/9, 43/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.518627
[5/9, 44/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.540043
[5/9, 45/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.516503
[5/9, 46/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.518212
[5/9, 47/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.466242
[5/9, 48/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.457636
[5/9, 49/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.451702
[5/9, 50/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.494516
[5/9, 51/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.462807
[5/9, 52/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.511743
[5/9, 53/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.518193
[5/9, 54/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.470347
[5/9, 55/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.478018
[5/9, 56/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.634718
[5/9, 57/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.638257
[5/9, 58/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.519008
[5/9, 59/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.443275
[5/9, 60/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.515574
[5/9, 61/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.473084
[5/9, 62/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.506339
[5/9, 63/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.430321
[5/9, 64/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.497391
[5/9, 65/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.459394
[5/9, 66/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.504722
[5/9, 67/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.463540
[5/9, 68/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.416646
[5/9, 69/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.504208
[5/9, 70/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.419885
[5/9, 71/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.470085
[5/9, 72/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.520346
[5/9, 73/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.458087
[5/9, 74/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.441701
[5/9, 75/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.486346
[5/9, 76/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.494093
[5/9, 77/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.626291
[5/9, 78/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.577444
[5/9, 79/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.535954
[5/9, 80/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.499475
[5/9, 81/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.433776
[5/9, 82/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.456398
[5/9, 83/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.466006
[5/9, 84/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.721672
[5/9, 85/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.513647
[5/9, 86/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.488531
[5/9, 87/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.492317
[5/9, 88/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.468513
[5/9, 89/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.451846
[5/9, 90/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.430843
[5/9, 91/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.469046
[5/9, 92/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.492984
[5/9, 93/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.443684
[5/9, 94/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.428320
Testing - 2024-06-15 11:52:58.208293
[5/9, 1/16]
[5/9, 2/16]
[5/9, 3/16]
[5/9, 4/16]
[5/9, 5/16]
[5/9, 6/16]
[5/9, 7/16]
[5/9, 8/16]
[5/9, 9/16]
[5/9, 10/16]
[5/9, 11/16]
[5/9, 12/16]
[5/9, 13/16]
[5/9, 14/16]
[5/9, 15/16]
[5/9, 16/16]
Testing Loss: 0.0508 - Epoch Time: 0:02:36.486820
Training - 2024-06-15 11:53:12.143247
[6/9, 1/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.493789
[6/9, 2/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.465509
[6/9, 3/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.486247
[6/9, 4/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.479416
[6/9, 5/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.485858
[6/9, 6/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.423842
[6/9, 7/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.467022
[6/9, 8/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.524048
[6/9, 9/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.447164
[6/9, 10/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.471962
[6/9, 11/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.470057
[6/9, 12/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.453680
[6/9, 13/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.471016
[6/9, 14/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.438712
[6/9, 15/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.447212
[6/9, 16/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.459646
[6/9, 17/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.518641
[6/9, 18/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.479516
[6/9, 19/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.509222
[6/9, 20/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.498306
[6/9, 21/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.470504
[6/9, 22/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.522628
[6/9, 23/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.468544
[6/9, 24/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.570739
[6/9, 25/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.465023
[6/9, 26/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.403111
[6/9, 27/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.481477
[6/9, 28/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.541464
[6/9, 29/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.458103
[6/9, 30/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.473487
[6/9, 31/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.440706
[6/9, 32/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.424323
[6/9, 33/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.470970
[6/9, 34/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.512201
[6/9, 35/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.576637
[6/9, 36/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.461541
[6/9, 37/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.448694
[6/9, 38/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.558286
[6/9, 39/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.495764
[6/9, 40/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.451651
[6/9, 41/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.479386
[6/9, 42/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.445675
[6/9, 43/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.489317
[6/9, 44/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.507198
[6/9, 45/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.459549
[6/9, 46/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.511902
[6/9, 47/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.515642
[6/9, 48/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.473944
[6/9, 49/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.432760
[6/9, 50/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.541456
[6/9, 51/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.523570
[6/9, 52/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.496764
[6/9, 53/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.456593
[6/9, 54/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.459560
[6/9, 55/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.452140
[6/9, 56/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.461562
[6/9, 57/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.447232
[6/9, 58/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.524687
[6/9, 59/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.453605
[6/9, 60/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.477932
[6/9, 61/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.517676
[6/9, 62/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.566258
[6/9, 63/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.446715
[6/9, 64/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.478469
[6/9, 65/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.495359
[6/9, 66/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.504711
[6/9, 67/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.521584
[6/9, 68/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.520673
[6/9, 69/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.516661
[6/9, 70/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.531994
[6/9, 71/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.510170
[6/9, 72/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.533315
[6/9, 73/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.564792
[6/9, 74/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.647119
[6/9, 75/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.451641
[6/9, 76/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.487337
[6/9, 77/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.477909
[6/9, 78/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.448187
[6/9, 79/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.463016
[6/9, 80/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.439254
[6/9, 81/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.469494
[6/9, 82/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.503750
[6/9, 83/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.480380
[6/9, 84/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.473941
[6/9, 85/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.494808
[6/9, 86/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.424319
[6/9, 87/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.609385
[6/9, 88/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.499252
[6/9, 89/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.520665
[6/9, 90/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.439220
[6/9, 91/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.493331
[6/9, 92/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.483367
[6/9, 93/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.460088
[6/9, 94/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.460558
Testing - 2024-06-15 11:55:31.963691
[6/9, 1/16]
[6/9, 2/16]
[6/9, 3/16]
[6/9, 4/16]
[6/9, 5/16]
[6/9, 6/16]
[6/9, 7/16]
[6/9, 8/16]
[6/9, 9/16]
[6/9, 10/16]
[6/9, 11/16]
[6/9, 12/16]
[6/9, 13/16]
[6/9, 14/16]
[6/9, 15/16]
[6/9, 16/16]
Testing Loss: 0.0508 - Epoch Time: 0:02:33.511747
Training - 2024-06-15 11:55:45.654994
[7/9, 1/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.445218
[7/9, 2/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.419527
[7/9, 3/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.442902
[7/9, 4/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.478479
[7/9, 5/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.457694
[7/9, 6/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.507377
[7/9, 7/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.427386
[7/9, 8/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.501323
[7/9, 9/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.439802
[7/9, 10/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.457814
[7/9, 11/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.613878
[7/9, 12/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.465039
[7/9, 13/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.459713
[7/9, 14/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.449206
[7/9, 15/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.447217
[7/9, 16/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.470542
[7/9, 17/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.461638
[7/9, 18/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.481999
[7/9, 19/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.448191
[7/9, 20/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.424014
[7/9, 21/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.459640
[7/9, 22/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.498893
[7/9, 23/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.413470
[7/9, 24/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.438253
[7/9, 25/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.384695
[7/9, 26/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.508298
[7/9, 27/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.418547
[7/9, 28/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.501362
[7/9, 29/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.476607
[7/9, 30/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.488873
[7/9, 31/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.436819
[7/9, 32/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.441765
[7/9, 33/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.460148
[7/9, 34/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.472077
[7/9, 35/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.447204
[7/9, 36/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.461103
[7/9, 37/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.462562
[7/9, 38/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.456689
[7/9, 39/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.562382
[7/9, 40/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.720834
[7/9, 41/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.788583
[7/9, 42/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.655903
[7/9, 43/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.710162
[7/9, 44/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.676455
[7/9, 45/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.518778
[7/9, 46/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.508626
[7/9, 47/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.519414
[7/9, 48/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.556786
[7/9, 49/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.497741
[7/9, 50/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.708108
[7/9, 51/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.578372
[7/9, 52/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.496818
[7/9, 53/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.537559
[7/9, 54/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.460068
[7/9, 55/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.453691
[7/9, 56/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.474080
[7/9, 57/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.489863
[7/9, 58/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.473715
[7/9, 59/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.431347
[7/9, 60/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.468064
[7/9, 61/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.487873
[7/9, 62/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.525810
[7/9, 63/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.426929
[7/9, 64/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.507793
[7/9, 65/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.477994
[7/9, 66/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.441946
[7/9, 67/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.469094
[7/9, 68/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.424917
[7/9, 69/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.583142
[7/9, 70/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.438769
[7/9, 71/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.426862
[7/9, 72/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.504766
[7/9, 73/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.693292
[7/9, 74/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.498822
[7/9, 75/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.569357
[7/9, 76/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.437734
[7/9, 77/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.433880
[7/9, 78/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.498444
[7/9, 79/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.537067
[7/9, 80/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.449198
[7/9, 81/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.447723
[7/9, 82/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.430843
[7/9, 83/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.436736
[7/9, 84/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.482904
[7/9, 85/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.415999
[7/9, 86/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.634767
[7/9, 87/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.485471
[7/9, 88/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.465646
[7/9, 89/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.437831
[7/9, 90/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.459139
[7/9, 91/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.451626
[7/9, 92/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.641261
[7/9, 93/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.501264
[7/9, 94/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.422872
Testing - 2024-06-15 11:58:06.110622
[7/9, 1/16]
[7/9, 2/16]
[7/9, 3/16]
[7/9, 4/16]
[7/9, 5/16]
[7/9, 6/16]
[7/9, 7/16]
[7/9, 8/16]
[7/9, 9/16]
[7/9, 10/16]
[7/9, 11/16]
[7/9, 12/16]
[7/9, 13/16]
[7/9, 14/16]
[7/9, 15/16]
[7/9, 16/16]
Testing Loss: 0.0488 - Epoch Time: 0:02:34.238823
Training - 2024-06-15 11:58:19.893817
[8/9, 1/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.487376
[8/9, 2/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.454170
[8/9, 3/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.450720
[8/9, 4/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.482835
[8/9, 5/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.486416
[8/9, 6/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.485536
[8/9, 7/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.437430
[8/9, 8/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.424360
[8/9, 9/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.555827
[8/9, 10/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.484491
[8/9, 11/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.493951
[8/9, 12/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.480867
[8/9, 13/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.432447
[8/9, 14/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.507774
[8/9, 15/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.420955
[8/9, 16/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.542482
[8/9, 17/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.474060
[8/9, 18/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.570799
[8/9, 19/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.498275
[8/9, 20/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.490434
[8/9, 21/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.449622
[8/9, 22/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.470643
[8/9, 23/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.447811
[8/9, 24/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.555483
[8/9, 25/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.489002
[8/9, 26/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.517894
[8/9, 27/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.456636
[8/9, 28/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.671546
[8/9, 29/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.445216
[8/9, 30/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.476566
[8/9, 31/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.477054
[8/9, 32/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.504822
[8/9, 33/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.464616
[8/9, 34/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.472135
[8/9, 35/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.491899
[8/9, 36/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.435822
[8/9, 37/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.586137
[8/9, 38/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.489848
[8/9, 39/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.434286
[8/9, 40/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.457067
[8/9, 41/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.454165
[8/9, 42/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.488881
[8/9, 43/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.505193
[8/9, 44/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.431875
[8/9, 45/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.463161
[8/9, 46/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.464054
[8/9, 47/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.515735
[8/9, 48/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.485903
[8/9, 49/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.426364
[8/9, 50/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.531119
[8/9, 51/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.519188
[8/9, 52/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.547903
[8/9, 53/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.495887
[8/9, 54/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.533979
[8/9, 55/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.438293
[8/9, 56/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.490326
[8/9, 57/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.507693
[8/9, 58/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.505221
[8/9, 59/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.506685
[8/9, 60/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.462029
[8/9, 61/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.524633
[8/9, 62/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.467592
[8/9, 63/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.452631
[8/9, 64/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.538155
[8/9, 65/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.459656
[8/9, 66/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.596531
[8/9, 67/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.512248
[8/9, 68/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.607976
[8/9, 69/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.710445
[8/9, 70/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.413957
[8/9, 71/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.477482
[8/9, 72/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.470004
[8/9, 73/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.451202
[8/9, 74/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.418983
[8/9, 75/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.419465
[8/9, 76/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.450180
[8/9, 77/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.447670
[8/9, 78/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.473465
[8/9, 79/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.537545
[8/9, 80/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.457121
[8/9, 81/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.570223
[8/9, 82/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.480931
[8/9, 83/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.721048
[8/9, 84/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.545421
[8/9, 85/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.506711
[8/9, 86/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.486878
[8/9, 87/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.405967
[8/9, 88/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.510723
[8/9, 89/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.541436
[8/9, 90/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.584116
[8/9, 91/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.547904
[8/9, 92/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.522595
[8/9, 93/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.537475
[8/9, 94/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.443257
Testing - 2024-06-15 12:00:40.510005
[8/9, 1/16]
[8/9, 2/16]
[8/9, 3/16]
[8/9, 4/16]
[8/9, 5/16]
[8/9, 6/16]
[8/9, 7/16]
[8/9, 8/16]
[8/9, 9/16]
[8/9, 10/16]
[8/9, 11/16]
[8/9, 12/16]
[8/9, 13/16]
[8/9, 14/16]
[8/9, 15/16]
[8/9, 16/16]
Testing Loss: 0.0471 - Epoch Time: 0:02:34.516557
Training - 2024-06-15 12:00:54.410871
[9/9, 1/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.483455
[9/9, 2/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.480922
[9/9, 3/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.529048
[9/9, 4/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.501271
[9/9, 5/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.572213
[9/9, 6/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.517639
[9/9, 7/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.442389
[9/9, 8/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.549376
[9/9, 9/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.439259
[9/9, 10/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.496350
[9/9, 11/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.502329
[9/9, 12/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.427862
[9/9, 13/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.599060
[9/9, 14/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.507240
[9/9, 15/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.499248
[9/9, 16/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.495854
[9/9, 17/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.538503
[9/9, 18/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.535067
[9/9, 19/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.441350
[9/9, 20/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.444803
[9/9, 21/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.465041
[9/9, 22/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.501327
[9/9, 23/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.553409
[9/9, 24/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.460073
[9/9, 25/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.532483
[9/9, 26/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.416966
[9/9, 27/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.479459
[9/9, 28/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.606991
[9/9, 29/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.462991
[9/9, 30/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.483068
[9/9, 31/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.467519
[9/9, 32/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.510225
[9/9, 33/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.540964
[9/9, 34/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.449184
[9/9, 35/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.469060
[9/9, 36/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.425880
[9/9, 37/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.530129
[9/9, 38/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.474460
[9/9, 39/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.546418
[9/9, 40/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.521645
[9/9, 41/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.424869
[9/9, 42/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.546469
[9/9, 43/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.486414
[9/9, 44/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.514716
[9/9, 45/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.493289
[9/9, 46/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.607966
[9/9, 47/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.498284
[9/9, 48/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.515147
[9/9, 49/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.488390
[9/9, 50/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.433772
[9/9, 51/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.495312
[9/9, 52/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.427313
[9/9, 53/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.529040
[9/9, 54/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.485464
[9/9, 55/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.482434
[9/9, 56/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.534007
[9/9, 57/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.493427
[9/9, 58/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.480095
[9/9, 59/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.515223
[9/9, 60/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.512225
[9/9, 61/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.468360
[9/9, 62/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.624859
[9/9, 63/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.541946
[9/9, 64/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.488155
[9/9, 65/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.423906
[9/9, 66/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.554903
[9/9, 67/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.511683
[9/9, 68/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.448181
[9/9, 69/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.484400
[9/9, 70/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.470968
[9/9, 71/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.467020
[9/9, 72/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.509674
[9/9, 73/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.596595
[9/9, 74/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.533011
[9/9, 75/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.441296
[9/9, 76/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.523109
[9/9, 77/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.504289
[9/9, 78/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.410125
[9/9, 79/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.658607
[9/9, 80/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.518120
[9/9, 81/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.538036
[9/9, 82/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.483443
[9/9, 83/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.460552
[9/9, 84/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.544467
[9/9, 85/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.691786
[9/9, 86/94] Training Loss: 0.0447 - Iteration Time: 0:00:01.521694
[9/9, 87/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.475466
[9/9, 88/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.438288
[9/9, 89/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.471572
[9/9, 90/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.443256
[9/9, 91/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.504778
[9/9, 92/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.459138
[9/9, 93/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.538448
[9/9, 94/94] Training Loss: 0.0434 - Iteration Time: 0:00:01.444176
Testing - 2024-06-15 12:03:15.552321
[9/9, 1/16]
[9/9, 2/16]
[9/9, 3/16]
[9/9, 4/16]
[9/9, 5/16]
[9/9, 6/16]
[9/9, 7/16]
[9/9, 8/16]
[9/9, 9/16]
[9/9, 10/16]
[9/9, 11/16]
[9/9, 12/16]
[9/9, 13/16]
[9/9, 14/16]
[9/9, 15/16]
[9/9, 16/16]
Testing Loss: 0.0451 - Epoch Time: 0:02:35.038969
Training and Testing Finished - Time: 0:23:53.067215
Assembling test data for t-sne projection
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 4
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 4
Applying t-SNE