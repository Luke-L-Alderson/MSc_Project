Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-18 04:14:17.815934
Scaler Value: 0.1
Training - 2024-06-18 04:14:17.816927
[1/9, 10/94] Training Loss: 2.1260 - Iteration Time: 0:00:01.418030
[1/9, 20/94] Training Loss: 2.0230 - Iteration Time: 0:00:01.409147
[1/9, 30/94] Training Loss: 1.9768 - Iteration Time: 0:00:01.551117
[1/9, 40/94] Training Loss: 1.9581 - Iteration Time: 0:00:01.408132
[1/9, 50/94] Training Loss: 1.9290 - Iteration Time: 0:00:01.413562
[1/9, 60/94] Training Loss: 1.8995 - Iteration Time: 0:00:01.621498
[1/9, 70/94] Training Loss: 1.8707 - Iteration Time: 0:00:01.487573
[1/9, 80/94] Training Loss: 1.8492 - Iteration Time: 0:00:01.495428
[1/9, 90/94] Training Loss: 1.8216 - Iteration Time: 0:00:01.410070
Testing - 2024-06-18 04:16:33.983112
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 1.7909 - Epoch Time: 0:02:29.540207
Training - 2024-06-18 04:16:47.357630
[2/9, 10/94] Training Loss: 1.7931 - Iteration Time: 0:00:01.540049
[2/9, 20/94] Training Loss: 1.7632 - Iteration Time: 0:00:01.421461
[2/9, 30/94] Training Loss: 1.7382 - Iteration Time: 0:00:01.601082
[2/9, 40/94] Training Loss: 1.7147 - Iteration Time: 0:00:01.373387
[2/9, 50/94] Training Loss: 1.6855 - Iteration Time: 0:00:01.425492
[2/9, 60/94] Training Loss: 1.6588 - Iteration Time: 0:00:01.401218
[2/9, 70/94] Training Loss: 1.6340 - Iteration Time: 0:00:01.426948
[2/9, 80/94] Training Loss: 1.6121 - Iteration Time: 0:00:01.411567
[2/9, 90/94] Training Loss: 1.5988 - Iteration Time: 0:00:01.580823
Testing - 2024-06-18 04:19:03.232238
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 1.5776 - Epoch Time: 0:02:29.225280
Training - 2024-06-18 04:19:16.583406
[3/9, 10/94] Training Loss: 1.5747 - Iteration Time: 0:00:01.394734
[3/9, 20/94] Training Loss: 1.5626 - Iteration Time: 0:00:01.435944
[3/9, 30/94] Training Loss: 1.5342 - Iteration Time: 0:00:01.480601
[3/9, 40/94] Training Loss: 1.5069 - Iteration Time: 0:00:01.444858
[3/9, 50/94] Training Loss: 1.4954 - Iteration Time: 0:00:01.441881
[3/9, 60/94] Training Loss: 1.4775 - Iteration Time: 0:00:01.407687
[3/9, 70/94] Training Loss: 1.4548 - Iteration Time: 0:00:01.447775
[3/9, 80/94] Training Loss: 1.4374 - Iteration Time: 0:00:01.384768
[3/9, 90/94] Training Loss: 1.4190 - Iteration Time: 0:00:01.483684
Testing - 2024-06-18 04:21:32.426972
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 1.3986 - Epoch Time: 0:02:29.229480
Training - 2024-06-18 04:21:45.812886
[4/9, 10/94] Training Loss: 1.3968 - Iteration Time: 0:00:01.415695
[4/9, 20/94] Training Loss: 1.3873 - Iteration Time: 0:00:01.414736
[4/9, 30/94] Training Loss: 1.3733 - Iteration Time: 0:00:01.416560
[4/9, 40/94] Training Loss: 1.3508 - Iteration Time: 0:00:01.467001
[4/9, 50/94] Training Loss: 1.3343 - Iteration Time: 0:00:01.388335
[4/9, 60/94] Training Loss: 1.3206 - Iteration Time: 0:00:01.393302
[4/9, 70/94] Training Loss: 1.3052 - Iteration Time: 0:00:01.513343
[4/9, 80/94] Training Loss: 1.2870 - Iteration Time: 0:00:01.400680
[4/9, 90/94] Training Loss: 1.2732 - Iteration Time: 0:00:01.418107
Testing - 2024-06-18 04:24:01.302148
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 1.2609 - Epoch Time: 0:02:28.892844
Training - 2024-06-18 04:24:14.705730
[5/9, 10/94] Training Loss: 1.2601 - Iteration Time: 0:00:01.461194
[5/9, 20/94] Training Loss: 1.2492 - Iteration Time: 0:00:01.419681
[5/9, 30/94] Training Loss: 1.2344 - Iteration Time: 0:00:01.452011
[5/9, 40/94] Training Loss: 1.2218 - Iteration Time: 0:00:01.405154
[5/9, 50/94] Training Loss: 1.2049 - Iteration Time: 0:00:01.526281
[5/9, 60/94] Training Loss: 1.1983 - Iteration Time: 0:00:01.401664
[5/9, 70/94] Training Loss: 1.1847 - Iteration Time: 0:00:01.433027
[5/9, 80/94] Training Loss: 1.1740 - Iteration Time: 0:00:01.408068
[5/9, 90/94] Training Loss: 1.1700 - Iteration Time: 0:00:01.396165
Testing - 2024-06-18 04:26:30.106755
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 1.1595 - Epoch Time: 0:02:28.617438
Training - 2024-06-18 04:26:43.323168
[6/9, 10/94] Training Loss: 1.1596 - Iteration Time: 0:00:01.414575
[6/9, 20/94] Training Loss: 1.1474 - Iteration Time: 0:00:01.398193
[6/9, 30/94] Training Loss: 1.1409 - Iteration Time: 0:00:01.500405
[6/9, 40/94] Training Loss: 1.1374 - Iteration Time: 0:00:01.427447
[6/9, 50/94] Training Loss: 1.1283 - Iteration Time: 0:00:01.394739
[6/9, 60/94] Training Loss: 1.1222 - Iteration Time: 0:00:01.410069
[6/9, 70/94] Training Loss: 1.1169 - Iteration Time: 0:00:01.403718
[6/9, 80/94] Training Loss: 1.1076 - Iteration Time: 0:00:01.438879
[6/9, 90/94] Training Loss: 1.0959 - Iteration Time: 0:00:01.419563
Testing - 2024-06-18 04:28:58.291022
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 1.0730 - Epoch Time: 0:02:28.684376
Training - 2024-06-18 04:29:12.008041
[7/9, 10/94] Training Loss: 1.0727 - Iteration Time: 0:00:01.550916
[7/9, 20/94] Training Loss: 1.0643 - Iteration Time: 0:00:01.412599
[7/9, 30/94] Training Loss: 1.0584 - Iteration Time: 0:00:01.436413
[7/9, 40/94] Training Loss: 1.0523 - Iteration Time: 0:00:01.412537
[7/9, 50/94] Training Loss: 1.0497 - Iteration Time: 0:00:01.485998
[7/9, 60/94] Training Loss: 1.0466 - Iteration Time: 0:00:01.436396
[7/9, 70/94] Training Loss: 1.0449 - Iteration Time: 0:00:01.417016
[7/9, 80/94] Training Loss: 1.0423 - Iteration Time: 0:00:01.417515
[7/9, 90/94] Training Loss: 1.0365 - Iteration Time: 0:00:01.498467
Testing - 2024-06-18 04:31:27.753574
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 1.0177 - Epoch Time: 0:02:29.058077
Training - 2024-06-18 04:31:41.066118
[8/9, 10/94] Training Loss: 1.0238 - Iteration Time: 0:00:01.445793
[8/9, 20/94] Training Loss: 1.0180 - Iteration Time: 0:00:01.425570
[8/9, 30/94] Training Loss: 1.0159 - Iteration Time: 0:00:01.408215
[8/9, 40/94] Training Loss: 1.0102 - Iteration Time: 0:00:01.496005
[8/9, 50/94] Training Loss: 1.0072 - Iteration Time: 0:00:01.414064
[8/9, 60/94] Training Loss: 1.0042 - Iteration Time: 0:00:01.457238
[8/9, 70/94] Training Loss: 1.0029 - Iteration Time: 0:00:01.424534
[8/9, 80/94] Training Loss: 1.0026 - Iteration Time: 0:00:01.422613
[8/9, 90/94] Training Loss: 1.0012 - Iteration Time: 0:00:01.404175
Testing - 2024-06-18 04:33:57.562328
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 0.9906 - Epoch Time: 0:02:30.145162
Training - 2024-06-18 04:34:11.211280
[9/9, 10/94] Training Loss: 0.9948 - Iteration Time: 0:00:02.010430
[9/9, 20/94] Training Loss: 0.9912 - Iteration Time: 0:00:01.463745
[9/9, 30/94] Training Loss: 0.9874 - Iteration Time: 0:00:01.491986
[9/9, 40/94] Training Loss: 0.9846 - Iteration Time: 0:00:01.428028
[9/9, 50/94] Training Loss: 0.9833 - Iteration Time: 0:00:01.412121
[9/9, 60/94] Training Loss: 0.9748 - Iteration Time: 0:00:01.423621
[9/9, 70/94] Training Loss: 0.9617 - Iteration Time: 0:00:01.397672
[9/9, 80/94] Training Loss: 0.9594 - Iteration Time: 0:00:01.435996
[9/9, 90/94] Training Loss: 0.9583 - Iteration Time: 0:00:01.513764
Testing - 2024-06-18 04:36:32.243914
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 0.9454 - Epoch Time: 0:02:34.507990
Training and Testing Finished - Time: 0:22:27.903336
torch.Size([200, 64, 1, 28, 28])
torch.Size([200, 64, 1, 28, 28])
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([200, 64, 100])
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([200, 40, 100])
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels    0    1      2      3    4  ...     94   95   96   97   98   99
0       2  0.0  0.0  0.455  0.150  0.0  ...  0.150  0.0  0.0  0.0  0.0  0.0
1       4  0.0  0.0  0.435  0.120  0.0  ...  0.145  0.0  0.0  0.0  0.0  0.0
2       7  0.0  0.0  0.455  0.145  0.0  ...  0.140  0.0  0.0  0.0  0.0  0.0
3       3  0.0  0.0  0.405  0.200  0.0  ...  0.145  0.0  0.0  0.0  0.0  0.0
4       7  0.0  0.0  0.435  0.135  0.0  ...  0.155  0.0  0.0  0.0  0.0  0.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying UMAP