Starting Sweep: Batch Size: 32, Learning Rate: 0.001
Making datasets and defining subsets
Training: 60000 -> 48000
Testing: 10000 -> 8000
Making Subsets
Training: 48000
Testing: 8000
Making Dataloaders
Defining network
Training!
[1/3, 150/1500] Training Loss: 1.256594822406769
[1/3, 300/1500] Training Loss: 1.0639728367328645
[1/3, 450/1500] Training Loss: 1.0401886188983918
[1/3, 600/1500] Training Loss: 1.019099591175715
[1/3, 750/1500] Training Loss: 0.9911760731538137
[1/3, 900/1500] Training Loss: 0.9675668315092723
[1/3, 1050/1500] Training Loss: 0.9553161311149597
[1/3, 1200/1500] Training Loss: 0.948436955610911
[1/3, 1350/1500] Training Loss: 0.9349442569414774
[1/3, 1500/1500] Training Loss: 0.9265975455443064
Testing!
[1/3, 1/250]
[1/3, 26/250]
[1/3, 51/250]
[1/3, 76/250]
[1/3, 101/250]
[1/3, 126/250]
[1/3, 151/250]
[1/3, 176/250]
[1/3, 201/250]
[1/3, 226/250]
Testing Loss: 0.8512415771484376
Training!
[2/3, 150/1500] Training Loss: 0.9233071033159892
[2/3, 300/1500] Training Loss: 0.8892513120174408
[2/3, 450/1500] Training Loss: 0.8385934523741404
[2/3, 600/1500] Training Loss: 0.8273913522561391
[2/3, 750/1500] Training Loss: 0.7985967171192169
[2/3, 900/1500] Training Loss: 0.7786241126060486
[2/3, 1050/1500] Training Loss: 0.7632176891962688
[2/3, 1200/1500] Training Loss: 0.7137415715058645
[2/3, 1350/1500] Training Loss: 0.6359919685125351
[2/3, 1500/1500] Training Loss: 0.5227054367462795
Testing!
[2/3, 1/250]
[2/3, 26/250]
[2/3, 51/250]
[2/3, 76/250]
[2/3, 101/250]
[2/3, 126/250]
[2/3, 151/250]
[2/3, 176/250]
[2/3, 201/250]
[2/3, 226/250]
Testing Loss: 0.6606466978192329
Training!
[3/3, 150/1500] Training Loss: 0.5174186728398005
[3/3, 300/1500] Training Loss: 0.5147998088598251
[3/3, 450/1500] Training Loss: 0.5169233234723409
[3/3, 600/1500] Training Loss: 0.5137455594539643
[3/3, 750/1500] Training Loss: 0.5056764819224675
[3/3, 900/1500] Training Loss: 0.5061772747834523
[3/3, 1050/1500] Training Loss: 0.5009620438019434
[3/3, 1200/1500] Training Loss: 0.4616408071915309
[3/3, 1350/1500] Training Loss: 0.4220327415068944
[3/3, 1500/1500] Training Loss: 0.39775248686472575
Testing!
Appending
[3/3, 1/250]
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
[3/3, 26/250]
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
[3/3, 51/250]
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
[3/3, 76/250]
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
[3/3, 101/250]
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
[3/3, 126/250]
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
[3/3, 151/250]
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
[3/3, 176/250]
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
[3/3, 201/250]
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
[3/3, 226/250]
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Appending
Concatenating
Features: (8000, 100)
All Labels: (8000,)
All Original Images: (8000, 28, 28)
All Reconstructed Images: (8000, 28, 28)
Testing Loss: 0.5551932408809662
Training and Testing Finished
Assembling test data for t-sne projection
Applying t-SNE
WARNING    C:\Users\lukea\anaconda3\envs\diss\Lib\site-packages\joblib\externals\loky\backend\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores < 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(
 [py.warnings]
  File "C:\Users\lukea\anaconda3\envs\diss\Lib\site-packages\joblib\externals\loky\backend\context.py", line 217, in _count_physical_cores
    raise ValueError(
Plotting Results Grid
2 added
7 added
4 added
1 added
5 added
9 added
8 added
0 added
6 added
3 added
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation