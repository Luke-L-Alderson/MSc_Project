Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-13 22:00:40.610848
Training - 2024-06-13 22:00:40.611344
[1/9, 10/94] Training Loss: 1341.76 - Iteration Time: 0:00:01.264128
[1/9, 20/94] Training Loss: 1304.80 - Iteration Time: 0:00:01.277577
[1/9, 30/94] Training Loss: 1297.53 - Iteration Time: 0:00:01.258160
[1/9, 40/94] Training Loss: 1290.65 - Iteration Time: 0:00:01.598035
[1/9, 50/94] Training Loss: 1273.20 - Iteration Time: 0:00:01.391134
[1/9, 60/94] Training Loss: 1251.06 - Iteration Time: 0:00:01.406025
[1/9, 70/94] Training Loss: 1228.86 - Iteration Time: 0:00:01.396230
[1/9, 80/94] Training Loss: 1217.79 - Iteration Time: 0:00:01.250271
[1/9, 90/94] Training Loss: 1190.13 - Iteration Time: 0:00:01.238348
Testing - 2024-06-13 22:02:52.319508
[1/9, 10/16]
Testing Loss: 1146.71 - Epoch Time: 0:02:23.672324
Training - 2024-06-13 22:03:04.284660
[2/9, 10/94] Training Loss: 1182.29 - Iteration Time: 0:00:01.279996
[2/9, 20/94] Training Loss: 1138.40 - Iteration Time: 0:00:01.246264
[2/9, 30/94] Training Loss: 1125.99 - Iteration Time: 0:00:01.285980
[2/9, 40/94] Training Loss: 1106.56 - Iteration Time: 0:00:01.275119
[2/9, 50/94] Training Loss: 1082.51 - Iteration Time: 0:00:01.287395
[2/9, 60/94] Training Loss: 1071.21 - Iteration Time: 0:00:01.296356
[2/9, 70/94] Training Loss: 1040.56 - Iteration Time: 0:00:01.276990
[2/9, 80/94] Training Loss: 1016.84 - Iteration Time: 0:00:01.257318
[2/9, 90/94] Training Loss: 1007.45 - Iteration Time: 0:00:01.286916
Testing - 2024-06-13 22:05:05.918425
[2/9, 10/16]
Testing Loss: 963.52 - Epoch Time: 0:02:13.307405
Training - 2024-06-13 22:05:17.592560
[3/9, 10/94] Training Loss: 979.98 - Iteration Time: 0:00:01.236312
[3/9, 20/94] Training Loss: 980.88 - Iteration Time: 0:00:01.323235
[3/9, 30/94] Training Loss: 954.59 - Iteration Time: 0:00:01.266592
[3/9, 40/94] Training Loss: 947.89 - Iteration Time: 0:00:01.272546
[3/9, 50/94] Training Loss: 942.86 - Iteration Time: 0:00:01.262730
[3/9, 60/94] Training Loss: 929.44 - Iteration Time: 0:00:01.284994
[3/9, 70/94] Training Loss: 911.11 - Iteration Time: 0:00:01.225488
[3/9, 80/94] Training Loss: 911.37 - Iteration Time: 0:00:01.344012
[3/9, 90/94] Training Loss: 904.25 - Iteration Time: 0:00:01.269667
Testing - 2024-06-13 22:07:19.387984
[3/9, 10/16]
Testing Loss: 866.00 - Epoch Time: 0:02:13.425762
Training - 2024-06-13 22:07:31.018818
[4/9, 10/94] Training Loss: 882.45 - Iteration Time: 0:00:01.371351
[4/9, 20/94] Training Loss: 888.37 - Iteration Time: 0:00:01.242299
[4/9, 30/94] Training Loss: 873.30 - Iteration Time: 0:00:01.309328
[4/9, 40/94] Training Loss: 862.29 - Iteration Time: 0:00:01.271049
[4/9, 50/94] Training Loss: 859.21 - Iteration Time: 0:00:01.259194
[4/9, 60/94] Training Loss: 845.29 - Iteration Time: 0:00:01.250716
[4/9, 70/94] Training Loss: 854.19 - Iteration Time: 0:00:01.301818
[4/9, 80/94] Training Loss: 842.56 - Iteration Time: 0:00:01.262608
[4/9, 90/94] Training Loss: 830.60 - Iteration Time: 0:00:01.252244
Testing - 2024-06-13 22:09:33.202229
[4/9, 10/16]
Testing Loss: 797.54 - Epoch Time: 0:02:14.212428
Training - 2024-06-13 22:09:45.231741
[5/9, 10/94] Training Loss: 817.08 - Iteration Time: 0:00:01.459574
[5/9, 20/94] Training Loss: 808.43 - Iteration Time: 0:00:01.510235