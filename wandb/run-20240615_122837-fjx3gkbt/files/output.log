Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-15 12:28:39.514495
Scaler Value: 0.013513513513513514
Training - 2024-06-15 12:28:39.514991
[1/9, 1/94] Training Loss: 0.0695 - Iteration Time: 0:00:01.802889
[1/9, 2/94] Training Loss: 0.0697 - Iteration Time: 0:00:01.488362
[1/9, 3/94] Training Loss: 0.0718 - Iteration Time: 0:00:01.487390
[1/9, 4/94] Training Loss: 0.0717 - Iteration Time: 0:00:01.475008
[1/9, 5/94] Training Loss: 0.0706 - Iteration Time: 0:00:01.429854
[1/9, 6/94] Training Loss: 0.0694 - Iteration Time: 0:00:01.504217
[1/9, 7/94] Training Loss: 0.0689 - Iteration Time: 0:00:01.646204
[1/9, 8/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.536536
[1/9, 9/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.473482
[1/9, 10/94] Training Loss: 0.0705 - Iteration Time: 0:00:01.463084
[1/9, 11/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.505758
[1/9, 12/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.458595
[1/9, 13/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.541475
[1/9, 14/94] Training Loss: 0.0697 - Iteration Time: 0:00:01.450164
[1/9, 15/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.429277
[1/9, 16/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.422360
[1/9, 17/94] Training Loss: 0.0711 - Iteration Time: 0:00:01.468026
[1/9, 18/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.485342
[1/9, 19/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.442183
[1/9, 20/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.489351
[1/9, 21/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.499749
[1/9, 22/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.466056
[1/9, 23/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.542966
[1/9, 24/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.478469
[1/9, 25/94] Training Loss: 0.0700 - Iteration Time: 0:00:01.557918
[1/9, 26/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.465568
[1/9, 27/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.570303
[1/9, 28/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.558833
[1/9, 29/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.524119
[1/9, 30/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.563299
[1/9, 31/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.478035
[1/9, 32/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.541469
[1/9, 33/94] Training Loss: 0.0704 - Iteration Time: 0:00:01.496794
[1/9, 34/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.543468
[1/9, 35/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.576688
[1/9, 36/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.505251
[1/9, 37/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.466772
[1/9, 38/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.444746
[1/9, 39/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.511273
[1/9, 40/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.506253
[1/9, 41/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.455787
[1/9, 42/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.500854
[1/9, 43/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.637677
[1/9, 44/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.522680
[1/9, 45/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.505361
[1/9, 46/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.463107
[1/9, 47/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.461547
[1/9, 48/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.615487
[1/9, 49/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.504274
[1/9, 50/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.551441
[1/9, 51/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.479433
[1/9, 52/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.482910
[1/9, 53/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.511348
[1/9, 54/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.506818
[1/9, 55/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.503325
[1/9, 56/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.465684
[1/9, 57/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.534072
[1/9, 58/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.450814
[1/9, 59/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.464104
[1/9, 60/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.455198
[1/9, 61/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.458701
[1/9, 62/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.477978
[1/9, 63/94] Training Loss: 0.0683 - Iteration Time: 0:00:01.508285
[1/9, 64/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.533568
[1/9, 65/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.468610
[1/9, 66/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.460587
[1/9, 67/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.491864
[1/9, 68/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.494084
[1/9, 69/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.452237
[1/9, 70/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.437210
[1/9, 71/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.611303
[1/9, 72/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.524196
[1/9, 73/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.541115
[1/9, 74/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.496490
[1/9, 75/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.545415
[1/9, 76/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.463642
[1/9, 77/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.515799
[1/9, 78/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.458605
[1/9, 79/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.467525
[1/9, 80/94] Training Loss: 0.0692 - Iteration Time: 0:00:01.483964
[1/9, 81/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.471518
[1/9, 82/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.540952
[1/9, 83/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.540062
[1/9, 84/94] Training Loss: 0.0674 - Iteration Time: 0:00:01.568788
[1/9, 85/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.511416
[1/9, 86/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.498759
[1/9, 87/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.723588
[1/9, 88/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.473522
[1/9, 89/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.483933
[1/9, 90/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.472482
[1/9, 91/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.522089
[1/9, 92/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.497920
[1/9, 93/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.483961
[1/9, 94/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.691748
Testing - 2024-06-15 12:31:12.243628
[1/9, 1/16]
[1/9, 2/16]
[1/9, 3/16]
[1/9, 4/16]
[1/9, 5/16]
[1/9, 6/16]
[1/9, 7/16]
[1/9, 8/16]
[1/9, 9/16]
[1/9, 10/16]
[1/9, 11/16]
[1/9, 12/16]
[1/9, 13/16]
[1/9, 14/16]
[1/9, 15/16]
[1/9, 16/16]
Testing Loss: 0.0619 - Epoch Time: 0:02:56.190152
Training - 2024-06-15 12:31:35.705639
[2/9, 1/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.597965
[2/9, 2/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.421340
[2/9, 3/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.459592
[2/9, 4/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.477407
[2/9, 5/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.516178
[2/9, 6/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.504703
[2/9, 7/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.446190
[2/9, 8/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.477893
[2/9, 9/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.464557
[2/9, 10/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.487844
[2/9, 11/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.444181
[2/9, 12/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.444230
[2/9, 13/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.510188
[2/9, 14/94] Training Loss: 0.0680 - Iteration Time: 0:00:01.540495
[2/9, 15/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.482431
[2/9, 16/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.521603
[2/9, 17/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.573764
[2/9, 18/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.671377
[2/9, 19/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.455169
[2/9, 20/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.487390
[2/9, 21/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.491823
[2/9, 22/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.482401
[2/9, 23/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.605979
[2/9, 24/94] Training Loss: 0.0650 - Iteration Time: 0:00:01.584193
[2/9, 25/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.441153
[2/9, 26/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.484843
[2/9, 27/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.428803
[2/9, 28/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.459527
[2/9, 29/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.449151
[2/9, 30/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.463541
[2/9, 31/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.451650
[2/9, 32/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.497721
[2/9, 33/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.524537
[2/9, 34/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.563742
[2/9, 35/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.513139
[2/9, 36/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.476392
[2/9, 37/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.576462
[2/9, 38/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.477890
[2/9, 39/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.652563
[2/9, 40/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.473949
[2/9, 41/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.510716
[2/9, 42/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.499309
[2/9, 43/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.522134
[2/9, 44/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.511707
[2/9, 45/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.568232
[2/9, 46/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.477371
[2/9, 47/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.511677
[2/9, 48/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.510634
[2/9, 49/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.484812
[2/9, 50/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.552311
[2/9, 51/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.518598
[2/9, 52/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.523520
[2/9, 53/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.524517
[2/9, 54/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.472432
[2/9, 55/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.466982
[2/9, 56/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.488800
[2/9, 57/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.593002
[2/9, 58/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.443643
[2/9, 59/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.495272
[2/9, 60/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.506681
[2/9, 61/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.456067
[2/9, 62/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.461577
[2/9, 63/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.481892
[2/9, 64/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.509193
[2/9, 65/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.486799
[2/9, 66/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.543403
[2/9, 67/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.504694
[2/9, 68/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.534504
[2/9, 69/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.434246
[2/9, 70/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.516639
[2/9, 71/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.475545
[2/9, 72/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.508275
[2/9, 73/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.423099
[2/9, 74/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.526548
[2/9, 75/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.560492
[2/9, 76/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.435757
[2/9, 77/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.421420
[2/9, 78/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.443744
[2/9, 79/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.438358
[2/9, 80/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.580106
[2/9, 81/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.473066
[2/9, 82/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.492371
[2/9, 83/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.532555
[2/9, 84/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.468542
[2/9, 85/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.651638
[2/9, 86/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.483380
[2/9, 87/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.489321
[2/9, 88/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.486363
[2/9, 89/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.563246
[2/9, 90/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.455064
[2/9, 91/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.442671
[2/9, 92/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.465992
[2/9, 93/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.491278
[2/9, 94/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.465999
Testing - 2024-06-15 12:33:56.766602
[2/9, 1/16]
[2/9, 2/16]
[2/9, 3/16]
[2/9, 4/16]
[2/9, 5/16]
[2/9, 6/16]
[2/9, 7/16]
[2/9, 8/16]
[2/9, 9/16]
[2/9, 10/16]
[2/9, 11/16]
[2/9, 12/16]
[2/9, 13/16]
[2/9, 14/16]
[2/9, 15/16]
[2/9, 16/16]
Testing Loss: 0.0622 - Epoch Time: 0:02:35.004100
Training - 2024-06-15 12:34:10.710235
[3/9, 1/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.444160
[3/9, 2/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.486847
[3/9, 3/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.454735
[3/9, 4/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.596492
[3/9, 5/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.442246
[3/9, 6/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.469516
[3/9, 7/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.481384
[3/9, 8/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.454625
[3/9, 9/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.551395
[3/9, 10/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.504166
[3/9, 11/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.482874
[3/9, 12/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.461506
[3/9, 13/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.541532
[3/9, 14/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.518649
[3/9, 15/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.483883
[3/9, 16/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.505200
[3/9, 17/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.560335
[3/9, 18/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.517109
[3/9, 19/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.459608
[3/9, 20/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.483940
[3/9, 21/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.515124
[3/9, 22/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.537015
[3/9, 23/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.459639
[3/9, 24/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.460119
[3/9, 25/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.494300
[3/9, 26/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.524086
[3/9, 27/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.444680
[3/9, 28/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.503205
[3/9, 29/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.448655
[3/9, 30/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.466525
[3/9, 31/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.440245
[3/9, 32/94] Training Loss: 0.0630 - Iteration Time: 0:00:01.448627
[3/9, 33/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.452660
[3/9, 34/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.600434
[3/9, 35/94] Training Loss: 0.0592 - Iteration Time: 0:00:01.646577
[3/9, 36/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.482857
[3/9, 37/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.579636
[3/9, 38/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.498230
[3/9, 39/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.494333
[3/9, 40/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.565237
[3/9, 41/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.586672
[3/9, 42/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.494744
[3/9, 43/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.495323
[3/9, 44/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.571645
[3/9, 45/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.445714
[3/9, 46/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.426275
[3/9, 47/94] Training Loss: 0.0624 - Iteration Time: 0:00:01.474333
[3/9, 48/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.468018
[3/9, 49/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.457088
[3/9, 50/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.481362
[3/9, 51/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.586082
[3/9, 52/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.476915
[3/9, 53/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.513119
[3/9, 54/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.434225
[3/9, 55/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.465492
[3/9, 56/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.498723
[3/9, 57/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.455080
[3/9, 58/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.418838
[3/9, 59/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.443167
[3/9, 60/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.450109
[3/9, 61/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.442164
[3/9, 62/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.483921
[3/9, 63/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.535027
[3/9, 64/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.489065
[3/9, 65/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.442741
[3/9, 66/94] Training Loss: 0.0586 - Iteration Time: 0:00:01.491869
[3/9, 67/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.517188
[3/9, 68/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.475520
[3/9, 69/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.457107
[3/9, 70/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.421401
[3/9, 71/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.451691
[3/9, 72/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.431813
[3/9, 73/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.501800
[3/9, 74/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.483434
[3/9, 75/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.601567
[3/9, 76/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.521623
[3/9, 77/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.470011
[3/9, 78/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.621334
[3/9, 79/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.487830
[3/9, 80/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.545505
[3/9, 81/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.548347
[3/9, 82/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.480967
[3/9, 83/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.542911
[3/9, 84/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.592121
[3/9, 85/94] Training Loss: 0.0591 - Iteration Time: 0:00:01.507719
[3/9, 86/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.510764
[3/9, 87/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.472554
[3/9, 88/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.439793
[3/9, 89/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.518604
[3/9, 90/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.540440
[3/9, 91/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.569228
[3/9, 92/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.524140
[3/9, 93/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.538440
[3/9, 94/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.477897
Testing - 2024-06-15 12:36:31.536448
[3/9, 1/16]
[3/9, 2/16]
[3/9, 3/16]
[3/9, 4/16]
[3/9, 5/16]
[3/9, 6/16]
[3/9, 7/16]
[3/9, 8/16]
[3/9, 9/16]
[3/9, 10/16]
[3/9, 11/16]
[3/9, 12/16]
[3/9, 13/16]
[3/9, 14/16]
[3/9, 15/16]
[3/9, 16/16]
Testing Loss: 0.0574 - Epoch Time: 0:02:35.058007
Training - 2024-06-15 12:36:45.768242
[4/9, 1/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.445676
[4/9, 2/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.461551
[4/9, 3/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.475492
[4/9, 4/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.511665
[4/9, 5/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.502837
[4/9, 6/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.524205
[4/9, 7/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.477426
[4/9, 8/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.469044
[4/9, 9/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.477505
[4/9, 10/94] Training Loss: 0.0587 - Iteration Time: 0:00:01.523601
[4/9, 11/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.570289
[4/9, 12/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.482585
[4/9, 13/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.511737
[4/9, 14/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.418429
[4/9, 15/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.513685
[4/9, 16/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.466110
[4/9, 17/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.492471
[4/9, 18/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.442740
[4/9, 19/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.418481
[4/9, 20/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.456607
[4/9, 21/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.507178
[4/9, 22/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.457112
[4/9, 23/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.470977
[4/9, 24/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.501741
[4/9, 25/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.450106
[4/9, 26/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.493800
[4/9, 27/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.526046
[4/9, 28/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.521611
[4/9, 29/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.473907
[4/9, 30/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.602455
[4/9, 31/94] Training Loss: 0.0584 - Iteration Time: 0:00:01.434228
[4/9, 32/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.497284
[4/9, 33/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.486830
[4/9, 34/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.493287
[4/9, 35/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.525518
[4/9, 36/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.501729
[4/9, 37/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.418840
[4/9, 38/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.495758
[4/9, 39/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.586520
[4/9, 40/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.469473
[4/9, 41/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.469490
[4/9, 42/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.465534
[4/9, 43/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.467496
[4/9, 44/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.479986
[4/9, 45/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.525050
[4/9, 46/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.507219
[4/9, 47/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.501775
[4/9, 48/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.468113
[4/9, 49/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.480413
[4/9, 50/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.509214
[4/9, 51/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.532946
[4/9, 52/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.555874
[4/9, 53/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.496619
[4/9, 54/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.512854
[4/9, 55/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.431862
[4/9, 56/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.449060
[4/9, 57/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.475439
[4/9, 58/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.489355
[4/9, 59/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.430983
[4/9, 60/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.455591
[4/9, 61/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.515644
[4/9, 62/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.504690
[4/9, 63/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.578617
[4/9, 64/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.443912
[4/9, 65/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.446735
[4/9, 66/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.561788
[4/9, 67/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.540404
[4/9, 68/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.432314
[4/9, 69/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.513617
[4/9, 70/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.484324
[4/9, 71/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.522573
[4/9, 72/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.549351
[4/9, 73/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.579591
[4/9, 74/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.484887
[4/9, 75/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.645561
[4/9, 76/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.438219
[4/9, 77/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.492765
[4/9, 78/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.503924
[4/9, 79/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.592586
[4/9, 80/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.464136
[4/9, 81/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.535209
[4/9, 82/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.507325
[4/9, 83/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.540477
[4/9, 84/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.470136
[4/9, 85/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.484443
[4/9, 86/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.483029
[4/9, 87/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.456662
[4/9, 88/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.522733
[4/9, 89/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.424042
[4/9, 90/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.526610
[4/9, 91/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.583103
[4/9, 92/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.432837
[4/9, 93/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.455720
[4/9, 94/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.395578
Testing - 2024-06-15 12:39:06.234510
[4/9, 1/16]
[4/9, 2/16]
[4/9, 3/16]
[4/9, 4/16]
[4/9, 5/16]
[4/9, 6/16]
[4/9, 7/16]
[4/9, 8/16]
[4/9, 9/16]
[4/9, 10/16]
[4/9, 11/16]
[4/9, 12/16]
[4/9, 13/16]
[4/9, 14/16]
[4/9, 15/16]
[4/9, 16/16]
Testing Loss: 0.0533 - Epoch Time: 0:02:34.088440
Training - 2024-06-15 12:39:19.857178
[5/9, 1/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.452135
[5/9, 2/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.451135
[5/9, 3/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.436284
[5/9, 4/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.427978
[5/9, 5/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.440224
[5/9, 6/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.481992
[5/9, 7/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.439199
[5/9, 8/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.438291
[5/9, 9/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.486409
[5/9, 10/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.393119
[5/9, 11/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.452138
[5/9, 12/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.506739
[5/9, 13/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.458174
[5/9, 14/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.479470
[5/9, 15/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.468070
[5/9, 16/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.551928
[5/9, 17/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.484902
[5/9, 18/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.423419
[5/9, 19/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.503357
[5/9, 20/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.472032
[5/9, 21/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.480502
[5/9, 22/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.498814
[5/9, 23/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.463651
[5/9, 24/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.490395
[5/9, 25/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.500864
[5/9, 26/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.551954
[5/9, 27/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.503262
[5/9, 28/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.597021
[5/9, 29/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.721548
[5/9, 30/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.475029
[5/9, 31/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.459045
[5/9, 32/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.471480
[5/9, 33/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.467591
[5/9, 34/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.455145
[5/9, 35/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.539548
[5/9, 36/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.515709
[5/9, 37/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.522593
[5/9, 38/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.467015
[5/9, 39/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.456613
[5/9, 40/94] Training Loss: 0.0557 - Iteration Time: 0:00:01.455192
[5/9, 41/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.552375
[5/9, 42/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.523642
[5/9, 43/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.542556
[5/9, 44/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.511735
[5/9, 45/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.446222
[5/9, 46/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.519728
[5/9, 47/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.501839
[5/9, 48/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.445264
[5/9, 49/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.530035
[5/9, 50/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.474623
[5/9, 51/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.430820
[5/9, 52/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.543998
[5/9, 53/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.496825
[5/9, 54/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.604072
[5/9, 55/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.560293
[5/9, 56/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.615937
[5/9, 57/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.498799
[5/9, 58/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.471593
[5/9, 59/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.478953
[5/9, 60/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.488419
[5/9, 61/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.520181
[5/9, 62/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.525193
[5/9, 63/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.490426
[5/9, 64/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.455612
[5/9, 65/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.414964
[5/9, 66/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.456337
[5/9, 67/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.456620
[5/9, 68/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.556409
[5/9, 69/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.490440
[5/9, 70/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.544945
[5/9, 71/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.472027
[5/9, 72/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.580779
[5/9, 73/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.472007
[5/9, 74/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.473948
[5/9, 75/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.599675
[5/9, 76/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.511227
[5/9, 77/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.441749
[5/9, 78/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.479548
[5/9, 79/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.464648
[5/9, 80/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.502832
[5/9, 81/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.478021
[5/9, 82/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.442197
[5/9, 83/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.492851
[5/9, 84/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.468123
[5/9, 85/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.445698
[5/9, 86/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.466117
[5/9, 87/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.491381
[5/9, 88/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.502832
[5/9, 89/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.454100
[5/9, 90/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.437753
[5/9, 91/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.450233
[5/9, 92/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.529097
[5/9, 93/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.443784
[5/9, 94/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.449675
Testing - 2024-06-15 12:41:39.989026
[5/9, 1/16]
[5/9, 2/16]
[5/9, 3/16]
[5/9, 4/16]
[5/9, 5/16]
[5/9, 6/16]
[5/9, 7/16]
[5/9, 8/16]
[5/9, 9/16]
[5/9, 10/16]
[5/9, 11/16]
[5/9, 12/16]
[5/9, 13/16]
[5/9, 14/16]
[5/9, 15/16]
[5/9, 16/16]
Testing Loss: 0.0502 - Epoch Time: 0:02:34.209944
Training - 2024-06-15 12:41:54.067122
[6/9, 1/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.513390
[6/9, 2/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.438501
[6/9, 3/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.558360
[6/9, 4/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.508770
[6/9, 5/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.491064
[6/9, 6/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.631830
[6/9, 7/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.485478
[6/9, 8/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.498791
[6/9, 9/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.503864
[6/9, 10/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.522193
[6/9, 11/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.431828
[6/9, 12/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.490402
[6/9, 13/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.535617
[6/9, 14/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.420431
[6/9, 15/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.512750
[6/9, 16/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.517694
[6/9, 17/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.516311
[6/9, 18/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.432313
[6/9, 19/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.636348
[6/9, 20/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.444738
[6/9, 21/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.463746
[6/9, 22/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.446272
[6/9, 23/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.449195
[6/9, 24/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.538804
[6/9, 25/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.465607
[6/9, 26/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.457158
[6/9, 27/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.440770
[6/9, 28/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.483877
[6/9, 29/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.457183
[6/9, 30/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.652096
[6/9, 31/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.585623
[6/9, 32/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.486339
[6/9, 33/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.558858
[6/9, 34/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.499333
[6/9, 35/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.475960
[6/9, 36/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.487356
[6/9, 37/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.459089
[6/9, 38/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.503269
[6/9, 39/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.454606
[6/9, 40/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.474072
[6/9, 41/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.517692
[6/9, 42/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.508724
[6/9, 43/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.417890
[6/9, 44/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.462037
[6/9, 45/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.614470
[6/9, 46/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.487876
[6/9, 47/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.508763
[6/9, 48/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.522660
[6/9, 49/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.543509
[6/9, 50/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.480000
[6/9, 51/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.492421
[6/9, 52/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.456629
[6/9, 53/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.493848
[6/9, 54/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.432345
[6/9, 55/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.553943
[6/9, 56/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.453150
[6/9, 57/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.633936
[6/9, 58/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.512679
[6/9, 59/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.510770
[6/9, 60/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.470119
[6/9, 61/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.491874
[6/9, 62/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.466062
[6/9, 63/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.475944
[6/9, 64/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.485013
[6/9, 65/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.579761
[6/9, 66/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.491846
[6/9, 67/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.475643
[6/9, 68/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.480451
[6/9, 69/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.429933
[6/9, 70/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.474126
[6/9, 71/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.517640
[6/9, 72/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.462577
[6/9, 73/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.640199
[6/9, 74/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.594683
[6/9, 75/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.498363
[6/9, 76/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.444258
[6/9, 77/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.651674
[6/9, 78/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.516166
[6/9, 79/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.488857
[6/9, 80/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.499275
[6/9, 81/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.593579
[6/9, 82/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.468523
[6/9, 83/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.510207
[6/9, 84/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.520148
[6/9, 85/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.582691
[6/9, 86/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.495355
[6/9, 87/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.449198
[6/9, 88/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.528593
[6/9, 89/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.487370
[6/9, 90/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.535525
[6/9, 91/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.524746
[6/9, 92/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.593032
[6/9, 93/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.471051
[6/9, 94/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.417991
Testing - 2024-06-15 12:44:15.503053
[6/9, 1/16]
[6/9, 2/16]
[6/9, 3/16]
[6/9, 4/16]
[6/9, 5/16]
[6/9, 6/16]
[6/9, 7/16]
[6/9, 8/16]
[6/9, 9/16]
[6/9, 10/16]
[6/9, 11/16]
[6/9, 12/16]
[6/9, 13/16]
[6/9, 14/16]
[6/9, 15/16]
[6/9, 16/16]
Testing Loss: 0.0505 - Epoch Time: 0:02:35.407084
Training - 2024-06-15 12:44:29.474702
[7/9, 1/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.464589
[7/9, 2/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.448862
[7/9, 3/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.433809
[7/9, 4/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.446835
[7/9, 5/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.480877
[7/9, 6/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.471028
[7/9, 7/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.508194
[7/9, 8/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.478492
[7/9, 9/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.486884
[7/9, 10/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.533582
[7/9, 11/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.507840
[7/9, 12/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.433398
[7/9, 13/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.517635
[7/9, 14/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.487844
[7/9, 15/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.499895
[7/9, 16/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.467112
[7/9, 17/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.445227
[7/9, 18/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.472489
[7/9, 19/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.502368
[7/9, 20/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.442213
[7/9, 21/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.594604
[7/9, 22/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.637272
[7/9, 23/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.462064
[7/9, 24/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.472476
[7/9, 25/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.496847
[7/9, 26/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.454635
[7/9, 27/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.450722
[7/9, 28/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.443227
[7/9, 29/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.445234
[7/9, 30/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.504275
[7/9, 31/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.636236
[7/9, 32/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.450280
[7/9, 33/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.573813
[7/9, 34/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.557360
[7/9, 35/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.459116
[7/9, 36/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.478085
[7/9, 37/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.538018
[7/9, 38/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.505681
[7/9, 39/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.439878
[7/9, 40/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.438755
[7/9, 41/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.440280
[7/9, 42/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.540504
[7/9, 43/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.509001
[7/9, 44/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.502746
[7/9, 45/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.447720
[7/9, 46/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.464608
[7/9, 47/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.469541
[7/9, 48/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.453154
[7/9, 49/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.458150
[7/9, 50/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.496389
[7/9, 51/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.494431
[7/9, 52/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.441877
[7/9, 53/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.473976
[7/9, 54/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.454155
[7/9, 55/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.488382
[7/9, 56/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.469042
[7/9, 57/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.437798
[7/9, 58/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.523235
[7/9, 59/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.526070
[7/9, 60/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.455173
[7/9, 61/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.536596
[7/9, 62/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.477492
[7/9, 63/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.673012
[7/9, 64/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.508693
[7/9, 65/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.459663
[7/9, 66/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.456114
[7/9, 67/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.480001
[7/9, 68/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.500309
[7/9, 69/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.452176
[7/9, 70/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.518308
[7/9, 71/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.481881
[7/9, 72/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.430320
[7/9, 73/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.463620
[7/9, 74/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.684454
[7/9, 75/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.456195
[7/9, 76/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.461047
[7/9, 77/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.539031
[7/9, 78/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.494343
[7/9, 79/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.534585
[7/9, 80/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.496866
[7/9, 81/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.538504
[7/9, 82/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.484397
[7/9, 83/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.492830
[7/9, 84/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.513751
[7/9, 85/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.577723
[7/9, 86/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.434346
[7/9, 87/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.517709
[7/9, 88/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.473933
[7/9, 89/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.469558
[7/9, 90/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.550865
[7/9, 91/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.475089
[7/9, 92/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.445793
[7/9, 93/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.415928
[7/9, 94/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.480046
Testing - 2024-06-15 12:46:49.650110
[7/9, 1/16]
[7/9, 2/16]
[7/9, 3/16]
[7/9, 4/16]
[7/9, 5/16]
[7/9, 6/16]
[7/9, 7/16]
[7/9, 8/16]
[7/9, 9/16]
[7/9, 10/16]
[7/9, 11/16]
[7/9, 12/16]
[7/9, 13/16]
[7/9, 14/16]
[7/9, 15/16]
[7/9, 16/16]
Testing Loss: 0.0480 - Epoch Time: 0:02:34.253627
Training - 2024-06-15 12:47:03.728825
[8/9, 1/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.445765
[8/9, 2/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.492443
[8/9, 3/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.469119
[8/9, 4/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.504963
[8/9, 5/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.429813
[8/9, 6/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.461699
[8/9, 7/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.431871
[8/9, 8/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.519712
[8/9, 9/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.458579
[8/9, 10/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.529619
[8/9, 11/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.501871
[8/9, 12/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.477011
[8/9, 13/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.563346
[8/9, 14/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.509226
[8/9, 15/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.418924
[8/9, 16/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.477454
[8/9, 17/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.559283
[8/9, 18/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.492467
[8/9, 19/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.548878
[8/9, 20/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.461689
[8/9, 21/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.528013
[8/9, 22/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.530617
[8/9, 23/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.438766
[8/9, 24/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.433354
[8/9, 25/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.671429
[8/9, 26/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.476980
[8/9, 27/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.535565
[8/9, 28/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.498967
[8/9, 29/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.445704
[8/9, 30/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.409101
[8/9, 31/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.439822
[8/9, 32/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.522686
[8/9, 33/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.466023
[8/9, 34/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.439894
[8/9, 35/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.463041
[8/9, 36/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.441349
[8/9, 37/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.514257
[8/9, 38/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.555361
[8/9, 39/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.632789
[8/9, 40/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.436918
[8/9, 41/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.511781
[8/9, 42/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.474682
[8/9, 43/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.459739
[8/9, 44/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.456658
[8/9, 45/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.506230
[8/9, 46/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.494320
[8/9, 47/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.510415
[8/9, 48/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.544467
[8/9, 49/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.489970
[8/9, 50/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.551444
[8/9, 51/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.516194
[8/9, 52/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.431428
[8/9, 53/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.444724
[8/9, 54/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.462527
[8/9, 55/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.521158
[8/9, 56/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.426917
[8/9, 57/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.435398
[8/9, 58/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.446796
[8/9, 59/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.633327
[8/9, 60/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.500798
[8/9, 61/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.490853
[8/9, 62/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.538435
[8/9, 63/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.508760
[8/9, 64/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.472963
[8/9, 65/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.508682
[8/9, 66/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.496353
[8/9, 67/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.560344
[8/9, 68/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.435746
[8/9, 69/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.441751
[8/9, 70/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.716225
[8/9, 71/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.486490
[8/9, 72/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.465075
[8/9, 73/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.466549
[8/9, 74/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.465134
[8/9, 75/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.425421
[8/9, 76/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.534277
[8/9, 77/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.550624
[8/9, 78/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.441717
[8/9, 79/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.605018
[8/9, 80/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.495891
[8/9, 81/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.507685
[8/9, 82/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.454144
[8/9, 83/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.426895
[8/9, 84/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.547487
[8/9, 85/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.493876
[8/9, 86/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.449771
[8/9, 87/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.484967
[8/9, 88/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.490339
[8/9, 89/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.470654
[8/9, 90/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.413968
[8/9, 91/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.517289
[8/9, 92/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.527114
[8/9, 93/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.471496
[8/9, 94/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.392128
Testing - 2024-06-15 12:49:24.025074
[8/9, 1/16]
[8/9, 2/16]
[8/9, 3/16]
[8/9, 4/16]
[8/9, 5/16]
[8/9, 6/16]
[8/9, 7/16]
[8/9, 8/16]
[8/9, 9/16]
[8/9, 10/16]
[8/9, 11/16]
[8/9, 12/16]
[8/9, 13/16]
[8/9, 14/16]
[8/9, 15/16]
[8/9, 16/16]
Testing Loss: 0.0468 - Epoch Time: 0:02:34.292941
Training - 2024-06-15 12:49:38.021766
[9/9, 1/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.448799
[9/9, 2/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.475007
[9/9, 3/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.433860
[9/9, 4/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.556879
[9/9, 5/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.476507
[9/9, 6/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.436780
[9/9, 7/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.434269
[9/9, 8/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.560915
[9/9, 9/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.597056
[9/9, 10/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.464031
[9/9, 11/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.471582
[9/9, 12/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.499318
[9/9, 13/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.472000
[9/9, 14/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.480418
[9/9, 15/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.586152
[9/9, 16/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.525546
[9/9, 17/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.585632
[9/9, 18/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.430327
[9/9, 19/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.514208
[9/9, 20/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.562757
[9/9, 21/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.478461
[9/9, 22/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.448178
[9/9, 23/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.607531
[9/9, 24/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.520178
[9/9, 25/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.504774
[9/9, 26/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.555905
[9/9, 27/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.616970
[9/9, 28/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.600613
[9/9, 29/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.453643
[9/9, 30/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.471599
[9/9, 31/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.529101
[9/9, 32/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.498315
[9/9, 33/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.525701
[9/9, 34/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.469492
[9/9, 35/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.503811
[9/9, 36/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.483523
[9/9, 37/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.429431
[9/9, 38/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.486858
[9/9, 39/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.469569
[9/9, 40/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.437818
[9/9, 41/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.460289
[9/9, 42/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.508267
[9/9, 43/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.554926
[9/9, 44/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.515221
[9/9, 45/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.504397
[9/9, 46/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.493376
[9/9, 47/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.506903
[9/9, 48/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.449250
[9/9, 49/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.450373
[9/9, 50/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.494402
[9/9, 51/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.555106
[9/9, 52/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.464083
[9/9, 53/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.515790
[9/9, 54/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.462141
[9/9, 55/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.608008
[9/9, 56/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.604029
[9/9, 57/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.441943
[9/9, 58/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.526068
[9/9, 59/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.443720
[9/9, 60/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.519122
[9/9, 61/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.464127
[9/9, 62/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.541010
[9/9, 63/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.528596
[9/9, 64/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.479970
[9/9, 65/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.504780
[9/9, 66/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.483381
[9/9, 67/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.432839
[9/9, 68/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.510710
[9/9, 69/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.494353
[9/9, 70/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.473578
[9/9, 71/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.531099
[9/9, 72/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.615820
[9/9, 73/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.489390
[9/9, 74/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.496259
[9/9, 75/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.513225
[9/9, 76/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.481440
[9/9, 77/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.484930
[9/9, 78/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.436301
[9/9, 79/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.553535
[9/9, 80/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.523637
[9/9, 81/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.459582
[9/9, 82/94] Training Loss: 0.0450 - Iteration Time: 0:00:01.419375
[9/9, 83/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.553998
[9/9, 84/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.629267
[9/9, 85/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.426917
[9/9, 86/94] Training Loss: 0.0443 - Iteration Time: 0:00:01.448680
[9/9, 87/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.489418
[9/9, 88/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.437877
[9/9, 89/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.528116
[9/9, 90/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.512643
[9/9, 91/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.478001
[9/9, 92/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.467586
[9/9, 93/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.467621
[9/9, 94/94] Training Loss: 0.0436 - Iteration Time: 0:00:01.462076
Testing - 2024-06-15 12:51:59.113047
[9/9, 1/16]
[9/9, 2/16]
[9/9, 3/16]
[9/9, 4/16]
[9/9, 5/16]
[9/9, 6/16]
[9/9, 7/16]
[9/9, 8/16]
[9/9, 9/16]
[9/9, 10/16]
[9/9, 11/16]
[9/9, 12/16]
[9/9, 13/16]
[9/9, 14/16]
[9/9, 15/16]
[9/9, 16/16]
Testing Loss: 0.0441 - Epoch Time: 0:02:35.030131
Training and Testing Finished - Time: 0:23:33.537900
Assembling test data for t-sne projection
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 4
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 4
Applying t-SNE