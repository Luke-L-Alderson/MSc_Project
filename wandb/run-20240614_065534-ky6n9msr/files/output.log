Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-14 06:55:35.561355
Scaler Value: 1000
Training - 2024-06-14 06:55:35.561853
[1/9, 10/94] Training Loss: 38662.32 - Iteration Time: 0:00:01.285969
[1/9, 20/94] Training Loss: 35437.92 - Iteration Time: 0:00:01.452166
[1/9, 30/94] Training Loss: 33797.35 - Iteration Time: 0:00:01.288451
[1/9, 40/94] Training Loss: 32914.27 - Iteration Time: 0:00:01.269098
[1/9, 50/94] Training Loss: 32290.45 - Iteration Time: 0:00:01.293024
[1/9, 60/94] Training Loss: 31570.80 - Iteration Time: 0:00:01.305292
[1/9, 70/94] Training Loss: 31037.35 - Iteration Time: 0:00:01.328166
[1/9, 80/94] Training Loss: 30681.33 - Iteration Time: 0:00:01.282481
[1/9, 90/94] Training Loss: 30354.79 - Iteration Time: 0:00:01.293376
Testing - 2024-06-14 06:57:41.062490
[1/9, 10/16]
Testing Loss: 30072.38 - Epoch Time: 0:02:17.291326
Training - 2024-06-14 06:57:52.853676
[2/9, 10/94] Training Loss: 29965.13 - Iteration Time: 0:00:01.339626
[2/9, 20/94] Training Loss: 29676.14 - Iteration Time: 0:00:01.295345
[2/9, 30/94] Training Loss: 29401.88 - Iteration Time: 0:00:01.298337
[2/9, 40/94] Training Loss: 29152.45 - Iteration Time: 0:00:01.312238
[2/9, 50/94] Training Loss: 28968.24 - Iteration Time: 0:00:01.296946
[2/9, 60/94] Training Loss: 28709.64 - Iteration Time: 0:00:01.330879
[2/9, 70/94] Training Loss: 28351.40 - Iteration Time: 0:00:01.279484
[2/9, 80/94] Training Loss: 27980.81 - Iteration Time: 0:00:01.365290
[2/9, 90/94] Training Loss: 27672.47 - Iteration Time: 0:00:01.299336
Testing - 2024-06-14 06:59:57.779373
[2/9, 10/16]
Testing Loss: 27326.39 - Epoch Time: 0:02:17.164040
Training - 2024-06-14 07:00:10.018213
[3/9, 10/94] Training Loss: 27142.14 - Iteration Time: 0:00:01.249726
[3/9, 20/94] Training Loss: 26838.43 - Iteration Time: 0:00:01.319184
[3/9, 30/94] Training Loss: 26427.94 - Iteration Time: 0:00:01.302492
[3/9, 40/94] Training Loss: 26039.36 - Iteration Time: 0:00:01.361394
[3/9, 50/94] Training Loss: 25705.52 - Iteration Time: 0:00:01.329697
[3/9, 60/94] Training Loss: 25372.44 - Iteration Time: 0:00:01.301833
[3/9, 70/94] Training Loss: 25056.14 - Iteration Time: 0:00:01.300366
[3/9, 80/94] Training Loss: 24770.24 - Iteration Time: 0:00:01.318463
[3/9, 90/94] Training Loss: 24566.43 - Iteration Time: 0:00:01.326108
Testing - 2024-06-14 07:02:15.028369
[3/9, 10/16]
Testing Loss: 24447.63 - Epoch Time: 0:02:16.937560
Training - 2024-06-14 07:02:26.956765
[4/9, 10/94] Training Loss: 24327.19 - Iteration Time: 0:00:01.304301
[4/9, 20/94] Training Loss: 24198.93 - Iteration Time: 0:00:01.313682
[4/9, 30/94] Training Loss: 23928.02 - Iteration Time: 0:00:01.316199
[4/9, 40/94] Training Loss: 23719.98 - Iteration Time: 0:00:01.335538
[4/9, 50/94] Training Loss: 23496.30 - Iteration Time: 0:00:01.379307
[4/9, 60/94] Training Loss: 23239.43 - Iteration Time: 0:00:01.295839
[4/9, 70/94] Training Loss: 23039.57 - Iteration Time: 0:00:01.474462
[4/9, 80/94] Training Loss: 22846.22 - Iteration Time: 0:00:01.314702
[4/9, 90/94] Training Loss: 22641.09 - Iteration Time: 0:00:01.394234
Testing - 2024-06-14 07:04:33.879682
[4/9, 10/16]
Testing Loss: 22500.08 - Epoch Time: 0:02:18.920645
Training - 2024-06-14 07:04:45.877907
[5/9, 10/94] Training Loss: 22408.61 - Iteration Time: 0:00:01.319649
[5/9, 20/94] Training Loss: 22215.98 - Iteration Time: 0:00:01.325199
[5/9, 30/94] Training Loss: 21848.26 - Iteration Time: 0:00:01.282546
[5/9, 40/94] Training Loss: 21684.05 - Iteration Time: 0:00:01.341026
[5/9, 50/94] Training Loss: 21556.52 - Iteration Time: 0:00:01.283548
[5/9, 60/94] Training Loss: 21444.40 - Iteration Time: 0:00:01.325644
[5/9, 70/94] Training Loss: 21359.67 - Iteration Time: 0:00:01.305844
[5/9, 80/94] Training Loss: 21256.32 - Iteration Time: 0:00:01.294848
[5/9, 90/94] Training Loss: 21196.41 - Iteration Time: 0:00:01.272527
Testing - 2024-06-14 07:06:51.975743
[5/9, 10/16]
Testing Loss: 21061.04 - Epoch Time: 0:02:18.202461
Training - 2024-06-14 07:07:04.080864
[6/9, 10/94] Training Loss: 20982.44 - Iteration Time: 0:00:01.291893
[6/9, 20/94] Training Loss: 20737.37 - Iteration Time: 0:00:01.307281
[6/9, 30/94] Training Loss: 20392.91 - Iteration Time: 0:00:01.286425
[6/9, 40/94] Training Loss: 20099.41 - Iteration Time: 0:00:01.270537
[6/9, 50/94] Training Loss: 19812.67 - Iteration Time: 0:00:01.279976
[6/9, 60/94] Training Loss: 19456.67 - Iteration Time: 0:00:01.282922
[6/9, 70/94] Training Loss: 19259.55 - Iteration Time: 0:00:01.317712
[6/9, 80/94] Training Loss: 19152.28 - Iteration Time: 0:00:01.275534
[6/9, 90/94] Training Loss: 19102.37 - Iteration Time: 0:00:01.499289
Testing - 2024-06-14 07:09:09.901840
[6/9, 10/16]
Testing Loss: 18915.32 - Epoch Time: 0:02:17.763839
Training - 2024-06-14 07:09:21.845696
[7/9, 10/94] Training Loss: 18866.12 - Iteration Time: 0:00:01.295630
[7/9, 20/94] Training Loss: 18667.21 - Iteration Time: 0:00:01.257145
[7/9, 30/94] Training Loss: 18567.60 - Iteration Time: 0:00:01.541438
[7/9, 40/94] Training Loss: 18443.26 - Iteration Time: 0:00:01.288393
[7/9, 50/94] Training Loss: 18291.59 - Iteration Time: 0:00:01.313229
[7/9, 60/94] Training Loss: 18228.14 - Iteration Time: 0:00:01.275018
[7/9, 70/94] Training Loss: 18183.02 - Iteration Time: 0:00:01.704737
[7/9, 80/94] Training Loss: 18071.66 - Iteration Time: 0:00:01.443266
[7/9, 90/94] Training Loss: 17902.61 - Iteration Time: 0:00:01.443713
Testing - 2024-06-14 07:11:35.515732
[7/9, 10/16]
Testing Loss: 17690.79 - Epoch Time: 0:02:26.014072
Training - 2024-06-14 07:11:47.860264
[8/9, 10/94] Training Loss: 17639.37 - Iteration Time: 0:00:01.377726
[8/9, 20/94] Training Loss: 17553.99 - Iteration Time: 0:00:01.300843
[8/9, 30/94] Training Loss: 17471.99 - Iteration Time: 0:00:01.283470
[8/9, 40/94] Training Loss: 17323.97 - Iteration Time: 0:00:01.281954
[8/9, 50/94] Training Loss: 17214.03 - Iteration Time: 0:00:01.260103
[8/9, 60/94] Training Loss: 17088.28 - Iteration Time: 0:00:01.328591
[8/9, 70/94] Training Loss: 16936.23 - Iteration Time: 0:00:01.322669
[8/9, 80/94] Training Loss: 16798.12 - Iteration Time: 0:00:01.299350
[8/9, 90/94] Training Loss: 16713.91 - Iteration Time: 0:00:01.312806
Testing - 2024-06-14 07:13:52.479997
[8/9, 10/16]
Testing Loss: 16564.84 - Epoch Time: 0:02:16.914246
Training - 2024-06-14 07:14:04.775006
[9/9, 10/94] Training Loss: 16543.43 - Iteration Time: 0:00:01.312738
[9/9, 20/94] Training Loss: 16509.29 - Iteration Time: 0:00:01.324183
[9/9, 30/94] Training Loss: 16379.97 - Iteration Time: 0:00:01.288493
[9/9, 40/94] Training Loss: 16240.46 - Iteration Time: 0:00:01.311743
[9/9, 50/94] Training Loss: 16194.45 - Iteration Time: 0:00:01.305298
[9/9, 60/94] Training Loss: 16077.26 - Iteration Time: 0:00:01.299328
[9/9, 70/94] Training Loss: 15955.62 - Iteration Time: 0:00:01.310870
[9/9, 80/94] Training Loss: 15866.36 - Iteration Time: 0:00:01.366315
[9/9, 90/94] Training Loss: 15749.76 - Iteration Time: 0:00:01.367296
Testing - 2024-06-14 07:16:09.307613
[9/9, 10/16]
Testing Loss: 15682.79 - Epoch Time: 0:02:16.512362
Training and Testing Finished - Time: 0:20:45.726509
Assembling test data for t-sne projection
-- 1/16 --
-- 2/16 --
-- 3/16 --
-- 4/16 --
-- 5/16 --
-- 6/16 --
-- 7/16 --
-- 8/16 --
-- 9/16 --
-- 10/16 --
-- 11/16 --
-- 12/16 --
-- 13/16 --
-- 14/16 --
-- 15/16 --
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2