Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-15 12:04:18.325179
Scaler Value: 0.013513513513513514
Training - 2024-06-15 12:04:18.326172
[1/9, 1/94] Training Loss: 0.0694 - Iteration Time: 0:00:02.031808
[1/9, 2/94] Training Loss: 0.0696 - Iteration Time: 0:00:01.569161
[1/9, 3/94] Training Loss: 0.0717 - Iteration Time: 0:00:01.439240
[1/9, 4/94] Training Loss: 0.0715 - Iteration Time: 0:00:01.443680
[1/9, 5/94] Training Loss: 0.0705 - Iteration Time: 0:00:01.443193
[1/9, 6/94] Training Loss: 0.0691 - Iteration Time: 0:00:01.490300
[1/9, 7/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.423859
[1/9, 8/94] Training Loss: 0.0689 - Iteration Time: 0:00:01.487331
[1/9, 9/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.528513
[1/9, 10/94] Training Loss: 0.0709 - Iteration Time: 0:00:01.505184
[1/9, 11/94] Training Loss: 0.0687 - Iteration Time: 0:00:01.457053
[1/9, 12/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.403028
[1/9, 13/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.536977
[1/9, 14/94] Training Loss: 0.0697 - Iteration Time: 0:00:01.453108
[1/9, 15/94] Training Loss: 0.0672 - Iteration Time: 0:00:01.471475
[1/9, 16/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.542048
[1/9, 17/94] Training Loss: 0.0716 - Iteration Time: 0:00:01.523114
[1/9, 18/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.451623
[1/9, 19/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.451639
[1/9, 20/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.442229
[1/9, 21/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.777353
[1/9, 22/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.843601
[1/9, 23/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.576642
[1/9, 24/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.630831
[1/9, 25/94] Training Loss: 0.0704 - Iteration Time: 0:00:01.648043
[1/9, 26/94] Training Loss: 0.0682 - Iteration Time: 0:00:01.479928
[1/9, 27/94] Training Loss: 0.0679 - Iteration Time: 0:00:01.466045
[1/9, 28/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.518600
[1/9, 29/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.449635
[1/9, 30/94] Training Loss: 0.0676 - Iteration Time: 0:00:01.523590
[1/9, 31/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.440293
[1/9, 32/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.446641
[1/9, 33/94] Training Loss: 0.0706 - Iteration Time: 0:00:01.545913
[1/9, 34/94] Training Loss: 0.0673 - Iteration Time: 0:00:01.438745
[1/9, 35/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.511248
[1/9, 36/94] Training Loss: 0.0678 - Iteration Time: 0:00:01.470454
[1/9, 37/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.528498
[1/9, 38/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.458105
[1/9, 39/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.450609
[1/9, 40/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.474924
[1/9, 41/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.517136
[1/9, 42/94] Training Loss: 0.0681 - Iteration Time: 0:00:01.462508
[1/9, 43/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.469444
[1/9, 44/94] Training Loss: 0.0684 - Iteration Time: 0:00:01.439679
[1/9, 45/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.474949
[1/9, 46/94] Training Loss: 0.0685 - Iteration Time: 0:00:01.493259
[1/9, 47/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.563259
[1/9, 48/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.412892
[1/9, 49/94] Training Loss: 0.0693 - Iteration Time: 0:00:01.555291
[1/9, 50/94] Training Loss: 0.0665 - Iteration Time: 0:00:01.497229
[1/9, 51/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.459069
[1/9, 52/94] Training Loss: 0.0677 - Iteration Time: 0:00:01.546371
[1/9, 53/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.538465
[1/9, 54/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.551322
[1/9, 55/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.475937
[1/9, 56/94] Training Loss: 0.0689 - Iteration Time: 0:00:01.515113
[1/9, 57/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.463540
[1/9, 58/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.496264
[1/9, 59/94] Training Loss: 0.0686 - Iteration Time: 0:00:01.455544
[1/9, 60/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.430794
[1/9, 61/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.492771
[1/9, 62/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.850251
[1/9, 63/94] Training Loss: 0.0688 - Iteration Time: 0:00:01.548391
[1/9, 64/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.479911
[1/9, 65/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.574817
[1/9, 66/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.496832
[1/9, 67/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.538963
[1/9, 68/94] Training Loss: 0.0661 - Iteration Time: 0:00:01.485936
[1/9, 69/94] Training Loss: 0.0658 - Iteration Time: 0:00:01.434347
[1/9, 70/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.465028
[1/9, 71/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.468771
[1/9, 72/94] Training Loss: 0.0670 - Iteration Time: 0:00:01.473068
[1/9, 73/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.472060
[1/9, 74/94] Training Loss: 0.0651 - Iteration Time: 0:00:01.552922
[1/9, 75/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.486422
[1/9, 76/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.554351
[1/9, 77/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.458618
[1/9, 78/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.490340
[1/9, 79/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.485892
[1/9, 80/94] Training Loss: 0.0690 - Iteration Time: 0:00:01.432792
[1/9, 81/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.506234
[1/9, 82/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.502313
[1/9, 83/94] Training Loss: 0.0667 - Iteration Time: 0:00:01.424833
[1/9, 84/94] Training Loss: 0.0668 - Iteration Time: 0:00:01.457601
[1/9, 85/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.514182
[1/9, 86/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.575687
[1/9, 87/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.595009
[1/9, 88/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.521107
[1/9, 89/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.644249
[1/9, 90/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.499273
[1/9, 91/94] Training Loss: 0.0643 - Iteration Time: 0:00:01.448165
[1/9, 92/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.477995
[1/9, 93/94] Training Loss: 0.0660 - Iteration Time: 0:00:01.482907
[1/9, 94/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.592039
Testing - 2024-06-15 12:06:50.929430
[1/9, 1/16]
[1/9, 2/16]
[1/9, 3/16]
[1/9, 4/16]
[1/9, 5/16]
[1/9, 6/16]
[1/9, 7/16]
[1/9, 8/16]
[1/9, 9/16]
[1/9, 10/16]
[1/9, 11/16]
[1/9, 12/16]
[1/9, 13/16]
[1/9, 14/16]
[1/9, 15/16]
[1/9, 16/16]
Testing Loss: 0.0617 - Epoch Time: 0:02:55.655364
Training - 2024-06-15 12:07:13.981536
[2/9, 1/94] Training Loss: 0.0648 - Iteration Time: 0:00:01.532589
[2/9, 2/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.585641
[2/9, 3/94] Training Loss: 0.0662 - Iteration Time: 0:00:01.441753
[2/9, 4/94] Training Loss: 0.0655 - Iteration Time: 0:00:01.443195
[2/9, 5/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.431792
[2/9, 6/94] Training Loss: 0.0666 - Iteration Time: 0:00:01.472989
[2/9, 7/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.613418
[2/9, 8/94] Training Loss: 0.0659 - Iteration Time: 0:00:01.486872
[2/9, 9/94] Training Loss: 0.0675 - Iteration Time: 0:00:01.489847
[2/9, 10/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.601077
[2/9, 11/94] Training Loss: 0.0657 - Iteration Time: 0:00:01.510686
[2/9, 12/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.460056
[2/9, 13/94] Training Loss: 0.0669 - Iteration Time: 0:00:01.429897
[2/9, 14/94] Training Loss: 0.0671 - Iteration Time: 0:00:01.462081
[2/9, 15/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.462021
[2/9, 16/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.507730
[2/9, 17/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.489970
[2/9, 18/94] Training Loss: 0.0664 - Iteration Time: 0:00:01.429346
[2/9, 19/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.492365
[2/9, 20/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.553894
[2/9, 21/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.481496
[2/9, 22/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.468534
[2/9, 23/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.463049
[2/9, 24/94] Training Loss: 0.0641 - Iteration Time: 0:00:01.522610
[2/9, 25/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.459582
[2/9, 26/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.481884
[2/9, 27/94] Training Loss: 0.0649 - Iteration Time: 0:00:01.520105
[2/9, 28/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.556838
[2/9, 29/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.441272
[2/9, 30/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.503711
[2/9, 31/94] Training Loss: 0.0639 - Iteration Time: 0:00:01.468065
[2/9, 32/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.759249
[2/9, 33/94] Training Loss: 0.0653 - Iteration Time: 0:00:01.533754
[2/9, 34/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.438848
[2/9, 35/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.463889
[2/9, 36/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.468512
[2/9, 37/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.427881
[2/9, 38/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.474486
[2/9, 39/94] Training Loss: 0.0642 - Iteration Time: 0:00:01.492115
[2/9, 40/94] Training Loss: 0.0622 - Iteration Time: 0:00:01.500746
[2/9, 41/94] Training Loss: 0.0646 - Iteration Time: 0:00:01.509415
[2/9, 42/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.434306
[2/9, 43/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.472444
[2/9, 44/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.498765
[2/9, 45/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.460111
[2/9, 46/94] Training Loss: 0.0663 - Iteration Time: 0:00:01.419370
[2/9, 47/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.703175
[2/9, 48/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.487371
[2/9, 49/94] Training Loss: 0.0636 - Iteration Time: 0:00:01.545907
[2/9, 50/94] Training Loss: 0.0627 - Iteration Time: 0:00:01.517129
[2/9, 51/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.543950
[2/9, 52/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.415407
[2/9, 53/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.485880
[2/9, 54/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.527527
[2/9, 55/94] Training Loss: 0.0644 - Iteration Time: 0:00:01.457113
[2/9, 56/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.448141
[2/9, 57/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.560308
[2/9, 58/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.595039
[2/9, 59/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.508688
[2/9, 60/94] Training Loss: 0.0645 - Iteration Time: 0:00:01.521624
[2/9, 61/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.492306
[2/9, 62/94] Training Loss: 0.0656 - Iteration Time: 0:00:01.542980
[2/9, 63/94] Training Loss: 0.0629 - Iteration Time: 0:00:01.466504
[2/9, 64/94] Training Loss: 0.0638 - Iteration Time: 0:00:01.462035
[2/9, 65/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.510180
[2/9, 66/94] Training Loss: 0.0631 - Iteration Time: 0:00:01.429307
[2/9, 67/94] Training Loss: 0.0647 - Iteration Time: 0:00:01.539069
[2/9, 68/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.544465
[2/9, 69/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.452651
[2/9, 70/94] Training Loss: 0.0652 - Iteration Time: 0:00:01.454663
[2/9, 71/94] Training Loss: 0.0632 - Iteration Time: 0:00:01.828890
[2/9, 72/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.659116
[2/9, 73/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.480466
[2/9, 74/94] Training Loss: 0.0618 - Iteration Time: 0:00:01.506818
[2/9, 75/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.522155
[2/9, 76/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.536998
[2/9, 77/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.445892
[2/9, 78/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.430336
[2/9, 79/94] Training Loss: 0.0609 - Iteration Time: 0:00:01.449687
[2/9, 80/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.483416
[2/9, 81/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.454079
[2/9, 82/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.590168
[2/9, 83/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.462081
[2/9, 84/94] Training Loss: 0.0654 - Iteration Time: 0:00:01.446183
[2/9, 85/94] Training Loss: 0.0634 - Iteration Time: 0:00:01.417437
[2/9, 86/94] Training Loss: 0.0633 - Iteration Time: 0:00:01.452706
[2/9, 87/94] Training Loss: 0.0637 - Iteration Time: 0:00:01.465491
[2/9, 88/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.499288
[2/9, 89/94] Training Loss: 0.0610 - Iteration Time: 0:00:01.445234
[2/9, 90/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.439713
[2/9, 91/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.598481
[2/9, 92/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.460061
[2/9, 93/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.557837
[2/9, 94/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.435771
Testing - 2024-06-15 12:09:34.970325
[2/9, 1/16]
[2/9, 2/16]
[2/9, 3/16]
[2/9, 4/16]
[2/9, 5/16]
[2/9, 6/16]
[2/9, 7/16]
[2/9, 8/16]
[2/9, 9/16]
[2/9, 10/16]
[2/9, 11/16]
[2/9, 12/16]
[2/9, 13/16]
[2/9, 14/16]
[2/9, 15/16]
[2/9, 16/16]
Testing Loss: 0.0614 - Epoch Time: 0:02:35.007691
Training - 2024-06-15 12:09:48.989723
[3/9, 1/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.511358
[3/9, 2/94] Training Loss: 0.0635 - Iteration Time: 0:00:01.508308
[3/9, 3/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.490449
[3/9, 4/94] Training Loss: 0.0626 - Iteration Time: 0:00:01.493903
[3/9, 5/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.520090
[3/9, 6/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.517207
[3/9, 7/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.471024
[3/9, 8/94] Training Loss: 0.0640 - Iteration Time: 0:00:01.569300
[3/9, 9/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.929437
[3/9, 10/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.489829
[3/9, 11/94] Training Loss: 0.0617 - Iteration Time: 0:00:01.470988
[3/9, 12/94] Training Loss: 0.0590 - Iteration Time: 0:00:01.452710
[3/9, 13/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.491821
[3/9, 14/94] Training Loss: 0.0613 - Iteration Time: 0:00:01.468055
[3/9, 15/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.462646
[3/9, 16/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.447715
[3/9, 17/94] Training Loss: 0.0605 - Iteration Time: 0:00:01.424866
[3/9, 18/94] Training Loss: 0.0628 - Iteration Time: 0:00:01.455112
[3/9, 19/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.477940
[3/9, 20/94] Training Loss: 0.0611 - Iteration Time: 0:00:01.432825
[3/9, 21/94] Training Loss: 0.0621 - Iteration Time: 0:00:01.457109
[3/9, 22/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.443713
[3/9, 23/94] Training Loss: 0.0619 - Iteration Time: 0:00:01.445739
[3/9, 24/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.419535
[3/9, 25/94] Training Loss: 0.0614 - Iteration Time: 0:00:01.445746
[3/9, 26/94] Training Loss: 0.0607 - Iteration Time: 0:00:01.524670
[3/9, 27/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.499334
[3/9, 28/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.482968
[3/9, 29/94] Training Loss: 0.0606 - Iteration Time: 0:00:01.444176
[3/9, 30/94] Training Loss: 0.0608 - Iteration Time: 0:00:01.473961
[3/9, 31/94] Training Loss: 0.0623 - Iteration Time: 0:00:01.521686
[3/9, 32/94] Training Loss: 0.0620 - Iteration Time: 0:00:01.458598
[3/9, 33/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.501735
[3/9, 34/94] Training Loss: 0.0603 - Iteration Time: 0:00:01.564821
[3/9, 35/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.485401
[3/9, 36/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.542419
[3/9, 37/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.564750
[3/9, 38/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.500761
[3/9, 39/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.532605
[3/9, 40/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.466071
[3/9, 41/94] Training Loss: 0.0616 - Iteration Time: 0:00:01.571222
[3/9, 42/94] Training Loss: 0.0596 - Iteration Time: 0:00:01.532998
[3/9, 43/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.694751
[3/9, 44/94] Training Loss: 0.0589 - Iteration Time: 0:00:01.490404
[3/9, 45/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.458598
[3/9, 46/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.439752
[3/9, 47/94] Training Loss: 0.0612 - Iteration Time: 0:00:01.485361
[3/9, 48/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.846043
[3/9, 49/94] Training Loss: 0.0625 - Iteration Time: 0:00:01.478882
[3/9, 50/94] Training Loss: 0.0597 - Iteration Time: 0:00:01.479882
[3/9, 51/94] Training Loss: 0.0593 - Iteration Time: 0:00:01.449640
[3/9, 52/94] Training Loss: 0.0600 - Iteration Time: 0:00:01.495277
[3/9, 53/94] Training Loss: 0.0604 - Iteration Time: 0:00:01.422802
[3/9, 54/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.433263
[3/9, 55/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.412892
[3/9, 56/94] Training Loss: 0.0602 - Iteration Time: 0:00:01.451095
[3/9, 57/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.495234
[3/9, 58/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.437827
[3/9, 59/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.556813
[3/9, 60/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.424408
[3/9, 61/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.468536
[3/9, 62/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.505316
[3/9, 63/94] Training Loss: 0.0615 - Iteration Time: 0:00:01.448727
[3/9, 64/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.457669
[3/9, 65/94] Training Loss: 0.0601 - Iteration Time: 0:00:01.518620
[3/9, 66/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.426889
[3/9, 67/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.506427
[3/9, 68/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.489395
[3/9, 69/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.473500
[3/9, 70/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.424416
[3/9, 71/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.464074
[3/9, 72/94] Training Loss: 0.0582 - Iteration Time: 0:00:01.452788
[3/9, 73/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.497320
[3/9, 74/94] Training Loss: 0.0599 - Iteration Time: 0:00:01.514120
[3/9, 75/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.521106
[3/9, 76/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.475941
[3/9, 77/94] Training Loss: 0.0598 - Iteration Time: 0:00:01.519606
[3/9, 78/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.509751
[3/9, 79/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.509243
[3/9, 80/94] Training Loss: 0.0583 - Iteration Time: 0:00:01.545973
[3/9, 81/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.481478
[3/9, 82/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.451658
[3/9, 83/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.502275
[3/9, 84/94] Training Loss: 0.0579 - Iteration Time: 0:00:01.480876
[3/9, 85/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.460091
[3/9, 86/94] Training Loss: 0.0578 - Iteration Time: 0:00:01.459651
[3/9, 87/94] Training Loss: 0.0585 - Iteration Time: 0:00:01.488374
[3/9, 88/94] Training Loss: 0.0573 - Iteration Time: 0:00:01.512635
[3/9, 89/94] Training Loss: 0.0563 - Iteration Time: 0:00:02.536250
[3/9, 90/94] Training Loss: 0.0588 - Iteration Time: 0:00:01.599934
[3/9, 91/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.494805
[3/9, 92/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.513647
[3/9, 93/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.703681
[3/9, 94/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.460051
Testing - 2024-06-15 12:12:10.867854
[3/9, 1/16]
[3/9, 2/16]
[3/9, 3/16]
[3/9, 4/16]
[3/9, 5/16]
[3/9, 6/16]
[3/9, 7/16]
[3/9, 8/16]
[3/9, 9/16]
[3/9, 10/16]
[3/9, 11/16]
[3/9, 12/16]
[3/9, 13/16]
[3/9, 14/16]
[3/9, 15/16]
[3/9, 16/16]
Testing Loss: 0.0568 - Epoch Time: 0:02:35.625567
Training - 2024-06-15 12:12:24.615290
[4/9, 1/94] Training Loss: 0.0594 - Iteration Time: 0:00:01.458596
[4/9, 2/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.514711
[4/9, 3/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.440792
[4/9, 4/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.506769
[4/9, 5/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.457078
[4/9, 6/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.433377
[4/9, 7/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.455196
[4/9, 8/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.483890
[4/9, 9/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.433780
[4/9, 10/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.472012
[4/9, 11/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.516608
[4/9, 12/94] Training Loss: 0.0581 - Iteration Time: 0:00:01.524047
[4/9, 13/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.569231
[4/9, 14/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.421355
[4/9, 15/94] Training Loss: 0.0570 - Iteration Time: 0:00:01.506202
[4/9, 16/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.444697
[4/9, 17/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.501762
[4/9, 18/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.493813
[4/9, 19/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.507227
[4/9, 20/94] Training Loss: 0.0572 - Iteration Time: 0:00:01.493788
[4/9, 21/94] Training Loss: 0.0565 - Iteration Time: 0:00:01.432313
[4/9, 22/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.503255
[4/9, 23/94] Training Loss: 0.0562 - Iteration Time: 0:00:01.435487
[4/9, 24/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.505196
[4/9, 25/94] Training Loss: 0.0580 - Iteration Time: 0:00:01.676383
[4/9, 26/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.511303
[4/9, 27/94] Training Loss: 0.0559 - Iteration Time: 0:00:01.470533
[4/9, 28/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.523055
[4/9, 29/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.599965
[4/9, 30/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.617371
[4/9, 31/94] Training Loss: 0.0574 - Iteration Time: 0:00:01.594520
[4/9, 32/94] Training Loss: 0.0571 - Iteration Time: 0:00:01.452594
[4/9, 33/94] Training Loss: 0.0560 - Iteration Time: 0:00:01.433805
[4/9, 34/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.500253
[4/9, 35/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.457557
[4/9, 36/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.434250
[4/9, 37/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.541956
[4/9, 38/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.507245
[4/9, 39/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.510158
[4/9, 40/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.465080
[4/9, 41/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.424319
[4/9, 42/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.482970
[4/9, 43/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.772660
[4/9, 44/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.473945
[4/9, 45/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.437743
[4/9, 46/94] Training Loss: 0.0576 - Iteration Time: 0:00:01.418401
[4/9, 47/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.445185
[4/9, 48/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.543877
[4/9, 49/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.452182
[4/9, 50/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.493854
[4/9, 51/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.474923
[4/9, 52/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.411930
[4/9, 53/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.599947
[4/9, 54/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.486852
[4/9, 55/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.500747
[4/9, 56/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.500238
[4/9, 57/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.434771
[4/9, 58/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.500767
[4/9, 59/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.538431
[4/9, 60/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.509169
[4/9, 61/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.443725
[4/9, 62/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.417432
[4/9, 63/94] Training Loss: 0.0561 - Iteration Time: 0:00:01.410479
[4/9, 64/94] Training Loss: 0.0568 - Iteration Time: 0:00:01.514721
[4/9, 65/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.477932
[4/9, 66/94] Training Loss: 0.0569 - Iteration Time: 0:00:01.648111
[4/9, 67/94] Training Loss: 0.0575 - Iteration Time: 0:00:01.434749
[4/9, 68/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.454147
[4/9, 69/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.468999
[4/9, 70/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.458613
[4/9, 71/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.463072
[4/9, 72/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.464043
[4/9, 73/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.448718
[4/9, 74/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.494293
[4/9, 75/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.459623
[4/9, 76/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.443868
[4/9, 77/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.531746
[4/9, 78/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.428840
[4/9, 79/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.485411
[4/9, 80/94] Training Loss: 0.0564 - Iteration Time: 0:00:01.458094
[4/9, 81/94] Training Loss: 0.0547 - Iteration Time: 0:00:01.428355
[4/9, 82/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.485887
[4/9, 83/94] Training Loss: 0.0577 - Iteration Time: 0:00:01.417391
[4/9, 84/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.473015
[4/9, 85/94] Training Loss: 0.0566 - Iteration Time: 0:00:01.482466
[4/9, 86/94] Training Loss: 0.0567 - Iteration Time: 0:00:01.523132
[4/9, 87/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.727513
[4/9, 88/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.421953
[4/9, 89/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.474945
[4/9, 90/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.498748
[4/9, 91/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.465071
[4/9, 92/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.528060
[4/9, 93/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.580401
[4/9, 94/94] Training Loss: 0.0553 - Iteration Time: 0:00:01.488361
Testing - 2024-06-15 12:14:44.812655
[4/9, 1/16]
[4/9, 2/16]
[4/9, 3/16]
[4/9, 4/16]
[4/9, 5/16]
[4/9, 6/16]
[4/9, 7/16]
[4/9, 8/16]
[4/9, 9/16]
[4/9, 10/16]
[4/9, 11/16]
[4/9, 12/16]
[4/9, 13/16]
[4/9, 14/16]
[4/9, 15/16]
[4/9, 16/16]
Testing Loss: 0.0530 - Epoch Time: 0:02:34.389738
Training - 2024-06-15 12:14:59.005028
[5/9, 1/94] Training Loss: 0.0545 - Iteration Time: 0:00:01.699047
[5/9, 2/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.565821
[5/9, 3/94] Training Loss: 0.0554 - Iteration Time: 0:00:01.434807
[5/9, 4/94] Training Loss: 0.0549 - Iteration Time: 0:00:01.505234
[5/9, 5/94] Training Loss: 0.0546 - Iteration Time: 0:00:01.443730
[5/9, 6/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.442245
[5/9, 7/94] Training Loss: 0.0556 - Iteration Time: 0:00:01.530525
[5/9, 8/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.399531
[5/9, 9/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.491884
[5/9, 10/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.525579
[5/9, 11/94] Training Loss: 0.0552 - Iteration Time: 0:00:01.487408
[5/9, 12/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.437759
[5/9, 13/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.475986
[5/9, 14/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.471047
[5/9, 15/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.487910
[5/9, 16/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.409544
[5/9, 17/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.473567
[5/9, 18/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.495341
[5/9, 19/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.509755
[5/9, 20/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.507768
[5/9, 21/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.491878
[5/9, 22/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.461101
[5/9, 23/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.499848
[5/9, 24/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.432279
[5/9, 25/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.424919
[5/9, 26/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.516172
[5/9, 27/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.521168
[5/9, 28/94] Training Loss: 0.0551 - Iteration Time: 0:00:01.430785
[5/9, 29/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.469513
[5/9, 30/94] Training Loss: 0.0550 - Iteration Time: 0:00:01.476023
[5/9, 31/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.486361
[5/9, 32/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.435891
[5/9, 33/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.499353
[5/9, 34/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.472033
[5/9, 35/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.441758
[5/9, 36/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.692387
[5/9, 37/94] Training Loss: 0.0538 - Iteration Time: 0:00:01.473484
[5/9, 38/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.480919
[5/9, 39/94] Training Loss: 0.0542 - Iteration Time: 0:00:01.454125
[5/9, 40/94] Training Loss: 0.0555 - Iteration Time: 0:00:01.495926
[5/9, 41/94] Training Loss: 0.0540 - Iteration Time: 0:00:01.438752
[5/9, 42/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.801507
[5/9, 43/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.527105
[5/9, 44/94] Training Loss: 0.0563 - Iteration Time: 0:00:01.472981
[5/9, 45/94] Training Loss: 0.0536 - Iteration Time: 0:00:01.463588
[5/9, 46/94] Training Loss: 0.0548 - Iteration Time: 0:00:01.428075
[5/9, 47/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.415902
[5/9, 48/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.443756
[5/9, 49/94] Training Loss: 0.0533 - Iteration Time: 0:00:01.518176
[5/9, 50/94] Training Loss: 0.0532 - Iteration Time: 0:00:01.407248
[5/9, 51/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.401528
[5/9, 52/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.445727
[5/9, 53/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.438762
[5/9, 54/94] Training Loss: 0.0558 - Iteration Time: 0:00:01.500295
[5/9, 55/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.438756
[5/9, 56/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.413439
[5/9, 57/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.435817
[5/9, 58/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.429822
[5/9, 59/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.447709
[5/9, 60/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.447176
[5/9, 61/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.456668
[5/9, 62/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.433275
[5/9, 63/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.459608
[5/9, 64/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.571190
[5/9, 65/94] Training Loss: 0.0544 - Iteration Time: 0:00:01.473525
[5/9, 66/94] Training Loss: 0.0530 - Iteration Time: 0:00:01.430805
[5/9, 67/94] Training Loss: 0.0528 - Iteration Time: 0:00:01.502778
[5/9, 68/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.488384
[5/9, 69/94] Training Loss: 0.0535 - Iteration Time: 0:00:01.471498
[5/9, 70/94] Training Loss: 0.0539 - Iteration Time: 0:00:01.496795
[5/9, 71/94] Training Loss: 0.0543 - Iteration Time: 0:00:01.525609
[5/9, 72/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.430287
[5/9, 73/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.431317
[5/9, 74/94] Training Loss: 0.0522 - Iteration Time: 0:00:01.418920
[5/9, 75/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.412021
[5/9, 76/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.466148
[5/9, 77/94] Training Loss: 0.0527 - Iteration Time: 0:00:01.448201
[5/9, 78/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.472557
[5/9, 79/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.432859
[5/9, 80/94] Training Loss: 0.0526 - Iteration Time: 0:00:01.439238
[5/9, 81/94] Training Loss: 0.0520 - Iteration Time: 0:00:01.458396
[5/9, 82/94] Training Loss: 0.0529 - Iteration Time: 0:00:01.622869
[5/9, 83/94] Training Loss: 0.0541 - Iteration Time: 0:00:01.593571
[5/9, 84/94] Training Loss: 0.0534 - Iteration Time: 0:00:01.444246
[5/9, 85/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.465115
[5/9, 86/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.475531
[5/9, 87/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.444242
[5/9, 88/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.479938
[5/9, 89/94] Training Loss: 0.0537 - Iteration Time: 0:00:01.449696
[5/9, 90/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.443762
[5/9, 91/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.490311
[5/9, 92/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.447685
[5/9, 93/94] Training Loss: 0.0531 - Iteration Time: 0:00:01.480035
[5/9, 94/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.409051
Testing - 2024-06-15 12:17:17.828450
[5/9, 1/16]
[5/9, 2/16]
[5/9, 3/16]
[5/9, 4/16]
[5/9, 5/16]
[5/9, 6/16]
[5/9, 7/16]
[5/9, 8/16]
[5/9, 9/16]
[5/9, 10/16]
[5/9, 11/16]
[5/9, 12/16]
[5/9, 13/16]
[5/9, 14/16]
[5/9, 15/16]
[5/9, 16/16]
Testing Loss: 0.0499 - Epoch Time: 0:02:32.689401
Training - 2024-06-15 12:17:31.694924
[6/9, 1/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.494826
[6/9, 2/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.462559
[6/9, 3/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.444728
[6/9, 4/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.513202
[6/9, 5/94] Training Loss: 0.0511 - Iteration Time: 0:00:01.444671
[6/9, 6/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.522140
[6/9, 7/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.475482
[6/9, 8/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.546945
[6/9, 9/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.469986
[6/9, 10/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.498347
[6/9, 11/94] Training Loss: 0.0525 - Iteration Time: 0:00:01.444715
[6/9, 12/94] Training Loss: 0.0524 - Iteration Time: 0:00:01.540474
[6/9, 13/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.568274
[6/9, 14/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.475448
[6/9, 15/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.452151
[6/9, 16/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.422899
[6/9, 17/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.464061
[6/9, 18/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.443722
[6/9, 19/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.456618
[6/9, 20/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.464567
[6/9, 21/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.809442
[6/9, 22/94] Training Loss: 0.0518 - Iteration Time: 0:00:01.471044
[6/9, 23/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.458097
[6/9, 24/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.437275
[6/9, 25/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.478951
[6/9, 26/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.563785
[6/9, 27/94] Training Loss: 0.0523 - Iteration Time: 0:00:01.473502
[6/9, 28/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.450180
[6/9, 29/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.459073
[6/9, 30/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.483443
[6/9, 31/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.477923
[6/9, 32/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.469480
[6/9, 33/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.577720
[6/9, 34/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.540983
[6/9, 35/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.689891
[6/9, 36/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.463594
[6/9, 37/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.454109
[6/9, 38/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.459616
[6/9, 39/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.465020
[6/9, 40/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.544888
[6/9, 41/94] Training Loss: 0.0513 - Iteration Time: 0:00:01.439270
[6/9, 42/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.482401
[6/9, 43/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.500254
[6/9, 44/94] Training Loss: 0.0510 - Iteration Time: 0:00:01.433288
[6/9, 45/94] Training Loss: 0.0505 - Iteration Time: 0:00:01.447674
[6/9, 46/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.498763
[6/9, 47/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.525043
[6/9, 48/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.636705
[6/9, 49/94] Training Loss: 0.0507 - Iteration Time: 0:00:01.538927
[6/9, 50/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.574713
[6/9, 51/94] Training Loss: 0.0519 - Iteration Time: 0:00:01.475942
[6/9, 52/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.480881
[6/9, 53/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.500348
[6/9, 54/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.487915
[6/9, 55/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.472494
[6/9, 56/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.500750
[6/9, 57/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.530005
[6/9, 58/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.478949
[6/9, 59/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.552820
[6/9, 60/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.537464
[6/9, 61/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.602446
[6/9, 62/94] Training Loss: 0.0514 - Iteration Time: 0:00:01.454090
[6/9, 63/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.506211
[6/9, 64/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.675362
[6/9, 65/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.577277
[6/9, 66/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.471076
[6/9, 67/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.470518
[6/9, 68/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.523645
[6/9, 69/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.459597
[6/9, 70/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.403522
[6/9, 71/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.434781
[6/9, 72/94] Training Loss: 0.0517 - Iteration Time: 0:00:01.471020
[6/9, 73/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.469527
[6/9, 74/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.431832
[6/9, 75/94] Training Loss: 0.0515 - Iteration Time: 0:00:01.543952
[6/9, 76/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.503267
[6/9, 77/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.516647
[6/9, 78/94] Training Loss: 0.0512 - Iteration Time: 0:00:01.477971
[6/9, 79/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.449201
[6/9, 80/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.513670
[6/9, 81/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.450155
[6/9, 82/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.435352
[6/9, 83/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.713650
[6/9, 84/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.569269
[6/9, 85/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.548472
[6/9, 86/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.439855
[6/9, 87/94] Training Loss: 0.0516 - Iteration Time: 0:00:01.447191
[6/9, 88/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.587190
[6/9, 89/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.506238
[6/9, 90/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.536494
[6/9, 91/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.526570
[6/9, 92/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.510201
[6/9, 93/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.498828
[6/9, 94/94] Training Loss: 0.0521 - Iteration Time: 0:00:01.398046
Testing - 2024-06-15 12:19:52.838276
[6/9, 1/16]
[6/9, 2/16]
[6/9, 3/16]
[6/9, 4/16]
[6/9, 5/16]
[6/9, 6/16]
[6/9, 7/16]
[6/9, 8/16]
[6/9, 9/16]
[6/9, 10/16]
[6/9, 11/16]
[6/9, 12/16]
[6/9, 13/16]
[6/9, 14/16]
[6/9, 15/16]
[6/9, 16/16]
Testing Loss: 0.0497 - Epoch Time: 0:02:35.461354
Training - 2024-06-15 12:20:07.156278
[7/9, 1/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.488849
[7/9, 2/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.457111
[7/9, 3/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.470483
[7/9, 4/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.431330
[7/9, 5/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.576669
[7/9, 6/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.467535
[7/9, 7/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.466498
[7/9, 8/94] Training Loss: 0.0506 - Iteration Time: 0:00:01.511645
[7/9, 9/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.440247
[7/9, 10/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.491810
[7/9, 11/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.498762
[7/9, 12/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.524051
[7/9, 13/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.506306
[7/9, 14/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.499258
[7/9, 15/94] Training Loss: 0.0493 - Iteration Time: 0:00:01.500756
[7/9, 16/94] Training Loss: 0.0508 - Iteration Time: 0:00:01.579162
[7/9, 17/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.546415
[7/9, 18/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.523093
[7/9, 19/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.522152
[7/9, 20/94] Training Loss: 0.0509 - Iteration Time: 0:00:01.487356
[7/9, 21/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.504257
[7/9, 22/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.459080
[7/9, 23/94] Training Loss: 0.0504 - Iteration Time: 0:00:01.550374
[7/9, 24/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.574677
[7/9, 25/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.476457
[7/9, 26/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.553952
[7/9, 27/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.457171
[7/9, 28/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.545978
[7/9, 29/94] Training Loss: 0.0497 - Iteration Time: 0:00:01.476966
[7/9, 30/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.529045
[7/9, 31/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.456087
[7/9, 32/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.430317
[7/9, 33/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.517721
[7/9, 34/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.473010
[7/9, 35/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.477939
[7/9, 36/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.844478
[7/9, 37/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.588554
[7/9, 38/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.494297
[7/9, 39/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.536472
[7/9, 40/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.476991
[7/9, 41/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.500739
[7/9, 42/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.444703
[7/9, 43/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.524068
[7/9, 44/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.508183
[7/9, 45/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.544901
[7/9, 46/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.492363
[7/9, 47/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.429291
[7/9, 48/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.478416
[7/9, 49/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.458081
[7/9, 50/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.538507
[7/9, 51/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.466042
[7/9, 52/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.464593
[7/9, 53/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.470018
[7/9, 54/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.568260
[7/9, 55/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.502268
[7/9, 56/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.523582
[7/9, 57/94] Training Loss: 0.0500 - Iteration Time: 0:00:01.518120
[7/9, 58/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.524638
[7/9, 59/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.534015
[7/9, 60/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.494833
[7/9, 61/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.495761
[7/9, 62/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.489837
[7/9, 63/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.527051
[7/9, 64/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.561817
[7/9, 65/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.476931
[7/9, 66/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.457110
[7/9, 67/94] Training Loss: 0.0501 - Iteration Time: 0:00:01.446218
[7/9, 68/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.457091
[7/9, 69/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.432818
[7/9, 70/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.439234
[7/9, 71/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.548923
[7/9, 72/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.512734
[7/9, 73/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.460059
[7/9, 74/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.472000
[7/9, 75/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.488343
[7/9, 76/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.512189
[7/9, 77/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.607166
[7/9, 78/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.498341
[7/9, 79/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.457601
[7/9, 80/94] Training Loss: 0.0486 - Iteration Time: 0:00:01.462114
[7/9, 81/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.432784
[7/9, 82/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.502779
[7/9, 83/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.418392
[7/9, 84/94] Training Loss: 0.0502 - Iteration Time: 0:00:01.577741
[7/9, 85/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.420892
[7/9, 86/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.409969
[7/9, 87/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.556857
[7/9, 88/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.428846
[7/9, 89/94] Training Loss: 0.0494 - Iteration Time: 0:00:01.488421
[7/9, 90/94] Training Loss: 0.0491 - Iteration Time: 0:00:01.480440
[7/9, 91/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.556868
[7/9, 92/94] Training Loss: 0.0496 - Iteration Time: 0:00:01.510720
[7/9, 93/94] Training Loss: 0.0503 - Iteration Time: 0:00:01.512660
[7/9, 94/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.425379
Testing - 2024-06-15 12:22:28.169652
[7/9, 1/16]
[7/9, 2/16]
[7/9, 3/16]
[7/9, 4/16]
[7/9, 5/16]
[7/9, 6/16]
[7/9, 7/16]
[7/9, 8/16]
[7/9, 9/16]
[7/9, 10/16]
[7/9, 11/16]
[7/9, 12/16]
[7/9, 13/16]
[7/9, 14/16]
[7/9, 15/16]
[7/9, 16/16]
Testing Loss: 0.0484 - Epoch Time: 0:02:35.002391
Training - 2024-06-15 12:22:42.159165
[8/9, 1/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.515146
[8/9, 2/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.430328
[8/9, 3/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.439765
[8/9, 4/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.478998
[8/9, 5/94] Training Loss: 0.0490 - Iteration Time: 0:00:01.441265
[8/9, 6/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.499277
[8/9, 7/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.515662
[8/9, 8/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.501748
[8/9, 9/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.468996
[8/9, 10/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.591071
[8/9, 11/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.556845
[8/9, 12/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.475473
[8/9, 13/94] Training Loss: 0.0499 - Iteration Time: 0:00:01.842171
[8/9, 14/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.449437
[8/9, 15/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.470159
[8/9, 16/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.530540
[8/9, 17/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.504222
[8/9, 18/94] Training Loss: 0.0498 - Iteration Time: 0:00:01.468569
[8/9, 19/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.460954
[8/9, 20/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.541514
[8/9, 21/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.517123
[8/9, 22/94] Training Loss: 0.0492 - Iteration Time: 0:00:01.421812
[8/9, 23/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.497895
[8/9, 24/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.446217
[8/9, 25/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.585629
[8/9, 26/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.994013
[8/9, 27/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.498294
[8/9, 28/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.439608
[8/9, 29/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.460079
[8/9, 30/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.482850
[8/9, 31/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.532521
[8/9, 32/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.491700
[8/9, 33/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.553345
[8/9, 34/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.506177
[8/9, 35/94] Training Loss: 0.0480 - Iteration Time: 0:00:01.516134
[8/9, 36/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.459597
[8/9, 37/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.465063
[8/9, 38/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.413435
[8/9, 39/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.422378
[8/9, 40/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.532006
[8/9, 41/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.771619
[8/9, 42/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.495984
[8/9, 43/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.504723
[8/9, 44/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.417875
[8/9, 45/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.438755
[8/9, 46/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.465439
[8/9, 47/94] Training Loss: 0.0482 - Iteration Time: 0:00:01.452609
[8/9, 48/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.474470
[8/9, 49/94] Training Loss: 0.0487 - Iteration Time: 0:00:01.430680
[8/9, 50/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.481901
[8/9, 51/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.399537
[8/9, 52/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.461083
[8/9, 53/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.670960
[8/9, 54/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.450164
[8/9, 55/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.472946
[8/9, 56/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.428813
[8/9, 57/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.487328
[8/9, 58/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.542440
[8/9, 59/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.434738
[8/9, 60/94] Training Loss: 0.0484 - Iteration Time: 0:00:01.488885
[8/9, 61/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.466295
[8/9, 62/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.518433
[8/9, 63/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.599666
[8/9, 64/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.435807
[8/9, 65/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.478409
[8/9, 66/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.478501
[8/9, 67/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.512319
[8/9, 68/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.450206
[8/9, 69/94] Training Loss: 0.0481 - Iteration Time: 0:00:01.441185
[8/9, 70/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.477180
[8/9, 71/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.439235
[8/9, 72/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.557341
[8/9, 73/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.418722
[8/9, 74/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.458594
[8/9, 75/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.490863
[8/9, 76/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.458106
[8/9, 77/94] Training Loss: 0.0489 - Iteration Time: 0:00:01.424351
[8/9, 78/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.465504
[8/9, 79/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.486860
[8/9, 80/94] Training Loss: 0.0488 - Iteration Time: 0:00:01.467446
[8/9, 81/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.517101
[8/9, 82/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.435756
[8/9, 83/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.440271
[8/9, 84/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.699220
[8/9, 85/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.446168
[8/9, 86/94] Training Loss: 0.0474 - Iteration Time: 0:00:01.427341
[8/9, 87/94] Training Loss: 0.0483 - Iteration Time: 0:00:01.418924
[8/9, 88/94] Training Loss: 0.0495 - Iteration Time: 0:00:01.525566
[8/9, 89/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.495850
[8/9, 90/94] Training Loss: 0.0477 - Iteration Time: 0:00:01.430769
[8/9, 91/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.433297
[8/9, 92/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.409465
[8/9, 93/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.832572
[8/9, 94/94] Training Loss: 0.0479 - Iteration Time: 0:00:01.444316
Testing - 2024-06-15 12:25:02.920040
[8/9, 1/16]
[8/9, 2/16]
[8/9, 3/16]
[8/9, 4/16]
[8/9, 5/16]
[8/9, 6/16]
[8/9, 7/16]
[8/9, 8/16]
[8/9, 9/16]
[8/9, 10/16]
[8/9, 11/16]
[8/9, 12/16]
[8/9, 13/16]
[8/9, 14/16]
[8/9, 15/16]
[8/9, 16/16]
Testing Loss: 0.0467 - Epoch Time: 0:02:34.475200
Training - 2024-06-15 12:25:16.634365
[9/9, 1/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.407005
[9/9, 2/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.432291
[9/9, 3/94] Training Loss: 0.0458 - Iteration Time: 0:00:01.501737
[9/9, 4/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.502742
[9/9, 5/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.497347
[9/9, 6/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.409001
[9/9, 7/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.618905
[9/9, 8/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.612408
[9/9, 9/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.432303
[9/9, 10/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.527560
[9/9, 11/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.420817
[9/9, 12/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.404027
[9/9, 13/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.441678
[9/9, 14/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.487873
[9/9, 15/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.493296
[9/9, 16/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.434347
[9/9, 17/94] Training Loss: 0.0485 - Iteration Time: 0:00:01.456076
[9/9, 18/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.552881
[9/9, 19/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.476980
[9/9, 20/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.404047
[9/9, 21/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.480879
[9/9, 22/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.417406
[9/9, 23/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.461608
[9/9, 24/94] Training Loss: 0.0476 - Iteration Time: 0:00:01.417887
[9/9, 25/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.441718
[9/9, 26/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.503292
[9/9, 27/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.432791
[9/9, 28/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.430761
[9/9, 29/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.563308
[9/9, 30/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.452654
[9/9, 31/94] Training Loss: 0.0475 - Iteration Time: 0:00:01.872935
[9/9, 32/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.507201
[9/9, 33/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.447730
[9/9, 34/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.523082
[9/9, 35/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.432287
[9/9, 36/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.511235
[9/9, 37/94] Training Loss: 0.0463 - Iteration Time: 0:00:01.452115
[9/9, 38/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.474948
[9/9, 39/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.639258
[9/9, 40/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.508200
[9/9, 41/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.421886
[9/9, 42/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.481928
[9/9, 43/94] Training Loss: 0.0478 - Iteration Time: 0:00:01.461074
[9/9, 44/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.543921
[9/9, 45/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.448181
[9/9, 46/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.430822
[9/9, 47/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.445779
[9/9, 48/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.526108
[9/9, 49/94] Training Loss: 0.0471 - Iteration Time: 0:00:01.442794
[9/9, 50/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.528632
[9/9, 51/94] Training Loss: 0.0448 - Iteration Time: 0:00:01.462629
[9/9, 52/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.506358
[9/9, 53/94] Training Loss: 0.0453 - Iteration Time: 0:00:01.612095
[9/9, 54/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.518253
[9/9, 55/94] Training Loss: 0.0464 - Iteration Time: 0:00:01.504562
[9/9, 56/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.553845
[9/9, 57/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.584150
[9/9, 58/94] Training Loss: 0.0469 - Iteration Time: 0:00:01.547878
[9/9, 59/94] Training Loss: 0.0472 - Iteration Time: 0:00:01.494815
[9/9, 60/94] Training Loss: 0.0473 - Iteration Time: 0:00:01.445698
[9/9, 61/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.540942
[9/9, 62/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.473949
[9/9, 63/94] Training Loss: 0.0467 - Iteration Time: 0:00:01.495306
[9/9, 64/94] Training Loss: 0.0461 - Iteration Time: 0:00:01.462070
[9/9, 65/94] Training Loss: 0.0470 - Iteration Time: 0:00:01.442672
[9/9, 66/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.494336
[9/9, 67/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.426862
[9/9, 68/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.506200
[9/9, 69/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.531016
[9/9, 70/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.959537
[9/9, 71/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.436240
[9/9, 72/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.530581
[9/9, 73/94] Training Loss: 0.0451 - Iteration Time: 0:00:01.474925
[9/9, 74/94] Training Loss: 0.0446 - Iteration Time: 0:00:01.475520
[9/9, 75/94] Training Loss: 0.0449 - Iteration Time: 0:00:01.548900
[9/9, 76/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.438743
[9/9, 77/94] Training Loss: 0.0456 - Iteration Time: 0:00:01.428317
[9/9, 78/94] Training Loss: 0.0455 - Iteration Time: 0:00:01.530994
[9/9, 79/94] Training Loss: 0.0452 - Iteration Time: 0:00:01.480900
[9/9, 80/94] Training Loss: 0.0462 - Iteration Time: 0:00:01.575289
[9/9, 81/94] Training Loss: 0.0460 - Iteration Time: 0:00:01.431817
[9/9, 82/94] Training Loss: 0.0444 - Iteration Time: 0:00:01.472605
[9/9, 83/94] Training Loss: 0.0454 - Iteration Time: 0:00:01.527038
[9/9, 84/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.450758
[9/9, 85/94] Training Loss: 0.0468 - Iteration Time: 0:00:01.513638
[9/9, 86/94] Training Loss: 0.0445 - Iteration Time: 0:00:01.463589
[9/9, 87/94] Training Loss: 0.0465 - Iteration Time: 0:00:01.501260
[9/9, 88/94] Training Loss: 0.0457 - Iteration Time: 0:00:01.425890
[9/9, 89/94] Training Loss: 0.0442 - Iteration Time: 0:00:01.418911
[9/9, 90/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.504828
[9/9, 91/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.504756
[9/9, 92/94] Training Loss: 0.0459 - Iteration Time: 0:00:01.416428
[9/9, 93/94] Training Loss: 0.0466 - Iteration Time: 0:00:01.439776
[9/9, 94/94] Training Loss: 0.0438 - Iteration Time: 0:00:01.449689
Testing - 2024-06-15 12:27:36.942008
[9/9, 1/16]
[9/9, 2/16]
[9/9, 3/16]
[9/9, 4/16]
[9/9, 5/16]
[9/9, 6/16]
[9/9, 7/16]
[9/9, 8/16]
[9/9, 9/16]
[9/9, 10/16]
[9/9, 11/16]
[9/9, 12/16]
[9/9, 13/16]
[9/9, 14/16]
[9/9, 15/16]
[9/9, 16/16]
Testing Loss: 0.0445 - Epoch Time: 0:02:34.314803
Training and Testing Finished - Time: 0:23:32.624485
Assembling test data for t-sne projection
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
{'rate_on': 75. * hertz, 'rate_off': 1. * hertz, 'total_time': 200. * msecond, 'bin_size': 1. * msecond}
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 4
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 4
Applying t-SNE