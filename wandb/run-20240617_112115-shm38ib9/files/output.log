Starting Sweep: Batch Size: 64, Learning Rate: 0.0001
Making datasets and defining subsets
Training: 60000 -> 6000
Testing: 10000 -> 1000
Making Dataloaders
Defining network
2024-06-17 11:21:16.364976
Scaler Value: 0.013513513513513514
Training - 2024-06-17 11:21:16.365472
[1/9, 10/94] Training Loss: 17.9699 - Iteration Time: 0:00:01.446674
[1/9, 20/94] Training Loss: 13.6274 - Iteration Time: 0:00:01.526029
[1/9, 30/94] Training Loss: 8.2187 - Iteration Time: 0:00:01.770277
[1/9, 40/94] Training Loss: 6.2573 - Iteration Time: 0:00:01.454604
[1/9, 50/94] Training Loss: 5.6553 - Iteration Time: 0:00:01.546868
[1/9, 60/94] Training Loss: 5.4202 - Iteration Time: 0:00:01.451177
[1/9, 70/94] Training Loss: 5.2927 - Iteration Time: 0:00:01.635707
[1/9, 80/94] Training Loss: 5.3032 - Iteration Time: 0:00:01.496765
[1/9, 90/94] Training Loss: 5.2394 - Iteration Time: 0:00:01.571673
Testing - 2024-06-17 11:23:40.797930
[1/9, 2/16]
[1/9, 4/16]
[1/9, 6/16]
[1/9, 8/16]
[1/9, 10/16]
[1/9, 12/16]
[1/9, 14/16]
[1/9, 16/16]
Testing Loss: 5.0194 - Epoch Time: 0:02:38.838416
Training - 2024-06-17 11:23:55.203888
[2/9, 10/94] Training Loss: 5.2786 - Iteration Time: 0:00:01.517595
[2/9, 20/94] Training Loss: 5.1500 - Iteration Time: 0:00:01.441711
[2/9, 30/94] Training Loss: 5.1621 - Iteration Time: 0:00:01.448700
[2/9, 40/94] Training Loss: 5.1630 - Iteration Time: 0:00:01.449167
[2/9, 50/94] Training Loss: 5.1262 - Iteration Time: 0:00:01.528536
[2/9, 60/94] Training Loss: 5.1862 - Iteration Time: 0:00:01.451112
[2/9, 70/94] Training Loss: 5.1222 - Iteration Time: 0:00:01.476445
[2/9, 80/94] Training Loss: 5.0630 - Iteration Time: 0:00:01.550023
[2/9, 90/94] Training Loss: 5.1160 - Iteration Time: 0:00:01.477446
Testing - 2024-06-17 11:26:19.126842
[2/9, 2/16]
[2/9, 4/16]
[2/9, 6/16]
[2/9, 8/16]
[2/9, 10/16]
[2/9, 12/16]
[2/9, 14/16]
[2/9, 16/16]
Testing Loss: 4.9702 - Epoch Time: 0:02:38.097907
Training - 2024-06-17 11:26:33.302291
[3/9, 10/94] Training Loss: 5.0630 - Iteration Time: 0:00:01.809349
[3/9, 20/94] Training Loss: 5.1323 - Iteration Time: 0:00:01.678889
[3/9, 30/94] Training Loss: 5.0504 - Iteration Time: 0:00:01.509182
[3/9, 40/94] Training Loss: 5.0724 - Iteration Time: 0:00:01.488326
[3/9, 50/94] Training Loss: 5.1045 - Iteration Time: 0:00:01.510670
[3/9, 60/94] Training Loss: 5.0652 - Iteration Time: 0:00:01.487389
[3/9, 70/94] Training Loss: 5.0238 - Iteration Time: 0:00:01.505738
[3/9, 80/94] Training Loss: 5.0707 - Iteration Time: 0:00:01.601443
[3/9, 90/94] Training Loss: 5.0636 - Iteration Time: 0:00:01.489820
Testing - 2024-06-17 11:28:59.817226
[3/9, 2/16]
[3/9, 4/16]
[3/9, 6/16]
[3/9, 8/16]
[3/9, 10/16]
[3/9, 12/16]
[3/9, 14/16]
[3/9, 16/16]
Testing Loss: 4.9081 - Epoch Time: 0:02:41.429601
Training - 2024-06-17 11:29:14.731892
[4/9, 10/94] Training Loss: 5.0077 - Iteration Time: 0:00:01.536953
[4/9, 20/94] Training Loss: 5.0716 - Iteration Time: 0:00:01.555307
[4/9, 30/94] Training Loss: 5.0348 - Iteration Time: 0:00:01.920085
[4/9, 40/94] Training Loss: 4.9957 - Iteration Time: 0:00:01.538979
[4/9, 50/94] Training Loss: 5.0297 - Iteration Time: 0:00:01.518115
[4/9, 60/94] Training Loss: 5.0055 - Iteration Time: 0:00:01.484898
[4/9, 70/94] Training Loss: 5.0714 - Iteration Time: 0:00:01.681911
[4/9, 80/94] Training Loss: 5.0585 - Iteration Time: 0:00:01.539432
[4/9, 90/94] Training Loss: 5.0070 - Iteration Time: 0:00:01.451104
Testing - 2024-06-17 11:31:42.651968
[4/9, 2/16]
[4/9, 4/16]
[4/9, 6/16]
[4/9, 8/16]
[4/9, 10/16]
[4/9, 12/16]
[4/9, 14/16]
[4/9, 16/16]
Testing Loss: 4.9389 - Epoch Time: 0:02:41.929472
Training - 2024-06-17 11:31:56.661364
[5/9, 10/94] Training Loss: 5.0075 - Iteration Time: 0:00:01.464577
[5/9, 20/94] Training Loss: 5.0510 - Iteration Time: 0:00:01.454602
[5/9, 30/94] Training Loss: 4.9897 - Iteration Time: 0:00:01.561780
[5/9, 40/94] Training Loss: 4.9985 - Iteration Time: 0:00:01.466085
[5/9, 50/94] Training Loss: 5.0442 - Iteration Time: 0:00:01.575225
[5/9, 60/94] Training Loss: 5.0269 - Iteration Time: 0:00:01.553239
[5/9, 70/94] Training Loss: 5.0283 - Iteration Time: 0:00:01.529031
[5/9, 80/94] Training Loss: 4.9488 - Iteration Time: 0:00:01.546911
[5/9, 90/94] Training Loss: 4.9901 - Iteration Time: 0:00:01.538266
Testing - 2024-06-17 11:34:22.184760
[5/9, 2/16]
[5/9, 4/16]
[5/9, 6/16]
[5/9, 8/16]
[5/9, 10/16]
[5/9, 12/16]
[5/9, 14/16]
[5/9, 16/16]
Testing Loss: 4.8314 - Epoch Time: 0:02:39.722850
Training - 2024-06-17 11:34:36.384214
[6/9, 10/94] Training Loss: 5.0166 - Iteration Time: 0:00:01.538455
[6/9, 20/94] Training Loss: 4.9561 - Iteration Time: 0:00:01.469505
[6/9, 30/94] Training Loss: 4.9718 - Iteration Time: 0:00:01.961733
[6/9, 40/94] Training Loss: 4.9899 - Iteration Time: 0:00:01.528600
[6/9, 50/94] Training Loss: 4.9723 - Iteration Time: 0:00:01.534476
[6/9, 60/94] Training Loss: 4.9680 - Iteration Time: 0:00:01.429789
[6/9, 70/94] Training Loss: 5.0085 - Iteration Time: 0:00:01.613846
[6/9, 80/94] Training Loss: 5.0050 - Iteration Time: 0:00:01.539930
[6/9, 90/94] Training Loss: 5.0255 - Iteration Time: 0:00:01.566244
Testing - 2024-06-17 11:37:05.027000
[6/9, 2/16]
[6/9, 4/16]
[6/9, 6/16]
[6/9, 8/16]
[6/9, 10/16]
[6/9, 12/16]
[6/9, 14/16]
[6/9, 16/16]
Testing Loss: 4.7135 - Epoch Time: 0:02:43.085352
Training - 2024-06-17 11:37:19.469566
[7/9, 10/94] Training Loss: 4.9892 - Iteration Time: 0:00:01.522582
[7/9, 20/94] Training Loss: 4.9849 - Iteration Time: 0:00:01.541931
[7/9, 30/94] Training Loss: 5.0205 - Iteration Time: 0:00:01.722515
[7/9, 40/94] Training Loss: 4.9975 - Iteration Time: 0:00:01.624816
[7/9, 50/94] Training Loss: 4.9698 - Iteration Time: 0:00:01.695337
[7/9, 60/94] Training Loss: 4.8955 - Iteration Time: 0:00:01.457603
[7/9, 70/94] Training Loss: 4.9650 - Iteration Time: 0:00:01.544432
[7/9, 80/94] Training Loss: 4.9532 - Iteration Time: 0:00:01.649577
[7/9, 90/94] Training Loss: 4.9697 - Iteration Time: 0:00:01.519136
Testing - 2024-06-17 11:39:44.647445
[7/9, 2/16]
[7/9, 4/16]
[7/9, 6/16]
[7/9, 8/16]
[7/9, 10/16]
[7/9, 12/16]
[7/9, 14/16]
[7/9, 16/16]
Testing Loss: 4.7244 - Epoch Time: 0:02:38.922240
Training - 2024-06-17 11:39:58.392302
[8/9, 10/94] Training Loss: 5.0153 - Iteration Time: 0:00:01.523575
[8/9, 20/94] Training Loss: 4.9321 - Iteration Time: 0:00:01.548140
[8/9, 30/94] Training Loss: 4.9611 - Iteration Time: 0:00:01.487824
[8/9, 40/94] Training Loss: 4.9451 - Iteration Time: 0:00:01.472978
[8/9, 50/94] Training Loss: 4.9342 - Iteration Time: 0:00:01.471498
[8/9, 60/94] Training Loss: 4.9654 - Iteration Time: 0:00:01.424832
[8/9, 70/94] Training Loss: 4.9638 - Iteration Time: 0:00:01.439773
[8/9, 80/94] Training Loss: 5.0003 - Iteration Time: 0:00:01.471469
[8/9, 90/94] Training Loss: 4.9601 - Iteration Time: 0:00:01.478432
Testing - 2024-06-17 11:42:21.765135
[8/9, 2/16]
[8/9, 4/16]
[8/9, 6/16]
[8/9, 8/16]
[8/9, 10/16]
[8/9, 12/16]
[8/9, 14/16]
[8/9, 16/16]
Testing Loss: 4.7468 - Epoch Time: 0:02:37.406875
Training - 2024-06-17 11:42:35.799177
[9/9, 10/94] Training Loss: 4.9348 - Iteration Time: 0:00:01.488452
[9/9, 20/94] Training Loss: 4.9771 - Iteration Time: 0:00:01.524620
[9/9, 30/94] Training Loss: 4.9812 - Iteration Time: 0:00:01.470488
[9/9, 40/94] Training Loss: 4.9202 - Iteration Time: 0:00:01.475466
[9/9, 50/94] Training Loss: 4.9093 - Iteration Time: 0:00:01.414458
[9/9, 60/94] Training Loss: 4.9671 - Iteration Time: 0:00:01.393063
[9/9, 70/94] Training Loss: 4.9406 - Iteration Time: 0:00:01.448647
[9/9, 80/94] Training Loss: 4.9240 - Iteration Time: 0:00:01.421408
[9/9, 90/94] Training Loss: 5.0117 - Iteration Time: 0:00:01.405502
Testing - 2024-06-17 11:44:56.004269
[9/9, 2/16]
[9/9, 4/16]
[9/9, 6/16]
[9/9, 8/16]
[9/9, 10/16]
[9/9, 12/16]
[9/9, 14/16]
[9/9, 16/16]
Testing Loss: 4.7137 - Epoch Time: 0:02:34.554214
Training and Testing Finished - Time: 0:23:53.988911
Assembling test data for t-sne projection
Code Layer Shape: torch.Size([64, 100])
-- 1/16 --
Code Layer Shape: torch.Size([64, 100])
-- 2/16 --
Code Layer Shape: torch.Size([64, 100])
-- 3/16 --
Code Layer Shape: torch.Size([64, 100])
-- 4/16 --
Code Layer Shape: torch.Size([64, 100])
-- 5/16 --
Code Layer Shape: torch.Size([64, 100])
-- 6/16 --
Code Layer Shape: torch.Size([64, 100])
-- 7/16 --
Code Layer Shape: torch.Size([64, 100])
-- 8/16 --
Code Layer Shape: torch.Size([64, 100])
-- 9/16 --
Code Layer Shape: torch.Size([64, 100])
-- 10/16 --
Code Layer Shape: torch.Size([64, 100])
-- 11/16 --
Code Layer Shape: torch.Size([64, 100])
-- 12/16 --
Code Layer Shape: torch.Size([64, 100])
-- 13/16 --
Code Layer Shape: torch.Size([64, 100])
-- 14/16 --
Code Layer Shape: torch.Size([64, 100])
-- 15/16 --
Code Layer Shape: torch.Size([40, 100])
-- 16/16 --
   Labels      0      1    2      3    4  ...     94   95   96     97     98     99
0       2  199.0  199.0  0.0  198.0  0.0  ...  199.0  0.0  0.0  199.0  199.0  198.0
1       4  199.0  198.0  0.0  199.0  0.0  ...  199.0  0.0  0.0  199.0  199.0  199.0
2       7  198.0  199.0  0.0  197.0  0.0  ...  199.0  0.0  0.0  199.0  199.0  199.0
3       3  199.0  199.0  0.0  199.0  0.0  ...  199.0  0.0  0.0  199.0  199.0  199.0
4       7  199.0  199.0  0.0  199.0  0.0  ...  198.0  0.0  0.0  199.0  199.0  199.0
[5 rows x 101 columns]
Plotting Results Grid
Plotting Spiking Input MNIST
Plotting Spiking Input MNIST Animation - 2
Plotting Spiking Output MNIST
Plotting Spiking Output MNIST Animation - 2
Applying t-SNE
Applying UMAP
Applying PCA