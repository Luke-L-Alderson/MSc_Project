"""github_testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IMVe2ipvPRsU3l9Codli-01onzhT_3YU

# Training a Spiking CNN via Backrpopagation

##Â Generate GitHub keys and clone repository
"""## Imports"""

#importing module
import sys
sys.path.append('snn-project')
import os, shutil

import torch
import torch.nn as nn
import torch.nn.functional as F

from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torchvision import utils as utls

import snntorch as snn
import snntorch.spikeplot as splt
from snntorch import utils
from snntorch import surrogate

from IPython.display import HTML
from brian2 import *
import seaborn as sns

from model.train.train_network import train_network
from model.image_to_latent import Net
from model.image_to_image import SAE
from model.aux.functions import get_poisson_inputs, process_labels, mse_count_loss
from data.aux.dataset import H5Dataset
from data_generator.ds_generator import make_dataset, make_exam_tests
from testing.exam import get_exam_per_constant

from model.train.trainMNIST import train
from model.train.trainMNIST import test

dtype = torch.float
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

def to_np(tensor):
  return tensor.detach().cpu().numpy()

def plot_input(inputs, index):
  plt.imshow(to_np(torch.transpose(torch.sum(inputs, 0)[index], 0 ,2)))

def curr_to_pA(curr, network):
  factor = network.network_params["v_th"]/network.network_params["R_m"]/(1 - network.network_params["beta"])
  try:
    return to_np(curr)*factor
  except:
    return curr*factor

def transfer(curr, network):
  T = -network.network_params["tau_m"]*np.log(1 - network.network_params["v_th"]/(curr*network.network_params["R_m"]))
  return np.clip(1/T, 0*Hz, inf*Hz)

def get_fr(raster, network):
  return to_np(torch.sum(raster, 0))/network.time_params["total_time"]

def print_network_architecure(network):
    netp, op, fp, cp = network.network_params, network.oscillation_params, network.frame_params, network.convolution_params
    input_layer_text = """
    Input layer: {} channels
                {}x{} neurons/channel
                {} total neurons
    """.format(fp["depth"], fp["size"], fp["size"],fp["depth"]*fp["size"]*fp["size"] )

    conv1_text = """
    Conv1 layer: {} channels
                {}x{} neurons/channel
                {} total neurons
                {} synapses/neuron (ff)
                {} total_synapses
    """.format(cp["channels_1"], cp["conv1_size"], cp["conv1_size"], netp["num_conv1"], cp["filter_1"]*cp["filter_1"], netp["num_conv1"]*cp["filter_1"]*cp["filter_1"])

    conv2_text = """
    Conv2 layer: {} channels
                {}x{} neurons/channel
                {} total neurons
                {} synapses/neuron (ff)
                {} total_synapses
    """.format(cp["channels_2"], cp["conv2_size"], cp["conv2_size"], netp["num_conv2"], cp["filter_2"]*cp["filter_2"], netp["num_conv2"]*cp["filter_2"]*cp["filter_2"])

    rec_text = """
    Rec layer:   {} total neurons
                {} synapses/neuron (ff) and {} synapses/neuron (rec)
                {} total_synapses
    """.format(netp["num_rec"], netp["num_conv2"], netp["num_rec"], netp["num_conv2"]*netp["num_rec"] + netp["num_rec"]**2)

    latent_text = """
    Lat layer:   {} total neurons
                {} synapses/neuron (ff)
                {} total_synapses
    """.format(netp["num_latent"], netp["num_rec"], netp["num_rec"], netp["num_rec"]*netp["num_latent"])

    Trec_text = ""
    Tconv2_text = ""
    Tconv1_text = ""
    output_layer_text = ""

    print(input_layer_text)
    print(conv1_text)
    print(conv2_text)
    print(rec_text)
    print(latent_text)
    print(Trec_text)
    print(Tconv2_text)
    print(Tconv1_text)
    print(output_layer_text)
    
def clear_all():
    """Clears all the variables from the workspace of the spyder application."""
    gl = globals().copy()
    for var in gl:
        if var[0] == '_': continue
        if 'func' in str(globals()[var]): continue
        if 'module' in str(globals()[var]): continue

        del globals()[var]

"""## Define network architecutre and parameters"""
# get MNIST in, get correct targets, try and vary some biophys params with plots
time_params = {}
time_params["dt"] = 1*ms
time_params["total_time"] = 200*ms

network_params = {}
network_params["tau_m"] = 24*ms
network_params["tau_syn"] = 10*ms
network_params["R_m"] = 146*Mohm
network_params["v_th"] = 15*mV
network_params["eta"] = 0.0 # controls noise amplitude - try adding noise in rec layer
network_params["num_rec"] = 100
network_params["num_latent"] = 8

oscillation_params = {}
oscillation_params["f"] = 10*Hz
oscillation_params["I_osc"] = 0*pA
#oscillation_params["phis"] = [0, 0, 0, 0]

frame_params = {}
frame_params["depth"] = 1
frame_params["size"] = 28

convolution_params = {}
convolution_params["channels_1"] = 12
convolution_params["filter_1"] = 3
convolution_params["channels_2"] = 64
convolution_params["filter_2"] = 3

input_specs = {}
label_specs = {}
train_specs = {}

input_specs["total_time"] = 200*ms
input_specs["bin_size"] = 1*ms
input_specs["rate_on"] = 75*Hz
input_specs["rate_off"] = 10*Hz

label_specs["total_time"] = 200*ms
label_specs["code"] = 'rate'
label_specs["rate"] = 75*Hz

train_specs["num_epochs"] = 1
train_specs["early_stop"] = 1000
train_specs["device"] = device
train_specs["lr"] = 1e-3
train_specs["loss_fn"] = "spike_count"
train_specs["lambda_rate"] = 0.0
train_specs["lambda_weights"] = None

exam_specs = {}
exam_specs["constant_list"] = ["none"]
exam_specs["batch_size"] = 16
exam_specs["recorded_vars"] = ["curr_conv1", "spk_conv1", "curr_conv2", "spk_conv2", "curr_total", "spk_rec", "curr_latent", "spk_latent"]
exam_specs["path"] = 'data/content/exam_world_data_1_1'

#%%
"""## Make or access existing datasets"""
folder = 'data/content'
for filename in os.listdir(folder):
    file_path = os.path.join(folder, filename)
    try:
        if os.path.isfile(file_path) or os.path.islink(file_path):
            os.unlink(file_path)
        elif os.path.isdir(file_path):
            shutil.rmtree(file_path)
    except Exception as e:
        print('Failed to delete %s. Reason: %s' % (file_path, e))

# create training/ and testing/ folders in your chosen path
if not os.path.isdir('figures/training'):
    os.makedirs('figures/training')

if not os.path.isdir('figures/testing'):
    os.makedirs('figures/testing')

data_path='/tmp/data/mnist'

transform = transforms.Compose([
            transforms.Grayscale(),
            transforms.ToTensor(),
            transforms.Normalize((0,), (1,))])

batch_size = 8

# create dataset in /content
print("1/5: Making Datasets...")

# Load MNIST
train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transform, download=True)
test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transform, download=True)

print("2/5: Making Dataloaders...")

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

# Plot examples from MNIST
unique_images = []
seen_labels = set()

for image, label in train_dataset:
    if label not in seen_labels:
        unique_images.append((image, label))
        seen_labels.add(label)

unique_images.sort(key=lambda x: x[1])

fig, axes = plt.subplots(2, 5, figsize=(15, 6))

axes = axes.flatten()

# Loop over each subplot
for i, ax in enumerate(axes):
    ax.set_title(f'Number: {unique_images[i][1]}')
    ax.imshow(unique_images[i][0].reshape(28,28), cmap = 'gray')  # Blank image, you can replace this with your content
    ax.axis('off')

plt.tight_layout()
plt.show()


'''
make_dataset(train_samples=3000, test_samples=300,  width=28, M_min=1, M_max=1, restrictions={}, path=folder)
make_exam_tests(test_samples=1000, width=28, M_min=1, M_max=1, path=folder)

#load dataset
print("2/5: Dividing train/test...")
train_dataset = H5Dataset('data/world_data_1_1/train.hdf5')
test_dataset = H5Dataset('data/world_data_1_1/test.hdf5')

# Create DataLoader
print("3/5: Creating Loaders...")

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
'''



#%%
print("4/5: Defining network...")
network = SAE(time_params, network_params, oscillation_params, frame_params, convolution_params, device).to(device)
#print_network_architecure(network)


#%%
"""## Training the network"""
num_epochs = train_specs["num_epochs"]

# unset retrieval to load pre-trained network
retrieval = 1;


if retrieval:
    for epoch in range(num_epochs):
      network, epoch_training_loss, epoch_testing_loss = train_network(network, train_loader, test_loader, input_specs, label_specs, train_specs, reporting = False)
      #exams_dict, av_recorded_dict = get_exam_per_constant(network, input_specs, label_specs, exam_specs, device)
      #print(f'Epoch: {epoch} - {exams_dict["none"]}')
    torch.save(network.state_dict(), 'data/content/pt_model_10_500.pth')
else:
    network.load_state_dict(torch.load('pt_model_10_500.pth'), strict=False)

#%% Plotting

input_specs["rate_on"] = 500*Hz
input_specs["rate_off"] = 10*Hz

# Plot originally input as image and as spiking representation - save gif.
inputs, labels = next(iter(train_loader))
poisson_inputs = get_poisson_inputs(inputs, **input_specs).to(device)

img_spk_recs, img_spk_outs = network(poisson_inputs)

# img
input_index = 0
poisson_inputs = poisson_inputs[:, input_index, 0]
img_spk_outs = img_spk_outs[:, input_index, 0].detach()

plt.imshow(to_np(inputs[input_index, 0]), cmap = 'grey')
plt.show()

plt.imshow(poisson_inputs.cpu().mean(axis=0), cmap='grey')



# anim
fig, ax = plt.subplots()
anim = splt.animator(poisson_inputs, fig, ax)
HTML(anim.to_html5_video())
anim.save("spike_mnist.gif")
plt.show()

# new data
plt.imshow(img_spk_outs.cpu().mean(axis=0), cmap='grey')

fig1, ax1 = plt.subplots()
animrec = splt.animator(img_spk_outs, fig1, ax1)
HTML(animrec.to_html5_video())
animrec.save("spike_mnistrec.gif")
plt.show()

fig = plt.figure(facecolor="w", figsize=(10, 5))
ax = fig.add_subplot(111)
splt.raster(poisson_inputs.reshape(200, -1), ax, s=1.5, c="black")

fig = plt.figure(facecolor="w", figsize=(10, 5))
ax = fig.add_subplot(111)
splt.raster(img_spk_outs.reshape(200, -1), ax, s=1.5, c="black")
ax.set_xlim([0, 200])

'''
input_specs["rate_on"] = 0*Hz
input_specs["rate_off"] = 0*Hz
recorded_vars = ["mem_conv1", "mem_conv2", "mem_rec", "mem_latent"]

traj_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, drop_last=True)
inputs, labels = next(iter(traj_loader))
traj_inputs = get_poisson_inputs(inputs, **input_specs).to(device)

num_trials = 100
trajectories = {var : [] for var in recorded_vars}
index = {var : [] for var in recorded_vars}

for trial in range(num_trials):
  print(f'Getting Recordings: {trial+1} / {num_trials}')
  recordings = network(traj_inputs, recorded_vars=recorded_vars)
  for var in recorded_vars:
    trajectories[var].append(to_np(recordings[var].view(int(network.time_params["total_time"]/ms), -1)[:, index[var]])*15)

index["mem_conv1"] = 26*26*2 + 1
plt.plot(to_np(recordings["mem_conv1"].view(int(network.time_params["total_time"]/ms), -1)[:, index["mem_conv1"]]))

index["mem_conv2"] = 24*24*8 + 1
plt.plot(to_np(recordings["mem_conv2"].view(int(network.time_params["total_time"]/ms), -1)[:, index["mem_conv2"]]))

index["mem_rec"] = 7
plt.plot(to_np(recordings["mem_rec"].view(int(network.time_params["total_time"]/ms), -1)[:, index["mem_rec"]]))

index["mem_latent"] = 5
plt.plot(to_np(recordings["mem_latent"].view(int(network.time_params["total_time"]/ms), -1)[:, index["mem_latent"]]))

t_values = np.arange(0, network.time_params["total_time"], step=network.time_params["dt"])
var_th = (1 - np.exp(-t_values/network.network_params["tau_m"]))*network.network_params["eta"]*network_params["v_th"]/mV
fig, axs = plt.subplots(1, len(recorded_vars), sharey=True)
fig.suptitle(r"$u$ trajectories (addition of noise)", y= 1.05, fontsize=20)
fig.set_size_inches(16, 5)
'''
